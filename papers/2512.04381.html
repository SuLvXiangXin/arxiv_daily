<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.04381" target="_blank" rel="noreferrer">2512.04381</a></span>
        <span>作者: He, Chengyang, Sun, Ge, Bai, Yue, Lu, Junkai, Zhao, Jiadong, Sartoretti, Guillaume</span>
        <span>日期: 2025/12/04</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>目前，机器人全身操作的主流方法是采用端到端的全身策略，即一个单一策略直接映射所有关节或任务空间观测到所有机器人执行器。这类方法虽然能产生紧密协调的运动，但也存在关键局限性：训练困难、对数据集覆盖范围敏感，以及当一个子系统遇到分布外情况（如意外地形）时，其共享的潜在表征容易损坏，导致整体失败。在腿式移动操作中，基座（负责动态稳定性和导航）与机械臂（负责精确操作）之间存在显著的不对称性，将它们视为单一同质控制问题会迫使策略融合异构的观测和控制目标，从而放大优化和泛化难度。</p>
<p>本文针对上述痛点，提出了“主动解耦”的新视角。具体而言，将移动操作解耦为两个独立的扩散策略：一个用于移动的基座速度策略和一个用于操作的机械臂末端执行器位置策略。核心挑战转变为如何协调两个强大但独立的专家。本文的核心思路是：通过一个冻结的视觉-语言基础模型（CLIP）作为语义协调器，将全局观测和语言指令编码为共享的潜在嵌入，以此条件化两个解耦的扩散策略，从而在保持模块化优势的同时恢复子系统间的协调。</p>
<h2 id="方法详解">方法详解</h2>
<p>FALCON的整体框架围绕三个设计原则构建：1) 移动操作的解耦控制；2) 基础模型引导的协调；3) 带有对比对齐的相位感知语义协调。</p>
<p><img src="https://arxiv.org/html/2512.04381v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：FALCON的整体框架。蓝色和绿色区域分别表示解耦的机械臂和四足机器人扩散策略，它们在自己的观测和控制空间中行动（机械臂：腕部/本体相机和末端执行器位姿；四足机器人：头部/本体相机、基座速度、身体高度/俯仰角）。一个冻结的CLIP模型与可训练的投影器将多视角RGB观测、本体感知状态和语言指令编码成一个共享的潜在嵌入 $z_t$，该嵌入同时条件化两个策略。此外，一个相位进度头利用任务阶段的手工文本描述来推断离散相位分数和连续进度估计。协调感知对比损失被应用于显式地塑造潜在空间，以编码臂-基动作的跨子系统兼容性。</p>
</blockquote>
<p><strong>整体框架与输入输出</strong>：系统包含两个独立的扩散策略网络：一个用于四足机器人移动，一个用于机械臂操作。移动策略的输入包括：头部和本体相机的RGB图像、基座线速度和角速度、身体高度和俯仰角。其输出是未来一段时间内的基座线速度、角速度、身体高度和俯仰角命令序列。操作策略的输入包括：腕部和本体相机的RGB图像、末端执行器当前位置。其输出是未来一段时间内的末端执行器目标位置序列。两个策略都通过一个共享的潜在嵌入 $z_t$ 进行条件化。</p>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>基础模型协调器</strong>：使用一个冻结的预训练CLIP模型（ViT-L/14）作为共享的特征提取器。将多视角RGB图像、串联的本体感知状态（关节位置、速度等）以及任务级语言指令，分别通过可训练的线性投影层映射到CLIP的嵌入空间，然后进行平均池化，生成统一的协调潜在嵌入 $z_t$。该嵌入被注入到两个扩散策略的条件输入中，作为共同的“任务和场景摘要”。</li>
<li><strong>扩散策略</strong>：两个策略均采用经典的扩散策略架构。它们学习去噪一个从标准高斯分布采样的噪声，以生成动作序列。去噪过程由一个以观测历史、当前观测以及协调潜在嵌入 $z_t$ 为条件的U-Net完成。</li>
<li><strong>相位进度头</strong>：为了提供时间上的协调，引入了相位进度头。它利用CLIP文本编码器，将手工编写的、描述任务不同阶段（如“导航到目标”、“调整身体姿势”、“执行精细操作”）的文本提示编码成文本嵌入。然后，通过计算协调潜在嵌入 $z_t$ 与这些阶段文本嵌入之间的余弦相似度，得到离散的相位分数。同时，将 $z_t$ 与一个可训练的“进度”文本嵌入（如“任务进度”）的相似度作为连续的进度估计。整个过程无需人工相位标签。</li>
<li><strong>协调感知对比损失</strong>：为了进一步结构化潜在空间，引入了对比损失。其核心思想是，协调潜在嵌入应能区分正确配对的臂-基动作与不匹配的组合。具体来说，对于一个给定的数据样本（包含臂动作 $a_a$ 和基动作 $a_b$），将 $z_t$ 与正样本对（$a_a$, $a_b$）的联合表征拉近，同时与负样本对（如 $a_a$ 与另一个时间步的 $a_b’$ 组合）的表征推远。</li>
</ol>
<p><strong>创新点</strong>：与现有方法相比，FALCON的主要创新在于：1) 明确将移动和操作解耦为独立策略，避免了异构观测融合问题；2) 创新性地将基础模型（CLIP）用作冻结的语义协调器，而非端到端控制器，提供了轻量且语义丰富的协调通道；3) 引入了无需标注的相位进度估计和显式的协调感知对比损失，增强了策略在时间上和动作层面的协调能力。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在NVIDIA Isaac Gym模拟器中，使用一个搭载6自由度机械臂的Unitree Go1四足机器人模型进行评估。实验平台涉及两个具有挑战性的移动操作任务：<strong>开门</strong>（导航到门前，操作把手打开门）和<strong>放置物体</strong>（导航到架子前，将物体放入指定隔间）。使用了三个基准方法进行对比：1) <strong>Centralized Diffusion</strong>：一个标准的端到端全身扩散策略。2) **Decoupled (No Coordination)**：两个独立的扩散策略，无任何协调机制（即无共享潜在嵌入）。3) <strong>LatentToM</strong>：一种先进的学习型协调方法，通过层理论一致性损失从头学习共识表示。</p>
<p><strong>关键实验结果</strong>：</p>
<p><img src="https://arxiv.org/html/2512.04381v1/x5.png" alt="定量结果"></p>
<blockquote>
<p><strong>图5</strong>：在开门和放置物体任务上的成功率对比。FALCON在两个任务上均取得了最高成功率（开门：92.5%，放置：90.0%），显著优于集中式、无协调解耦以及LatentToM基线。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.04381v1/x6.png" alt="协调误差分析"></p>
<blockquote>
<p><strong>图6</strong>：协调误差分析，衡量基座和机械臂动作的不兼容性。FALCON的协调误差最低，表明其共享潜在嵌入有效地促进了跨子系统的动作兼容性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.04381v1/x7.png" alt="分布外泛化"></p>
<blockquote>
<p><strong>图7</strong>：在分布外（OOD）场景下的性能，如未知的物体位置、障碍物和地形变化。FALCON表现出最强的鲁棒性和泛化能力，成功率下降最小。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.04381v1/x8.png" alt="消融实验"></p>
<blockquote>
<p><strong>图8</strong>：消融研究结果。移除了协调感知对比损失（w/o CCL）或相位进度头（w/o Phase）都会导致性能下降，验证了这两个组件的必要性。其中，对比损失对提升协调性（降低协调误差）贡献尤为关键。</p>
</blockquote>
<p><strong>消融实验总结</strong>：消融实验表明，协调感知对比损失（CCL）和相位进度头都是FALCON成功的关键组件。移除CCL会导致协调误差显著上升和成功率下降；移除相位进度头则会降低任务完成效率。两者结合使用效果最佳。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了FALCON框架，将主动解耦的视觉运动策略与基础模型引导的协调相结合，为移动操作提供了一种新颖且高效的解决方案。</li>
<li>设计了无需标注的相位进度头和协调感知对比损失，增强了策略的时间连贯性与跨子系统动作兼容性。</li>
<li>在模拟实验中验证了该框架优于集中式和解耦基线，并在分布外场景中表现出更强的鲁棒性和泛化能力。</li>
</ol>
<p><strong>局限性</strong>：论文提到，当前方法依赖于预训练的CLIP模型，其语义先验可能无法完美覆盖所有机器人任务场景。此外，相位描述文本需要手工设计，未来可探索更自动化的生成方式。</p>
<p><strong>启示</strong>：FALCON的工作表明，在机器人学习与基础模型融合的背景下，将解耦的、基于RGB的视觉运动专家与基础模型引导的协调相结合，是替代完全集中式全身策略的一条有前景的路径。这为构建模块化、鲁棒且可推广的通用机器人系统提供了新的设计思路。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文解决移动操作中，单一策略因需融合移动与操作的不匹配异构观察而导致性能下降的问题。提出FALCON框架，其核心是**主动解耦的视觉运动策略**：将移动与操作解耦为两个专用策略，并通过**视觉-语言基础模型**作为协调器，将全局观察与语言指令编码为共享潜在嵌入以恢复协调。引入**阶段进展预测头**和**协调感知对比损失**进一步结构化学习。实验表明，该方法在需要紧密协调的移动操作任务上，**超越了集中式与分散式基线**，并展现出**更强的鲁棒性与对分布外场景的泛化能力**。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.04381" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>