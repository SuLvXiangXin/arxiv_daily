<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>ArtGS:3D Gaussian Splatting for Interactive Visual-Physical Modeling and Manipulation of Articulated Objects - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>ArtGS:3D Gaussian Splatting for Interactive Visual-Physical Modeling and Manipulation of Articulated Objects</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.02600" target="_blank" rel="noreferrer">2507.02600</a></span>
        <span>作者: Yu, Qiaojun, Yuan, Xibin, jiang, Yu, Chen, Junting, Zheng, Dongzhe, Hao, Ce, You, Yang, Chen, Yixing, Mu, Yao, Liu, Liu, Lu, Cewu</span>
        <span>日期: 2025/07/03</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>铰接物体操作是机器人领域的关键挑战，现有方法在复杂运动学约束和物理推理方面存在局限。主流方法可分为两类：一是基于端到端强化学习或模仿学习的方法，它们需要大量的试错或演示数据，且缺乏对关节运动学的原理性物理知识，容易产生违反约束的运动并导致操作失败；二是基于3D视觉的显式建模方法（如GAMMA、RPMArt），它们通过部件分割和关节参数估计来构建铰接模型，但依赖的点云数据具有稀疏、无序和时间一致性差的固有缺点。</p>
<p>本文针对现有方法在视觉重建与物理建模结合上的不足，特别是如何获得高精度、物理一致的铰接参数以支持可靠操作这一具体痛点，提出了一个新视角：将高保真、可微分的3D高斯泼溅（3DGS）重建与视觉语言模型（VLM）的语义推理相结合，并通过机器人交互实现闭环优化。本文的核心思路是：首先利用3DGS从多视角RGB-D图像重建静态场景，然后利用微调的VLM推理铰接骨骼的初始参数，最后通过机器人交互驱动动态3DGS，以可微分渲染为桥梁，对骨骼参数进行物理一致的闭环优化。</p>
<h2 id="方法详解">方法详解</h2>
<p>ArtGS的整体框架包含三个核心模块：静态高斯重建、基于VLM的骨骼初始化、动态3D高斯铰接建模。输入是多视角RGB-D图像和物体掩码，输出是铰接物体的精确运动学模型（关节参数）。</p>
<p><img src="https://arxiv.org/html/2507.02600v1/x2.png" alt="方法流程"></p>
<blockquote>
<p><strong>图2</strong>：ArtGS的流程总览。从多视角RGB-D输入和物体掩码开始，ArtGS首先进行静态3DGS重建并合成机器人姿态；然后使用基于VLM的骨骼初始化模块，通过视觉-语言推理推断铰接骨骼参数；最后，骨骼细化模块通过动态交互优化旋转和棱柱关节的参数，产生精确的铰接物体运动学模型。</p>
</blockquote>
<p><strong>1. 静态3D高斯重建</strong>：该模块使用标准3DGS方法，分别重建处于静态的铰接物体和处于特定姿态的机械臂。场景被表示为一组3D高斯球，每个高斯球由均值、旋转、缩放、不透明度和颜色（球谐系数）等属性参数化。对于机械臂，由于可以访问其URDF文件，该方法将每个连杆视为独立静态场景进行重建和优化，以保留细节（如夹爪），避免整体优化导致的远处细节丢失问题。利用修正的Denavit-Hartenberg（MDH）参数和正向运动学，可以根据任意机械臂姿态 <code>p</code>，计算出每个关节相对于基座的变换矩阵 <code>T_j(p)</code>，从而实现对机械臂高斯点的前向运动学驱动控制。</p>
<p><strong>2. 基于VLM的骨骼推理</strong>：此模块利用一个在领域特定数据集上微调的视觉语言模型（基于InternVL-2.5-4B）来初始化关节参数估计。首先，利用3DGS的新视角合成能力，从重建的高斯点生成物体的正面视图，以便观察所有可动部件，提高视觉问答（VQA）的稳定性。对于铰接物体，VLM需要完成三项任务（任务模板见表I）：物体分类（识别物体类别和可动部件数量）、骨骼推理（预测每个可动部件的关节类型、参数及其在图像中的边界框坐标）、交互部件 grounding（检测可动部件内部操作手柄的边界框）。对于每个预测的可动部件，利用其边界框作为视觉提示，VLM输出关节类型和定义关节轴的两个顶点像素坐标。结合深度图，将这两个点映射到世界坐标 <code>(p1, p2)</code>。若关节类型为旋转关节，则沿 <code>p1</code> 和 <code>p2</code> 连线采样点进行主成分分析（PCA），保留最显著的特征值以确定关节轴方向，采样点的平均位置作为轴基点。若为棱柱关节，则沿预测边界框的水平与垂直线各采样一个方向，取其叉积作为平移轴方向。最终输出所有关节的初始参数估计 <code>J_init</code>。</p>
<p><strong>3. 动态3D高斯铰接建模</strong>：这是方法的优化核心。与优化单个高斯球的6D运动不同，ArtGS将高斯球绑定到估计的骨骼上，使其受关节参数约束进行协调的1D运动变换。具体而言，为每个高斯球引入了可学习的蒙皮权重 <code>W ∈ R^(K+1)</code>，量化其与各铰接部件的关联度。在交互优化阶段，采用阻抗控制使机械臂跟踪基于物体关节配置 <code>J</code> 计算出的期望轨迹 <code>x_d</code>。通过机器人-环境交互产生外部力 <code>F_ext</code>，形成闭环。关键创新在于利用3DGS的可微分渲染，将物理交互的动态序列与视觉观测相结合，构建优化目标。通过比较机器人交互过程中采集的真实RGB-D图像与由当前铰接参数 <code>J</code> 驱动的高斯场景所渲染的图像，计算损失（如光度损失、深度损失），并通过梯度下降反向传播优化关节参数 <code>ψ_i = (u_i, q_i, c_i)</code>（包括轴方向 <code>u_i</code>、原点 <code>q_i</code> 和关节类型 <code>c_i</code>）。这种动态、可微分的优化过程能够有效缓解遮挡影响，并逐步细化初始估计，确保模型同时满足视觉保真度和物理约束。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在模拟环境（SAPIEN仿真器）和真实世界环境中进行。使用了PartNet-Mobility和SAPIEN数据集作为Benchmark，涵盖了柜子、冰箱、微波炉等多种铰接物体类别。</p>
<p>对比的基线方法包括：显式建模方法RPMArt和GAMMA；开环操作预测方法UMPNet和VAT-Mart；以及作为消融对比的ArtGS变体（如不使用VLM初始化、不使用动态优化）。</p>
<p>关键实验结果如下：</p>
<ul>
<li><strong>关节参数估计精度</strong>：ArtGS在关节参数估计上显著优于基线。例如，在旋转轴方向误差（以角度度量的轴方向偏差）和轴位置误差（以厘米度量的轴原点位置偏差）上，ArtGS的平均误差最低。</li>
<li><strong>操作成功率</strong>：在PartNet-Mobility数据集上的物体操作任务中，ArtGS取得了最高的平均成功率。具体数值为84.7%，相较于GAMMA（65.8%）、RPMArt（61.2%）、UMPNet（58.3%）和VAT-Mart（53.1%）有显著提升（约20个百分点）。</li>
</ul>
<p><img src="https://arxiv.org/html/2507.02600v1/x3.png" alt="关节估计与操作结果"></p>
<blockquote>
<p><strong>图3</strong>：在SAPIEN模拟环境中，ArtGS与基线方法在关节参数估计误差（左）和操作成功率（右）上的定量对比。ArtGS在两项指标上均取得最佳性能。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.02600v1/x4.png" alt="真实世界实验"></p>
<blockquote>
<p><strong>图4</strong>：真实世界操作实验的定性结果。展示了ArtGS成功操作微波炉、柜门、抽屉等不同铰接物体的序列。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.02600v1/x5.png" alt="消融实验"></p>
<blockquote>
<p><strong>图5</strong>：消融实验结果表明，完整的ArtGS框架（使用VLM初始化并进行动态优化）性能最优。移除VLM初始化或动态优化任一组件，都会导致关节估计误差上升和操作成功率下降。</p>
</blockquote>
<p><strong>消融实验总结</strong>：消融实验验证了各个组件的贡献。使用VLM进行骨骼初始化提供了良好的优化起点，避免了陷入局部最优；而动态交互优化模块则至关重要，它通过物理交互和可微分渲染持续细化参数，是获得高精度物理模型和高操作成功率的关键。两者结合才能实现最佳性能。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：</p>
<ol>
<li>提出了ArtGS框架，首次将静态3DGS重建、VLM语义推理与机器人交互式闭环优化相结合，为铰接物体的视觉-物理建模与操作建立了新范式。</li>
<li>通过MDH前向运动学将机器人转化为高保真3DGS数字孪生，实现了跨不同机器人构型的适应性表示，并利用动态3DGS的时空一致性和可微分渲染有效优化了铰接骨骼参数。</li>
<li>在模拟和真实环境中进行了广泛实验，证明该框架能显著提升多种铰接物体的建模精度和操作成功率。</li>
</ol>
<p>论文提到的局限性包括：对于具有复杂内部遮挡或高度非刚性变形的物体，方法可能面临挑战。</p>
<p>对后续研究的启示：ArtGS展示了显式、可微分的3D表示（如3DGS）与大规模语义模型（VLM）及物理交互闭环结合的巨大潜力。这一思路可扩展到更复杂的多物体场景、柔性体操作，或用于提升机器人仿真与技能迁移的逼真度和物理真实性。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出ArtGS框架，旨在解决机器人操作中铰接物体因复杂运动学约束和现有方法物理推理不足导致的操控难题。该工作扩展3D高斯泼溅（3DGS），通过多视角RGB-D重建、视觉语言模型（VLM）推理提取语义与骨骼结构，并利用动态可微的3DGS渲染优化铰接骨骼参数，确保物理一致的运动约束。实验表明，ArtGS在关节估计精度与操作成功率上显著优于先前方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.02600" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>