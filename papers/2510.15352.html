<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>GaussGym: An open-source real-to-sim framework for learning locomotion from pixels - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>GaussGym: An open-source real-to-sim framework for learning locomotion from pixels</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.15352" target="_blank" rel="noreferrer">2510.15352</a></span>
        <span>作者: Pieter Abbeel Team</span>
        <span>日期: 2025-10-17</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，足式机器人运动技能学习的主流范式是“模拟到现实”的强化学习，即在模拟器中训练控制策略，然后零样本迁移到真实机器人。以Isaac Gym为代表的向量化GPU物理模拟器极大地提升了物理模拟的吞吐量，推动了基于几何（如深度、高程图）和本体感知输入的运动策略发展。然而，这些模拟器在视觉处理上存在关键局限：要么渲染速度过慢，无法满足大规模强化学习训练的需求；要么视觉保真度不足，难以反映真实世界的丰富视觉细节。这导致现有的大多数感知运动框架依赖于激光雷达或深度输入，限制了策略利用环境中语义线索（如斑马线、水坑、颜色特征）的能力，也缩小了可在模拟中现实追求的任务范围。</p>
<p>本文针对“高吞吐量物理模拟”与“高保真度视觉渲染”难以兼得的痛点，提出了将3D高斯溅射作为即插即用渲染器集成到向量化物理模拟器（如IsaacGym）中的新视角。核心思路是构建一个名为GaussGym的开源框架，它能够从多样化的真实世界数据（如手机扫描、视频模型生成）中数字化重建场景，并同步进行高速物理模拟与逼真视觉渲染，从而支持直接从RGB像素端到端地学习运动与导航策略。</p>
<h2 id="方法详解">方法详解</h2>
<p>GaussGym的整体流程分为数据收集处理、场景重建与模拟渲染三个阶段。输入可以是带姿态的数据集（如ARKitScenes）、智能手机扫描的RGB序列，甚至是视频生成模型（如Veo）输出的无姿态视频。输出则是能够在模拟器中实时渲染的、与物理碰撞网格对齐的高保真RGB（及深度）图像，用于训练视觉运动策略。</p>
<p><img src="https://arxiv.org/html/2510.15352v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：GaussGym整体流程。框架从多种数据源摄取数据，使用VGGT处理以获得相机外参、内参、带法线的点云。前两者用于训练3D高斯溅射以进行渲染，后两者用于估计场景碰撞网格。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>数据标准化与处理</strong>：所有输入数据首先通过视觉接地几何变换器统一处理。VGGT负责估计相机内参、外参，并生成密集点云与表面法线。这些中间表示至关重要：点云直接用于初始化3D高斯溅射，以提高几何精度和收敛速度；点云和法线则送入神经核表面重建模块以生成用于物理碰撞的高质量网格。</li>
<li><strong>3D高斯溅射作为即插即用渲染器</strong>：重建后的3D高斯表示被用作渲染引擎。与传统的射线追踪或光栅化管线不同，高斯溅射能够在现代GPU上实现高效的差异化光栅化。GaussGym将其批量渲染能力与向量化模拟环境相结合，实现了跨数千个环境的并行渲染。</li>
<li><strong>优化策略</strong>：<ul>
<li><strong>解耦渲染频率</strong>：为最大化效率，渲染帧率（如10Hz）与机器人控制频率（如50Hz）及物理模拟步长解耦。策略在控制步长间重复使用最新的渲染图像，从而在不牺牲视觉输入有效性的前提下获得显著加速。</li>
<li><strong>模拟运动模糊</strong>：为了减小模拟到现实的差距，GaussGym模拟了真实的运动模糊。方法是在相机速度方向偏移的位置渲染一小批帧，然后通过alpha混合将它们合并成单张图像，这在机器人高速运动或突然震动时能产生更真实的视觉效果。</li>
<li><strong>向量化与扩展性</strong>：通过PyTorch多线程内核进行批处理渲染，确保高效的GPU利用率。在单张RTX 4090 GPU上，GaussGym能以每秒超过10万步的仿真速度，在4096个并行环境中渲染640×480分辨率的图像，且支持近乎线性的多GPU扩展。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2510.15352v1/x5.png" alt="渲染示例"></p>
<blockquote>
<p><strong>图5</strong>：GaussGym渲染的RGB和深度图像。深度是高斯溅射光栅化过程的副产品，因此渲染深度不会增加额外时间。</p>
</blockquote>
<p><strong>创新点</strong>：GaussGym的主要创新在于首次将3D高斯溅射无缝集成到大规模向量化物理模拟器中，实现了前所未有的“高保真视觉”与“高吞吐量模拟”的结合。相较于类似工作LucidSim，GaussGym的流程自动化程度更高（无需手动对齐网格与高斯），支持的数据源更广（包括视频模型输出），并真正实现了跨大量环境的向量化渲染。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：GaussGym构建了包含超过2500个场景的资产库，数据源包括智能手机扫描、开源数据集以及视频生成模型Veo。实验平台主要为搭载RTX 4090等消费级GPU的机器。训练任务聚焦于<strong>视觉楼梯攀爬</strong>和<strong>视觉导航</strong>。</p>
<p><strong>基线方法</strong>：主要对比了使用<strong>RGB像素输入</strong>的策略与使用<strong>仅深度输入</strong>的策略。此外，在消融实验中对比了不同网络设计组件的影响。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>视觉楼梯攀爬与零样本迁移</strong>：在模拟中，使用Unitree A1机器人、仅以RGB为输入训练的策略，学会了精确地将脚放置在楼梯踏板上并调整步态以避免碰撞。作为概念验证，该策略在未经任何微调的情况下，成功零样本迁移到真实的楼梯攀爬任务中。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.15352v1/x6.png" alt="模拟到现实"></p>
<blockquote>
<p><strong>图6</strong>：(a) 在GaussGym中预训练的RGB策略。(b) 零样本部署到现实世界。</p>
</blockquote>
<ol start="2">
<li><strong>语义导航能力</strong>：在一个稀疏目标跟踪的导航任务中，环境中设置了障碍物和一个作为惩罚区域的黄色地面斑块。实验表明，<strong>RGB策略能够感知并成功避开黄色斑块</strong>，而<strong>仅深度策略则无法检测该语义信息，径直穿过惩罚区</strong>。这直观证明了RGB输入所提供的语义线索远超纯几何深度信息。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.15352v1/x8.png" alt="语义推理"></p>
<blockquote>
<p><strong>图8</strong>：在稀疏目标跟踪任务中，RGB训练的策略（绿色轨迹）避开惩罚斑块，而深度仅策略（紫色轨迹）无法检测并穿过它。</p>
</blockquote>
<ol start="3">
<li><strong>消融实验</strong>：论文在四种地形（平坦、陡坡、矮楼梯、高楼梯）上进行了大规模消融。关键结论包括：<ul>
<li><strong>体素预测头的重要性</strong>：移除用于预测场景占用和地形的体素回归头会显著降低性能。</li>
<li><strong>预训练视觉编码器的重要性</strong>：不使用预训练的DINOv2编码器也会导致性能下降。</li>
<li><strong>场景多样性的重要性</strong>：使用全部场景训练相比仅使用10%或50%的场景，带来了显著的性能提升，突出了GaussGym支持大规模多样化场景训练的价值。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2510.15352v1/x7.png" alt="网络架构"></p>
<blockquote>
<p><strong>图7</strong>：视觉运动策略的神经网络架构。一个LSTM编码器融合本体感知与DinoV2 RGB特征。输出一方面馈入3D转置卷积头进行占据和地形预测，另一方面馈入策略LSTM输出动作。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>GaussGym</strong>，一个开源的高速高保真模拟框架，支持从手动扫描、开源数据集到生成式视频模型在内的多种数据源，可快速创建数千个逼真训练场景。</li>
<li>在缩小视觉模拟到现实差距方面提供了实证发现，证明<strong>引入基于真实网格数据的几何重建作为辅助任务</strong>，能显著提升楼梯攀爬等任务的学习速度和性能。</li>
<li>展示了<strong>RGB导航策略的语义推理能力</strong>。在目标到达任务中，基于像素训练的策略能够成功避开仅深度策略无法察觉的不良区域，凸显了利用丰富视觉语义进行决策的优势。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ol>
<li><strong>视觉策略泛化与迁移挑战</strong>：视觉模拟到现实的迁移仍是未完全解决的难题。策略在未见过的楼梯上表现可能下降，且真实迁移时精确的足部放置能力较模拟有所衰减。</li>
<li><strong>物理参数简化</strong>：场景资产使用统一的物理参数（如摩擦系数），无法准确模拟冰、泥、沙等不同材质表面，割裂了视觉外观与物理触感之间的联系。</li>
<li><strong>依赖上游模型</strong>：继承了所用视觉模型（如Veo）的局限性，例如输出可能不一致、仅通过文本控制相机有限。</li>
<li><strong>场景动态性与复杂性</strong>：目前无法处理动态场景，也无法模拟流体和可变形物体。</li>
</ol>
<p><strong>对后续研究的启示</strong>：<br>GaussGym如同当年的GPU物理模拟器 democratized 几何运动学习一样，为视觉运动与导航研究提供了一个强大的开源平台。它使得利用海量、逼真、多样化的视觉场景进行端到端策略训练成为可能，将推动社区在视觉感知、跨域泛化、语义理解与物理属性关联等方向进行更深入的探索。未来工作可聚焦于集成更可控的世界模型、开发自动化的基于语义或语言的奖励函数生成机制，以及探索视觉与物理属性联合建模的方法。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出GaussGym，一个开源的真实到仿真框架，旨在解决现有仿真器视觉保真度低或速度慢的问题，从而阻碍从RGB像素直接学习机器人运动策略。其核心技术是将**3D高斯泼溅渲染技术**作为插件，集成到向量化物理引擎中，实现了**超过10万步/秒的高通量仿真**。实验表明，该框架能利用丰富的视觉语义（如避开特定区域）来提升导航与决策，并能快速从手机扫描、场景数据集等多样化数据源构建逼真训练环境。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.15352" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>