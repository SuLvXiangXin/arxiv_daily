<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2503.20384" target="_blank" rel="noreferrer">2503.20384</a></span>
        <span>作者: Zhang, Rongyu, Dong, Menghang, Zhang, Yuan, Heng, Liang, Chi, Xiaowei, Dai, Gaole, Du, Li, Du, Yuan, Zhang, Shanghang</span>
        <span>日期: 2025/03/26</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，多模态大语言模型（MLLMs）驱动的视觉-语言-动作（VLA）模型（如RT-2、OpenVLA）在机器人操作任务中展现出强大的感知与推理能力。然而，其巨大的计算和存储需求阻碍了在资源受限、需要高控制频率的真实机器人平台上的部署。近期研究发现，LLM层间存在高度同质性（如连续层输出余弦相似度超过90%），表明存在计算冗余。现有高效化方法如早期退出（Early Exit）虽能减少计算，但往往忽略了编码关键语义信息的深层网络，丢弃它们可能导致性能显著下降。</p>
<p>本文受神经科学中“浅层大脑假说”（Shallow Brain Hypothesis）的启发，该假说认为大脑通过浅层、平行的皮质-皮质下环路来平衡深度层次结构，以进行认知和因果推理。针对VLA模型计算冗余与关键语义信息保留的矛盾，本文提出了一个新视角：将每个LLM层视为一个专家，并设计一个动态层激活机制，模仿大脑选择性地激活与当前任务最相关的信号通路。本文核心思路是：提出一种基于混合层（Mixture-of-Layers, MoLe）的VLA模型架构，通过一个时空感知路由器动态选择激活部分LLM层以提升效率，并辅以认知自知识蒸馏来补偿因跳层可能损失的认知能力。</p>
<h2 id="方法详解">方法详解</h2>
<p>MoLe-VLA的整体目标是在保持甚至提升VLA模型性能的同时，显著降低其LLM部分（MLLM）的计算成本。其基础VLA模型由视觉编码器（DINO-v2+Siglip）、MLLM（作为多模态特征提取器π）和动作模块（采用扩散头）组成，通过最小化预测噪声与真实噪声的均方误差进行端到端训练。</p>
<p><img src="https://arxiv.org/html/2503.20384v2/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：MoLe-VLA整体框架。左侧为Spatial-Temporal Aware Router (STAR)，它处理视觉和语言输入，生成层激活门控向量。中间为MLLM主体，其中部分层根据门控向量被跳过（灰色块）。右侧为Cognition self-Knowledge Distillation (CogKD)模块，使用完整层模型作为教师，通过可学习的认知令牌引导跳层模型（学生）学习关键任务信息。</p>
</blockquote>
<p>核心创新在于引入了<strong>混合层（MoLe）机制</strong>、<strong>时空感知路由器（STAR）</strong> 和<strong>认知自知识蒸馏（CogKD）</strong>。</p>
<ol>
<li><p><strong>MoLe层跳过机制</strong>：对于一个具有K层的MLLM π，MoLe引入一个轻量级路由器。该路由器处理输入嵌入，并为每一层k生成一个二元门控值G_k ∈ {0, 1}（通过top-k选择）。前向传播时，若G_k=1，则执行该层变换π_k；若G_k=0，则直接跳过该层，将输入特征直接传递至下一层（公式7：<code>h_k = G_k · π_k(h_{k-1}) + (1 - G_k) · h_{k-1}</code>）。这与传统MoE在层内进行令牌级专家选择不同，MoLe是在层级别进行整体激活/跳过，避免了因不同层处理同一令牌可能导致的感知不一致性问题。</p>
</li>
<li><p><strong>时空感知路由器（STAR）</strong>：这是MoLe机制的核心决策模块。传统路由器使用简单的线性层，难以捕捉机器人动态任务中至关重要的时空信息。STAR则分别处理来自视觉输入的空间特征和来自语言指令的时序依赖。</p>
<ul>
<li><strong>空间路由权重</strong>：将视觉特征投影后，通过一个带有GELU激活函数的两层MLP提取空间特征，生成空间路由权重 <strong>S</strong>。</li>
<li><strong>时序路由权重</strong>：将语言特征投影后，先通过一个Transformer模块捕捉指令的上下文依赖，再进行平均池化，最后通过一个线性层生成时序路由权重 <strong>T</strong>。</li>
<li><strong>动态温度与门控融合</strong>：从语言特征的[CLS]令牌计算一个动态温度因子α ∈ [0,1]，用于调制路由决策的“锐利度”。最终的门控权重 <strong>G</strong> 由 <strong>S</strong> 和 <strong>T</strong> 加权求和并经α缩放后，通过Gumbel-Softmax得到，从而实现可微分的层选择。</li>
</ul>
</li>
<li><p><strong>认知自知识蒸馏（CogKD）</strong>：跳过某些层可能会削弱模型的认知表达能力。为补偿此损失，CogKD使用完整的原始模型（所有层激活）作为教师模型，MoLe跳层模型作为学生模型。受CogAct启发，引入一个可学习的<strong>认知令牌（cognition token）</strong>，它聚合了视觉和语言信息，用于理解任务需求。通过计算学生与教师认知令牌的相似度，识别出代表任务关键信息的“兴趣令牌（Tokens of Interest, ToIs）”。在知识蒸馏损失中，这些ToIs被赋予更高的权重，从而引导学生模型专注于学习教师模型中与任务最相关的认知特征，确保在跳层效率下仍能维持甚至提升任务理解能力。</p>
</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<p>实验主要在<strong>RLBench仿真环境</strong>和<strong>真实世界环境</strong>中进行，使用了基于不同MLLM（如OpenVLA、CogAct）构建的VLA模型作为基础。</p>
<p>对比的基线方法包括：<strong>完整模型（Full Model）</strong>、<strong>早期退出（Early Exit，EE）</strong>、<strong>均匀跳过（Uniform Skip）</strong> 以及<strong>混合深度（Mixture-of-Depth, MoD）</strong>。</p>
<p><img src="https://arxiv.org/html/2503.20384v2/extracted/6359963/images/mole_icon.jpg" alt="层相似性与早期退出分析"></p>
<blockquote>
<p><strong>图1</strong>：（A）显示OpenVLA在RLBench任务中连续层输出余弦相似度极高（&gt;90%），表明冗余；（B）显示早期退出策略（如仅用前6层）相比完整模型（24层）性能下降严重，说明深层信息关键；（C）类比浅层大脑假说，提出动态选择激活层的思想。</p>
</blockquote>
<p><strong>关键性能结果</strong>：在RLBench的10个任务上，MoLe-VLA在多个基础模型上均取得了最佳平均成功率。例如，在OpenVLA基础上，MoLe将平均成功率从76.6%提升至<strong>84.6%（相对提升8%）</strong>，同时将LLM的计算成本（FLOPs）最高降低了<strong>5.6倍</strong>。这实现了“既更快又更好”的效果。</p>
<p><img src="https://arxiv.org/html/2503.20384v2/x3.png" alt="性能与效率对比"></p>
<blockquote>
<p><strong>图4</strong>：在RLBench上的性能（成功率）与效率（GFLOPs）对比图。MoLe-VLA（红星）在显著降低计算量的同时，取得了比完整模型（Full）、早期退出（EE）、均匀跳过（Uniform）和MoD更高的成功率，占据了帕累托前沿的有利位置。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2503.20384v2/x5.png" alt="真实世界实验"></p>
<blockquote>
<p><strong>图6</strong>：真实世界机器人操作任务定性结果。MoLe-VLA成功完成了“打开微波炉”、“堆叠杯子”等复杂长视野任务，展示了其在实际场景中的有效性和高效性。</p>
</blockquote>
<p><strong>消融实验分析</strong>：<br><img src="https://arxiv.org/html/2503.20384v2/x4.png" alt="消融实验"></p>
<blockquote>
<p><strong>图5</strong>：消融实验展示了各组件贡献。（左）单独使用STAR路由器（MoLe w/o KD）已能超越早期退出和均匀跳过基线；加入CogKD后（MoLe），性能得到进一步显著提升。（右）不同top-k选择（激活层数）的影响，表明MoLe在较大k值范围内性能稳健，且均优于均匀跳过策略。</p>
</blockquote>
<p>消融实验证实了各个组件的有效性：1) <strong>STAR路由器</strong>：相较于均匀跳过或简单路由器，STAR能更智能地选择层，带来明显的性能增益。2) <strong>CogKD蒸馏</strong>：在STAR的基础上，CogKD通过知识蒸馏进一步恢复了因跳层损失的认知能力，是性能超越完整模型的关键。3) <strong>动态温度α</strong>：实验表明动态调节的α比固定温度能带来更好的性能。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 受神经科学启发，提出了<strong>混合层（MoLe）</strong> 这一新颖的VLA模型动态层激活架构，首次将“层”视为可路由的专家，实现了计算效率的显著提升。2) 设计了<strong>时空感知路由器（STAR）</strong>，首次在路由器中显式建模机器人任务中的空间（视觉）和时间（语言）依赖性，做出了更精准的层激活决策。3) 提出了<strong>认知自知识蒸馏（CogKD）</strong> 范式，通过兴趣令牌引导的蒸馏，有效补偿了稀疏化模型可能损失的认知能力，从而在减耗的同时实现了性能提升。</p>
<p>论文自身提到的局限性包括：当前方法主要应用于解码器架构的LLM，对于编码器-解码器架构的适配是未来方向；此外，路由器本身虽然轻量，但仍引入额外计算，在极端资源受限场景下需进一步优化。</p>
<p>本工作对后续研究的启示在于：为大规模具身智能模型的高效部署提供了新思路，将动态网络稀疏化从“令牌级”、“早期退出”推进到了“层级”的精细控制。将神经科学的发现（如SBH）与模型结构设计相结合，是一个富有潜力的交叉研究方向。如何将MoLe思想扩展到更广泛的序列模型和多模态任务中，值得进一步探索。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对用于机器人操作的视觉语言动作（VLA）模型计算开销大的问题，提出MoLe-VLA架构。其核心是动态层激活机制，通过一个空间-时间感知路由器（STAR）根据当前状态选择性执行部分模型层，并引入认知自知识蒸馏（CogKD）来补偿可能损失的语义理解能力。实验表明，该方法在十个任务上实现了平均8%的成功率提升，同时将大语言模型部分计算成本最多降低了5.6倍。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2503.20384" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>