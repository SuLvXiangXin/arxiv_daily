<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>PolaRiS: Scalable Real-to-Sim Evaluations for Generalist Robot Policies - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>PolaRiS: Scalable Real-to-Sim Evaluations for Generalist Robot Policies</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.16881" target="_blank" rel="noreferrer">2512.16881</a></span>
        <span>作者: Karl Pertsch Team</span>
        <span>日期: 2025-12-18</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人学习研究面临的一个重大挑战是准确测量和比较机器人策略性能的能力。由于真实世界评估的随机性、难以复现和耗时等特性，机器人领域的基准测试历来充满挑战。这一挑战对于需要跨多种场景和任务进行评估的通用策略而言尤为突出。仿真评估为真实世界评估提供了一种可扩展的补充，但现有仿真基准与真实世界之间的视觉和物理领域差距使其成为策略改进的不可靠信号。此外，构建逼真且多样化的仿真环境传统上需要大量的人力投入和专业知识。为了弥合这一差距，本文提出了PolaRiS，一个用于高保真仿真机器人评估的可扩展真实到仿真框架。PolaRiS利用神经重建方法，将真实世界场景的短视频扫描转换为交互式仿真环境。此外，本文开发了一种简单的仿真数据协同训练方法，以弥合剩余的领域差距，并实现在未见过的仿真环境中的零样本评估。核心思路是：通过神经重建快速创建高保真仿真环境，并辅以轻量级的仿真数据协同训练，从而实现对通用策略性能的、与真实世界强相关的可扩展仿真评估。</p>
<h2 id="方法详解">方法详解</h2>
<p>PolaRiS的整体目标是在仿真环境中评估真实世界的通用机器人策略，并使仿真评估能忠实反映真实世界性能。其框架包含两个核心部分：1）利用2D高斯泼溅（2DGS）等技术从视频快速重建高保真、可交互的仿真环境；2）提出一种轻量级的仿真数据协同训练策略，以弥合视觉领域差距，确保策略在未见过的PolaRiS环境中也能被准确评估。</p>
<p><img src="https://arxiv.org/html/2512.16881v2/figures/Teaser_Karl_version.jpg" alt="方法总览"></p>
<blockquote>
<p><strong>图1</strong>：PolaRiS概述。这是一个真实到仿真的方法，将真实世界场景的短视频转换为用于可扩展机器人策略评估的高保真仿真环境。通过少量迭代的仿真数据协同微调，可以使通用策略在未见过的PolaRiS环境中进行准确的零样本评估。</p>
</blockquote>
<p><strong>环境生成流程</strong>：PolaRiS采用组合式方法创建环境。首先，用户使用普通相机拍摄场景（静态背景）和机器人的单独短视频（约2-5分钟），并放置ChArUco标定板以辅助确定全局方向和度量尺度。随后，使用COLMAP估计相机参数，并训练独立的2D高斯泼溅模型来分别重建场景和机器人的视觉外观与几何。每个高斯泼溅元组表示为 $g_j = (\bm{\mu}_j, \mathbf{R}_j, \mathbf{S}_j, \mathbf{c}_j, \alpha_j)$，分别代表中心、朝向、协方差、颜色和不透明度。为了进行物理仿真，需要从重建结果中提取网格。具体做法是：通过栅格化泼溅和体素深度融合获得截断有符号距离场（TSDF），再使用行进立方体算法提取显式网格 $\mathcal{M}$，最后将其导入IsaacSim物理引擎。</p>
<p><img src="https://arxiv.org/html/2512.16881v2/figures/polaris_pipeline.jpg" alt="环境创建流程"></p>
<blockquote>
<p><strong>图2</strong>：PolaRiS中的环境创建。用户首先扫描真实世界环境、机器人和物体。然后使用PolaRiS创建捕获环境几何和视觉外观的关节化高斯泼溅表示。最后，通过组合扫描的场景、物体和机器人来构建用于策略评估的仿真场景。</p>
</blockquote>
<p><strong>自动关节化</strong>：为了使机器人模型在仿真中可运动，PolaRiS将高斯泼溅图元锚定到机器人的运动学连杆上。对于具有连杆 ${\mathcal{L}_1, \ldots, \mathcal{L}<em>L}$ 和关节配置 $\mathbf{q}$ 的机器人，每个连杆关联一组高斯图元 $\mathcal{G}<em>\ell$。当关节运动时，通过正向运动学获得连杆的刚体变换 $T_\ell(\mathbf{q})$，并据此更新每个关联高斯的中心位置 $\bm{\mu}</em>{\ell j}^{\prime}$ 和协方差 $\Sigma</em>{\ell j}^{\prime}$，从而实现高斯泼溅与底层网格模型的同步运动与渲染。</p>
<p><strong>物体创建与场景组合</strong>：对于场景中的物体，PolaRiS利用生成模型（如TRELLIS）从多视角图像创建3D资产。用户通过SAM2分割物体图像，输入TRELLIS获得结构化潜在表示，进而解码为用于外观的高斯泼溅和用于几何的网格。最后，所有组件（环境、机器人、物体）通过一个场景组合GUI在欧几里得空间中组合、变换，并导出为USD文件用于评估。创建新评估环境的总人力时间通常少于20分钟，总耗时（包括高斯泼溅训练）通常少于一小时。</p>
<p><img src="https://arxiv.org/html/2512.16881v2/figures/scene_comp_gui.jpg" alt="场景组合GUI"></p>
<blockquote>
<p><strong>图3</strong>：场景组合GUI示例。用户可以轻松导入环境和物体资产，自动加载DROID机器人，并将仿真就绪的环境保存为USD文件。该过程通常只需不到5分钟。</p>
</blockquote>
<p><strong>协同训练以提升评估相关性</strong>：尽管能创建高保真环境，但策略在未经调整的情况下直接评估，其仿真与真实性能的相关性可能仍不理想。论文指出，视觉不匹配（如细微光照变化、缺失的物体间阴影）是主要误差来源。为此，PolaRiS提出了一种策略无关的仿真数据协同训练方案。具体而言，在一组仿真协同训练环境 $\mathcal{E}<em>{\mathcal{S}}^{\text{train}}$ 中，通过人工遥操作收集一个小的仿真数据集 $\mathcal{D}</em>{\mathcal{S}} = {(o_t^{\mathcal{S}}, a_t^{\mathcal{S}}, p_t^{\mathcal{S}})}$。然后，将预训练的通用策略 $\pi_\theta$ 在其原始训练数据 $\mathcal{D}<em>{\text{pre}}$ 和仿真数据 $\mathcal{D}</em>{\mathcal{S}}$ 的混合批次上进行微调，优化标准行为克隆损失 $\mathcal{L}<em>{\text{BC}}$：<br>$\theta^{\prime} \leftarrow \theta - \eta \nabla</em>{\theta} \mathbb{E}<em>{(o,a,p)\sim(1-\lambda)\mathcal{D}</em>{\text{pre}}+\lambda\mathcal{D}<em>{\mathcal{S}}}\big[ \mathcal{L}</em>{\text{BC}}(\pi_{\theta}(o,p), a) \big]$<br>其中 $\lambda$ 控制仿真数据在批次中的混合比例。此方法旨在提高策略对仿真视觉差异的鲁棒性，而非学习新任务技能。仅需数百个仿真 episode 和数百步微调（&lt;25分钟），即可显著提升真实到仿真的相关性，且微调后的策略可在未见过的仿真测试环境 $\mathcal{E}_{\mathcal{S}}^{\text{test}}$ 中进行零样本评估。</p>
<p><img src="https://arxiv.org/html/2512.16881v2/x1.png" alt="协同训练数据集环境"></p>
<blockquote>
<p><strong>图4</strong>：PolaRiS仿真协同训练数据集环境。在仿真中收集少量演示数据，并用此数据协同微调策略，以提高真实到仿真评估的相关性。一旦微调完成，策略在PolaRiS中的评估（即使在未见过的环境中）也能表现出与真实世界的强相关性。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在DROID机器人平台和RoboArena真实世界基准上进行。评估的策略包括OpenVLA、Octo、GR00T-N1和BlackPI0等通用策略。对比的基线方法包括直接在真实世界评估、在现有仿真基准（如SIMPLER）中评估，以及使用世界模型（视频预测模型）进行评估。评估指标为皮尔逊相关系数（$r$）和平均最大秩违反（MMRV），以衡量仿真评估与真实世界评估的相关性和排名一致性。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>与真实世界的强相关性</strong>：在DROID平台上，PolaRiS评估与最先进通用策略的真实世界性能表现出强相关性，平均皮尔逊相关系数 $r = 0.9$。PolaRiS评估也与迄今为止最全面的通用策略真实世界基准RoboArena的策略得分高度相关（$r = 0.98$）。</li>
</ol>
<p><img src="https://arxiv.org/html/2512.16881v2/figures/roboarena_correlation.png" alt="RoboArena相关性"></p>
<blockquote>
<p><strong>图8</strong>：PolaRiS仿真评估得分与RoboArena真实世界评估得分的相关性。两者呈现出极强的线性相关（$r=0.98$），表明PolaRiS能高度预测策略在真实基准上的表现。</p>
</blockquote>
<ol start="2">
<li><strong>超越现有仿真基准</strong>：实验表明，现有仿真基准（如SIMPLER）与真实世界性能的相关性较弱（$r=0.32$），而PolaRiS（未协同训练时 $r=0.72$，协同训练后 $r=0.9$）显著优于它们。此外，基于世界模型的评估方法也未能提供可靠的相关性。</li>
</ol>
<p><img src="https://arxiv.org/html/2512.16881v2/figures/visual_fidelity_pearson_r_and_mmrv.png" alt="视觉保真度消融"></p>
<blockquote>
<p><strong>图9</strong>：不同视觉保真度方法对评估相关性的影响。PolaRiS（2DGS）在皮尔逊相关系数（r）和平均最大秩违反（MMRV）上均优于背景抠图（Green Screen）和程序化生成（Proc.）等方法。</p>
</blockquote>
<ol start="3">
<li><strong>协同训练的有效性</strong>：消融实验证实了仿真数据协同训练的关键作用。仅使用PolaRiS环境而不进行协同训练，相关性为 $r=0.72$；加入协同训练后，相关性提升至 $r=0.9$。实验还探索了协同训练数据混合比例 $\lambda$ 的影响，发现 $\lambda=0.5$ 通常能取得最佳效果。</li>
</ol>
<p><img src="https://arxiv.org/html/2512.16881v2/figures/data_mix_pearson_r_and_mmrv.png" alt="数据混合比例消融"></p>
<blockquote>
<p><strong>图10</strong>：协同训练中仿真数据混合比例（λ）对评估相关性的影响。适中的混合比例（如λ=0.5）能取得最佳的皮尔逊相关系数（r）和最低的平均最大秩违反（MMRV）。</p>
</blockquote>
<ol start="4">
<li><strong>支持手腕相机</strong>：与依赖背景抠图的方法（如SIMPLER）不同，PolaRiS的3D重建支持从任意角度渲染，包括机器人手腕相机的视角，从而能够评估主流的、配备手腕相机的通用策略。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了PolaRiS，一个通过神经场景重建创建高保真仿真评估环境的可扩展框架，显著降低了构建定制化仿真环境的门槛（&lt;1小时）。</li>
<li>开发了一种简单的仿真数据协同训练方法，通过轻量级微调（&lt;25分钟）有效弥合真实到仿真的视觉领域差距，使通用策略能在未见过的PolaRiS环境中进行零样本且高相关的评估。</li>
<li>通过大量实验验证了PolaRiS评估与真实世界性能的强相关性（在DROID上 $r=0.9$，在RoboArena上 $r=0.98$），优于现有仿真基准和世界模型评估方法，并开源了所有工具以促进社区共享。</li>
</ol>
<p><strong>局限性</strong>：论文提到，当前方法主要处理静态场景和刚体物体，对动态物体（如流动液体）和透明/反射表面的重建仍具挑战性。此外，环境创建依赖于一段质量尚可的视频扫描。</p>
<p><strong>后续启示</strong>：PolaRiS为机器人社区提供了一个快速创建和共享高保真仿真评估环境的可行路径，有望推动通用策略评估的民主化和分布式协作。未来的工作可以专注于改进重建技术以处理更复杂的物体和场景，并探索如何将PolaRiS框架更无缝地集成到策略开发循环中。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对通用机器人策略性能评估的挑战，提出PolaRiS框架。核心问题是真实评估耗时、不可控，而模拟评估存在视觉与物理领域差距。PolaRiS利用神经重建方法将真实场景短视频转换为高保真交互式模拟环境，并通过模拟数据协同训练实现零样本评估。实验表明，PolaRiS评估与真实世界性能的相关性显著强于现有模拟基准，且能快速创建多样化环境。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.16881" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>