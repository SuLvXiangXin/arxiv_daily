<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Single-View Shape Completion for Robotic Grasping in Clutter - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Single-View Shape Completion for Robotic Grasping in Clutter</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.16449" target="_blank" rel="noreferrer">2512.16449</a></span>
        <span>作者: Todor Stoyanov Team</span>
        <span>日期: 2025-12-18</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在基于视觉的机器人操作中，单目相机视图只能捕获物体的一侧，而杂乱场景中的遮挡进一步限制了可见性，导致观察到的几何信息不完整，抓取估计算法表现不佳。现有解决单视图抓取挑战的方法，如S4G直接回归抓取或GraspNet-1Billion处理遮挡，在面对最优抓取向量与遮挡表面碰撞时仍有困难。近期一些工作（如3DSGrasp、SCARP、SceneGrasp）虽在抓取预测前进行形状补全，但大多在无遮挡或模拟的简化场景中评估，或缺乏可靠的抓取验证。ZeroGrasp在真实世界进行了评估，但其在存在深度传感器噪声时性能会下降。这些方法的一个关键局限是，它们通常假设部分点云已在规范坐标系中对齐，这在物体姿态任意且存在遮挡的真实世界操作中不切实际。本文针对在真实杂乱场景中，由于几何信息不完整导致抓取不可靠这一具体痛点，提出利用扩散模型从单视图深度观测中完成类别级3D形状补全，为抓取规划提供完整几何上下文的新视角。本文的核心思路是：构建一个模块化系统，先分割目标物体，再利用扩散模型从其未对齐的部分点云补全完整形状，最后在补全形状上进行抓取推断，从而提升杂乱环境中的抓取成功率。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文采用模块化方法，将杂乱环境中的抓取问题分解为场景获取、物体分割、形状补全和抓取推断四个阶段。这种设计允许灵活更换不同分割或抓取组件，而无需重新训练整个系统。</p>
<p><img src="https://arxiv.org/html/2512.16449v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：所提方法概览。RGB信息用于分割感兴趣物体。物体点云随后输入扩散模型以获得补全表面，进而指导抓取规划。抓取被排序并选择执行（图中绿色抓取）。</p>
</blockquote>
<p><strong>整体流程</strong>：给定机器人、工作空间中的一组家庭物品和静态安装的RGB-D相机，通过语言提示指定并分割目标物体。输入RGB-D数据的RGB分量经过语言引导的分割生成物体掩码，该掩码应用于对应的深度图像以提取目标物体的可见点云。这个部分点云随后由形状补全模块处理，估计完整的3D几何形状。补全的物体形状作为抓取推断网络的输入，预测候选抓取位姿。最终，使用标准运动规划器执行选定的抓取。</p>
<p><strong>核心模块1：物体分割</strong>：该模块从场景点云中分离出单个物体的点云，作为形状补全模型的输入。为了获得精确的掩码，本文采用LangSAM，通过短文本提示（如“红色碗”、“木块”）引导实例分割，有效避免了过分割或合并相邻物体的问题。</p>
<p><strong>核心模块2：单视图物体重建</strong>：使用有符号距离场表示3D物体，并采用Diffusion-SDF模型从单视图深度感知获得的部分点云估计完整物体形状。模型架构包含三个核心组件：用于学习可泛化有符号距离场的GenSDF、将物体形状压缩为紧凑潜在表示的变分自编码器，以及直接预测去噪潜在向量的扩散网络。</p>
<p><strong>创新点：类别级形状补全</strong>：为了解决不同类别物体共享相似局部几何特征时产生的基本模糊性问题（例如，曲面块可能属于瓶子、杯子或碗），本文实施了类别级补全。具体策略是训练一个集成模型，为每个物体类别（见表1）保存一个单独的检查点。这为形状推断提供了必要的上下文约束，并使通过向集成中添加新模型来扩展到新类别变得简单。</p>
<p><strong>核心模块3：抓取位姿估计</strong>：给定点云输入，抓取位姿估计预测能引导机械臂末端执行器成功抓取物体的候选抓取。本文利用模块化设计，集成了基于点云的最新扩散模型GraspGen来预测补全物体形状上的抓取。所有预测抓取都关联一个预测得分。根据其接近向量是否落在与垂直方向成40°的锥形范围内，将预测抓取分为两类。两类抓取分别按其预测得分排序。优先选择锥形内的前K=5个抓取，因为这种垂直接近方式能最小化与相邻物体和基面的碰撞风险。如果锥形内抓取不足K个，则从锥形外补充至K个。随后循环尝试这K个抓取，传递给运动规划器，直到规划成功为止。这种多尝试策略提高了处理因手臂可达性和工作空间物体布局等实际约束导致的运动规划失败的鲁棒性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：重建质量评估使用ReOcS真实世界数据集，该数据集包含基于杂乱和遮挡程度分为“简单”、“正常”、“困难”三个难度级别的家庭物品。使用双向倒角距离作为评估指标。全系统抓取实验在配备Robotiq 2F-85夹爪的Franka Emika Panda机器人上进行，使用ROS2和MoveIt2进行运动规划。评估了两种不同的实验设置（图4），以确保所有物体类别都有适当的遮挡水平。每个物体类别进行10次试验，记录成功抓取的百分比（抓取后抬起并保持超过5秒判定为成功）。</p>
<p><strong>对比方法</strong>：1) <strong>GraspGen（无形状补全）</strong>：直接在部分点云上进行抓取推断的基线。2) <strong>ZeroGrasp</strong>：同时进行形状补全和抓取预测的最新方法。</p>
<p><img src="https://arxiv.org/html/2512.16449v1/images/real_robot_exp/setup1.jpg" alt="实验场景配置"></p>
<blockquote>
<p><strong>图4a</strong>：真实机器人实验使用的场景配置之一。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.16449v1/images/real_robot_exp/setup2.jpg" alt="实验场景配置"></p>
<blockquote>
<p><strong>图4b</strong>：真实机器人实验使用的另一种场景配置，旨在使所有物体类别都有适当的遮挡水平。</p>
</blockquote>
<p><strong>重建质量结果</strong>：如表2所示，在ReOcS数据集上，虽然ZeroGrasp在成功重建的样本上取得了更低的倒角距离，但其发布的检查点在大约30-35%的样本上失败（原因未知），而本文模型重建了所有实例。本文方法的整体重建成功率为100%，显著高于ZeroGrasp的62.34%-69.85%。</p>
<p><img src="https://arxiv.org/html/2512.16449v1/images/ReOcS/easy/shard_0/scene_1/view_6/rgb.jpg" alt="定性重建结果"></p>
<blockquote>
<p><strong>图3（部分）</strong>：ReOcS数据集“简单”难度级别的RGB图像示例。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.16449v1/images/ReOcS/easy/shard_0/scene_1/view_6/recon_top.jpg" alt="定性重建结果"></p>
<blockquote>
<p><strong>图3（部分）</strong>：本文方法（Diffusion-SDF）对“简单”级别场景的补全结果（顶视图）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.16449v1/images/ReOcS/easy/shard_0/scene_1/view_6/recon_underside.jpg" alt="定性重建结果"></p>
<blockquote>
<p><strong>图3（部分）</strong>：本文方法（Diffusion-SDF）对“简单”级别场景的补全结果（底视图），展示了补全的不可见面。</p>
</blockquote>
<p><strong>抓取成功率结果</strong>：如表3所示，本文方法（带形状补全）的平均抓取成功率达到80%，比不使用形状补全的基线（56.67%）高出约23%，也比ZeroGrasp（61.67%）高出约19%。在苹果、碗、盒子、锤子等类别上，本文方法均取得了最高或并列最高的成功率。</p>
<p><img src="https://arxiv.org/html/2512.16449v1/images/compare_recon/wooden_block/partial.jpg" alt="重建质量对比"></p>
<blockquote>
<p><strong>图5（部分）</strong>：真实实验中的输入部分点云示例（木块）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.16449v1/images/compare_recon/wooden_block/zerograsp.png" alt="重建质量对比"></p>
<blockquote>
<p><strong>图5（部分）</strong>：ZeroGrasp对木块的重建结果，显示几何形状不合理。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.16449v1/images/compare_recon/wooden_block/diffusionsdf.png" alt="重建质量对比"></p>
<blockquote>
<p><strong>图5（部分）</strong>：本文方法对木块的重建结果，产生了更合理的几何形状。图中对比直观展示了本文方法在重建质量上的优势。</p>
</blockquote>
<p><strong>推理时间</strong>：在NVIDIA RTX 2000 Ada Laptop GPU上，完整流程（图2）约需4-5秒：物体分割0.8秒，形状补全3秒，对齐0.2秒，抓取估计0.4-0.6秒。ZeroGrasp的推理时间为2-3秒，更快但重建质量较差。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) 提出了一种面向杂乱场景抓取的系统级集成方案，结合了开放词汇物体分割、基于扩散的任意方向部分点云形状补全和模块化抓取生成。2) 通过真实机器人实验证明了将形状补全作为预处理步骤，能有效提高在杂乱环境中对多样家庭物品的抓取成功率。3) 首次将基于扩散的形状补全集成到机器人操作中，并设计了训练方案以提高对遮挡的鲁棒性。</p>
<p>论文提到的局限性在于，其类别级方法需要为每个物体类型训练单独的模型。尽管这使扩展到新类别变得直接，但需要额外的训练和数据。</p>
<p>本文的启示在于：在机器人抓取中，利用生成模型（如扩散模型）补全被遮挡的几何信息是提升在真实、杂乱环境中操作可靠性的有效途径。模块化设计提供了灵活性，但如何平衡补全质量与推理速度，以及如何向更通用的、与语言对齐的补全模型发展，是未来值得探索的方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人抓取在杂乱环境中因单视图遮挡导致几何形状不完整、抓取性能下降的问题，提出基于扩散模型的类别级3D形状补全方法。该方法从单视图深度观测中重建完整物体几何，集成场景分割与抓取推理，为规划提供完整上下文。在家庭物品杂乱场景的初步实验中，抓取成功率比无形状补全基线提高23%，比现有最优形状补全方法提高19%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.16449" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>