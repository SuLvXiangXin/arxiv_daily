<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>How Well do Diffusion Policies Learn Kinematic Constraint Manifolds? - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>How Well do Diffusion Policies Learn Kinematic Constraint Manifolds?</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.01404" target="_blank" rel="noreferrer">2510.01404</a></span>
        <span>作者: Russ Tedrake Team</span>
        <span>日期: 2025-10-01</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>扩散策略在机器人模仿学习中展现了卓越的性能，即使对于需要满足运动学等式约束的任务也是如此。然而，任务性能本身并不是衡量策略精确学习训练数据中约束能力的可靠指标。当前主流方法通常将约束满足问题从扩散策略转移到机器人系统的其他部分，例如依赖底层控制器来强制执行约束。这种做法使得扩散策略自身学习和满足数据中约束的内在能力尚不明确。本文针对这一具体痛点，提出需要量化扩散策略对机器人数据中约束流形的遵循程度，并系统研究影响这种遵循质量的因素。本文的核心思路是：通过一个需要满足运动学约束的双手抓取-放置任务作为案例研究，分析数据集大小、数据集质量和约束流形曲率三个因素如何影响扩散策略学习约束流形的能力。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文方法的整体流程是：首先，为一项受约束的双手抓取-放置任务收集遥操作演示数据；然后，通过扰动这些演示生成三个额外的数据集，这些数据集仍能完成任务但包含递增程度的约束违反；接着，在每个数据集上训练一个策略，并分析其任务成功率和约束遵循情况；最后，在真实硬件上收集同一任务的演示，训练策略，并评估其在相似指标上的性能。</p>
<p><img src="https://arxiv.org/html/2510.01404v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：方法整体框架。左侧展示了仿真和硬件的实验设置（两个KUKA iiwa机器人执行将盒子放入架子的任务）。右侧概述了方法流程：收集遥操作数据，通过扰动生成不同质量的数据集，训练策略并评估任务成功与约束遵循，最后进行硬件验证。</p>
</blockquote>
<p>核心模块与技术细节包括：</p>
<ol>
<li><strong>任务与约束定义</strong>：研究任务是双手协调将一个盒子从桌子运输到架子上。成功的关键在于运输过程中两个末端执行器必须保持恒定的相对位姿，这构成了机器人构型空间中的一个非线性运动学等式约束。</li>
<li><strong>数据收集系统</strong>：使用配备虚拟现实手柄的遥操作栈。其关键特性是“变换锁定”模式：启用后，操作者选择一只手臂作为控制臂，系统将固定末端执行器间的相对位姿。操作者只需遥操作控制臂，从属臂会自动计算并跟踪逆运动学解以维持初始相对变换，从而确保所有训练数据满足约束。</li>
<li><strong>数据集生成</strong>：为了研究数据质量的影响，作者对原始的、满足约束的演示进行扰动，生成三个包含不同程度约束违反的新数据集。扰动通过向机器人命令添加噪声实现，扰动水平（η）越高，约束违反的平均位置和方向误差越大（如表I所示）。</li>
<li><strong>策略架构与训练</strong>：采用标准的扩散策略框架。观测空间包括机器人关节角（每臂7自由度）、过去的夹爪命令（每臂1自由度）以及来自四个摄像头（两个场景相机，两个腕部相机）的RGB图像。动作空间是一个16维向量，包含两个机器人的绝对指令关节角和夹爪动作。选择输出关节角指令而非末端执行器指令，原因有二：一是本任务中的约束流形在末端执行器空间是仿射的，但在构型空间高度非线性，便于研究流形曲率等更丰富的问题；二是在存在障碍物的任务中，关节空间指令能更好地利用运动学冗余避免碰撞。</li>
<li><strong>推理流程</strong>：在推理时，策略基于最近两次观测预测接下来16个时间步的动作。控制系统执行前8个命令，并使用一阶保持进行插值。评估时，仅在策略预测动作的节点处评估约束满足情况，以避免插值引入的违反。</li>
</ol>
<p>与现有方法相比，本文的创新点在于没有采用显式约束编码或基于引导的方法来保证约束，也没有依赖底层控制器来弥补策略的不足，而是首次系统地评估了标准扩散策略在“裸奔”状态下（即独立于底层控制栈）学习数据中隐式运动学约束的内在能力。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：主要实验在仿真中进行，以便精确控制研究变量。最后在真实硬件（两个KUKA iiwa 14机器人）上进行验证，以确保结论的现实适用性。<br><strong>对比基准</strong>：由于核心是分析不同因素对同一扩散策略架构的影响，因此主要进行的是自身对照实验，比较在不同数据集（不同大小、不同质量）上训练的策略性能。<br><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>数据集大小的影响</strong>：在满足约束的高质量数据集上，随着演示数量从25个增加到100个，任务成功率从约60%提升至约95%，同时约束违反（末端执行器相对位姿误差）显著降低。这表明更多的数据有助于策略更好地学习约束流形。</li>
<li><strong>数据集质量的影响</strong>：使用100个演示但质量不同（扰动水平η不同）的数据集进行训练。结果表明，随着训练数据中约束违反程度的增加（η从0增加到0.005），训练出的策略在测试时的约束违反也显著增加。虽然所有策略在夹爪顺应性的帮助下仍能维持较高的任务成功率，但约束遵循能力明显下降。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.01404v1/x2.png" alt="实验结果"></p>
<blockquote>
<p><strong>图2</strong>：仿真实验结果汇总。<strong>左图</strong>展示了在不同大小和不同质量（扰动水平η）数据集上训练的策略，其任务成功率（条形图）和平均约束违反（折线图，位置误差）。可见数据量增加提升性能，数据质量下降增加约束违反。<strong>右图</strong>展示了策略预测动作（节点）与底层控制器插值后实际执行动作（路径）在约束违反上的差异，凸显了仅评估节点动作的必要性。</p>
</blockquote>
<ol start="3">
<li><strong>约束流形曲率的影响</strong>：作者尝试研究约束流形在策略预测动作处的曲率与任务成功或约束遵循之间的相关性，但结果没有定论，未发现明确的相关性。</li>
<li><strong>硬件实验结果</strong>：在真实机器人上使用“变换锁定”系统收集了100个演示，训练的策略取得了90%的成功率，并且显示出与仿真中类似的约束遵循行为，验证了仿真结论在现实世界中的适用性。<br><strong>消融实验总结</strong>：本文通过控制变量实验，分别揭示了数据集大小和数据集质量两个组件对策略学习约束能力的独立贡献：数据量不足会限制流形学习，导致成功率低和约束违反高；而数据中存在噪声（约束违反）则会直接“教坏”策略，使其在测试时更倾向于违反约束。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个关键问题并提供了系统的评估框架：首次专注于量化扩散策略自身（独立于底层控制器）学习机器人数据中运动学约束流形的能力。</li>
<li>通过详实的实验揭示了影响该能力的两个关键因素：数据集大小和数据质量（约束纯净度）。扩散策略能够学习约束流形的粗略近似，但其性能受数据量减少和数据质量下降的负面影响。</li>
<li>设计并验证了一个实用的“变换锁定”遥操作接口，能够高效收集满足复杂运动学约束的演示数据，并在真实硬件上验证了整体方法的有效性。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，研究集中于一个特定的双手操作任务和一种运动学约束，结论的普适性有待在其他任务和约束类型上验证。此外，用于度量约束违反的末端执行器空间误差可能无法完全捕捉构型空间中所有的违反情况。</p>
<p><strong>对后续研究的启示</strong>：这项工作表明，仅凭任务成功率不足以评估策略对关键约束的学习程度。在收集模仿学习数据时，应优先保证数据的“纯净度”（即约束满足），这可能比单纯追求数据量更重要。未来的工作可以探索如何使扩散策略对训练数据中的噪声（约束违反）更具鲁棒性，或者如何将显式约束知识更有效地融入训练过程，以提升策略对约束流形的精确学习能力。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文研究扩散策略学习运动学约束流形的效果，核心问题是评估其在机器人模仿学习中精确学习约束的能力。通过双手机器人拾取-放置任务案例，采用扩散策略方法，扰动演示生成不同约束违反程度的数据集，分析任务成功和约束遵守。实验表明，扩散策略能学习约束流形的粗略近似，但数据集大小和质量下降会负面影响学习效果；流形曲率与约束满足和任务成功的相关性不明确。硬件评估验证了结果的现实适用性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.01404" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>