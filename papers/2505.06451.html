<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Adaptive Wiping: Adaptive contact-rich manipulation through few-shot imitation learning with Force-Torque feedback and pre-trained object representations - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Adaptive Wiping: Adaptive contact-rich manipulation through few-shot imitation learning with Force-Torque feedback and pre-trained object representations</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.06451" target="_blank" rel="noreferrer">2505.06451</a></span>
        <span>作者: Tsuji, Chikaha, Coronado, Enrique, Osorio, Pablo, Venture, Gentiane</span>
        <span>日期: 2025/05/09</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>模仿学习为机器人执行重复性任务提供了一条途径，但面临需要大量演示数据以及训练环境与现实环境存在差异的挑战。本文聚焦于使用柔软、可变形物体（如海绵）的接触密集型任务（如擦拭），这类任务需要自适应的力控制来应对擦拭表面高度和海绵物理性质的变化。现有方法如基于强化学习的方法样本效率低，而基于模仿学习的方法（例如先前工作[16]）虽能利用预训练物体表征进行小样本学习，但其擦拭运动采用开环控制，无法适应环境变化（如表面高度变化）。传统的导纳控制或阻抗控制方法则需要已知目标力或目标位置，在此类目标未知的场景下不适用。因此，本文针对“机器人能否通过小样本模仿学习，习得一个能适应环境变化（操作表面高度和操作物体物理性质）的通用操作策略”这一痛点，提出了结合实时力扭矩反馈与预训练物体表征的新视角。其核心思路是：在模拟器中预训练一个编码器来捕捉海绵的物理属性，然后在真实世界中用小样本人类演示数据训练一个运动轨迹解码器和一个基于力扭矩历史的反馈控制器，从而实现在线适应。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的方法分为三个步骤：在模拟器中使用未标记数据进行预训练、在真实机器人上使用少量演示数据进行训练、以及最终部署。整体框架是一个分阶段学习的pipeline。</p>
<p><img src="https://arxiv.org/html/2505.06451v1/extracted/6426510/imgs/overview.png" alt="方法框架总览"></p>
<blockquote>
<p><strong>图2</strong>：提出的框架概述。首先，使用模拟的未标记数据预训练海绵属性编码器φ_sponge（预训练步骤III-A）。然后，使用少量人类演示数据训练运动轨迹解码器θ_traj和力扭矩反馈循环φ_ft-θ_height，以获得具有主动推理施加力的擦拭策略（训练步骤III-B）。最后，将习得的策略部署在真实机器人硬件上（部署III-C）。</p>
</blockquote>
<p><strong>1. 预训练步骤</strong>：目标是让编码器φ_sponge学习海绵物理属性（如刚度、摩擦力）的隐式表征。在模拟器中，对具有随机化物理参数的海绵执行预定义的探索动作（以0.01 m/s速度按压2秒，以0.05 m/s速度左右横向移动各1秒），收集力扭矩轨迹τ^exp ∈ R^(400×6)，构成未标记数据集D_sim。采用变分自编码器架构，编码器φ_sponge（两层全连接层）将τ^exp映射为一个5维高斯分布的隐空间Z_sponge，解码器θ_sponge（两层全连接层，使用ReLU激活和0.1的dropout）则从Z_sponge重构出力扭矩轨迹τ̂^exp。损失函数L_ssl包含重构均方误差和KL散度正则项（β=0.06），旨在让Z_sponge覆盖广泛的物理属性分布。</p>
<p><strong>2. 训练步骤</strong>：使用真实机器人收集的未标记数据D_real（通过相同探索动作获得）和少量人类演示数据D_demo（包含演示的运动轨迹x^demo、垂直位移Δh^demo和力扭矩τ^demo）进行训练。此步骤包含两个核心模块：</p>
<ul>
<li><strong>运动轨迹解码器θ_traj</strong>：用于根据所用海绵的属性生成离线（x, y）平面擦拭轨迹。采用编码器-解码器结构，其中编码器φ_sponge使用预训练权重并冻结，解码器θ_traj（单层全连接，dropout=0.1）根据从D_real中提取的海绵力扭矩轨迹，生成对应的运动轨迹x̂^demo。损失函数L_motion是生成轨迹与演示轨迹之间的均方误差。</li>
<li><strong>力扭矩反馈循环φ_ft-θ_height</strong>：用于在线自适应调整末端执行器的垂直（z轴）位置，以应对表面高度变化并施加合适的力。它由力扭矩编码器φ_ft和垂直位置解码器θ_height组成。φ_ft是一个时序卷积网络，处理最近5个时间步（t-4到t）的力扭矩历史D_demo_ft，输出6维隐空间Z_ft。θ_height（两层全连接层，第一层128维，ReLU激活，dropout=0.1）将Z_sponge和Z_ft拼接后作为输入，预测下一时间步的垂直位移Δĥ^demo_{t+1}。损失函数L_height是预测位移与真实位移之间的均方误差。</li>
</ul>
<p><strong>3. 部署</strong>：执行任务时，机器人结合离线生成的水平运动x̂^task和在线调整的垂直运动Δĥ^task_{t+1}。首先，通过探索动作收集当前任务所用海绵的D_task，并生成水平轨迹离线执行。同时，力扭矩反馈循环根据实时力扭矩历史D_task_ft，持续在线推断并调整下一个垂直位置，从而实现动态适应。</p>
<p><strong>创新点</strong>：与开环控制的先前方法[16]相比，本文通过引入力扭矩反馈循环实现了<strong>闭环控制</strong>，使机器人能动态适应环境变化（如表面高度）。相较于需要已知目标力/位置的导纳/阻抗控制，本方法在目标未知的情况下，能同时适应未见过的海绵属性和表面高度变化。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：使用UR5e机械臂，末端安装6轴力扭矩传感器和海绵。任务为擦拭，评估机器人适应不同表面高度（低、高、斜坡）和不同海绵物理属性的能力。使用了10块海绵（图4）：1块普通海绵用于训练，9块自定义海绵（3种刚度×3种摩擦力）作为未见过的测试对象。此外，还用一面垂直墙进行了额外验证。共测试了40种场景（10海绵×4高度）。</p>
<p><img src="https://arxiv.org/html/2505.06451v1/extracted/6426510/imgs/sponges.png" alt="实验所用海绵"></p>
<blockquote>
<p><strong>图4</strong>：实验中使用的10块海绵。一块现成的海绵（普通海绵）用于训练和部署，9块具有不同物理性质的自制海绵（3种刚度水平 × 3种摩擦水平）作为部署时未见过的海绵。</p>
</blockquote>
<p><strong>对比方法</strong>：</p>
<ol>
<li><strong>Baseline</strong>：简单地复现演示轨迹，垂直运动不考虑环境变化（开环）。</li>
<li><strong>导纳控制</strong>：一种经典的力控制方法。</li>
<li><strong>Ours</strong>：本文提出的方法。</li>
</ol>
<p><img src="https://arxiv.org/html/2505.06451v1/extracted/6426510/imgs/force_boxplot.png" alt="不同条件下的实验结果"></p>
<blockquote>
<p><strong>图5</strong>：各种条件下的基线、导纳控制和本文方法的结果。接触百分比表示施加力按压海绵的时间步比例，括号内的数字表示z方向平均力与对应演示（参考力）平均力的比值。</p>
</blockquote>
<p><strong>关键定量结果</strong>：主要评估指标是施加的z方向力与演示中参考力的匹配程度（比值越接近100%越好）以及接触时间百分比（越高越好）。如图5所示：</p>
<ul>
<li>在<strong>应用参考力</strong>方面，本文方法在所有40个场景中的平均比值达到<strong>96%<strong>，显著优于仅达到</strong>4%</strong> 的基线方法和<strong>42%</strong> 的导纳控制方法。</li>
<li>在<strong>保持接触</strong>方面，本文方法和导纳控制均能达到100%的接触时间，而基线方法的平均接触时间仅为14%。</li>
<li>导纳控制虽然能保持接触，但施加的力普遍不足（平均仅为参考力的42%），且其性能在不同海绵间波动较大。本文方法则能更准确地匹配参考力，并对未见过的海绵和高度表现出良好的适应性。</li>
</ul>
<p><img src="https://arxiv.org/html/2505.06451v1/extracted/6426510/imgs/execution.png" alt="不同设置下的操作过程"></p>
<blockquote>
<p><strong>图3</strong>：使用一块未见过的海绵在三种不同设置（低、高、斜坡）下的操作过程。右侧图表显示了力扭矩曲线。基线方法（灰色）简单地跟踪演示，不考虑设置变化。相比之下，本文方法（红色）能够适应这些变化，同时保持期望的擦拭运动。</p>
</blockquote>
<p><strong>定性结果</strong>：图3直观展示了本文方法相较于基线的优势。在表面高度变化时，基线方法因开环控制而失去接触或施加错误大小的力；本文方法则能通过力扭矩反馈在线调整垂直位置，维持合适的接触力并完成擦拭轨迹。</p>
<p><strong>消融实验</strong>：</p>
<ul>
<li><strong>网络层深度</strong>（图9）：增加FT编码器φ_ft的TCN层数（1层 vs 2层）和垂直解码器θ_height的全连接层数（1层 vs 2层）能提升性能，2层架构最佳。</li>
<li><strong>力扭矩历史窗口大小</strong>（图10）：使用5个时间步的窗口（当前及前4步）比仅使用当前时刻能获得更低的预测误差。</li>
<li><strong>演示数据量</strong>（图11）：仅用1次演示训练时，性能（参考力比值83%）已显著优于基线，使用5次演示可进一步提升至96%，表明方法具有小样本学习能力。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个结合预训练物体物理属性表征与实时力扭矩反馈的框架，使机器人能够通过少量人类演示，动态适应环境变化（表面高度和物体属性）。</li>
<li>将先前开环的模仿学习方法扩展为闭环控制策略，使其能够处理目标力和位置均未知的场景，特别适用于可变形和弹性物体。</li>
<li>在真实硬件上通过系统的擦拭实验验证了方法的有效性，展示了其对未见过的海绵和表面高度变化的强适应能力。</li>
</ol>
<p><strong>局限性</strong>：论文提到，该方法假设海绵的物理属性在单次任务执行过程中保持不变。此外，依赖预定义的探索动作来获取物体表征。</p>
<p><strong>后续启示</strong>：本工作展示了利用模拟预训练和小样本真实数据学习接触密集型任务自适应策略的可行性。将类似的框架扩展到其他需要精细力交互的操作任务（如装配、打磨）是一个自然的方向。此外，探索更自动化的探索动作生成，或结合视觉等其他模态来感知环境变化，可能进一步提升系统的通用性和实用性。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人在执行擦拭等接触丰富任务时，难以适应表面高度和海绵物理属性变化的核心问题，提出一种结合实时力-扭矩反馈和预训练对象表示的少样本模仿学习方法。该方法通过预训练海绵属性编码器学习对象特征，并利用力-扭矩反馈动态调整操作策略。真实世界实验显示，该方法在应用参考力时达到96%的准确率，显著优于无反馈方法的4%，在40个涉及不同海绵和表面高度的场景中验证了其强大的适应性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.06451" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>