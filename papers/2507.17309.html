<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Confounded Causal Imitation Learning with Instrumental Variables - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Confounded Causal Imitation Learning with Instrumental Variables</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.17309" target="_blank" rel="noreferrer">2507.17309</a></span>
        <span>作者: Zhi Geng Team</span>
        <span>日期: 2025-07-23</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>模仿学习（IL）旨在通过模仿专家示范来学习决策策略，在奖励函数难以设计的复杂任务中具有广泛应用。然而，从示范中学习策略通常会受到未测量变量（即未测量混淆因子）对状态和动作的混淆效应影响。忽略这些混淆因子将导致对策略的有偏估计。现有基于因果推断处理混淆问题的方法中，Swamy等人（2022）提出的TCN模型利用前一时刻状态作为工具变量（IV），并发展了DoubIL和ResiduIL算法。但该方法的核心局限在于其严格的时间假设：每个混淆因子只能影响两个相邻的动作，即混淆被限制在单个时间步内。然而，在现实场景中，混淆因子可能持续影响多个时间步，例如驾驶员的分心可能持续多个交通交互过程。一旦混淆持续超过一个时间步，过去状态作为工具变量的有效性便不再成立。</p>
<p>本文针对现有方法无法处理多时间步持续混淆效应的痛点，提出了一个更具一般性的混淆因果模仿学习模型。本文的核心思路是：首先，提出一个允许混淆因子影响任意长度动作序列的模型，并建立基于辅助残差变量的检验准则，从观测数据中识别有效的工具变量；其次，基于识别出的工具变量，设计一个两阶段的模仿学习框架进行策略优化。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的混淆因果模仿学习模型称为C2L模型，其核心是允许潜在混淆因子影响跨越多个时间步的动作序列。</p>
<p><img src="https://arxiv.org/html/2507.17309v1/x3.png" alt="C2L模型示意图"></p>
<blockquote>
<p><strong>图3</strong>：提出的混淆因果模仿学习（C2L）模型。潜在混淆因子会影响连续τ个时间步的动作，例如$u_{t-\tau}$会影响$a_{t-\tau}, ..., a_{t-1}$和$a_t$。红色箭头表示来自多个混淆因子$u_{t-\tau}, ..., u_{t-1}$对状态$s_t$和动作$a_t$的混淆效应流，导致对策略π的有偏估计。目标是找到有效的工具变量$s_{t-\tau}$来消除这种混淆。</p>
</blockquote>
<p>在该模型下，状态和动作的生成机制遵循结构因果模型。当前动作$a_t$受到当前状态$s_t$和当前及过去τ个混淆因子$u_t, ..., u_{t-\tau}$的影响。这些混淆因子同时通过过去的动作和动力学模型影响当前状态$s_t$，从而在$s_t$和$a_t$之间产生混淆。此时，近期状态$s_{t-1}, ..., s_{t-\tau+1}$由于与混淆因子相关，成为无效的工具变量。理论上，$s_{t-\tau}$可能是满足相关性、排他性和外生性三个假设的有效工具变量，但参数τ未知。</p>
<p>为解决有效工具变量的识别问题，本文首先提出了一个基于辅助的检验准则。</p>
<p><strong>定义1（基于辅助的检验准则，AB Criterion）</strong>：给定当前状态$s_t$、动作$a_t$和候选的历史状态$s_k$，定义辅助残差变量$\mathcal{R}<em>{s_t,a_t||s_k} := a_t - l(s_t)$，其中$l(\cdot)$满足$\mathbb{E}[\mathcal{R}</em>{s_t,a_t||s_k} \mid s_k] = 0$且$l(\cdot) \neq 0$。如果$\mathcal{R}_{s_t,a_t||s_k}$独立于$s_k$，则称${s_t, a_t || s_k}$满足AB准则。</p>
<p><strong>定理1（IV有效性的必要条件）</strong>：在C2L模型中，如果$s_k$是相对于$s_t \to a_t$的有效工具变量，那么${s_t, a_t || s_k}$总是满足AB准则。这意味着，违反AB准则的候选变量一定是无效的工具变量。</p>
<p>为了获得充分条件，论文在线性模型下引入了<strong>部分非高斯性假设</strong>，要求至少有一个影响状态的潜在混淆因子或状态噪声项服从非高斯分布。该假设至关重要，因为在所有噪声均为高斯分布时，仅凭二阶统计量无法区分无效的工具变量（引理1）。而非高斯性使得可以利用更高阶的统计信息进行识别（引理2）。</p>
<p>基于上述理论，本文设计了一个两阶段的因果模仿学习框架。</p>
<p><img src="https://arxiv.org/html/2507.17309v1/x4.png" alt="两阶段框架总览图"></p>
<blockquote>
<p><strong>图4</strong>：提出的两阶段因果模仿学习框架概览。第一阶段：IV识别。使用AB准则检验不同的候选历史状态$s_{t-k}$，通过条件独立性测试找出有效的工具变量$\hat{Z}$。第二阶段：策略学习。在识别出有效IV后，提出两种策略优化方法：1）基于模拟器的方法（Simulator-based），在模拟环境中使用两阶段最小二乘（TSLS）估计器进行策略优化；2）离线方法（Offline），直接从观测数据中学习策略。</p>
</blockquote>
<p><strong>第一阶段：有效工具变量识别</strong><br>输入为观测到的状态-动作轨迹数据。对于每个候选的历史状态$s_{t-k}$（k为滞后阶数），算法执行以下步骤：1) 拟合一个函数$l(\cdot)$（如神经网络）来预测$a_t$，并使其满足残差$\mathcal{R}$在给定$s_{t-k}$下的条件期望为零；2) 对计算出的残差$\mathcal{R}$和候选变量$s_{t-k}$进行条件独立性检验（例如，使用基于核的测试）。选择能够通过独立性检验（即p值大于显著性水平）的$s_{t-k}$作为识别出的有效工具变量$\hat{Z}$。</p>
<p><strong>第二阶段：策略学习</strong><br>在获得有效工具变量后，论文提出了两种策略学习途径：</p>
<ol>
<li><strong>基于模拟器的方法</strong>：此方法需要与环境模拟器交互。它采用经典的两阶段最小二乘（TSLS）思想：首先，利用工具变量$\hat{Z}$对状态$s_t$进行回归，得到“净化”后的状态预测$\hat{s}_t$；然后，将$\hat{s}_t$作为输入，通过监督学习拟合专家动作$a_t$，从而得到策略π。该方法在模拟器中通过试错进行优化。</li>
<li><strong>离线方法</strong>：此方法完全从离线数据中学习，无需模拟器。其核心是构建一个加权损失函数。权重通过一个“权重网络”计算，该网络以工具变量$\hat{Z}$和状态$s_t$为输入，旨在纠正由于混淆造成的分布偏移。策略网络通过最小化加权后的动作预测误差进行训练。</li>
</ol>
<p>与现有方法（如TCN）相比，本文的创新点具体体现在：1）模型层面，放宽了混淆因子仅影响相邻动作的限制，允许持续多时间步的混淆，更具一般性；2）理论层面，提出了用于检验工具变量有效性的AB准则及其充分必要条件，为从数据中自动识别有效工具变量提供了理论保证；3）框架层面，将有效工具变量识别作为一个独立的、可计算的阶段，并提供了适应不同资源（有无模拟器）的策略学习方案。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在三个连续控制基准环境中进行：LunarLander、HalfCheetah和AntBulletEnv。通过向专家策略添加具有特定持续长度（τ）的时序相关噪声（TCN）来生成带有混淆的示范数据。</p>
<p><strong>对比方法</strong>：对比了行为克隆（BC）、生成对抗模仿学习（GAIL）以及最新的基于工具变量的方法TCN（包括其DoubIL和ResiduIL算法）。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>IV识别准确性</strong>：首先验证了第一阶段IV识别的有效性。在LunarLander环境中，当真实混淆长度τ=3时，本文方法能够以接近100%的准确率识别出正确的工具变量$s_{t-3}$，而将$s_{t-1}$或$s_{t-2}$误判为有效工具变量的概率极低。</li>
</ol>
<p><img src="https://arxiv.org/html/2507.17309v1/x5.png" alt="IV识别准确率"></p>
<blockquote>
<p><strong>图5</strong>：在LunarLander环境中，不同方法的IV识别准确率比较。C2L（Ours）能够准确识别出有效的工具变量（滞后阶数k=3），而基线方法（k=1）在τ=3的设置下识别的是无效工具变量。</p>
</blockquote>
<ol start="2">
<li><strong>策略性能对比</strong>：在混淆持续多时间步（τ=3）的设置下，评估学习到的策略在真实环境中的期望回报。</li>
</ol>
<p><img src="https://arxiv.org/html/2507.17309v1/x6.png" alt="LunarLander策略性能"></p>
<blockquote>
<p><strong>图6</strong>：在LunarLander环境（τ=3）中，不同方法的策略期望回报（J）对比。C2L-S（基于模拟器）和C2L-O（离线）均显著优于所有基线方法。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.17309v1/x7.png" alt="HalfCheetah策略性能"></p>
<blockquote>
<p><strong>图7</strong>：在HalfCheetah环境（τ=3）中，C2L方法在策略期望回报上大幅领先于基线方法。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.17309v1/x8.png" alt="AntBulletEnv策略性能"></p>
<blockquote>
<p><strong>图8</strong>：在AntBulletEnv环境（τ=3）中，C2L方法同样展现出最优的策略性能。</p>
</blockquote>
<ol start="3">
<li><strong>鲁棒性分析</strong>：测试了当混淆长度τ变化时（从2到5）方法的鲁棒性。如图1所示，当生成机制从2-TCN变为3-TCN时，TCN等方法性能显著下降，而C2L方法保持稳定。</li>
</ol>
<p><img src="https://arxiv.org/html/2507.17309v1/x1.png" alt="混淆长度变化下的性能"></p>
<blockquote>
<p><strong>图1</strong>：当训练示范的生成机制从单时间步混淆（2-TCN）变为多时间步混淆（3-TCN）时，各方法的均方误差（MSE）和策略值（J）变化。标记“New”的方法表示在3-TCN设置下的性能。C2L方法在两种设置下均表现良好，而TCN等方法在假设被违反（3-TCN）时性能严重退化。</p>
</blockquote>
<ol start="4">
<li><strong>消融实验</strong>：<ul>
<li><strong>IV识别阶段的重要性</strong>：比较了使用正确识别出的IV（k=3）与使用错误IV（k=1）的策略学习效果。使用错误IV导致性能大幅下降，与BC等基线方法相当，验证了正确识别IV的必要性。</li>
<li><strong>两种策略学习方法的比较</strong>：基于模拟器的方法（C2L-S）在大多数情况下优于离线方法（C2L-O），这符合预期，因为在线交互能获得更多信息。但离线方法在无法获取模拟器时提供了一个可行的替代方案。</li>
<li><strong>AB准则中函数l的选择</strong>：实验比较了使用线性函数与神经网络拟合l的效果，神经网络由于更强的表达能力，带来了更好的性能。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2507.17309v1/x9.png" alt="消融实验"></p>
<blockquote>
<p><strong>图9</strong>：消融实验结果。(a) 使用正确识别IV (Lag=3) 与错误IV (Lag=1) 的策略性能对比，正确IV至关重要。(b) 基于模拟器（C2L-S）与离线（C2L-O）方法对比，模拟器方法通常更优。(c) 使用线性与非线性函数拟合AB准则中的<code>l</code>，非线性（神经网络）效果更好。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个更具一般性的混淆因果模仿学习模型，允许混淆因子持续影响多个时间步的动作，突破了现有方法对单时间步混淆的限制。</li>
<li>建立了基于辅助残差变量的工具变量有效性检验准则，并在线性非高斯噪声假设下给出了有效工具变量识别的充分必要条件，为从纯观测数据中自动识别有效工具变量提供了理论基础和实用方法。</li>
<li>设计了一个两阶段学习框架，第一阶段进行工具变量识别，第二阶段提供了基于模拟器和离线的两种策略优化方案，并在多个实验环境中验证了其有效性。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ol>
<li>理论上的充分性检验依赖于<strong>部分非高斯性假设</strong>。虽然该假设在实际中常见，但在完全高斯噪声的场景下，仅凭AB准则可能无法确定性地识别出有效工具变量。</li>
<li>离线策略学习方法在性能上仍与基于模拟器的方法存在差距，表明在完全离线的设定下处理持续混淆仍有挑战。</li>
</ol>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li>探索在更弱的假设下（例如，允许部分噪声为高斯分布）进行工具变量识别的可能性。</li>
<li>改进离线策略学习方法，例如设计更稳健的加权方案或价值函数估计器，以进一步缩小与在线方法的性能差距。</li>
<li>将框架扩展到更复杂的混淆结构，例如时变的混淆强度或存在多个不同类型混淆因子的场景。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对模仿学习中未测量混杂变量导致策略估计偏差的核心问题，提出**混淆因果模仿学习（C2L）模型**。其关键技术是**利用工具变量（IV）** 解决混杂，并开发了一个**两阶段框架**：第一阶段通过定义伪变量构建测试准则，识别有效的工具变量；第二阶段利用识别出的IV，通过基于模拟器或离线的策略学习方法进行优化。实验验证了该方法在识别有效工具变量及学习策略方面的有效性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.17309" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>