<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>DexFormer: Cross-Embodied Dexterous Manipulation via History-Conditioned Transformer - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>DexFormer: Cross-Embodied Dexterous Manipulation via History-Conditioned Transformer</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.08278" target="_blank" rel="noreferrer">2602.08278</a></span>
        <span>作者: Zhang, Ke, Xu, Lixin, Song, Chengyi, Xu, Junzhe, Lin, Xiaoyi, Jiang, Zeyu, Xu, Renjing</span>
        <span>日期: 2026/02/09</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>灵巧操作是机器人领域的核心挑战，其难点在于高自由度手和臂在复杂、接触丰富的动力学下的协调控制。一个主要障碍是具身可变性：不同的灵巧手具有不同的运动学和动力学特性，迫使现有方法为每个具身训练单独的策略，或依赖共享动作空间配合每个具身的解码头。现有弥合仿真与现实差距的方法主要分为三大范式：系统识别（SysID）需要为每个新具身重复拟合参数；领域随机化（Domain Randomization）通过在广泛的物理和形态参数分布上训练策略来增强鲁棒性，但缺乏在测试时显式补偿具身特定动力学的机制；残差模型（Residual Models）学习未建模动力学的补偿，但依赖于收集具身特定的真实世界数据，无法直接实现零样本跨具身迁移。</p>
<p>本文针对缺乏能够零样本适应不同手形态、无需显式形态编码或重定向的闭环控制策略这一具体痛点，提出了一个新的视角：利用历史观察序列，通过序列模型隐式在线推断形态和动力学。其核心思路是：训练一个基于历史条件Transformer的单一策略，使其在广泛的、程序化生成的灵巧手形态分布上学习，从而通过时序上下文隐式推断具身特性，实现跨异构手具身的零样本泛化。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架将灵巧操作建模为一个部分可观测马尔可夫决策过程（POMDP），策略需要在不观测具身身份的情况下，从历史观察中推断形态相关的转移动力学。策略的输入是固定长度H的历史观测序列，输出是规范化的共享动作空间中的动作。该动作经平滑处理后，由具身特定的底层控制器执行。</p>
<p><img src="https://arxiv.org/html/2602.08278v1/transformer.png" alt="方法框架"></p>
<blockquote>
<p><strong>图3</strong>：历史条件Transformer策略架构。在每个时间步，一个固定长度为H的观测历史被作为输入并标记化为H个标记的序列。该序列由三层Transformer层（包含位置编码和因果自注意力）处理。提取最后一个标记的表示（它关注所有先前的历史），并将其传递给MLP动作头以参数化一个随机策略。然后从得到的分布中采样动作用于执行。</p>
</blockquote>
<p>核心模块包括：</p>
<ol>
<li><strong>共享动作空间</strong>：定义了一个基于解剖功能（如拇指外展、食指屈曲）的D_F维规范手指动作空间。不同具手将其原生关节命令通过固定嵌入算子P_e映射到对应的规范索引中，自由度较低的具手（如LEAP、Allegro）对未使用的规范维度进行零填充，而自由度较高的具手（如Rapid Hand）则完全占据该空间。这实现了跨异构具手的统一控制接口。输出的原始手指动作会经过一阶低通滤波平滑处理，再与机械臂的增量姿态动作合并为最终的高层动作。</li>
<li><strong>具身生成</strong>：通过对规范手（如Allegro, LEAP, RAPID）的形态参数（连杆长度、质量、惯性）进行程序化随机扰动，同时保持其运动学图拓扑和驱动结构不变，从而构造出一个包含大量随机变体的训练具身集合ℰ_train。这为策略提供了丰富的形态和动力学分布以供学习。</li>
<li><strong>历史条件Transformer</strong>：这是策略的核心架构。为了从单帧状态无法观测的隐变量（如形态参数）中推断信息，策略以有限历史窗口为条件。历史h_t由过去H步的观测序列构成。该序列被处理为H个时序标记，并辅以学习的位置编码，输入到一个Transformer编码器中。关键之处在于使用了因果自注意力掩码，确保每个标记只能关注其自身及之前的标记，防止未来信息泄露。Transformer输出上下文化的潜在嵌入序列，最后一个（对应当前时刻t）的嵌入作为历史的紧凑摘要，通过一个MLP动作头来产生动作分布。</li>
</ol>
<p>与现有方法相比，创新点在于：1) 提出了一个无需显式形态标识符或具身特定头、仅通过历史条件Transformer隐式适应不同动力学的端到端策略；2) 设计了一个基于解剖对应关系的共享动作空间，配合大规模形态随机化流程，为跨具身训练提供了可扩展的基础。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验平台使用Isaac Lab进行训练和评估。使用了三种规范手具身：Franka-Allegro、Franka-LEAP和Franka-RAPID。通过对每种规范手生成100个形态随机变体（共300个）构建训练集，并预留规范手及其额外的32个变体作为零样本测试集。任务涉及抓取10种不同的日常物体。评估指标为成功率（物体到达目标位置，误差小于0.05米）。对比的基线方法是使用LSTM和GRU作为时序记忆模块的循环策略。</p>
<p><img src="https://arxiv.org/html/2602.08278v1/train2.png" alt="训练与测试具身变体"></p>
<blockquote>
<p>**图5(a)**：训练具身变体（每种规范手各100个中的示例）。展示了用于训练DexFormer的多样化手形态。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.08278v1/objects.png" alt="测试物体"></p>
<blockquote>
<p><strong>图6</strong>：训练中使用的物体。展示了策略需要抓取的十种不同物体的示例。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ul>
<li><strong>主结果对比</strong>：经过4万回合训练后，DexFormer在三种规范手及其32个变体的测试集上，平均成功率达到77.50%，显著优于LSTM基线（58.72%）和GRU基线（44.29%）。这表明DexFormer在跨具身灵巧抓取任务上具有优越性能。</li>
<li><strong>历史长度消融</strong>：比较了使用1步历史与5步历史的DexFormer性能。在同等训练预算下，5步历史在LEAP和Allegro手上带来了明显的性能提升（如Allegro规范手从56.47%提升至74.19%），验证了利用时序上下文进行隐式推断的有效性。</li>
<li><strong>训练集多样性消融</strong>：研究了训练中使用的具身数量（25, 50, 100）对零样本泛化的影响。增加形态多样性显著提升了在未见具手上的性能，例如使用100个训练具身时，平均组合成功率从80.18%（25个）提升至84.09%。</li>
<li><strong>并行规模消融</strong>：分析了每个GPU上并行环境数量（1024, 2048, 4096）的影响。增加并行环境通常能提升性能（如平均成功率从69.24%提升至78.07%），但对RAPID手出现了性能波动，作者归因于训练时形态统计的不平衡。</li>
<li><strong>关节锁定鲁棒性测试</strong>：评估了策略在单个关节被锁定（失效）时的表现。结果显示，不同关节的锁定会导致不同程度的性能下降，远端屈曲关节（PIP/DIP）影响较小，而基础屈曲和拇指CMC关节影响显著。延长执行时间（从2秒到4秒）能在一定程度上补偿形态损伤。</li>
</ul>
<p><img src="https://arxiv.org/html/2602.08278v1/x1.jpg" alt="零样本性能对比表"></p>
<blockquote>
<p><strong>表II</strong>：与LSTM和GRU基线的零样本性能对比。DexFormer在所有手型和设置下均取得最高成功率，平均达77.50%。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.08278v1/ADR_compare.png" alt="历史长度消融表"></p>
<blockquote>
<p><strong>表III</strong>：历史长度（1步 vs 5步）消融实验结果。5步历史在多数情况下提升了性能，尤其在Allegro手上提升显著。</p>
</blockquote>
<p><strong>真实世界评估</strong>：策略通过离线蒸馏后部署到搭载LEAP手的真实Franka机械臂上，使用双RealSense D435相机生成点云观测。部署的策略能够成功抓取物体并将其移动到目标位置。</p>
<p><img src="https://arxiv.org/html/2602.08278v1/leap_reducted_3.png" alt="真实世界评估"></p>
<blockquote>
<p><strong>图8</strong>：DexFormer策略的真实世界评估。展示了在真实LEAP手和Franka臂上执行抓取任务的设置。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) 提出了DexFormer，一个基于历史条件Transformer、在大规模手具身上训练的跨具身灵巧操作策略，能够执行隐式形态推断以实现自适应控制；2) 开发了一个大规模形态随机化流程和用于灵巧手跨具身训练的分布式训练框架；3) 实证表明，单一的无形态感知策略能够零样本泛化到未见的灵巧具身和多个真实灵巧手上，无需手动重定向、显式形态编码或单独的策略头。</p>
<p>论文自身提到的局限性包括：分布式训练中，由于形态统计可能不平衡，可能对某些手具身（如RAPID）的零样本性能产生负面影响。</p>
<p>对后续研究的启示在于：证明了历史条件建模（尤其是Transformer）能够有效地从时序交互中隐式学习潜在的物理结构（如形态和动力学），为实现可扩展的、通用的跨机器人平台策略学习提供了一个有前景的方向。同时，大规模程序化形态随机化是获得强大零样本泛化能力的关键。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对灵巧操作中因不同机械手运动学/动力学差异导致的“具身变异性”问题，提出DexFormer。该方法基于改进的Transformer架构，通过历史观测序列实时推断形态与动力学，生成适应特定机械手的控制指令。实验表明，单个DexFormer策略在Leap Hand、Allegro Hand和Rapid Hand等多种异构灵巧手上实现了零样本泛化，为跨具身灵巧操作提供了可扩展的解决方案。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.08278" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>