<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>DexVLG: Dexterous Vision-Language-Grasp Model at Scale - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Computer Vision and Pattern Recognition (cs.CV)</span>
      <h1>DexVLG: Dexterous Vision-Language-Grasp Model at Scale</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.02747" target="_blank" rel="noreferrer">2507.02747</a></span>
        <span>作者: He, Jiawei, Li, Danshi, Yu, Xinqiang, Qi, Zekun, Zhang, Wenyao, Chen, Jiayi, Zhang, Zhaoxiang, Zhang, Zhizheng, Yi, Li, Wang, He</span>
        <span>日期: 2025/07/03</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前基于梯度的灵巧抓取合成方法常使用可微分力闭合（DFC）作为优化目标，以鼓励生成稳定的抓取姿态。然而，标准的DFC假设所有接触点施加的接触力大小相等，这一简化限制了合成抓取姿态的质量，可能导致指尖倾斜、接触点漂移等不自然的姿态。本文针对DFC优化中因等效力假设导致的姿态失真问题，提出了线性规划增强的可微分力闭合（LP-based DFC）优化方法。本文的核心思路是：通过结合物体部件语义分割、基于部件几何先验的灵巧手初始化策略，以及改进的力闭合优化能量，在大规模3D资产库上自动化合成高质量、语义对齐的灵巧抓取数据集，并基于此训练视觉-语言-抓取模型。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文方法的核心是构建大规模、高质量的灵巧抓取数据集（DexGraspNet 3.0）的pipeline，其关键在于数据生成过程中的优化方法与初始化策略。</p>
<p><img src="https://arxiv.org/html/2507.02747v1/extracted/6593799/img/DFC.jpg" alt="LP-based DFC与DFC对比"></p>
<blockquote>
<p><strong>图1</strong>：LP-based DFC与原始DFC的定性对比。左侧：DFC产生了指尖倾斜和接触点漂移等伪影（红色高亮）。右侧：LP-based DFC生成了更自然、更符合物体几何形状的姿态（绿色高亮）。两种抓取姿态从相同的初始姿态开始优化，仅优化时使用的DFC版本不同。</p>
</blockquote>
<p>整体流程首先对物体进行预处理与部件分割，然后为每个部件生成大量遵循几何先验的初始手部姿态，最后通过基于能量的优化（核心是LP-based DFC）合成最终抓取姿态。</p>
<p><strong>核心模块1: LP-based DFC优化</strong><br>原始的DFC能量定义为 (E_{fc} = |Gc|<em>2)，其中 (G) 是抓取矩阵，(c) 是由接触点法向量近似的等效力向量。LP-based DFC对此进行了改进。在优化每一步，首先固定手部姿态，通过线性规划求解各接触点的最优力大小 (\mathbf{f})，以最小化施加到物体上的净外力矩：(P = \min</em>{\mathbf{f}} |G(\mathbf{f} \odot c)|_2)，约束条件为 (\max_i(\mathbf{f})_i = 1) 且 ((\mathbf{f})<em>i \geq 0)。然后，根据净外力矩 (P) 和求解的力向量 (\mathbf{f})，动态调整优化能量：<br>[<br>E</em>{FC} = \left{ \begin{aligned} &amp;|G(\mathbf{f} \odot c)|<em>2, &amp;\text{if } P &lt; \tau</em>{FC} \text{ and } \min_i(\mathbf{f})_i \geq \tau_f \ &amp;|Gc|_2, &amp;\text{otherwise} \end{aligned} \right.<br>]<br>当当前姿态已接近稳定（(P) 小且各点力非零）时，使用考虑力大小的能量；否则使用原始DFC能量进行高效搜索。如图1所示，该方法能生成更自然的抓取姿态。</p>
<p><strong>核心模块2: 正则化能量</strong><br>为了在优化过程中避免不良行为，引入了多项正则化能量：穿透能量 (E_{pen})、自穿透能量 (E_{spen})、关节限位能量 (E_{limit})，以及鼓励手-物接触点法向与手部网格前表面法向对齐的方向能量 (E_{dir} = \sum_{i=0}^{n}(1 - c_i \cdot N_i))。总正则化能量为各加权项之和：(E_{reg} = \omega_{limit}E_{limit} + \omega_{pen}E_{pen} + \omega_{spen}E_{spen} + \omega_{dir}E_{dir})。</p>
<p><strong>核心模块3: 物体预处理与部件对齐初始化</strong><br>数据集的构建始于从Objaverse中过滤和预处理物体。使用GPT-4o结合多视图图像判断物体是否适合抓取。对合格物体进行水密性重网格化和凸分解，并使用SAMesh进行语义部件分割。分割后的部件由GPT-4o生成语义标注（如图2所示）并合理缩放。</p>
<p><img src="https://arxiv.org/html/2507.02747v1/extracted/6593799/img/seg.png" alt="部件分割与标注"></p>
<blockquote>
<p><strong>图2</strong>：部件分割和GPT生成的部件标注可视化示例。</p>
</blockquote>
<p>抓取合成针对每个物体部件进行。关键创新在于根据部件的几何特征（通过其定向包围盒分析）将其分类，并设计不同的初始化策略来对齐手掌姿态：</p>
<ol>
<li><strong>盖状部件</strong>：如旋钮、盖子。手掌从抓取点后退，方向垂直于部件主轴。</li>
<li><strong>盘状部件</strong>：如底座、桌面。手掌前表面垂直于抓取点法向，手掌向上方向对齐部件主轴。</li>
<li><strong>L形部件</strong>：如耳机头梁、水壶手柄。手掌前表面垂直于抓取点法向，手掌向上方向指向部件包围盒中心。</li>
<li><strong>轴状部件</strong>：如工具手柄、连接杆。手掌前表面垂直于抓取点法向，手掌虎口方向对齐部件主轴。</li>
</ol>
<p><img src="https://arxiv.org/html/2507.02747v1/extracted/6593799/img/supp_init_lid.png" alt="不同部件类型的初始化策略可视化"></p>
<blockquote>
<p><strong>图4</strong>：盖状部件初始化示例。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.02747v1/extracted/6593799/img/supp_init_disk.png" alt="不同部件类型的初始化策略可视化"></p>
<blockquote>
<p><strong>图5</strong>：盘状部件初始化示例。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.02747v1/extracted/6593799/img/supp_init_L.png" alt="不同部件类型的初始化策略可视化"></p>
<blockquote>
<p><strong>图6</strong>：L形部件初始化示例。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.02747v1/extracted/6593799/img/supp_init_shaft.png" alt="不同部件类型的初始化策略可视化"></p>
<blockquote>
<p><strong>图7</strong>：轴状部件初始化示例。</p>
</blockquote>
<p>此外，还预设了两种手部初始关节姿态和接触候选点集，分别对应<strong>包裹抓取</strong>（Ours-Wrap，接触点位于5指尖和手掌）和<strong>捏取抓取</strong>（Ours-Pinch，接触点位于拇指、食指、中指和手掌），以合成不同风格的抓取。</p>
<p><img src="https://arxiv.org/html/2507.02747v1/extracted/6593799/img/canonical.jpg" alt="初始手部关节位置与接触候选点"></p>
<blockquote>
<p><strong>图3</strong>：手部初始关节位置和接触候选点可视化。左：Ours-Wrap分割（7个接触点）；右：Ours-Pinch分割（4个接触点）。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p>本文构建了DexGraspNet 3.0数据集，并进行了数据集质量评估与模型训练的消融实验。</p>
<p><strong>数据集与评估基准</strong>：数据集从Objaverse过滤生成，包含约17.4万个物体，1.7亿个抓取姿态，每个姿态配有部件语义描述。评估时使用了模拟穿透深度（Pen）、自穿透深度（SPen）和稳定性度量Q1来评估抓取质量。</p>
<p><strong>对比Baseline与关键结果</strong>：将DexGraspNet 3.0（分为Ours-Wrap和Ours-Pinch）与现有灵巧抓取数据集（DexGraspNet, DexGYS, SemGrasp, Multi-GraspLLM）进行对比。</p>
<ul>
<li><strong>数据集质量</strong>：如表2所示，DexGraspNet 3.0在穿透（Pen: 1.75mm/1.42mm）和自穿透（SPen: 0.19mm/0.22mm）方面显著低于其他数据集，表明其抓取姿态的物理合理性更高。其Q1稳定性度量（0.085/0.067）与侧重稳定性的“力量抓取”数据集相当，同时兼顾了语义对齐的目标。</li>
</ul>
<pre><code>Method        Scale     Pen(mm)↓ SPen(mm)↓ Q1↑
DexGraspNet    1.32M     13.5      0.93    0.114
Ours-Wrap      103M      1.75      0.19    0.085
Ours-Pinch     67M       1.42      0.22    0.067
</code></pre>
<blockquote>
<p><strong>表2</strong>：数据集评估对比。DexGraspNet 3.0在穿透和自穿透指标上表现优异。</p>
</blockquote>
<p><strong>消融实验</strong>：</p>
<ol>
<li><strong>抓取风格消融</strong>：如表3所示，在多个测试集上，包裹抓取（Wrap）的成功率（Suc）和部件可抓取性（PGA）均显著高于捏取抓取（Pinch）。例如，在LVIS-Seen数据集上，Wrap的Suc为87.7%，PGA为62.1%，而Pinch的Suc为71.8%，PGA为20.2%。这表明包裹抓取更稳定、有效，而捏取抓取在稳定性上存在挑战。</li>
<li><strong>去噪范式消融</strong>：在姿态预测模型中（表4），流匹配（FlowMatching）范式显著优于DDPM和DDIM扩散模型。在LVIS-Seen数据集上，FlowMatching的Suc（75.3%）和PGA（39.1%）远高于DDPM（51.9%， 7.8%）和DDIM（57.7%， 12.5%），表明流匹配更易于学习姿态生成。</li>
</ol>
<p><img src="https://arxiv.org/html/2507.02747v1/extracted/6593799/img/alignment.jpg" alt="随机初始化与部件对齐初始化对比"></p>
<blockquote>
<p><strong>图9</strong>：随机初始化（绿色）与部件对齐初始化（红色）合成抓取姿态的对比。部件对齐初始化注入了关于自然抓取姿态的先验，使得优化后的抓取姿态更自然、语义更清晰。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.02747v1/extracted/6593799/img/prompt_part.png" alt="部件标注提示词"></p>
<blockquote>
<p><strong>图10</strong>：用于GPT-4o查询物体部件名称的提示词示例，采用Set-of-Marks提示方法。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.02747v1/extracted/6593799/img/prompt_size.png" alt="物体尺寸估计提示词"></p>
<blockquote>
<p><strong>图11</strong>：用于GPT-4o查询物体合理尺寸的提示词示例。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) 提出了LP-based DFC优化方法，通过线性规划考虑接触力大小，改善了基于DFC优化生成的抓取姿态的自然度；2) 设计了一套基于物体部件几何分类的灵巧手初始化策略，将人类抓取先验注入优化过程，生成了语义对齐、自然度高的抓取姿态；3) 构建了迄今为止规模最大、质量高、富含部件语义标注的灵巧抓取数据集DexGraspNet 3.0。</p>
<p>论文自身提到的局限性体现在泛化能力上：消融实验表明，无论是包裹抓取还是捏取抓取，在未见过的物体上性能均有所下降，这揭示了模型泛化的挑战。</p>
<p>本文对后续研究的启示在于：1) 在灵巧抓取合成中，结合物体语义和几何先验进行初始化是提升抓取自然性和任务相关性的有效途径；2) 对物理优化目标（如力闭合）进行可微分的、更精细的建模（如LP-based DFC）可以显著提升合成姿态的质量；3) 大规模、高质量、富语义的数据集是训练视觉-语言-抓取模型的基础，自动化数据构建流程至关重要。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本论文提出DexVLG模型，旨在解决大规模灵巧视觉-语言-抓取任务中生成稳定抓取姿态的核心问题。关键技术方法包括基于能量的优化，其中关键使用可微分力闭合（DFC）作为能量项，表达式为 \( E_{fc} = \|Gc\|_2 \)，通过梯度下降优化接触法向向量和位置，以实现力闭合的稳定抓取。提供的节选内容未包含实验结论或性能提升数据。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.02747" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>