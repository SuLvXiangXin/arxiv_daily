<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Evaluating the Robustness of Open-Source Vision-Language Models to Domain Shift in Object Captioning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Evaluating the Robustness of Open-Source Vision-Language Models to Domain Shift in Object Captioning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.19579" target="_blank" rel="noreferrer">2506.19579</a></span>
        <span>作者: Tavella, Federico, Drinkwater, Amber, Cangelosi, Angelo</span>
        <span>日期: 2025/06/24</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，基于Transformer架构的视觉语言模型（VLM），如BLIP和Flamingo，通过在海量网络数据上训练，在图像描述等任务上取得了显著进展。然而，这些模型在基准数据集上的优异表现往往掩盖了其在真实世界部署中的一个关键挑战：对领域偏移（Domain Shift）缺乏鲁棒性。已有研究表明，VLM在面对常见的视觉干扰（如高斯噪声、运动模糊）或光照变化时性能会显著下降，并且容易出现物体幻觉问题。尽管已有工作通过在现有网络数据上添加人工扰动来证明这一点，但这些研究通常不涉及物理世界的根本性变化。</p>
<p>本文针对一个具体且物理现实的痛点展开研究：当物体的形状保持可识别，但其纹理和材料属性发生显著变化时（例如，从真实的多材料物体变为单一材料的3D打印物体），VLM的泛化能力如何。本文提出了一个系统性的实证研究，通过一个受控的物理领域偏移案例，评估开源VLM在单视图物体描述任务上的鲁棒性。核心思路是：比较VLM在描述一组真实多材料工具和一组形状相似但材质纹理迥异的3D打印物品时的性能，量化其因材质纹理变化而导致的性能退化。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文的评估流程旨在系统性地测试VLM在面对从真实物体到3D打印物体的物理领域偏移时的鲁棒性。整体框架分为数据准备、物体分割和描述生成三个主要阶段。</p>
<p><img src="https://arxiv.org/html/2506.19579v2/imgs/ICASSP.png" alt="评估流程"></p>
<blockquote>
<p><strong>图1</strong>：物体描述评估流程。首先使用Segment Anything Model 2 (SAM2) 从场景中分割出单个物体，然后将分割出的物体图像输入给视觉语言模型（VLM）生成描述。示例输出展示了性能的差异，包括成功识别（如“铸铁煎锅”）和常见的失败模式，例如VLM将螺栓误认为“电子元件”。</p>
</blockquote>
<p><strong>1. 数据构建：</strong><br>为了创建受控的领域偏移，研究使用了两个截然不同的物体集合。第一个集合包含10个由金属、木材等真实材料制成的日常工具（如铸铁锅、带木柄的锤子）。第二个集合包含10个对应的、形状相似但由单一塑料材料3D打印而成的物品。3D打印物品在纹理和材料属性上引入了显著变化，作为分布外（OOD）数据的代理，用以挑战模型的泛化能力。</p>
<p><strong>2. 物体分割：</strong><br>为了从场景图像中隔离出单个待描述的物体，研究采用了Segment Anything Model 2 (SAM2)。利用其零样本分割能力，在无需模型微调或手动标注的情况下，对桌面场景进行鲁棒的物体级解析。具体操作中，使用SAM2的自动模式生成密集的分割掩码，然后通过程序过滤掉小区域或包含其他掩码的掩码，确保每个掩码对应一个独立的物体。</p>
<p><strong>3. 描述生成（VLM评估）：</strong><br>研究评估了8个开源的、参数量小于350亿的VLM，以确保结果可在消费级硬件（RTX 4090 24GB VRAM）上完全复现。这些模型包括：SmolVLM2 (2.2B)、BLIP-2 (2.7B)、Gemma 3n E4B (4B)、LLaMA 3.2 (11B)、Mistral Small 3.1 (24B)、Gemma 3 (27B)、Qwen 2.5VL (32B) 和 LLaVA 1.6 (34B)。所有模型使用统一的提示词：“详细描述图像中的物体，用几句话。保持简洁、客观的语气。忽略背景。以下是一个示例：如果给你一张桌子上红苹果的图片，你的输出是：红苹果。”</p>
<p><strong>4. 评估指标：</strong><br>为了全面评估生成描述的质量，研究采用了多指标组合策略：</p>
<ul>
<li><strong>CLIPScore</strong>：基于ViT-B/32模型，衡量生成描述与图像本身的语义相似性。</li>
<li><strong>ROUGE</strong>：基于n-gram召回率，评估是否捕捉到基本词汇。</li>
<li><strong>CIDEr</strong>：衡量生成描述与人类共识（真实标注）的一致性，是图像描述任务的常用指标。</li>
<li><strong>BERTScore</strong>：使用<code>deberta-xlarge-mnli</code>模型计算，比较上下文嵌入，捕捉超越简单词汇重叠的语义。</li>
<li><strong>GPTScore</strong>：利用大语言模型，以真实标注为上下文，评估生成描述的可能性。</li>
</ul>
<p><strong>创新点：</strong> 与以往通过数字方式腐蚀现有数据来研究鲁棒性的工作不同，本文的创新在于引入了一个<strong>物理的、受控的领域偏移</strong>（从真实物体到3D打印物体），这更贴近现实世界中可能遇到的、因制造工艺或材料差异导致的外观变化。该方法为评估VLM对表面特征（纹理、材质）的依赖程度提供了一个直观且可复现的基准。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置：</strong> 实验在两个物体集（各10个物体）上进行单视图物体描述评估。使用了8个开源VLM作为测试对象，并采用CLIPScore、ROUGE、CIDEr、BERTScore和GPTScore五个指标进行综合评估。</p>
<p><strong>基线对比：</strong> 研究比较了上述8个VLM在同一任务上的性能，模型参数量从2.2B到34B不等，涵盖了不同的架构和规模。</p>
<p><strong>关键实验结果：</strong><br>定量结果（见表2）揭示了几个关键发现。最显著的结论是，几乎所有模型在描述3D打印物体时，性能都出现了<strong>一致且可量化的下降</strong>。这证实了材质纹理的领域偏移对VLM构成了重大挑战。性能下降在衡量人类共识的CIDEr指标上最为明显。例如，表现最好的Qwen 2.5 VL模型，其CIDEr分数从真实物体集的1.19骤降至3D打印物体集的0.68，降幅超过40%。BLIP2（从0.84降至0.31）和Gemma 3（从0.57降至0.16）也表现出类似的大幅下降。</p>
<p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIyMDBweCIgdmlld0JveD0iMCAwIDgwMCAyMDAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgPGRlc2M+VGhpcyBpcyBhIHBsYWNlaG9sZGVyIGZvciBUYWJsZSAyIGZyb20gdGhlIHBhcGVyLjwvZGVzYz4KICA8cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBmaWxsPSIjZmZmZmZmIiBzdHJva2U9IiMwMDAwMDAiIHN0cm9rZS13aWR0aD0iMSIvPgogIDx0ZXh0IHg9IjUwJSIgeT0iNTAlIiBmb250LWZhbWlseT0iQXJpYWwiIGZvbnQtc2l6ZT0iMTYiIHRleHQtYW5jaG9yPSJtaWRkbGUiIGRvbWluYW50LWJhc2VsaW5lPSJtaWRkbGUiPkZpZ3VyZSAyOiBRdWFudGl0YXRpdmUgcmVzdWx0cyBmb3IgdGhlIHNpbmdsZS12aWV3IG9iamVjdCBjYXB0aW9uaW5nIHRhc2suIFBlcmZvcm1hbmNlIGlzIGNvbXBhcmVkIGFjcm9zcyBlaWdodCBvcGVuLXNvdXJjZSBWTE1zIG9uIHRoZSBSZWFsLXdvcmxkIGFuZCAzRC1wcmludGVkIG9iamVjdCBzZXRzLiBBbGwgc2NvcmVzIGFyZSByZXBvcnRlZCBhcyBtZWFuIGFuZCBzdGFuZGFyZCBkZXZpYXRpb24gYWNyb3NzIHRoZSAxMCBvYmplY3RzIGluIGVhY2ggc2V0LjwvdGV4dD4KPC9zdmc+" alt="定量结果表"></p>
<blockquote>
<p><strong>表2</strong>：单视图物体描述任务的定量结果。比较了八个开源VLM在真实世界和3D打印物体集上的性能。所有分数以各集合10个物体的平均值和标准差报告。对于CLIPScore、ROUGE、CIDEr和BERTScore，分数越高越好。对于GPTScore，分数越接近零表示性能越好。每个VLM和物体集在特定指标上表现最佳的模型已加粗显示。</p>
</blockquote>
<p>该图表清晰地展示了所有模型在3D打印集上CIDEr和BERTScore的普遍下降，尤其是CIDEr的降幅显著。同时，该表也建立了模型间的性能层次：Qwen 2.5 VL (32B) 是表现最出色的模型，在真实物体集上取得了最高的ROUGE、CIDEr和BERTScore，并在更具挑战性的3D打印集上保持了CIDEr和BERTScore的领先优势。而LLaMA 3.2 (11B) 和 LLaVA 1.6 (34B) 则 consistently 排名靠后。有趣的是，参数量仅2.2B的SmolVLM2在3D集上的ROUGE表现具有竞争力，甚至超过了34B的LLaVA 1.6，表明模型规模并非决定性能的唯一因素。</p>
<p><strong>定性分析：</strong><br>定性示例生动地展示了定量结果背后的语义漂移。对于真实物体，表现好的模型能生成准确描述。然而，对于3D打印物体，描述经常出现关键性误识别。例如，对于真实标注为“塑料绿色螺丝刀”的物体，Gemma 3n生成了“绿色塑料开瓶器”；对于“塑料绿色翼形螺栓”，Gemma 3甚至生成了“绿色牛油果”。这些错误导致了极低的CIDEr分数（分别为0.08和0.0）。</p>
<p><strong>评估指标分析：</strong><br>研究还对评估指标本身在物理领域偏移背景下的有效性进行了批判性分析：</p>
<ul>
<li><strong>ROUGE &amp; CIDEr</strong>：有效捕捉了主要性能下降趋势，CIDEr对语义漂移尤其敏感。但它们可能惩罚有效的改写，且无法完全捕捉句子结构质量。</li>
<li><strong>BERTScore</strong>：擅长捕捉语义相似性和识别改写，但在此任务中区分度较低，所有模型的分数聚集在一个小范围内，难以清晰区分顶级模型。</li>
<li><strong>GPTScore</strong>：作为基于LLM的最新指标，旨在提供更全面的质量判断，但结果显示其存在不可靠性。它有时未能惩罚事实错误的描述，反而因描述流畅而给出较高分数（例如将“黑色塑料翼形螺栓”误描述为“深棕色椭圆形糖壳”仍获得相对较高的GPTScore -3.83）。</li>
<li><strong>CLIPScore</strong>：在此评估中被证明完全不适合。其分数在“真实”和“3D”物体集之间几乎没有变化，对旨在测量的领域偏移不敏感，因此被排除在主要分析之外。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献：</strong></p>
<ol>
<li><strong>建立了物理领域偏移的基准</strong>：首次通过系统性的实证研究，利用真实物体与3D打印物体的对比，量化了开源VLM在面对材质纹理变化的物理领域偏移时的性能退化。</li>
<li><strong>揭示了VLM的泛化局限</strong>：明确证明了当前VLM严重依赖训练数据中的表面特征（如纹理、材质），在物体核心形状不变但表面属性变化时泛化能力不足，这对机器人、辅助技术等真实世界信号处理应用是关键的局限。</li>
<li><strong>评估了指标的有效性</strong>：批判性地评估了多种自动评估指标在此任务上的表现，指出CLIPScore不适用，GPTScore可能因流畅性而误判，强调了需要结合多种互补指标进行综合评估的重要性。</li>
</ol>
<p><strong>局限性：</strong><br>论文明确指出，实验仅在包含10个真实物体和10个3D打印物体的数据集上进行。虽然结果显示了清晰的趋势，但需要在更大、更多样的物体集上进行进一步验证以确立结论的普适性。此外，本研究仅聚焦于材质和纹理相关的领域偏移，未探索光照条件、场景杂乱等其他变化的影响。</p>
<p><strong>对后续研究的启示：</strong><br>本文的工作为未来研究开辟了多个方向。首先，需要开发能够减轻此类性能退化的方法，例如探索多视图策略、结合人类在环反馈或设计对材质纹理变化更加鲁棒的训练机制。其次，构建更大规模、涵盖更广泛领域偏移（如不同光照、视角、遮挡）的基准数据集至关重要。最后，开发能够更好权衡事实准确性与语言流畅性的评估指标，对于推动可靠的VLM评估协议和模型进步具有重要意义。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文评估了开源视觉语言模型（VLMs）在物体描述任务中对物理领域迁移的鲁棒性。核心问题是模型在脱离网络训练数据分布（如纹理、材质变化）时，性能是否稳定。研究方法为对比评估：在单视角物体描述任务中，使用真实多材料工具集和3D打印单材料物品集，后者构成显著的纹理与材质领域迁移。核心实验结论是，所有测试的VLMs在描述3D打印物体时，相比真实工具均表现出显著的性能下降，揭示了当前模型难以泛化超越表面特征的局限。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.19579" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>