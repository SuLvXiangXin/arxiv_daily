<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.01061" target="_blank" rel="noreferrer">2512.01061</a></span>
        <span>作者: Yuke Zhu Team</span>
        <span>日期: 2025-11-30</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人的全身移动操作（Loco-manipulation）是自主机器人领域的重大挑战。开门任务尤其典型，它要求机器人仅凭RGB视觉，就能完成从识别抓握位置、旋转弹簧门把手、跟踪门板运动到在铰链力作用下保持平衡等一系列紧密耦合的感知-动作协调。现有方法存在关键局限：许多系统依赖深度感知、物体中心特征或硬编码的动作基元；另一些则简化了接触力学或需要精确的物体定位；早期的系统严重依赖脚本和操作员干预，而基于遥操作的方法则泛化性差。这些设计无法为日常环境中多样化的移动操作技能提供可扩展的解决方案。尽管仿真、硬件和强化学习（RL）的进步在移动、运动模仿和灵巧操作上取得了显著成果，但将这些技术应用于需要协调感知、平衡、接触和导航的全身移动操作仍探索不足。</p>
<p>本文针对两个根本性挑战：1）算法本身必须简单、可扩展且对部分可观测性鲁棒，能够为多样化任务协调视觉和全身控制；2）视觉仿真到现实的鸿沟涵盖了巨大的外观和物理变化空间，需要广泛、异构的数据而非少数精心设计的场景。为此，本文提出了一个新颖、可扩展的教师-学生-自举（teacher-student-bootstrap）学习框架，其核心思路是：首先利用特权信息训练一个教师策略，然后通过交互式蒸馏将其知识迁移至仅使用RGB和本体感知的学生策略，最后通过基于GRPO的微调来弥补学生策略因部分可观测性带来的性能差距，并辅以大规模物理和视觉随机化来确保策略的泛化能力。</p>
<h2 id="方法详解">方法详解</h2>
<p>DoorMan的训练流程分为三个阶段，均在IsaacLab环境中交互式完成。</p>
<p><img src="https://..." alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：DoorMan训练流程。第一阶段：使用特权观测通过PPO训练教师策略。第二阶段：使用DAgger将教师策略蒸馏为基于RGB的学生策略。第三阶段：使用二元成功信号，通过GRPO进一步微调学生策略。</p>
</blockquote>
<p><strong>第一阶段：教师策略RL训练</strong>。教师策略π_T(a|s)在时间t可以访问仿真中的特权信息，包括真实的机器人根坐标系到门的变换ξ_RD、左右手到门把手的变换ξ_LD/ξ_RD、18个手部身体的净接触力τ_H以及根线速度v_R。其动作空间为33维（29个身体关节+14个手部关节），输出目标关节位置，由底层PD控制器跟踪。使用近端策略优化（PPO）进行训练，并设计了分阶段奖励系统，将开门任务分解为接近、开门、穿越等原子阶段。</p>
<p>为了应对接触丰富的操作任务中探索后期阶段困难、策略易“遗忘”前期技能的问题，本文引入了<strong>分阶段重置探索机制</strong>。其核心思想是利用仿真器的完全可恢复性：当环境进入一个新阶段时，会将该时刻场景中所有铰接和刚体物体的广义坐标快照缓存到一个滚动缓冲区（例如保留最近100个快照）。在重置时，机器人以非零概率被随机重置到初始阶段或某个中间阶段。这从初始分布上提高了下游状态在折扣占用度量中的权重，从而增加了对这些状态的梯度更新频率和有效幅度，显著提升了长视野任务的训练效率和稳定性。</p>
<p><img src="https://..." alt="分阶段重置探索"></p>
<blockquote>
<p><strong>图3</strong>：分阶段重置探索方案概述。当进入新阶段时，仿真的快照被缓存到缓冲区。任务重置时，环境通过从缓存加载被随机重置到先前的某个阶段。</p>
</blockquote>
<p><strong>第二阶段：学生策略蒸馏</strong>。学生策略π_S(a|o)仅能访问非特权观测，包括关节角度q、关节速度q̇、根角速度ω̇等本体感知，以及关键的RGB视觉输入。图像由视觉编码器处理，其潜在表示与本体感知特征拼接后，通过一个两层LSTM和一个三层MLP，最终映射为目标关节角度。视觉编码器与策略联合微调。采用DAgger进行交互式蒸馏，这能直接对学生策略的输入分布进行监督，相比仅覆盖教师分布的行为克隆更具优势。</p>
<p><strong>第三阶段：学生策略自举微调</strong>。由于学生策略的观测空间缺少关键特征（如遮挡），单纯的行为克隆损失可能无法达到最优性能。学生策略需要通过自身 rollout 来发现补偿部分可观测性的额外策略，例如调整机器人位置以使操作区域保持在相机视野中。为此，本文使用<strong>组相对策略优化（GRPO）</strong> 对学生策略进行微调。GRPO是一种无需价值函数的actor-only PPO变体，它从分组轨迹回报中估计基线。微调时主要使用二元任务成功信号，辅以关节速度、加速度和动作速率惩罚等简单整形奖励来规范人形行为。这使得GRPO成为一种轻量级、稳定的强化学习精炼阶段，能够弥补从特权演示模仿到鲁棒自主性能之间的差距。</p>
<p><strong>大规模仿真随机化</strong>。为了将视觉和动力学多样性扩展到前所未有的水平，本文在IsaacLab中设计了一个程序化生成流程，创建物理和视觉上多样且真实的铰接资产。<strong>物理变化</strong>包括5种门类型（推拉门、旋转把手等），并随机化门的尺寸、把手位置、铰链阻尼、把手阻力矩等，特别是模拟了真实的门闩机制。<strong>视觉变化</strong>则从PBR材质库中随机抽取纹理应用于所有表面，并使用5232个穹顶光纹理来模拟不同地点和时间。相机内外参也被对齐并轻微随机化。这种设计有意让策略暴露在广泛的变异范围内，而非重建特定真实场景，这是实现从仿真到现实可迁移人形移动操作的前提。</p>
<p><img src="https://..." alt="程序化生成的门"></p>
<blockquote>
<p><strong>图4</strong>：用于训练DoorMan的程序化生成门，涵盖了面板设计、闩锁机制、灯光、材质等。每个并行化环境都在一组独特的门参数上训练。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在仿真和真实世界中进行评估。使用了三种门类别：旋转把手推门、旋转把手拉门、推杆把手推门。视觉随机化使用留出集的纹理，真实世界场景在训练中未见过。机器人被随机放置在门前方1米处，面向门中心，偏航角在±0.3弧度内扰动。成功标准是机器人穿过门并到达门框另一侧1米外的点。</p>
<p><strong>Baseline对比</strong>：主要对比了<strong>人类遥操作基线</strong>。操作者使用与自主策略相同的全身控制器，通过VR头盔和摇杆进行逆运动学控制。操作者分为新手（经验&lt;1天）和专家（经验&gt;3个月）。</p>
<p><img src="https://..." alt="性能对比"></p>
<blockquote>
<p><strong>图5</strong>：在所有开门任务上的平均性能。左图：成功率（越高越好）。右图：任务流畅性，以完成开门任务所需时间衡量（越低越好）。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>超越人类遥操作</strong>：DoorMan在真实世界中的成功率为**83%<strong>，与专家操作者（80%）相当，比新手（60%）高出23个百分点。在任务流畅性（完成时间）上，DoorMan（平均15.40秒）比专家（20.02秒）快</strong>23.8%<strong>，比新手（22.55秒）快</strong>31.7%**。</li>
<li><strong>视觉随机化的影响</strong>：如表1所示，使用全部可用纹理和穹顶光随机化训练，在未见场景中获得了最佳泛化能力（各子任务成功率81-86%）。移除穹顶光随机化会导致性能下降15-30%。仅使用10%的纹理即可获得与使用100%纹理相近的性能（相差4-8%）。而完全不进行视觉随机化则使成功率骤降至5-20%，证实了纹理和光照随机化对仿真到现实泛化的有效性。仅使用纯色随机化（早期RGB sim-to-real工作的典型设置）可获得65.8-70%的成功率，与现代高保真渲染带来的更丰富材质光照变化相比仍有差距。</li>
</ol>
<p><strong>消融实验总结</strong>：</p>
<ul>
<li><strong>GRPO微调的效果</strong>：如图6a所示，初始学生策略性能停滞在50-70%，低于教师策略的80-90%。经过GRPO自举微调后，学生策略在各子任务上的成功率提升至80.8-85.8%，有效缩小了因部分可观测性导致的差距。</li>
<li><strong>分阶段重置探索的效果</strong>：如图6b所示，在教师训练中，使用大小为100的缓冲区能使策略快速探索所有阶段（约1700次迭代）。缓冲区大小为10时，探索需要超过4000次迭代。而不使用重置缓冲区时，探索失败，策略难以进入“抓握门把手”的第二阶段。</li>
</ul>
<p><img src="https://..." alt="训练进度"></p>
<blockquote>
<p><strong>图6</strong>：DoorMan训练进度：(a) 学生GRPO自举微调期间的成功率（虚线表示教师成功率）；(b) 在不同分阶段重置缓冲区大小（0， 10， 100）下的教师训练进度（达到的阶段数）。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了首个能够仅凭纯RGB感知完成多样化铰接物体移动操作的<strong>人形仿真到现实策略</strong>。</li>
<li>引入了一个用于全身移动操作的<strong>教师-学生-自举学习框架</strong>，其中包含用于稳定教师训练的<strong>分阶段重置探索机制</strong>，以及用于缓解学生策略部分可观测性的<strong>GRPO微调方法</strong>。</li>
<li>在IsaacLab中提供了一个<strong>物理精确且视觉多样的合成生成流程</strong>，专为并行和分布式RL工作流设计，能够大规模生成可交互的门环境。</li>
<li>实验表明，使用相同的全身控制器，该策略在任务完成时间上比人类遥操作快**31.7%**，突显了逼真仿真在扩展基于视觉的全身移动操作学习方面的潜力。</li>
</ol>
<p><strong>局限性</strong>：论文自身未明确陈述局限性，但根据方法描述可推断，该方法高度依赖于高质量的物理仿真（IsaacLab）和程序化生成内容，以及大规模并行计算资源进行训练。GRPO微调需要一个具有非零成功率的基策略。</p>
<p><strong>启示</strong>：本研究为纯视觉的人形复杂操作任务仿真到现实迁移打开了新的大门。其提出的分阶段探索和GRPO微调框架具有通用性，可应用于其他长视野、部分可观测的移动操作任务。大规模、多样化的仿真随机化被证明是实现零样本现实世界泛化的关键。这项工作表明，通过精心设计的仿真训练流程，自主策略的性能可以超越当前基于人类演示的方法。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人仅凭RGB视觉进行全身协调的移动操作（特别是开门）这一核心难题，提出了一种仿真到现实的策略迁移方法。关键技术包括：用于稳定长时程特权策略训练的分阶段重置探索策略，以及基于GRPO的微调程序以缓解部分可观测性并提升闭环一致性。实验表明，完全在仿真中训练的策略能零样本泛化至多种真实门类型，其任务完成时间比人类遥操作快31.7%，是首个仅用纯RGB感知实现多样化铰接移动操作的人形仿真到现实策略。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.01061" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>