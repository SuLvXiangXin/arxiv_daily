<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>RoboBenchMart: Benchmarking Robots in Retail Environment - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>RoboBenchMart: Benchmarking Robots in Retail Environment</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2511.10276" target="_blank" rel="noreferrer">2511.10276</a></span>
        <span>作者: Vlad Shakhuro Team</span>
        <span>日期: 2025-11-13</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前部署在现实世界中的机器人系统主要在受限环境中运行，通常执行单一特定任务。尽管这些系统具有经济价值，但未来机器人的真正潜力在于能在无约束、嘈杂的真实环境中运行、适应广泛变化并执行多任务的系统。零售业，特别是暗店（专门处理在线订单的零售配送中心），因其人机交互少、环境相对结构化且自动化需求迫切，被视为机器人近期有望大规模部署的应用领域。</p>
<p>然而，现有的机器人操作基准大多集中于简化的桌面或家庭场景，未能充分捕捉零售环境的复杂性。零售环境涉及在杂乱空间中操作、商品种类繁多、多层货架系统，并且需要先进的避障策略以防止对商品、货架和机器人自身造成损坏。针对这一空白，本文提出了RoboBenchMart，一个开源的模拟零售基准套件，旨在更准确地反映现实世界零售任务的复杂性。本文的核心思路是创建一个包含多样化商店布局生成、轨迹自动采样和标准化评估工具的完整基准套件，用以评估和推动零售场景下的机器人策略研究。</p>
<h2 id="方法详解">方法详解</h2>
<p>RoboBenchMart套件包含三个核心组件：商店布局生成器（Store Plan Generator）、轨迹采样器（Store Trajectories Sampler）和机器人基准测试（Store Robotics Benchmark）。</p>
<p><strong>整体框架</strong>：首先，商店布局生成器创建多样化的零售店场景（包括货架布局和商品摆放）。然后，轨迹采样器利用运动规划和强化学习在该场景中为特定任务自动生成机器人演示轨迹。最后，使用生成的轨迹对通用机器人模型进行微调，并在基准测试定义的多样化测试场景下评估其性能。</p>
<p><strong>核心模块1：商店布局生成器</strong><br>该模块旨在程序化生成逼真且多样的商店布局和商品摆放，包含三个子阶段：</p>
<ol>
<li><strong>货架随机初始放置</strong>：在矩形店铺区域内使用拒绝采样随机放置货架、托盘、冰箱等初始装置，确保无碰撞。</li>
<li><strong>商店张量场计算</strong>：受程序化街道建模启发，计算一个指导货架排列方向的张量场。其计算步骤为：(1) 提取店铺地板和已放置装置的边界多边形；(2) 为多边形上的每个点计算一个基础张量，该张量编码了边的长度和方向信息；(3) 通过对所有基础张量进行指数衰减加权求和，得到覆盖整个店铺布局的最终张量场。</li>
<li><strong>货架单元排列</strong>：根据张量场指示的局部方向，分水平和垂直两个阶段放置货架，确保布局有序、无碰撞且留有通道，并通过概率性跳过增加布局可变性。</li>
</ol>
<p><img src="https://arxiv.org/html/2511.10276v1/imgs/tf.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：商店布局生成流程。(a) 采样的张量场（颜色表示方向）；(b) 根据张量场排列的货架布局；(c) 最终生成的商店场景。</p>
</blockquote>
<p><strong>商品摆放</strong>：在生成的货架上，利用<code>scene_synthesizer</code>包检测可放置表面，并实现自定义模块将商品按规则网格摆放，同时引入微小姿态扰动和垂直堆叠以模拟真实感。该模块还能通过泊松过程在货架前端留下空位，模拟商品随时间消耗的过程。</p>
<p><img src="https://arxiv.org/html/2511.10276v1/imgs/day0_.png" alt="商品摆放示例"><br><img src="https://arxiv.org/html/2511.10276v1/imgs/day7_.png" alt="商品消耗模拟"></p>
<blockquote>
<p><strong>图3</strong>：商品摆放及随时间消耗的示例。从左至右展示了第1、2、4、8天的货架状态，模拟了商品被取走后的空位。</p>
</blockquote>
<p><strong>资产与纹理</strong>：收集了3个货架模型、2个冰箱模型和来自21个类别的370个商品3D资产，以及多种地板、墙壁和天花板纹理以增强视觉多样性。所有资产均经过手动尺度、方向标准化，并开发了自动网格简化流水线（结合QuadriFlow、Marching Cubes等方法）来优化高面数模型，以提升渲染性能。</p>
<p><img src="https://arxiv.org/html/2511.10276v1/imgs/01_canned_quick_cof_.png" alt="资产示例"><br><img src="https://arxiv.org/html/2511.10276v1/imgs/textures/g.png" alt="纹理示例"></p>
<blockquote>
<p><strong>图4</strong>：收集的商品资产示例（部分类别）。<br><strong>图5</strong>：使用的天花板、墙壁和地板纹理示例（部分变体）。</p>
</blockquote>
<p><strong>核心模块2：轨迹采样器</strong><br>该模块结合运动规划和强化学习自动生成机器人演示轨迹。</p>
<ol>
<li><strong>运动规划</strong>：为每个任务启发式定义一系列初始、中间和最终锚点姿态。在连续锚点之间的分段上，依次使用螺钉运动（不考虑障碍物）和RRT-Connect（考虑障碍物）进行规划。对于需要移动底座的阶段，则使用特定任务的启发式规划器。该管道平均成功率为60%。</li>
<li><strong>强化学习</strong>：为每个任务使用近端策略优化（PPO）训练单独的策略，利用完全环境状态信息，并设计包含接近目标、成功放置和避免碰撞等项的手动奖励函数。该管道平均成功率也为60%。</li>
</ol>
<p><img src="https://arxiv.org/html/2511.10276v1/imgs/mp1.png" alt="轨迹采样锚点"></p>
<blockquote>
<p><strong>图8</strong>：运动规划中使用的启发式生成锚点姿态示例，用于引导轨迹生成。</p>
</blockquote>
<p><strong>核心模块3：商店机器人基准测试</strong><br>基准基于高性能机器人仿真框架ManiSkill3构建，使用Fetch移动操作机器人（差分驱动底座、7自由度手臂、可升降躯干和平行夹爪）。基准定义了从简单到复杂的多种测试场景以评估策略泛化能力，包括：机器人起始位置随机化、纹理随机化、未见过的商店布局、未见过的货架排列、在其它任务中见过但在当前任务中未见的商品、完全未见过的商品。评估主要聚焦于前三种及“未见过的场景和物品”组合。</p>
<p><strong>任务设计</strong>：包含5个原子任务（“放入购物篮”、“从地上拾取”、“从一层搬到另一层”、“打开冰箱”、“关闭冰箱”）和2个复合任务（“拾取3件商品”、“从冰箱中拾取”）。成功标准不仅要求完成任务，还需确保周围物品未被扰动。</p>
<p><strong>创新点</strong>：与现有基准（见表1对比）相比，RoboBenchMart是首个专注于零售环境、并提供从场景生成、轨迹生成到策略评估完整工具链的开源基准。其商店布局生成方法引入了张量场引导的结构化排列，商品摆放模拟了真实消耗，轨迹生成结合了多种自动方法，并系统性地定义了零售场景下的泛化评估维度。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：基准使用Fetch机器人，在ManiSkill3仿真环境中进行评估。对比了三个先进的通用视觉-语言-动作（VLA）模型：轻量级Transformer模型Octo（93M参数），以及基于LLM的π0和π0.5（均为3.3B参数）。这些模型使用轨迹采样器生成的演示（每个任务-物品-装置三元组248条轨迹，总计2480条）进行模仿学习微调。评估时，每个三元组进行50次试验以计算平均成功率。</p>
<p><strong>关键实验结果</strong>：主要结果如表2所示（对应论文中的Table 2，用户提供的图片链接中<code>x1.png</code>和<code>x2.png</code>可能为此表的截图，但根据正文描述，此处以文字总结）。</p>
<p><img src="https://arxiv.org/html/2511.10276v1/x1.png" alt="实验结果表"><br><img src="https://arxiv.org/html/2511.10276v1/x2.png" alt="实验结果表续"></p>
<blockquote>
<p><strong>表2</strong>：通用VLA模型在不同测试场景下对原子任务和复合任务的平均成功率（%）。π0.5在“领域内”场景表现最佳，但在泛化场景下性能急剧下降，所有模型在复合任务上成功率均为0。</p>
</blockquote>
<ul>
<li><strong>领域内测试</strong>：仅随机化机器人起始位置。π0.5表现最好，在“放入购物篮”、“从地上拾取”等原子任务上成功率可达63%、44%、55%。Octo和π0表现较差。</li>
<li><strong>未见过的场景</strong>：增加了纹理和商店布局的随机化。所有模型性能均大幅下降。π0.5的成功率下降至38%、11%、22%；Octo和π0则接近失败。</li>
<li><strong>未见过的场景和物品</strong>：在“未见过的场景”基础上，加入在其它任务训练过但在当前任务未见过的物品。这是最具挑战性的泛化测试。仅π0.5在部分任务上取得非零成功率（10%、23%），其余模型均为0。</li>
<li><strong>复合任务</strong>：所有模型在“拾取3件商品”和“从冰箱中拾取”任务上的成功率均为0%，表明现有模型无法可靠执行多步骤指令或进行组合式执行。</li>
</ul>
<p><strong>结果总结</strong>：实验表明，当前最先进的通用模型即使在基本的零售任务上也表现挣扎。它们对微小的场景变化（布局、纹理）非常脆弱，从有限演示到新颖物品-任务组合的泛化能力差，且缺乏执行长视野、组合任务的能力。这揭示了现有预训练模型的能力与零售领域实际需求之间存在明显差距。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>RoboBenchMart</strong>，据作者所知是首个专注于零售环境的开源机器人基准测试套件，填补了该领域空白。</li>
<li>开发了<strong>程序化商店布局生成器</strong>和<strong>自动轨迹采样管道</strong>，能够大规模创建多样化的零售训练和评估环境。</li>
<li>利用该基准进行的评估<strong>首次系统性地揭示了当前先进通用VLA模型在零售场景下的严重不足</strong>，为后续研究指明了方向。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到：1）仅支持平行夹爪，未建模吸盘式或多指灵巧手；2）某些形状特殊的包裹可能无法抓取，且商品摆放预留了较大间隙以简化抓取，这在一定程度上牺牲了真实性；3）仅包含刚体物品，未涉及可变形物体带来的挑战。</p>
<p><strong>对后续研究的启示</strong>：实验结果强烈表明，直接在现有通用模型上进行微调不足以应对零售自动化需求。这指向了未来可能需要<strong>针对零售领域进行大规模、有针对性的预训练</strong>，以及开发<strong>对场景变化更鲁棒、能更好处理组合任务</strong>的新模型架构和学习范式。RoboBenchMart提供的工具和资产将为这一方向的研究奠定基础。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对现有机器人操作基准测试局限于简化桌面场景的问题，提出了RoboBenchMart基准测试，旨在评估机器人在真实零售环境（特别是黑暗商店）中的复杂操作能力。该环境挑战巨大，包括物品密集堆放和多样的空间布局。关键技术是发布了一套完整的RoboBenchMart工具包，包含程序化商店布局生成器、轨迹生成管道、评估工具和微调基线模型。核心实验结论表明，当前最先进的通用模型难以完成常见的零售任务，凸显了该基准的必要性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2511.10276" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>