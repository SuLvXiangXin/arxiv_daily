<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Towards Space-Based Environmentally-Adaptive Grasping - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Towards Space-Based Environmentally-Adaptive Grasping</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.21394" target="_blank" rel="noreferrer">2601.21394</a></span>
        <span>作者: Aleksandr Artemov Team</span>
        <span>日期: 2026-01-29</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人抓取在非结构化环境，特别是空间任务（如在轨服务、碎片清除）中，面临着严峻挑战。这些环境中的目标物体几何、质量分布、表面属性以及末端执行器形态可能各不相同，同时操作条件（接触力学、传感条件、动力学状态）也会在每次任务中发生变化。长期任务中，热循环、真空导致的摩擦学变化、辐射诱导的材料老化等环境效应会持续扰动感知和接触，而基于硬件的反复试错成本高昂或不可行。</p>
<p>当前主流方法存在关键局限性：经典的解析抓取合成方法依赖于精确的物体模型和接触参数，在分布偏移时非常脆弱；而基于学习的方法，特别是直接从高维感知输入（如图像、点云）训练强化学习策略，通常样本效率低下，对实现细节敏感。常用的缓解策略是领域/动力学随机化，但这仅将环境变化视为策略必须隐式平均处理的未观测随机性。</p>
<p>本文针对上述痛点，提出了一个结构化的新视角：如果环境/状态描述符是可测量或可指定的，则将其显式地作为策略的条件变量进行集成。本文的核心思路是：避免直接在原始观测空间学习控制，而是在一个紧凑、结构化的潜在空间中学习，该空间将异质输入融合为一个任务相关的“语法”，并显式地注入环境描述符，以实现跨状态的条件化零样本适应。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文方法的整体目标是，在每次任务开始时仅能获取一次高维外感受性快照（如RGB-D观测）的约束下，以最少的交互预算达到高抓取成功率。为此，系统构建为一个模块化流程：首先将异质任务信息压缩为紧凑的语法化潜在代码，然后在该低维空间中学习一个状态条件化的控制策略。</p>
<p><img src="https://arxiv.org/html/2601.21394v1/General/Flowchart.jpg" alt="方法流程图"></p>
<blockquote>
<p><strong>图1</strong>：端到端方法流程。展示了从初始观察<code>x_0</code>和环境向量<code>e</code>到最终抓取动作的完整过程。核心创新在于将环境描述符<code>e</code>显式集成到语法化潜在代码<code>z_C</code>中，并与几何状态<code>p_t</code>一同作为策略<code>π_θ</code>的输入。</p>
</blockquote>
<p>方法的核心模块与创新点如下：</p>
<ol>
<li><p><strong>环境嵌入作为策略输入</strong>：定义一个环境参数向量<code>ẽ ∈ ℝ^{d_e}</code>，并将其维度归一化到<code>[-1, 1]</code>区间得到<code>e</code>。在实验中，<code>ẽ</code>被实例化为在任务级别随机化的物理参数（如摩擦系数、质量缩放、重力、恢复系数、阻尼）。这种设计使得策略能够通过条件化，在不同状态间进行零样本适应，而无需为每个状态训练单独的策略或在线微调。</p>
</li>
<li><p><strong>状态增强的语法化控制状态</strong>：策略的输入从基线方法的<code>[z_0 || p_t]</code>扩展为<code>s_t = [z_0 || p_t || e]</code>。这是“环境适应”的核心机制，通过将当前任务状态<code>e</code>作为条件输入，使策略能够显式地适应不同的操作状态。</p>
</li>
<li><p><strong>结构化潜在拆分与四元数有效性</strong>：当任务需要方向推理时，在潜在表示中预留一个专用的四元数通道<code>z_q ∈ ℝ^4</code>，其余为<code>z_s</code>。对<code>z_q</code>应用确定性的单位范数投影<code>q = z_q / (||z_q||_2 + ε)</code>，以确保生成有效的旋转四元数，稳定涉及方向控制的优化过程。</p>
</li>
<li><p><strong>信息解耦与模块感知控制</strong>：为了减少语义不同子空间（如方向<code>z_q</code>与形状/状态<code>(z_s, e)</code>）之间的梯度干扰，引入了互信息正则化。具体采用基于InfoNCE的估计器并设置铰链上限，以限制<code>z_q</code>和<code>[z_s || e]</code>之间的信息泄漏。同时，策略网络采用模块感知的actor架构，为方向和非方向更新使用独立的头部。</p>
</li>
</ol>
<p>与现有方法相比，本文的创新点具体体现在：1) 将环境/状态向量<code>e</code>作为策略的显式条件输入，而非隐式处理随机化；2) 在语法化框架内集成了环境适应机制；3) 通过结构化潜在拆分和互信息解耦，提升了学习的稳定性和样本效率。</p>
<h2 id="实验与结果">实验与结果</h2>
<ul>
<li><strong>实验平台与数据集</strong>：实验在ManiSkill机器人操作基准（基于SAPIEN的仿真）上实现，支持GPU并行滚动以进行高通量训练。任务实例化为“抓取-抬起”。</li>
<li><strong>对比方法</strong>：<ul>
<li><strong>一次性视觉基线</strong>：使用从初始观测<code>x_0</code>直接提取的特征（如通过CNN）作为策略输入<code>[φ(x_0) || p_t]</code>。</li>
<li><strong>潜在基线</strong>：使用语法化潜在代码<code>z_0</code>作为策略输入<code>[z_0 || p_t]</code>。</li>
<li><strong>潜在+环境方法</strong>：本文方法，策略输入为<code>[z_0 || p_t || e]</code>。</li>
</ul>
</li>
<li><strong>关键实验结果</strong>：在持续变化的任务条件下，本文的潜在+环境方法在大约850万环境步数后达到了<strong>95%</strong> 的持续成功率。在相同的单次开环约束和训练预算下，一次性视觉基线的收敛速度<strong>明显更慢且不稳定</strong>。</li>
</ul>
<p><img src="https://arxiv.org/html/2601.21394v1/Grammarization/train__ep_success_rate_os.png" alt="训练成功率对比"></p>
<blockquote>
<p><strong>图7</strong>：一次性视觉基线的训练成功率曲线。收敛缓慢且不稳定。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.21394v1/Grammarization/train__ep_success_rate_l.png" alt="训练成功率对比"></p>
<blockquote>
<p><strong>图8</strong>：潜在基线的训练成功率曲线。性能优于视觉基线。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.21394v1/Grammarization/train__ep_success_rate_el.png" alt="训练成功率对比"></p>
<blockquote>
<p><strong>图9</strong>：本文潜在+环境方法的训练成功率曲线。收敛最快且最稳定，最终达到95%以上的成功率。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.21394v1/Grammarization/rollout__ep_rew_mean_os.png" alt="奖励均值对比"></p>
<blockquote>
<p><strong>图10</strong>：一次性视觉基线的平均奖励曲线。奖励增长缓慢。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.21394v1/Grammarization/rollout__ep_rew_mean.png" alt="奖励均值对比"></p>
<blockquote>
<p><strong>图11</strong>：潜在基线的平均奖励曲线。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.21394v1/Grammarization/rollout__ep_rew_mean_el.png" alt="奖励均值对比"></p>
<blockquote>
<p><strong>图12</strong>：本文潜在+环境方法的平均奖励曲线。奖励最高，表明策略性能更优。</p>
</blockquote>
<ul>
<li><strong>消融实验分析</strong>：通过对比“潜在基线”和“潜在+环境”方法，直接验证了显式环境条件化的贡献。实验结果表明，添加环境描述符<code>e</code>显著加快了学习收敛速度并提高了最终性能，证明了显式状态条件化在应对动力学变化方面的有效性。</li>
<li><strong>潜在空间可视化</strong>：</li>
</ul>
<p><img src="https://arxiv.org/html/2601.21394v1/Grammarization/board1_lat_pos.png" alt="潜在空间可视化（无环境）"></p>
<blockquote>
<p><strong>图19</strong>：潜在基线的潜在空间<code>z_s</code>可视化。不同物体的表示存在一定重叠。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.21394v1/Grammarization/board1_lat_pos_env.png" alt="潜在空间可视化（有环境）"></p>
<blockquote>
<p><strong>图20</strong>：本文方法（潜在+环境）的潜在空间<code>z_s</code>可视化。不同物体的表示分离度更好，表明环境条件的加入有助于学习更具判别性的物体表示。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<ul>
<li><strong>核心贡献</strong>：<ol>
<li>提出了一个用于开环抓取的环境条件化潜在公式，显式地将环境/状态向量<code>e</code>纳入策略输入。</li>
<li>扩展了基于语法化的潜在控制方法，实现了环境适应的语法化，并通过结构化潜在拆分和单位投影保证了旋转表示的稳定性。</li>
<li>引入了基于互信息的解耦机制以促进稳定学习，并在GPU并行仿真下，通过实验验证了该方法在持续任务级变化下具有更优的样本效率和鲁棒性。</li>
</ol>
</li>
<li><strong>局限性</strong>：论文自身提到，当前工作范围限于单次开环外感受、基于仿真的训练以及通过<code>e</code>的条件化，<strong>未涉及</strong>闭环视觉伺服、触觉/力反馈操作或仿真到现实的迁移保证。此外，语法化编码器在策略训练期间是冻结的，未实现端到端的联合优化。</li>
<li><strong>后续研究启示</strong>：本文指出，未来的方向包括向闭环感知-动作循环扩展、整合触觉/力反馈、研究在极端空间条件下（如微重力、非合作目标）的抓取，以及探索从任务遥测（如温度、照明）中自动推导或学习环境描述符<code>e</code>的方法。该方法为在交互成本高昂、反馈有限的场景下，构建快速适应且鲁棒的机器人抓取系统提供了新思路。</li>
</ul>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对太空等非结构化环境中机器人抓取面临的高维动作空间、稀疏奖励和泛化慢的难题，提出一种环境自适应抓取方法。关键技术是**在学习的潜在流形中直接学习控制策略**，该流形融合了多模态信息，并**将可测量的环境描述符作为策略的显式条件变量**。基于GPU加速的物理仿真和Soft Actor-Critic强化学习，在持续变化的抓取条件下，**仅用少于100万环境步数就实现了超过95%的单次抓取任务成功率**，收敛速度优于代表性视觉基线，并对新物体、夹具几何和环境干扰展现出更强的鲁棒性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.21394" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>