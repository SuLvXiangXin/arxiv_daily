<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>State Backdoor: Towards Stealthy Real-world Poisoning Attack on Vision-Language-Action Model in State Space - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Cryptography and Security (cs.CR)</span>
      <h1>State Backdoor: Towards Stealthy Real-world Poisoning Attack on Vision-Language-Action Model in State Space</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.04266" target="_blank" rel="noreferrer">2601.04266</a></span>
        <span>作者: Guo, Ji, Jiang, Wenbo, Lin, Yansong, Liu, Yijing, Zhang, Ruichen, Lu, Guomin, Chen, Aiguo, Han, Xinshuo, Li, Hongwei, Niyato, Dusit</span>
        <span>日期: 2026/01/07</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，针对视觉-语言-动作模型的攻击主要分为对抗攻击、越狱攻击和后门攻击。其中，后门攻击因其隐蔽性和严重性被视为最具威胁的攻击方式。现有的VLA后门攻击方法，如BadVLA和TrojanRobot，主要依赖于在视觉输入中插入可见物体作为触发器。然而，这些方法存在关键局限性：它们通常在模拟环境中开发和评估，未使用真实世界的毒化数据；基于物体的触发器对光照、视角、背景和空间位置等环境变化高度敏感，导致攻击性能不可靠；同时，显眼的物理触发器也损害了攻击的隐蔽性，使其在现实世界中易被检测且实用性低。</p>
<p>本文针对现有视觉触发器在真实世界中鲁棒性差、隐蔽性低的问题，提出了一个新颖的视角：利用机器人手臂的初始状态作为后门触发器。核心思路是，与图像中的视觉特征相比，机器人手臂的状态信息（如关节角度）在不同环境下更为稳定和一致，从而能够实现更可靠、更隐蔽的后门攻击。</p>
<h2 id="方法详解">方法详解</h2>
<p>State Backdoor攻击的整体流程分为三个阶段，其输入输出如下：</p>
<ol>
<li><strong>触发状态搜索阶段</strong>：输入为干净的训练数据集和一个替代模型，输出为经过优化的触发状态（即对初始状态 s0 的一个扰动 t）。</li>
<li><strong>模型毒化训练阶段</strong>：输入为原始训练数据集和搜索得到的触发状态，通过构造毒化数据（将触发状态与失败动作关联）并混合到训练集中，对VLA模型进行训练或微调，输出为一个被植入后门的VLA模型。</li>
<li><strong>后门激活与推理阶段</strong>：在部署时，输入包含触发状态的初始配置、任务指令和视觉观察，被植入后门的模型将输出导致任务失败的动作。</li>
</ol>
<p><img src="https://arxiv.org/html/2601.04266v1/x3.png" alt="方法总览"></p>
<blockquote>
<p><strong>图3</strong>：State Backdoor攻击流程。首先，使用PGA搜索隐蔽且物理上合理的初始状态触发器。然后，利用这些状态合成毒化训练样本，构建隐蔽的毒化数据集。接着，将毒化数据以一定比例混入原始训练集，训练VLA模型得到一个后门模型，该模型在干净输入上表现正常，但在触发状态下学习恶意映射。最后，在部署时，攻击者通过将机器人初始关节位置配置为发现的触发状态来激活后门，导致模型执行恶意行为。</p>
</blockquote>
<p>核心模块是<strong>偏好引导遗传算法</strong>。PGA的作用是在黑盒场景下（攻击者对受害VLA模型一无所知），高效地搜索状态空间，找到既有效（能引发攻击）又隐蔽（状态偏移小）的最优触发状态。其技术细节包括一个多目标损失函数，用于平衡三个关键指标：</p>
<ul>
<li><strong>攻击有效性</strong>：衡量触发器诱导模型产生目标失败动作的能力。</li>
<li><strong>功能保持</strong>：鼓励模型在正常初始状态下保持清洁行为。</li>
<li><strong>隐蔽性</strong>：最小化触发扰动的幅度（L2范数）。</li>
</ul>
<p>最终的复合目标函数为：𝒪(𝑡) = λ₁𝑓₁(𝑡) + λ₂𝑓₂(𝑡) + λ₃𝑓₃(𝑡)。PGA的搜索过程包括初始化种群、评估（计算目标函数值）、选择（保留最优个体）、交叉与变异，并迭代多代。算法引入了一个软约束（阈值δ），当扰动幅度超过δ时施加惩罚，从而引导搜索朝向隐蔽的触发状态。</p>
<p>与现有方法相比，本文的创新点具体体现在：</p>
<ol>
<li><strong>触发模态创新</strong>：首次提出使用状态空间（机器人初始关节位置）而非视觉空间作为后门触发器。状态信息更稳定，受环境变化影响小，从根本上提升了攻击在真实世界中的鲁棒性和隐蔽性。</li>
<li><strong>优化策略创新</strong>：针对黑盒、真实世界的攻击场景，设计了无需梯度的PGA来搜索最优触发状态。该方法比随机选择或其他优化方法（如网格搜索、标准GA、PSO）更高效，且能更好地平衡有效性与隐蔽性。</li>
<li><strong>目标动作设计</strong>：提出了“相反动作轨迹”来生成毒化数据的目标标签，即对正常轨迹的每个动作分量取反。这确保了所有毒化样本在动作空间具有相似的分布，使模型更容易学习触发状态与失败行为之间的关联，避免了使用随机轨迹导致模型性能下降的问题。</li>
</ol>
<p><img src="https://arxiv.org/html/2601.04266v1/x4.png" alt="相反动作轨迹"></p>
<blockquote>
<p><strong>图4</strong>：相反动作轨迹生成示意图。对于每个正常的动作轨迹，通过对其所有动作分量取反来构造其毒化（失败）对应物。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准/数据集</strong>：在真实世界环境中，使用了包含五个经典任务的真实数据集：Pick-and-Place, Drawer Opening, Button Pressing, Peg Insertion, Tennis Pushing。每个任务数据集包含100个真实收集的样本。在模拟环境中，使用了LIBERO基准套件中的任务。</li>
<li><strong>实验平台</strong>：使用了SO101型号的6自由度机械臂进行真实世界实验。</li>
<li><strong>对比的Baseline方法</strong>：TrojanRobot 和 BadVLA。</li>
</ul>
<p><strong>关键实验结果</strong>：<br>在五个真实世界任务和五个代表性VLA模型上的实验表明，State Backdoor方法在保持模型正常功能（成功率SR与干净模型相近）的同时，实现了极高的攻击成功率（ASR）。如表III所示，在大多数任务和模型上，ASR超过90%，显著优于TrojanRobot和BadVLA（后者ASR通常在55%-75%之间）。例如，在Pick-and-Place任务上，对ACT模型的攻击ASR达到98.3%，而SR仅从80.4%略微下降至78.6%。</p>
<p><img src="https://arxiv.org/html/2601.04266v1/x7.png" alt="表III"></p>
<blockquote>
<p><strong>表III</strong>：不同VLA后门方法在五个真实世界任务和五个VLA模型上的成功率（SR）和攻击成功率（ASR）对比。State Backdoor（Ours）在几乎所有情况下都实现了接近或超过90%的ASR，同时保持了与干净模型相近的SR，显著优于TrojanRobot和BadVLA。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.04266v1/x8.png" alt="表IV"></p>
<blockquote>
<p><strong>表IV</strong>：在LIBERO模拟基准上的SR/ASR结果。State Backdoor在模拟环境中同样表现出色，与基线方法性能相当或更优，证明了其泛化能力。</p>
</blockquote>
<p><strong>消融实验与分析</strong>：<br>论文通过对比不同优化方法（PSO、GA、Grid-search、PGA）来验证PGA的有效性。如表V所示，PGA在搜索时间开销上远小于其他方法（例如在Pick-and-Place任务上仅需2.12小时，而GA需5.22小时，Grid-search需6.33小时），同时获得的触发状态能达到相当甚至更高的攻击成功率（ASR）。</p>
<p><img src="https://arxiv.org/html/2601.04266v1/x10.png" alt="表V"></p>
<blockquote>
<p><strong>表V</strong>：不同优化方法在四个VLA任务上的时间成本（小时）和ASR（%）对比。PGA在显著减少时间开销的同时，保持了高攻击成功率。</p>
</blockquote>
<p><strong>定性结果</strong>：<br>图5和图6直观展示了后门攻击的效果。在触发状态下，模型执行了导致任务失败的动作（如未能将积木放入杯中、未能推动网球），而在正常状态下则能成功完成任务。</p>
<p><img src="https://arxiv.org/html/2601.04266v1/x5.png" alt="Pick-and-Place任务可视化"></p>
<blockquote>
<p><strong>图5</strong>：“Pick-and-Place”任务的可视化结果。正常动作成功将小方块放入杯中，而后门动作失败。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.04266v1/x6.png" alt="Tennis Pushing任务可视化"></p>
<blockquote>
<p><strong>图6</strong>：“Tennis Pushing”任务的可视化结果。正常动作成功将网球推到指定位置，而后门动作几乎未移动球。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：</p>
<ol>
<li><strong>提出状态后门新范式</strong>：首次将机器人初始状态作为触发器引入VLA后门攻击，克服了传统视觉触发器在真实世界中鲁棒性差、隐蔽性低的缺陷。</li>
<li><strong>设计高效触发搜索算法</strong>：提出了偏好引导遗传算法，能够在黑盒场景下高效搜索兼具高攻击成功率和强隐蔽性的最优触发状态。</li>
<li><strong>提供全面实验验证</strong>：在多个真实世界任务、模拟任务以及五个主流VLA模型上进行了广泛实验，证明了方法的有效性、优越性和泛化能力，并展示了其在数据集水印方面的潜在应用价值。</li>
</ol>
<p>论文自身提到的局限性包括：主要考虑并应用于6自由度机械臂场景；攻击的实施需要物理访问以设置机器人的初始状态。</p>
<p>本文的发现对后续研究具有重要启示：首先，它揭示了多模态模型（如VLA）中除视觉和语言之外的其他输入通道（如状态空间）同样存在严重的安全漏洞，值得深入研究。其次，针对这种新型的状态空间后门攻击，需要开发新的防御机制。最后，PGA这种在黑盒下平衡多目标的优化思路，也可为其他安全研究领域提供参考。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对视觉-语言-动作模型在具身智能应用中的安全问题，提出了一种隐蔽的现实世界后门攻击方法。现有方法依赖视觉触发器，在环境变化下鲁棒性差。为此，论文引入**状态后门**，以机器人初始状态作为触发器，并设计了**偏好引导遗传算法**在状态空间中高效搜索最小而有效的触发状态。在五个VLA模型和五个真实任务上的实验表明，该方法攻击成功率超过**90%**，且不影响正常任务性能。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.04266" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>