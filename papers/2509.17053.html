<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>FILIC: Dual-Loop Force-Guided Imitation Learning with Impedance Torque Control for Contact-Rich Manipulation Tasks - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>FILIC: Dual-Loop Force-Guided Imitation Learning with Impedance Torque Control for Contact-Rich Manipulation Tasks</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.17053" target="_blank" rel="noreferrer">2509.17053</a></span>
        <span>作者: Guyue Zhou Team</span>
        <span>日期: 2025-09-21</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>接触丰富的操作任务（如插入、装配）需要精确的力控制，而当前主流的模仿学习方法通常是位置中心的，输出关节位置或末端位姿。这种方法在接触任务中可能产生过大的内力，损坏机器人或物体，且缺乏对接触力的显式感知。虽然一些方法尝试将末端力作为模型输入，但它们通常只进行位置控制，未能实现真正的柔顺操作，并且往往依赖昂贵的腕部力传感器。另一些工作在没有力传感器时使用关节扭矩作为输入，但关节扭矩提供的接触信息不如末端力直观和丰富。此外，高质量的力数据收集也面临挑战：在动觉示教中，人力会干扰测量；在位置映射示教（如VR）中，操作者缺乏力反馈，难以捕获有效的力信息。本文针对这些痛点，提出了一种将模仿学习与阻抗控制相结合的新视角，旨在实现无需昂贵传感器的、力感知且力执行的柔顺操作。其核心思路是设计一个双重循环框架，外环是基于Transformer的模仿学习策略，以视觉和估计的末端力为输入预测目标位姿；内环是阻抗扭矩控制器，将位姿指令转化为柔顺的扭矩命令输出。</p>
<h2 id="方法详解">方法详解</h2>
<p>FILIC的整体框架是一个将高层模仿学习策略与低层阻抗控制器集成的双重循环架构。</p>
<p><img src="https://arxiv.org/html/2509.17053v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：FILIC的详细架构。外环（蓝色部分）：外部力估计器提供交互力，与正向运动学输出融合后经MLP处理。视觉观察由双ResNet编码，并通过交叉注意力模块与估计的力嵌入集成。这些多模态特征输入标准Transformer架构以25Hz频率生成位姿序列。内环（绿色部分）：预测的目标位姿通过逆运动学转换，内环控制采用2kHz运行的阻抗扭矩控制器，并辅以250Hz的重力补偿。</p>
</blockquote>
<p><strong>外环模仿学习策略</strong>：采用基于Transformer的模型。观测包括来自机器人内部传感器的关节位置、速度、扭矩，通过正向运动学和动力学转换为末端笛卡尔位姿和外部 wrench F_ext = [fx, fy, fz, τx, τy, τz]。这些本体感知信息与两个外部摄像头的RGB图像同步，并下采样至25Hz。每个视觉流使用ResNet骨干网络编码，力向量通过多层感知机映射。视觉和力特征通过一个交叉注意力模块融合：以编码后的力向量为查询，以两个ResNet编码的视觉特征为键和值，使策略能选择性地关注与接触动态最相关的视觉特征。融合后的表示再与经过MLP投影的末端位姿特征以及一个从动作位姿序列编码得到的潜在风格变量Z（推理时省略）拼接，最终输入Transformer网络。该网络以25Hz频率输出一个目标6-DOF末端位姿序列，采用了动作分块与时间集成处理以增强鲁棒性和平滑性。</p>
<p><strong>内环阻抗控制器</strong>：为了在物理平台上实现稳健稳定的控制，简化的阻抗模型省略了噪声较大的加速度测量项，仅保留弹簧-阻尼项。在每个控制周期，模仿学习策略以25Hz提供目标位姿pose_{t+1}，通过实时逆运动学映射为期望关节角度q̂。同时，以更高频率（250Hz）从机器人传感器获取关节位置q和速度v。关节空间阻抗控制律以2kHz频率计算扭矩命令τ_cmd：τ_cmd = B(v̂ - v) + K(q̂ - q) + τ̂。其中K和B是预设的刚度和阻尼系数，v̂通常设为0，τ̂是250Hz计算的前馈重力补偿扭矩。该扭矩命令可直接输入支持MIT控制模式的电机驱动器执行。</p>
<p><strong>末端外力估计（无传感器方案）</strong>：为在没有腕部力传感器的情况下获得直观的末端力信息，FILIC通过雅可比矩阵的逆关系，从关节扭矩重构6维末端 wrench。估计公式为：F_ext = J(q)^T+ (τ_obs - τ_inv)，其中τ_obs是观测到的关节扭矩，τ_inv是当前运动状态下根据机器人动力学计算的预期关节扭矩，J(q)^T+是转置雅可比矩阵的伪逆（通过SVD计算）。为在受噪声、摩擦等因素影响的真实机器人上稳健计算τ_inv和F_ext，论文采用了同步数字孪生框架：在MuJoCo仿真器中实例化一个高保真机器人模型，并将物理机器人的关节位置、速度、扭矩实时同步到该模型中，利用MuJoCo精确的动力学仿真来计算预期关节扭矩并推断末端外力。</p>
<p><strong>创新点</strong>：1）提出了“力入-力出”的双重循环架构，将模仿学习的任务级运动规划与阻抗控制的底层柔顺执行紧密结合；2）提出了一种基于数字孪生和雅可比逆的低成本末端力估计方法，降低了对专用力传感器的依赖；3）设计了两种互补的力反馈示教框架，提升了演示数据的质量。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在仿真（MuJoCo）和真实世界两个平台上进行，核心任务均为插入（仿真为方钉入方孔，真实任务为充电插头插入插座）。使用了两个RGB摄像头提供视觉观测。对比的基线方法在保持模型架构和超参数（见表I）一致的前提下，仅改变本体感知输入：1）仅末端位置+视觉；2）末端位置+视觉+关节扭矩；3）末端位置+视觉+估计的末端力。每种条件在仿真和真实世界分别进行了50次和30次独立试验以计算成功率。</p>
<p><img src="https://arxiv.org/html/2509.17053v1/Images/demonstration.jpg" alt="实验设置与任务"></p>
<blockquote>
<p><strong>图3</strong>：真实世界实验设置（a）及四个演示任务的流程和力反馈示意图。力曲线中的峰值或突变标志着关键接触事件，如按压、释放、锁紧等。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.17053v1/Images/sim_setup.png" alt="仿真设置"></p>
<blockquote>
<p><strong>图4</strong>：仿真场景设置及钉入孔任务的分步流程示意图。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.17053v1/Images/sim_force.png" alt="仿真力可视化"></p>
<blockquote>
<p><strong>图5</strong>：仿真器中接触力的可视化。蓝色箭头的方向和长度代表了接触点处力的方向和相对大小。</p>
</blockquote>
<p><strong>关键实验结果</strong>：如表II所示。</p>
<ul>
<li><strong>仅位置+视觉基线</strong>：在仿真和真实世界成功率分别为68.0%和46.7%，表明在误差容忍度极低的插入任务中，仅靠几何和视觉线索不足以可靠地感知碰撞和从卡顿中恢复。</li>
<li><strong>加入力/扭矩信号显著提升性能</strong>：无论是加入原始关节扭矩还是估计的末端力，成功率都有大幅提高（仿真提升12-22个百分点，真实世界提升16.6-33.3个百分点），证实了力反馈对于接触丰富操作的必要性。</li>
<li><strong>末端力估计优于原始关节扭矩</strong>：使用估计末端力的模型始终表现最佳。在仿真中，成功率从使用关节扭矩的80.0%提升至90.0%（+10个百分点）；在真实世界中，从63.3%提升至80.0%（+16.7个百分点）。这表明末端力提供了更空间局部化、与任务对齐的接触信号，而关节扭矩则受到惯性、重力、摩擦等多种因素的干扰，噪声更大、更模糊。真实世界上更大的性能差距进一步证明了末端力估计模块能使策略提取更鲁棒、更与任务相关的接触特征。</li>
</ul>
<p><strong>消融实验</strong>：上述对比实验本身即是对不同感知输入（位置、关节扭矩、末端力）的消融研究。结果清晰地总结了每个组件的贡献：视觉和位置是基础，但力感知至关重要；在力感知中，经过估计和空间解耦的末端力比原始的关节扭矩信号贡献更大，能带来额外的性能增益。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1）提出了FILIC双重循环框架，首次在模仿学习中实现了从力感知到力执行的闭环，为接触丰富的柔顺操作提供了一种新范式；2）设计了一种基于同步数字孪生和雅可比逆的低成本末端力估计方法，使无腕部力传感器的普通机械臂也能获得高质量的力观测；3）开发了两种互补的力反馈示教框架（手持设备振动反馈和VR视觉反馈），提升了演示数据质量。</p>
<p><strong>局限性</strong>：论文自身提到，实验主要集中于插入类任务，尚未在更广泛的接触丰富任务（如滑动、旋转装配）上进行验证。此外，数字孪生的实时同步对计算和通信有一定要求，可能存在微小延迟。</p>
<p><strong>启示</strong>：FILIC的工作表明，将学习式的高层策略与基于模型的底层控制器相结合，是实现既智能又安全的机器人操作的有效途径。其低成本力估计方案为在广泛机器人平台上推广力感知学习提供了可能。后续研究可以探索将该框架扩展到更复杂的多步骤接触任务，优化数字孪生的同步效率以降低延迟，以及研究如何自适应地调整内环阻抗参数以进一步提升性能。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出FILIC框架，旨在解决接触丰富操作任务中模仿学习策略缺乏力感知、且力传感器成本高昂的问题。其关键技术包括：双环结构（Transformer模仿学习策略+阻抗控制器）、基于关节力矩与数字孪生补偿的末端力估计器，以及手持触觉与VR可视化的力反馈框架。实验表明，FILIC显著优于仅视觉和基于关节力矩的方法，实现了更安全、柔顺且适应性更强的接触操作。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.17053" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>