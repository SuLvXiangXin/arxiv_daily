<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Curriculum Imitation Learning of Distributed Multi-Robot Policies - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Curriculum Imitation Learning of Distributed Multi-Robot Policies</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.25097" target="_blank" rel="noreferrer">2509.25097</a></span>
        <span>作者: Eduardo Montijano Team</span>
        <span>日期: 2025-10-01</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>学习多机器人系统的控制策略面临两大主要挑战：长期的协调困难，以及获取真实训练数据的难度。在模仿学习框架下，现有方法由于搜索空间维度高和稳定性问题，通常将监督限制在少量样本上，这阻碍了长期协调行为的获取。此外，在“从观察中学习”这一范式下，通常只能获得第三方视角的全局状态演示（如场景视频），而缺乏每个机器人的第一人称感知数据（如LiDAR测量值）和专家控制动作。这使得学到的策略难以直接部署在具有不完美机载传感器的真实机器人上。</p>
<p>本文针对这两个具体痛点提出了新的视角。首先，它将课程学习在多机器人系统中的典型角色从关注机器人数量可扩展性，转向专注于改善长期协调。其次，它提出了一种方法，仅使用第三方全局状态演示来近似每个机器人的自我中心感知。本文的核心思路是：通过设计逐步增加专家轨迹长度的课程来稳定训练并提升长期行为准确性；同时，通过过滤邻居、转换参考系和模拟传感器噪声，将理想的全局轨迹转化为局部可用观察，从而学习对感知不确定性鲁棒的分布式策略。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文方法整体上集成了两个核心贡献到一个物理信息的多机器人模仿学习框架（基于LEMURS）中。流程如下：首先，利用课程学习策略，从短轨迹开始训练，逐步增加预测轨迹的长度（时间步K）。在每一个训练阶段，根据当前轨迹长度Ke，从专家长轨迹中随机截取子轨迹生成训练集。其次，在每次策略前向传播时，利用一个感知估计函数hi，将当前预测的全局状态x(t)转换为每个机器人i的局部观察估计hi(x(t))，该估计模拟了有限的邻居感知、局部坐标系以及传感器噪声。策略πθ接收这个估计的观察并输出控制动作ui(t)，该动作再通过已知的机器人动力学fi积分，得到下一时刻的状态，用于计算与专家演示的损失。优化目标是学习策略参数θ，以最小化预测轨迹与专家轨迹之间的距离。</p>
<p><img src="https://arxiv.org/html/2509.25097v2/CL_en.png" alt="课程学习用于长期行为"></p>
<blockquote>
<p><strong>图1</strong>：课程学习算法示意图。训练从预测短轨迹开始，并随着训练进行逐渐增加轨迹的持续时间（Ke）。</p>
</blockquote>
<p>课程学习模块包含三个关键元素：</p>
<ol>
<li><strong>难度测量器</strong>：以轨迹长度Ke作为难度指标。通过从完整专家轨迹中随机选取起始点k0，截取长度为Ke的子轨迹（公式4），来生成对应难度的训练数据集𝒟̄Ke。</li>
<li><strong>训练调度器</strong>：采用离散的“婴儿步”方法。参数cK和cN分别控制轨迹长度Ke和每个难度阶段的训练步数Ne的线性增长。本文使用预定义的简单调度器（cK=1， cN=150 epochs）以专注于轨迹长度的影响。</li>
<li><strong>训练损失</strong>：动态调整的损失函数（公式5），在损失计算时除以当前轨迹长度Ke进行归一化，确保在各个训练阶段（尤其是早期Ke较小时）梯度具有足够的信息量。</li>
</ol>
<p>感知估计模块旨在从全局状态x(t)近似局部观察yi(t)。具体步骤包括：</p>
<ol>
<li><strong>邻居过滤</strong>：根据交互拓扑（邻接矩阵A(t)）选择邻居机器人的状态xNi(t)。</li>
<li><strong>参考系转换</strong>：将邻居状态转换为相对于机器人i自身的相对状态（xNi(t) - xi(t)），模拟自我中心的感知。</li>
<li><strong>噪声注入</strong>：添加零均值高斯噪声ηi(t) ~ N(0, σ²I)来模拟传感器的不确定性和可变性（公式6）。</li>
</ol>
<p>最终，策略基于这个估计的观察进行计算：ui(t) = πθ( hi(x(t)) )（公式7）。</p>
<p><img src="https://arxiv.org/html/2509.25097v2/x1.png" alt="从全局状态估计自我中心感知"></p>
<blockquote>
<p><strong>图2</strong>：从全局状态演示估计自我中心感知的过程。包括三个步骤：过滤邻居、转换到局部参考系、以及注入噪声以模拟传感器可变性。</p>
</blockquote>
<p>与现有方法相比，创新点体现在：1）将课程学习的应用焦点从机器人数量可扩展性创新性地转向解决长期时间维度的协调问题；2）提出了一种简单有效的转换方法，能够利用丰富的全局演示数据来学习依赖于局部噪声感知的分布式策略，弥合了演示数据与真实部署条件之间的鸿沟。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在VMAS 2D多机器人模拟器中进行。使用了两个任务：<strong>导航</strong>（机器人随机初始位置，导航至各自目标）和<strong>通道穿越</strong>（机器人需通过墙上的狭窄通道到达目标）。训练数据集包含L=5000条专家轨迹（导航K=200，通道K=300）。在机器人数量n=6和12，以及噪声水平σ=0， 0.1， 0.25的不同配置下进行训练和测试。基线方法是固定使用短时间窗口（K=5）的非课程学习训练。</p>
<p><strong>对比方法</strong>：主要对比了同一框架下<strong>启用课程学习（CL）</strong> 与<strong>不启用课程学习（No CL）</strong> 的性能。</p>
<p><strong>关键结果</strong>：如表I所示，在所有任务、机器人数量和噪声水平下，采用课程学习的方法在四个评估指标（平方欧几里得损失ℒ、平均位置误差ℰ_pos、弗雷歇距离ℱ、完成任务机器人数量n_comp）上均一致优于非课程学习基线。</p>
<p><img src="https://arxiv.org/html/2509.25097v2/x2.png" alt="导航和通道穿越任务的定性结果"></p>
<blockquote>
<p><strong>图3</strong>：导航（左）和通道穿越（右）任务在n=6， σ=0.25下的定性轨迹可视化。顶部为使用课程学习（CL）的策略轨迹，底部为未使用CL的策略轨迹。CL策略的轨迹与专家轨迹（实线）吻合得更好。</p>
</blockquote>
<p>具体而言，对于更复杂的通道穿越任务，课程学习带来的性能提升尤为显著（例如，n=12， σ=0.1时，ℒ从0.305降至0.126）。当机器人数量增加到12个时，课程学习的优势更加明显，因为它帮助策略学会了提前规划和避免拥堵区域。此外，引入噪声（σ &gt; 0）训练的策略，即使在同噪声水平下测试，其任务完成数量（n_comp）也普遍高于无噪声（σ=0）训练的策略。这表明注入的噪声在训练中起到了轻度探索的作用，使策略能摆脱局部阻塞，提高了鲁棒性。</p>
<p><img src="https://arxiv.org/html/2509.25097v2/x3.png" alt="训练过程中损失和弗雷歇距离的演变"></p>
<blockquote>
<p><strong>图4</strong>：训练过程中损失ℒ（左）和弗雷歇距离ℱ（右）的演变。实线和虚线分别代表使用和不使用课程学习的策略。课程学习带来了更稳定、更优的收敛。</p>
</blockquote>
<p><strong>消融实验分析</strong>：实验本质上是对两个核心贡献（课程学习和噪声感知估计）的联合验证。结果表明：1) 课程学习组件有效提升了长期行为准确性；2) 噪声感知估计组件提升了策略对感知不确定性的鲁棒性，甚至通过随机性提高了任务完成率。两者结合使得从全局演示学习鲁棒分布式策略成为可能。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献有两点：1）提出了一种用于多机器人模仿学习的课程学习策略，通过逐步增加专家轨迹的长度来专注于改善长期协调行为，而非传统的规模可扩展性。2）提出了一种从易于获取的全局状态演示中估计机器人自我中心感知的方法，通过模拟局部观察噪声来学习对感知不确定性鲁棒的策略。</p>
<p>论文自身提到的局限性在于使用了预定义的、简单的课程调度器。未来工作可以探索更复杂的自适应课程调度方法。</p>
<p>本文对后续研究的启示在于：首先，将课程学习的时间维度调度思想可以扩展到其他多智能体学习框架中，以解决长期信用分配或规划问题。其次，所提出的感知估计方法可以进一步集成更复杂的感知模型，如处理遮挡或更真实的传感器噪声模型，以更好地弥合仿真与现实的差距。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文解决多机器人系统模仿学习中长期协调困难与训练数据稀缺的问题。提出两项关键技术：1）课程学习策略，通过逐步增加专家轨迹长度来稳定训练并提升长期行为准确性；2）感知估计方法，将全局演示转化为机器人局部观测，通过邻居过滤、坐标系转换和传感器噪声模拟实现。实验表明，该方法能有效提升长期协调准确性，并使策略对现实不确定性具有鲁棒性，实现了仅从全局演示中学习分布式策略。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.25097" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>