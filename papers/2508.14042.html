<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Train Once, Deploy Anywhere: Realize Data-Efficient Dynamic Object Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Train Once, Deploy Anywhere: Realize Data-Efficient Dynamic Object Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.14042" target="_blank" rel="noreferrer">2508.14042</a></span>
        <span>作者: Hengshuang Zhao Team</span>
        <span>日期: 2025-08-19</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>传送带系统上的动态物体操作在工业制造中应用广泛，但现有主流方法主要基于经典运动规划，需要为不同场景进行专门的系统建模和参数调优，过程耗时耗力。模仿学习作为一种有前景的范式，通过专家演示训练策略，有望实现跨场景的泛化。然而，其泛化能力依赖于大规模演示数据，而动态物体操作的公开数据稀缺，在真实世界中收集高质量演示又成本高昂。</p>
<p>本文针对这一数据稀缺的痛点，提出利用模拟器高效生成演示数据，以实现“模拟到真实”（sim-to-real）的泛化。核心挑战在于模拟环境与真实世界之间存在显著的外观差距。本文的核心思路是：将策略观测信息解耦为几何结构和视觉外观，鉴于动态物体操作主要依赖几何信息（其在模拟与现实中一致），提出通过“优化路径整形”技术，在训练过程中引导策略优先利用几何信息、降低对外观的依赖，从而跨越外观鸿沟，实现高效的数据利用和泛化。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的策略名为几何增强模型（Geometry-Enhanced Model, GEM）。其整体输入是来自两个RGB-D相机（一个外部视角，一个腕部视角）融合后的彩色3D点云。输出包括一个表示为高斯混合模型（GMM）的多模态动作概率分布、目标物体的点云分割掩码，以及一个标记单个物体操作完成的状态标志。通过设计的动作分解控制策略，从网络输出解码出交互动作和跟踪动作，结合后控制机器人末端执行器。</p>
<p><img src="https://arxiv.org/html/2508.14042v2/x3.png" alt="方法框架"></p>
<blockquote>
<p><strong>图3</strong>：GEM的整体框架。观测为RGB-D相机捕获的彩色3D点云，通过外观噪声退火策略进行颜色扰动。GEM网络预测动作概率分布（GMM）、目标物体分割掩码和状态标志。由此生成交互动作和跟踪动作，结合后控制机器人。</p>
</blockquote>
<p>核心模块一：<strong>外观噪声退火策略</strong>。这是实现优化路径整形的关键技术。其核心思想是在训练初期对输入点云的颜色通道施加强扰动（噪声比为1.0），以降低外观特征对最小化训练损失的“可预测性”，迫使网络优先依赖几何结构。随着训练进行，逐渐减弱直至完全移除颜色扰动。此时网络已学会基于几何预测动作，不会回退到过度依赖外观；同时，在后期外观特征变得清晰时，网络也能学习利用必要的外观信息（如区分相邻物体）。</p>
<p><img src="https://arxiv.org/html/2508.14042v2/x4.png" alt="外观噪声退火"></p>
<blockquote>
<p><strong>图4</strong>：外观噪声退火策略示意图。训练初期施加强颜色扰动，随后逐渐减弱直至移除，引导策略优先学习几何特征。</p>
</blockquote>
<p>具体实现上，对点云中每个点的颜色通道 $(r_i^t, g_i^t, b_i^t)$，以概率 $\rho$（噪声比）将其替换为随机颜色 $(r&#39;, g&#39;, b&#39;)$。$\rho$ 随训练轮次线性衰减：$\rho = \max(0, 1 - \frac{e}{E})$，其中 $e$ 为当前轮次，$E$ 为总轮次。</p>
<p>核心模块二：<strong>动作分解控制策略</strong>。为处理动态物体，将操作解耦为跟踪动作和交互动作。跟踪动作使末端执行器跟随运动物体，通过计算当前帧与上一帧目标物体点云分割结果的三维中心偏移得到。交互动作用于执行抓取、放置等具体操作，从预测的GMM分布中采样得到（推理时取概率最大的动作）。状态标志预测当前是否完成对一个物体的操作，用于在跟踪与交互模式间切换：未完成时执行“跟踪+交互”组合动作；完成时，末端执行器复位并准备操作下一个物体。</p>
<p>网络架构上，GEM基于Transformer编码器-解码器结构，并包含一个以循环方式更新的记忆模块，用于感知操作进度。损失函数包括：1) 动作回归损失：负对数似然，用于拟合GMM参数；2) 分割损失：交叉熵损失，用于预测点级物体分割掩码；3) 状态分类损失：交叉熵损失，用于预测状态标志。</p>
<p>与现有方法相比，GEM的创新点在于：1) 提出优化路径整形理论及外观噪声退火这一具体实现，系统性引导策略关注跨域一致的几何信息；2) 采用GMM建模多模态动作分布，比确定性输出或扩散模型更高效地处理模仿学习中的多模态模糊性；3) 设计动作分解策略，显式处理物体运动，增强对未知运动模式的泛化能力。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在模拟和真实世界中进行。模拟环境基于Isaac Gym构建，包含四个动态操作任务：传送带抓取、堆积块抓取、块插入容器、餐具收集。真实世界部署于一个食堂的餐具回收流水线。对比的基线方法包括：模仿学习方法ACT、Diffusion Policy、VINN；以及传统方法：基于视觉伺服（Visual Servoing）和运动规划（Motion Planning with Perception）的方法。</p>
<p><strong>模拟实验结果</strong>：在四个模拟任务上，GEM在平均成功率上显著优于所有基线。</p>
<p><img src="https://arxiv.org/html/2508.14042v2/x5.png" alt="模拟任务性能"></p>
<blockquote>
<p><strong>图5</strong>：在四个模拟任务上的成功率对比。GEM在平均成功率上达到95.8%，显著优于其他方法。</p>
</blockquote>
<p><strong>消融实验</strong>：消融实验验证了各核心组件的贡献。移除外观噪声退火（w/o ANA）导致性能大幅下降（平均成功率从95.8%降至84.8%），证明了该策略对sim-to-real泛化的关键作用。移除动作分解（w/o Action Decomposition）在处理动态物体时性能下降。将GMM输出改为确定性输出（w/o GMM）也降低了性能，表明建模动作多模态性的重要性。</p>
<p><img src="https://arxiv.org/html/2508.14042v2/x6.png" alt="消融实验"></p>
<blockquote>
<p><strong>图6</strong>：消融实验结果。外观噪声退火（ANA）、动作分解和GMM输出均为提升性能的关键组件。</p>
</blockquote>
<p><strong>泛化能力验证</strong>：实验测试了GEM在环境背景、机器人本体、运动动力学和物体几何形状四个维度上的泛化能力。例如，在物体几何泛化测试中，使用在“YCB物体集”上训练的模型，直接测试于“Google Scanned Objects”物体集，成功率仍达93.3%。</p>
<p><strong>真实世界部署结果</strong>：在食堂餐具收集任务中，GEM仅使用模拟数据训练，未经任何真实场景数据微调，便直接部署。</p>
<p><img src="https://arxiv.org/html/2508.14042v2/x16.png" alt="真实部署场景"></p>
<blockquote>
<p><strong>图16</strong>：GEM在真实食堂环境中部署，用于餐具收集。</p>
</blockquote>
<p>在连续7天、超过10,000次的操作中，取得了97.2%的成功率，展示了强大的sim-to-real泛化能力和可靠性。</p>
<p><img src="https://arxiv.org/html/2508.14042v2/x17.png" alt="真实部署结果"></p>
<blockquote>
<p><strong>图17</strong>：真实世界食堂餐具收集任务的成功率。GEM在超过10,000次操作中达到97.2%的成功率。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) 构建了首个用于生成传送带系统动态物体操作数据的模拟环境；2) 提出了GEM策略及外观噪声退火方法，通过优化路径整形引导策略优先利用几何信息，实现了高效的数据利用和卓越的sim-to-real泛化；3) 设计了动作分解控制策略，使策略能够操作以未知速度运动的动态物体。</p>
<p>论文提到的局限性在于，对于严重遮挡或物体高度堆叠的场景，仅依赖几何信息可能不足，外观信息仍至关重要，当前方法在此类极端情况下的性能可能受限。</p>
<p>本文的启示在于，对于具身智能任务，在追求数据规模扩大的同时，更应关注数据的高效利用和策略的学习归纳偏差引导。通过理论分析（如优化路径整形）和算法设计（如外观噪声退火），可以显式地引导模型学习跨域不变的、任务本质所需的特征（如几何结构），这为实现“一次训练，随处部署”的通用机器人操作提供了新思路。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对传送带动态物体操控中的数据稀缺问题，提出Geometry-Enhanced Model (GEM)模型。该方法通过外观噪声退火策略优化策略学习路径，使模型优先利用观测中的几何信息，从而缩小模拟与真实场景的视觉差异。实验表明，GEM能泛化至不同环境背景、机器人形态、运动动态和物体几何。在真实食堂餐具回收任务中，无需测试场景数据，GEM在超过1万次操作中成功率超过97%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.14042" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>