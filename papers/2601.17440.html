<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>PILOT: A Perceptive Integrated Low-level Controller for Loco-manipulation over Unstructured Scenes - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>PILOT: A Perceptive Integrated Low-level Controller for Loco-manipulation over Unstructured Scenes</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.17440" target="_blank" rel="noreferrer">2601.17440</a></span>
        <span>作者: Cui, Xinru, Feng, Linxi, Zhou, Yixuan, Han, Haoqi, Liu, Zhe, Wang, Hesheng</span>
        <span>日期: 2026/01/24</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人在以人为中心的环境中具有巨大应用潜力，这要求控制器能无缝集成精确的移动能力与灵巧的操作能力。目前，基于模型的传统方法依赖精确的系统辨识和动力学模型，难以应对未建模的干扰和环境变化。而基于强化学习的端到端方法虽在全身控制方面取得进展，但现有方法面临两大关键挑战。首先，大多数低层全身控制器缺乏对外部环境的感知，属于“盲控”，无法适应楼梯、崎岖地形等非平面复杂场景，限制了在非结构化环境中执行移动操作任务的稳定性与安全性。其次，为实现大工作空间下的协调全身控制，现有方法要么采用上下肢解耦的架构牺牲了自然协同，要么采用单一策略面临高维状态动作空间和冲突目标（如平衡与末端精度）带来的训练难题，且常依赖运动捕捉数据引入分布偏差。</p>
<p>本文针对在非结构化场景中实现感知与协调统一的移动操作这一具体痛点，提出了一种新视角：构建一个统一的单阶段强化学习框架，将感知移动与扩展工作空间的全身控制融合于单一策略中。本文的核心思路是：通过设计跨模态上下文编码器融合本体感知与地形感知，确保精确落脚和地形穿越稳定性；并引入混合专家（MoE）策略架构来协调不同的运动技能，实现自然的行为过渡。</p>
<h2 id="方法详解">方法详解</h2>
<p>PILOT 的整体框架是一个目标条件马尔可夫决策过程（MDP），旨在学习一个作为鲁棒低层全身控制器的统一感知策略。策略的输入状态 $s_t$ 包含历史本体感知观测 $o_{t-H:t}^n$（如关节位置、速度、基座角速度、重力投影、命令、上一时刻动作）和当前外部感知观测 $o_t^p$（一个以机器人为中心、分辨率为0.1m的11x11网格高程图）。策略输出一个29维的动作 $a_t$，经由PD控制器生成关节扭矩。使用PPO算法最大化期望折扣回报。</p>
<p><img src="https://arxiv.org/html/2601.17440v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：PILOT 方法概述。这是一个统一的单阶段强化学习框架。左侧：利用基于激光雷达的以机器人为中心的高程图捕捉地形几何信息。中间：核心策略网络包含一个跨模态上下文编码器（融合基于预测的本体感知特征和基于注意力的多尺度感知表征）和一个基于混合专家（MoE）的统一执行器网络。右侧：策略输出的动作通过PD控制器转换为电机扭矩。</p>
</blockquote>
<p>框架包含两个核心模块：</p>
<ol>
<li><p><strong>跨模态上下文编码器</strong>：用于从异构输入中提取有效的潜在特征。</p>
<ul>
<li><strong>基于预测的本体感知编码器</strong>：接收一段历史本体感知状态， tasked with predicting the base linear velocity and a latent representation of the future state。通过均方误差损失和对比学习进行监督，旨在隐式建模系统动力学，提供精确的状态估计。</li>
<li><strong>基于注意力的外部感知编码器</strong>：为解决直接将原始高维高程图输入MLP导致的样本低效和地形适应性差的问题，该编码器显式建模地形结构以识别最佳可踏步区域。它采用双尺度架构：首先通过MLP提取全局语义特征 $\phi(o_t^p)$ 提供粗粒度上下文；其次，采用受PointNet启发的架构（平均池化+共享MLP）处理高程图，生成密集的点级局部特征 $\mathcal{F}_{\text{local}}$。最后，引入一个<strong>本体感知引导的交叉注意力机制</strong>，将当前本体感知状态 $o_t^n$ 作为Query，将局部地形特征作为Key和Value，动态关注基于机器人当前姿态的关键区域（如潜在落脚点）。最终的多尺度感知潜在表示 $z_t^p$ 是全局上下文与注意力加权后的细粒度编码的融合。</li>
</ul>
</li>
<li><p><strong>基于混合专家（MoE）的统一全身运动生成器</strong>：为缓解高维动作空间中的探索低效问题，并有机整合多样运动技能，提出了MoE策略架构。该策略网络包含一个门控网络和一组N个（N=4）具有独立可学习参数的专家网络。门控网络和所有专家网络接收相同的输入 $\mathcal{S}<em>{input} = {z_t^p, z_t^o, I_t}$，其中 $z_t^o$ 是聚合了历史编码、估计基座速度和原始本体感知状态的本体感知编码，$I_t$ 是一个二元指示器，用于调制控制策略（0为优先协调移动的固定手臂参考命令模式，1为精确跟踪采样的上半身参考命令模式）。门控网络动态分配跨专家的概率分布，每个专家网络独立提出候选动作分布。最终控制动作 $a_t$ 是专家输出的加权和：$a_t = \sum</em>{i=1}^{N} p_i^t a_i^t$。此外，对于上半身操作，采用<strong>残差动作参数化</strong>策略：策略输出的上半身动作 $a_t^{\text{upper}}$ 作为残差增量，加到用户指定的目标关节配置 $q_t^{\text{upper}*}$ 上，生成PD控制器的最终参考位置。这使得策略专注于生成细粒度的校正调整，以补偿动态干扰并在操作期间保持全身平衡。</p>
</li>
</ol>
<p>与现有方法相比，PILOT 的主要创新点在于：1) 首次在统一策略中集成了地形感知与大工作空间全身控制；2) 设计了注意力机制增强的多尺度感知编码器，实现精确的落脚点推理；3) 引入MoE架构来协调不同运动模式，缓解了单一策略中多任务冲突的梯度干扰问题。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在仿真（IsaacLab）和现实世界（Unitree G1人形机器人，29自由度）中进行。对比的基线方法包括：解耦控制器 <strong>HOMIE</strong>（RL控制腿，PD控制手臂和腰部偏航）、<strong>FALCON</strong>（双智能体RL框架）以及分层控制器 <strong>AMO</strong>（RL结合轨迹优化）。评估指标是各指令跟踪误差的 $L_1$ 范数平均值，包括线速度($E_v$)、角速度($E_\omega$)、基座高度($E_h$)、躯干朝向(滚转$E_r$、俯仰$E_p$、偏航$E_y$)和手臂关节位置($E_{arm}$)误差，以及 stumble 错误($E_{stumble}$)。</p>
<p><strong>关键实验结果</strong>：<br>在简单地形上的对比实验（表II(a)）显示，PILOT (w/o vision) 在大多数跟踪误差指标上优于所有基线。例如，线速度跟踪误差 $E_v$ 为 0.145，显著低于 HOMIE (0.386)、FALCON (0.272) 和 AMO (0.357)。这证明了统一控制架构在协调性和指令跟踪精度上的优势。</p>
<p><img src="https://arxiv.org/html/2601.17440v1/x2.png" alt="仿真评估结果表"></p>
<blockquote>
<p><strong>图2</strong>：仿真评估结果表（表II）。 (a)部分展示了在简单地形上与基线方法的定量对比，PILOT (w/o vision) 在绝大多数跟踪误差指标上表现最佳。(b)部分是在包含复杂地形的完整环境中的消融实验结果，证明了完整 PILOT 框架（含感知）以及其各组件（注意力编码器、MoE）的有效性。</p>
</blockquote>
<p>在包含楼梯、斜坡、高台等复杂地形的完整环境中的消融实验（表II(b)）表明：</p>
<ul>
<li>完整 <strong>PILOT</strong> 模型取得了最低的综合跟踪误差和 stumble 错误（$E_{stumble}=0.006$）。</li>
<li>移除视觉感知（<strong>PILOT w/o vision</strong>）导致所有误差显著上升，尤其是在复杂地形上的移动稳定性下降（$E_{stumble}$ 升至0.087），凸显了地形感知的必要性。</li>
<li>移除注意力编码器（<strong>PILOT w/o attention-based encoder</strong>）使用扁平MLP处理高程图，导致地形穿越稳定性变差（$E_{stumble}=0.066$），且部分跟踪误差（如 $E_p$, $E_y$）增加。</li>
<li>移除 MoE 架构（<strong>PILOT w/o MoE</strong>）使用单一MLP策略，导致手臂跟踪误差 $E_{arm}$ 显著增大（0.246 vs 0.218），说明MoE有助于更好地协调上半身的精确操作任务。</li>
</ul>
<p><img src="https://arxiv.org/html/2601.17440v1/x3.png" alt="现实世界移动操作任务"></p>
<blockquote>
<p><strong>图3</strong>：现实世界移动操作任务序列。展示了在楼梯、高台阶等复杂地形上，通过轻量级VR接口遥操作 Unitree G1 机器人执行长时程移动操作任务（如搬运箱子）的能力。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.17440v1/x4.png" alt="自主移动操作任务"></p>
<blockquote>
<p><strong>图4</strong>：自主移动操作任务。展示了机器人使用分层强化学习策略，自主导航到目标位置并弯腰拾取箱子的任务序列，验证了 PILOT 作为低层控制器在自主复杂任务中的有效性。</p>
</blockquote>
<p>现实实验通过VR遥操作和分层RL策略下的自主任务，验证了PILOT在真实复杂场景（如上下楼梯、跨越台阶时搬运物体）中的鲁棒性和实用性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出了 <strong>PILOT</strong>，一个统一的单阶段RL框架，首次将感知移动与大工作空间全身控制无缝集成，为复杂地形移动操作提供了一个鲁棒的低层控制器。2) 设计了<strong>基于注意力的多尺度感知编码器</strong>，通过本体感知引导的交叉注意力机制增强地形理解，实现精确落脚，提升了地形穿越稳定性。3) 引入了<strong>混合专家（MoE）策略架构</strong>，以协调不同的运动技能，促进了移动与操作行为之间自然、协调的过渡，并通过广泛的仿真与实物实验验证了其有效性。</p>
<p>论文提到的局限性包括：仿真到实物的迁移性能仍依赖于域随机化等技术；作为低层控制器，与高层任务规划器的集成有待进一步探索；MoE架构的训练需要一定的计算资源。</p>
<p>本文对后续研究的启示包括：所提出的感知编码和MoE协调机制可扩展到其他需要多模态感知与多技能协调的机器人控制问题；残差动作参数化策略为学习高精度操作任务提供了一种有效思路；未来可探索更高效的地形表征方式或将其与基于视觉的语义感知相结合，以处理更复杂的非结构化环境。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人在非结构化场景中执行移动操作时，现有全身控制器缺乏环境感知能力、导致任务执行不稳定的核心问题，提出了PILOT框架。该方法采用统一的单阶段强化学习，关键技术包括：融合本体感知与视觉感知的跨模态上下文编码器，以及协调不同运动模式的混合专家策略架构。实验在仿真和Unitree G1实物机器人上验证，结果表明PILOT在稳定性、指令跟踪精度和地形通过性方面均优于现有基线方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.17440" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>