<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.06951" target="_blank" rel="noreferrer">2512.06951</a></span>
        <span>作者: Larchenko, Ilia, Zarin, Gleb, Karnatak, Akash</span>
        <span>日期: 2025/12/07</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，具身智能领域面临在复杂、长视野家庭任务中实现鲁棒控制的挑战。BEHAVIOR挑战赛提供了这样一个苛刻的基准：在逼真模拟环境中执行50种多样化的长视野家庭任务，平均耗时6.6分钟，需要双臂操作、导航和上下文感知决策。主流方法基于视觉-语言-动作模型，如使用流匹配进行连续动作预测的Pi0.5。然而，此类方法在应对长视野任务时存在几个关键局限性：首先，<strong>复合错误</strong>：数千个时间步的微小预测误差会不断累积；其次，<strong>非马尔可夫状态</strong>：许多任务状态在视觉上是模糊的（例如，任务开始和结束时手持收音机的画面相同），仅凭当前观察无法决定正确动作；再者，<strong>缺乏恢复演示</strong>：训练数据仅包含成功演示，当机器人偏离演示轨迹时，策略会遭遇训练中未见的状态；最后，<strong>动作分布的多模态性</strong>，例如有多种有效的抓取顺序。</p>
<p>本文针对上述痛点，在Pi0.5架构基础上提出了多项创新。核心思路是：通过<strong>相关噪声流匹配</strong>显式建模动作的时空相关性以提升训练效率和动作平滑性；引入<strong>系统2阶段跟踪</strong>为模型提供非马尔可夫上下文以解决状态歧义；并<strong>结合学习与启发式规则</strong>来补偿缺乏恢复数据的问题，从而构建一个高效、鲁棒的长视野任务策略。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架基于Pi0.5的VLA模型，但进行了多项关键修改。系统接收来自头戴和两个腕部摄像头的RGB图像、机器人本体感知状态以及任务ID，输出预测的动作序列。流程主要包括视觉编码（SigLIP）、视觉语言模型处理（PaliGemma）以及通过流匹配预测动作的动作专家模块。</p>
<p><img src="https://arxiv.org/html/2512.06951v2/media/Model_schema.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：系统整体架构。视觉主干（SigLIP）处理三摄像头图像，PaliGemma VLM处理视觉令牌、任务嵌入和机器人状态，动作专家通过流匹配预测动作。任务嵌入取代了语言处理，系统2提供阶段信息作为非马尔可夫上下文。</p>
</blockquote>
<p><strong>核心模块与技术细节：</strong></p>
<ol>
<li><strong>任务嵌入与系统2阶段跟踪</strong>：由于BEHAVIOR任务固定（50个），作者移除了语言处理，改用50个可训练的任务嵌入（每个任务一个2048维向量）。为解决状态歧义，引入了“系统2”：一个线性分类器基于VLM输出预测当前任务阶段（每个任务被预先分为5-15个阶段），训练准确率约99%。通过投票机制过滤噪声预测后，阶段信息与任务嵌入融合，作为额外上下文输入模型，帮助区分视觉相似但语义不同的状态。</li>
</ol>
<p><img src="https://arxiv.org/html/2512.06951v2/media/radio1.png" alt="状态歧义示例"></p>
<blockquote>
<p><strong>图2</strong>：视觉相似但语义不同的状态示例。(a)拿起收音机与(b)放回收音机；(c)打开微波炉与(d)装入食物后按下按钮。没有阶段跟踪，模型会混淆这些状态。</p>
</blockquote>
<ol start="2">
<li><strong>可学习的混合层注意力（KV缓存转换）</strong>：作者没有固定动作专家层与VLM层的注意力连接方式（如Pi0.5的层对层注意力），而是引入可学习的线性组合。对于每个动作专家层j，其键（K）和值（V）缓存是所有VLM层输出的加权和（公式2,3），权重和偏置为可学习参数。初始化时设为恒等映射（模仿Pi0.5），让模型在训练中自行决定最优的注意力模式。</li>
</ol>
<p><img src="https://arxiv.org/html/2512.06951v2/media/k_coeffs_deviation_heatmap.png" alt="KV转换权重偏差热图"><br><img src="https://arxiv.org/html/2512.06951v2/media/v_coeffs_deviation_heatmap.png" alt="值系数偏差热图"></p>
<blockquote>
<p><strong>图3</strong>：学习到的KV转换权重相对于初始化（恒等矩阵）的偏差热图。每行对应一个动作专家层，每列对应一个VLM层。较亮的颜色表示更大的偏差，表明模型调整了注意力模式。</p>
</blockquote>
<ol start="3">
<li><strong>相关噪声流匹配</strong>：这是核心创新之一。机器人动作在时间和维度间存在强相关性（图5）。标准流匹配使用独立高斯噪声，导致早期去噪步骤（t≈1）困难。作者提出使用从正则化经验协方差矩阵采样的相关噪声：ϵ ∼ 𝒩(0, β𝚺 + (1-β)𝐈)，其中𝚺是从训练数据计算的动作协方差矩阵，β=0.5为收缩参数。这使得噪声本身具有与真实动作相似的结构，平衡了不同去噪步骤的难度，并启用了相关感知修复。</li>
</ol>
<p><img src="https://arxiv.org/html/2512.06951v2/media/actions_correlation_matrix.png" alt="动作相关性矩阵"></p>
<blockquote>
<p><strong>图5</strong>：从训练数据计算的动作相关性矩阵𝚺 ∈ ℝ690×690（30时间步×23维=690）。矩阵显示出强烈的块对角结构，表明高时间相关性和显著的跨维度相关性。</p>
</blockquote>
<ol start="4">
<li><p><strong>训练优化：多样本流匹配与损失函数</strong>：为减少梯度方差并分摊昂贵的VLM前向计算，作者采用多样本流匹配：每次VLM前向传播后，用不同的（时间t, 噪声ϵ）采样计算15个动作预测，然后进行反向传播。总损失是动作流匹配损失、阶段预测交叉熵损失（权重0.1）和FAST辅助损失（权重0.05）的加权和。</p>
</li>
<li><p><strong>推理优化</strong>：</p>
<ul>
<li><strong>相关感知软修复</strong>：采用滚动窗口预测（预测30步，执行26步）。在下一个预测窗口，将上一步最后4个预测动作作为“软”条件，通过相关噪声分布引导剩余自由维度的采样，以保持动作序列的平滑过渡。</li>
<li><strong>动作压缩</strong>：使用三次样条插值将预测的26个动作压缩到20个执行步，实现1.3倍的加速。</li>
<li><strong>校正规则</strong>：基于失败分析，添加了简单的启发式规则来纠正常见故障模式（如意外夹爪闭合后的恢复）。</li>
</ul>
</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>基准与数据集</strong>：实验在BEHAVIOR-1K基准上进行，该基准包含50个长视野家庭任务，使用OmniGibson/NVIDIA Isaac Sim模拟器。使用了提供的10,000个专家演示（跨50个任务）进行训练，并在具有随机初始条件的10个回合中评估每个任务。</p>
<p><strong>对比方法</strong>：作为竞赛方案，主要与挑战赛排行榜上的其他方案进行对比。方法本身是在Pi0.5架构上的改进。</p>
<p><strong>关键实验结果</strong>：该方法在2025 BEHAVIOR挑战赛的公共和私人排行榜上均获得第一名，在所有50个任务上的综合**q-score达到26%**。图13展示了每个任务以及每个任务10个回合的平均得分分布，显示了方法在不同任务和随机性下的性能。</p>
<p><img src="https://arxiv.org/html/2512.06951v2/media/per_task_and_eps_score.png" alt="每任务及每回合得分"></p>
<blockquote>
<p><strong>图13</strong>：每个任务（左）以及每个任务10个回合（右）的得分分布。小提琴图和箱线图展示了方法在不同任务和随机种子下的性能变化。</p>
</blockquote>
<p><strong>消融分析与失败原因</strong>：作者提供了失败案例的定性分析（图14）。主要失败原因包括：1）<strong>阶段跳跃</strong>（占失败的35%）：阶段预测错误导致动作序列错误；2）<strong>操作失败</strong>（30%）：如抓取、放置等底层技能失败；3）<strong>探索失败</strong>（20%）：在复杂导航或搜索中陷入困境；4）<strong>硬件/模拟限制</strong>（15%）。这些分析指出了当前方法的局限性和未来改进方向。</p>
<p><img src="https://arxiv.org/html/2512.06951v2/media/reasons.png" alt="失败原因分析"></p>
<blockquote>
<p><strong>图14</strong>：失败原因分析饼图。阶段跳跃（35%）、操作失败（30%）、探索失败（20%）和硬件/模拟限制（15%）是主要的失败模式。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1) 提出了<strong>相关噪声流匹配</strong>，显式建模动作的时空相关性，提升了训练效率并实现了相关感知修复，使动作序列更平滑。2) 设计了<strong>系统2阶段跟踪</strong>机制，通过预测和过滤任务阶段信息，有效解决了长视野任务中的非马尔可夫状态歧义问题。3) 展示了一种<strong>实用的竞赛方案设计思路</strong>：结合可学习的混合层注意力、多样本训练、动作压缩以及针对性的启发式校正规则，在有限计算预算下显著提升了策略在复杂基准上的性能。</p>
<p><strong>局限性</strong>：作者明确指出，作为竞赛方案而非严格的研究论文，许多设计选择基于直觉或快速实验，缺乏系统的消融研究来精确量化每个组件的贡献。此外，方法移除了语言处理，使用了任务特定的嵌入，这限制了其向未见过的、以语言描述的新任务的泛化能力。</p>
<p><strong>对后续研究的启示</strong>：1) <strong>显式建模先验</strong>：在生成式机器人策略中（如流匹配/扩散），显式融入领域知识（如动作相关性）可以显著改善训练和推理。2) <strong>层次化状态表示</strong>：对于长视野任务，引入类似“阶段”或“子目标”的离散高层状态表示，是解决非马尔可夫性和复合错误的一种有效且轻量化的途径。3) <strong>学习与规则的结合</strong>：在缺乏恢复数据或模拟到现实存在差距的场景下，将学习策略与精心设计的、基于故障分析的启发式规则相结合，是一种实用且高效的鲁棒性提升策略。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出了在2025年BEHAVIOR挑战赛中夺冠的视觉-语言-动作模型任务适应方案。核心问题是解决长时域家庭任务中错误累积、状态歧义和缺乏恢复演示等挑战。关键技术包括：引入相关噪声的流匹配以提升训练效率并生成平滑动作；采用可学习混合层注意力和系统2阶段跟踪进行歧义消解；训练使用多样本流匹配减少方差，推理时采用动作压缩与特定校正规则。该方法在50项任务上实现了26%的综合q-score。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.06951" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>