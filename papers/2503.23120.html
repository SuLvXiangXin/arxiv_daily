<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Dexterous Non-Prehensile Manipulation for Ungraspable Object via Extrinsic Dexterity - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Dexterous Non-Prehensile Manipulation for Ungraspable Object via Extrinsic Dexterity</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2503.23120" target="_blank" rel="noreferrer">2503.23120</a></span>
        <span>作者: Wang, Yuhan, Li, Yu, Yang, Yaodong, Chen, Yuanpei</span>
        <span>日期: 2025/03/29</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，针对无法抓握（如底面积过大超出末端执行器最大开合范围）物体的操作，主流方法是通过外在灵巧性（extrinsic dexterity），即利用环境特征进行非抓取式操作。现有研究主要使用夹爪或欠驱动的多指手，而多指灵巧手虽然提供了更高的灵活性和操作潜力，但其高维动作空间和复杂的接触动力学带来了巨大的控制挑战。传统方法如基于简化接触模型的轨迹优化在接触丰富的场景中往往失效；模仿学习则因难以通过遥操作收集高质量、动态接触丰富的演示数据而受限。尽管强化学习在模拟中训练并迁移至实体的范式显示出优势，但直接训练端到端策略来完成将物体从桌面中心重新定位至边缘或墙壁这一需要序列技能和战略规划的任务，仍然非常困难。</p>
<p>本文针对使用多指灵巧手操作无法抓握物体这一具体痛点，提出了一种结合高层战略规划和底层技能执行的分层学习新视角。核心思路是：首先通过一个高层规划器分析环境点云，决策是将物体推向墙壁还是桌沿，并预测最佳目标位置；然后由底层强化学习策略依次执行推动和基于环境的抓取操作，从而完成整个操作任务。</p>
<h2 id="方法详解">方法详解</h2>
<p>ExDex 系统是一个分层框架，整体流程如图2所示，包含训练和推理两个阶段。</p>
<p><img src="https://arxiv.org/html/2503.23120v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：ExDex 系统设计示意图。(A) 训练阶段分为三步：第1步通过监督学习训练预测模型 π_pre；第2步通过强化学习分别训练推动策略 π_push、墙边抓取策略 π_wall 和桌边抓取策略 π_edge；第3步对策略进行联合微调。(B) 推理阶段：π_pre 处理点云，决策（墙或边）并预测目标位置 Pt；π_push 将物体推至 Pt；最后执行 π_wall 或 π_edge 完成抓取。</p>
</blockquote>
<p><strong>1. 高层规划器设计</strong>：高层规划器是一个预测模型 π_pre，其输入为环境点云 p，输出是三维目标坐标 Pt = (Px, Py, Pz) 和一个信号 s。Pt 作为底层推动策略 π_push 的目标位置，信号 s 用于自动选择后续执行 π_wall 或 π_edge 策略。该模型通过监督学习进行训练。</p>
<p><strong>2. 底层策略训练</strong>：基于高层规划器预测的 Pt，使用无模型强化学习训练三个专用策略：推动策略 π_push、墙边抓取策略 π_wall 和桌边抓取策略 π_edge。</p>
<ul>
<li><strong>观察空间</strong>：包括机器人状态（18维手臂和手部关节位置 qt，15维五个指尖位姿 {Ft^f,i}）、物体状态（SE(3)位姿 pt^obj，6维速度 vt^obj）、目标信息（预测位姿 Pt）以及接触信息（一个相对于物体中心固定的设计点 cp）。</li>
<li><strong>动作空间</strong>：包括手部关节的绝对目标角度 at^hand (ℝ^6) 和手臂关节的相对位置变化 at^arm (ℝ^6)，通过PD控制器转换为关节扭矩。</li>
<li><strong>奖励设计</strong>：采用分阶段的统一奖励函数 r = r_motion + r_pregrasp · P(a) + r_grasp · P(b)。其中 P(·) 是条件概率函数，T(·,·) 是距离接近度函数。<ul>
<li><strong>运动奖励 r_motion</strong>：对于 π_push 和 π_wall，鼓励物体到达目标位姿（π_push 的目标是 Pt，π_wall 的目标是一个预定义位姿）；对于 π_edge，鼓励指尖到达特定布局（拇指在上，其余四指在下）。</li>
<li><strong>预抓取奖励 r_pregrasp</strong>：鼓励手部在物体重新定位后达到有利的预抓取姿势，即中指指尖 Ft^f,3 接近物体上的固定点 cp。</li>
<li><strong>抓取奖励 r_grasp</strong>：在预抓取位置达成后，鼓励稳定抓取，通过优化所有五个指尖相对于物体的集体位置来实现。</li>
</ul>
</li>
<li><strong>训练方法</strong>：使用PPO算法，在IsaacGym中并行4096个环境进行加速。采用全面的域随机化（机器人及物体属性）和课程学习策略（从相似物体、固定位置开始，逐步增加物体尺寸差异并随机化初始位置）来提高策略的鲁棒性和训练效率。</li>
</ul>
<p><strong>3. 联合微调</strong>：为解决顺序执行策略时可能出现的状态分布不匹配（技能链问题），对策略进行联合微调。具体做法是：首先对 π_push 的预测目标 Pt 添加高斯噪声以增强其鲁棒性；然后将 π_push 与 π_wall 或 π_edge 连接，在微调阶段共同训练，使前一策略的终止状态更好地匹配后一策略的初始状态分布。</p>
<p><strong>4. 模拟到真实的迁移</strong>：通过在训练中引入大量域随机化（包括动力学参数、视觉外观、物体属性等），使得在模拟中训练的策略能够零样本迁移到真实的机器人系统上。真实系统使用RGB-D相机获取点云，并需要一个额外的物体6D姿态估计模块来提供物体状态信息。</p>
<p><strong>与现有方法的核心创新点</strong>：</p>
<ol>
<li><strong>首次探索</strong>：首次在模拟和真实环境中探索了使用多指灵巧手进行外在灵巧性操作。</li>
<li><strong>分层框架</strong>：提出了结合高层目标位置预测与底层技能执行的分层框架，有效解决了长视野操作中的规划与技能链问题。</li>
<li><strong>灵活的策略设计</strong>：底层策略奖励函数针对不同子任务（推、墙边抓、桌边抓）进行专门设计，并采用课程学习与联合微调，提升了学习效率和策略鲁棒性。</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准与数据集</strong>：在模拟环境（IsaacGym）和真实机器人系统（Unitree H1机器人，定制五指灵巧手）上进行验证。使用了数十个多样化的家庭日常物体进行测试。</li>
<li><strong>对比方法</strong>：与以下基线方法进行比较：1) <strong>GraspNet</strong>：一个先进的抓取生成网络；2) <strong>UniDexGrasp</strong>：一个基于抓取演示的灵巧抓取策略；3) **Zhou et al.**：一个使用夹爪和外在灵巧性的强化学习工作；4) <strong>PreAfford</strong>：一个学习可供性以指导物体重新定位的方法。</li>
</ul>
<p><strong>关键实验结果</strong>：<br>在模拟实验中，ExDex在“墙”和“边”两种任务上均取得了最高成功率。例如，在“墙”任务中，ExDex对训练物体的成功率为93.3%，对未见物体的泛化成功率为86.7%，显著高于其他基线方法（GraspNet: 0%, UniDexGrasp: 13.3%, Zhou et al.: 60%, PreAfford: 53.3%）。在“边”任务中，ExDex对训练物体和未见物体的成功率分别为96.7%和90%。</p>
<p><img src="https://arxiv.org/html/2503.23120v1/x4.png" alt="对比结果"></p>
<blockquote>
<p><strong>图4</strong>：模拟环境中的定量对比结果。ExDex在“墙”和“边”两种任务上，无论是训练物体还是未见物体，其成功率均显著优于所有基线方法。</p>
</blockquote>
<p>消融实验验证了各组件的重要性。移除高层规划器（“w/o High-level Planner”）或联合微调（“w/o Joint Training”）都会导致性能显著下降。具体来说，在“墙”任务中，完整模型成功率为93.3%，移除高层规划器后降至73.3%，移除联合微调后降至80%。</p>
<p><img src="https://arxiv.org/html/2503.23120v1/x5.png" alt="消融实验"></p>
<blockquote>
<p><strong>图5</strong>：消融实验结果。结果表明，高层规划器和联合微调对于系统性能都至关重要，移除任一组件都会导致成功率大幅下降。</p>
</blockquote>
<p>真实世界的零样本迁移实验也取得了成功。ExDex策略被直接部署到真实的Unitree H1机器人上，无需额外训练，成功操作了包括书本、平板电脑盒、餐盘在内的多个未见物体，展示了良好的泛化能力和实际应用潜力。</p>
<p><img src="https://arxiv.org/html/2503.23120v1/x6.png" alt="真实世界结果"></p>
<blockquote>
<p><strong>图6</strong>：真实世界零样本迁移的定性结果。展示了ExDex系统成功操作多种未见家庭物体的序列图像，包括推向墙边并抓取，以及推向桌沿并抓取。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>首次在模拟和真实世界场景中探索了使用多指灵巧手进行外在灵巧性操作，扩展了灵巧手的应用范围。</li>
<li>提出了一个新颖的分层学习框架（ExDex），将高层环境感知、规划与底层强化学习技能相结合，有效解决了无法抓握物体的操作问题。</li>
<li>通过广泛的模拟与实物实验验证了框架的有效性、泛化能力以及模拟到真实的零样本迁移能力。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到的局限性包括：1) 目前主要处理具有大而平坦底面的物体；2) 真实世界部署需要一个额外的物体6D姿态估计模块，该系统误差可能影响性能。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>分层与组合</strong>：将复杂的长视野操作任务分解为可学习的子技能，并结合规划或学习的高层策略进行组合，是解决复杂机器人操作问题的有效途径。</li>
<li><strong>模拟到真实的桥梁</strong>：大规模的域随机化和课程学习是实现零样本策略迁移的强大工具。</li>
<li><strong>外在灵巧性的拓展</strong>：未来工作可以探索利用更多类型的环境特征（如角落、其他物体）以及更复杂的非抓取操作（如翻滚、滑动调整姿态）来操纵更多样化的物体。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机械手因开合范围有限而无法直接抓取大面积物体的问题，提出ExDex系统。该系统采用灵巧臂手结合强化学习，训练非抓取操作策略：将物体从桌面中心推至边缘或墙壁，利用环境约束辅助抓取。实验表明，该方法在多种物体上表现优异，并具备对新物体的泛化能力，且学习到的策略能零样本迁移至真实机器人系统。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2503.23120" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>