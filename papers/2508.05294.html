<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.05294" target="_blank" rel="noreferrer">2508.05294</a></span>
        <span>作者: Salimpour, Sahar, Fu, Lei, Rachwał, Kajetan, Bertrand, Pascal, O&#39;Sullivan, Kevin, Jakob, Robert, Keramat, Farhad, Militano, Leonardo, Toffetti, Giovanni, Edelman, Harry, Queralta, Jorge Peña</span>
        <span>日期: 2025/08/07</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人领域目前存在两种主要范式。早期工作侧重于端到端（end-to-end）管道，直接将原始感官输入和自然语言映射到机器人动作。当前兴趣则转向使用基础模型（Foundation Models）作为高级智能体的模块化系统。这些智能体解释用户意图、生成计划、调用机器人API或与中间件（如ROS）接口，而非取代底层的机器人软件栈。现有综述主要关注多模态架构及其组件，强调多模态模型在机器人决策和高级规划中的一般使用，以及特定领域（如操作）中用于低级控制的端到端学习框架。然而，随着具身和通用AI智能体（Embodied and Generalist AI Agents）的兴起，尚无综述研究AI智能体与现有控制软件、库或中间件交互的新兴设计模式。此外，许多实用系统（GitHub托管的项目、ROS包或初创公司原型）尽管现实相关性和影响力日益增长，但在文献中代表性不足。本文旨在填补这一空白，核心思路是提出一个分类法，从<strong>集成方法</strong>和<strong>智能体角色</strong>两个维度对LLM/VLM/VLA驱动的机器人自主性与交互工作进行系统性梳理和比较，并提供实用的设计指南。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文的核心贡献是提出了一个用于分类LLM/VLM/VLA与机器人系统集成方法的四象限分类法。整体上，论文从概念和交互的角度，将现有工作归纳为四种主要的集成方向。</p>
<p><img src="https://..." alt="项目进展时间线"></p>
<blockquote>
<p><strong>图2</strong>：生成式AI与机器人交叉领域项目的进展时间线。上图聚焦于智能体导向的方法，下图列出了塑造该领域进展的其他相关模型。展示了从2015年端到端模型开始，到2023年ChatGPT发布后出现早期LLM接口（如ChatGPT for Robotics），再到2024-2025年出现更复杂的智能体框架（如ROSA、RAI、BUMBLE）和通用VLA模型（如RT-2、π0、Gemini Robotics）的演进过程。</p>
</blockquote>
<p><strong>1. 协议集成 (Protocol Integration)<strong>：这是概念上最简单的集成方式，将基础模型用作用户输入的“翻译器”。例如，<code>ros2ai</code>将通用用户提示翻译为特定的ROS 2命令行工具调用，交互有限且主要是单向的。随着模型上下文协议（MCP）成为LLM/VLM工具使用的实际标准，出现了如<code>ROS-MCP</code>库等技术集成，使AI助手（如Claude）能够与ROS 2应用交互，包括启动UI、管理ROS资源、发布主题、调用服务等。</strong>代码即策略（Code as Policies， CaP）</strong> 也属于此类，其核心是LLM生成可执行的Python代码（语言模型程序，LMPs），通过代码生成间接调用工具，实现对机器人的反应式和基于视觉的控制。</p>
<p><strong>2. 接口/智能体集成 (Interface / Agentic Integration)<strong>：在保留协议集成工具调用能力的基础上，增强了交互性。这类方法中，要么（i）工具的输出（通常是现实世界中的动作）会影响模型未来的命令或额外的工具调用；要么（ii）重点在于用户交互，例如在人机交互（HRI）应用中。这符合向更具智能体特性的应用发展的研究趋势，基础模型相对于用户命令获得更多自主权，执行更复杂的工具调用，并且通常以循环方式运行，每次迭代包含多个工具调用。在此范式下，用户指令可以保持高级别，而基础模型能够将指令分解为一系列工具调用。例如，</strong>ROSA</strong>、<strong>RAI</strong>、<strong>BUMBLE</strong>以及最近的<strong>OpenMind OM1</strong>都属于此类。它们作为用户与机器人系统之间的智能中介，进行推理并执行动作。</p>
<p><strong>3. 编排导向集成 (Orchestration-Oriented Integration)<strong>：与接口集成的区别在于，此类方法侧重于</strong>资源管理</strong>问题，而非与用户的交互。主要包括LLM或VLM充当规划者或协调者的情况，通常涉及其他AI智能体。此类别横跨集成方法和智能体角色（第IV节将进一步描述规划者和编排者角色）。例如，<strong>AutoRT</strong> 就是利用模型来编排多个机器人智能体。</p>
<p><strong>4. 嵌入式或直接集成 (Embedded or Direct Integration)<strong>：此类方法中，LLM（或其多模态变体）直接（i）以端到端方式产生机器人动作，或（ii）产生特定输出（例如用作感知模块）。这些通常被称为机器人基础模型（Robotic Foundation Models）。例如，</strong>RT-2</strong> 通过共同微调预训练的VLM，将互联网规模的视觉-语言任务与机器人轨迹数据结合，形成了一个新颖的VLA框架。<strong>π0</strong> 则通过流匹配扩散策略实现了实时连续控制，在单一可微分框架中统一了感知、推理和运动生成。</p>
<p><img src="https://..." alt="智能体角色分类"></p>
<blockquote>
<p><strong>图3</strong>：按主要角色和功能对现有工作的分类。将智能体分为规划智能体、编排智能体、任务特定智能体、模型中心智能体和通用系统智能体等类别，展示了不同系统在决策和架构上的侧重。</p>
</blockquote>
<p>论文通过表I总结了前三类集成方法的主要区别：</p>
<table>
<thead>
<tr>
<th align="left">方面</th>
<th align="left">协议聚焦集成</th>
<th align="left">接口 / 智能体集成</th>
<th align="left">编排导向集成</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>主要角色</strong></td>
<td align="left">LLM将用户文本直接映射到工具/API调用</td>
<td align="left">LLM作为面向用户的智能体，进行推理并执行动作</td>
<td align="left">LLM（或小型团队）协调多个智能体、技能或机器人</td>
</tr>
<tr>
<td align="left"><strong>工具焦点</strong></td>
<td align="left">单个API或CLI调用，简单包装器</td>
<td align="left">MCP或内部工具，循环或并发工具调用</td>
<td align="left">LangChain/LangGraph，或自定义多智能体编排管道</td>
</tr>
<tr>
<td align="left"><strong>典型框架</strong></td>
<td align="left">MCP服务器，ROS CLI绑定</td>
<td align="left">LangChain, LangGraph (ReAct智能体), ROSA, RAI</td>
<td align="left">LangGraph, 自定义编排器 (如 AutoRT)</td>
</tr>
<tr>
<td align="left"><strong>用户交互</strong></td>
<td align="left">直接查询-响应</td>
<td align="left">对话式，带有人类在环推理</td>
<td align="left">有限的直接对话；用户给出高级目标，编排器内部管理子任务</td>
</tr>
<tr>
<td align="left"><strong>物理交互</strong></td>
<td align="left">最小化或间接（通过一个API）</td>
<td align="left">是：调用影响传感器或执行器的工具</td>
<td align="left">间接：将现实世界执行委托给子智能体或机器人</td>
</tr>
<tr>
<td align="left"><strong>智能体焦点</strong></td>
<td align="left">自然语言与系统命令之间的翻译</td>
<td align="left">推理 + 执行</td>
<td align="left">任务分配、调度和监控</td>
</tr>
<tr>
<td align="left"><strong>类比</strong></td>
<td align="left">命令翻译器</td>
<td align="left">助手 / 操作员</td>
<td align="left">项目经理 / 任务控制中心</td>
</tr>
</tbody></table>
<p>此外，论文指出更复杂的系统可能跨越多个类别。例如，一个系统可能包含用于用户输入的接口智能体、一个内部协调器智能体，以及由协调器管理的协议和直接智能体作为子系统。然而，由于该领域相对不成熟，目前大多数工作都专注于一种特定的集成方法。像<strong>RAI</strong>或<strong>OpenMind</strong>这样的解决方案也可被视为框架，因为它们为多智能体协调和专家智能体支持提供了工具和基础设施，但目前的发展阶段更接近接口集成类。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>作为一篇综述性论文，本文并未进行传统的对比实验，而是通过系统性的分类和比较来呈现“结果”。其核心分析体现在对代表性工作的梳理和表格化对比中。</p>
<p><img src="https://..." alt="代表性工作对比表"></p>
<blockquote>
<p><strong>表II</strong>：自ChatGPT发布以来，按本综述提出的集成方法分类的部分最具代表性工作对比。表格从项目、描述、年份、集成方法、工具集/技能集、记忆、多模态、世界模型、开源和适应性等多个维度进行了详细比较。</p>
</blockquote>
<p>表II比较了包括CaP、ros2ai、ROS-LLM、ROScribe、ChatGPT for Robotics、ROSA、RAI、Embodied Agents、BUMBLE、AutoRT、ROS-MCP、Gemini Robotics、MoManip VLA、ARNA、OpenMind OM1、explainable ros、LLama ros、Stretch AI和UROSA在内的多个项目。从该表可以总结出以下关键观察：</p>
<ol>
<li><strong>工具集/技能集</strong>：主要分为自定义工具、ROS API/CLI、预训练策略/技能库和代码生成。这反映了从直接调用现有API到学习通用策略的频谱。</li>
<li><strong>记忆模块</strong>：常见形式有聊天历史、日志、语义记忆和多模态记忆。更近期的工作（如BUMBLE、ARNA）开始采用结构化数据库或多模态记忆架构来存储文本和视觉上下文。</li>
<li><strong>多模态支持</strong>：从早期的纯LLM接口，发展到普遍集成VLM，再到最新的VLA模型，体现了感知与动作结合日益紧密的趋势。</li>
<li><strong>世界模型</strong>：主要通过系统提示（Sys. prompt）、自定义工具/技能或预训练策略来体现，为智能体提供环境理解、目标、约束和操作规则。</li>
<li><strong>开源与适应性</strong>：大部分学术和社区项目是开源的。适应性（Adaptation）则通过系统提示、自定义工具或预训练策略的扩展来实现。</li>
</ol>
<p>这些比较系统地展示了不同集成方法在技术实现上的共性与差异，以及该领域从简单协议翻译向复杂、交互式、多智能体编排演进的清晰脉络。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：</p>
<ol>
<li><strong>概念界定与分类法提出</strong>：明确了机器人领域中“智能体AI”（Agentic AI）的概念，将其与端到端学习或经典符号规划方法区分开来，并提出了一个创新的双维度分类法（集成方法与智能体角色），为理解纷繁复杂的研究现状提供了清晰框架。</li>
<li><strong>全面涵盖与实用导向</strong>：不仅回顾了学术论文，还重点纳入了快速发展的社区驱动项目、ROS包和工业框架，弥补了现有文献的空白。此外，提供了实用的设计工具包（§V），指导研究者和开发者进行系统实现和原型设计。</li>
<li><strong>前瞻性讨论</strong>：通过详细的讨论（§VI），指出了关键开放问题（如可靠性、安全伦理、评估基准等），并勾勒出未来具身智能体AI研究的 promising 方向。</li>
</ol>
<p>论文自身提到的局限性包括：该领域发展极其迅速，许多有影响力的社区项目难以被学术综述全面覆盖；一些框架（如ROSA）与ROS紧密耦合，限制了与非ROS系统的互操作性；LLM-based智能体在空间推理和自我纠正方面存在局限，可能导致对物理边界、物体交互和任务完成的理解失败。</p>
<p>对后续研究的启示包括：需要开发更健壮的空间推理和失败恢复机制；探索去中心化、硬件无关的架构（如OM1的FABRIC协议）；加强记忆模块的研究，特别是多模态和长期记忆；推动开源框架和标准化工具协议（如MCP）的采用；建立更全面的评估基准，并持续关注安全性和可靠性在关键任务机器人应用中的挑战。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文是一篇综述论文，旨在解决当前缺乏对AI智能体（基于LLM/VLM）如何与现有机器人控制软件、中间件（如ROS）及工业框架进行接口集成的设计模式进行系统梳理的问题。论文提炼并分类了相关技术方法，重点阐述了将基础模型作为高级协调者、规划者或通用接口的模块化“智能体”架构，使其能理解指令、调用API并协调子系统，而非取代底层机器人栈。核心贡献是提出了一种对模型集成方法的分类法，并对不同解决方案中智能体的角色进行了比较分析。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.05294" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>