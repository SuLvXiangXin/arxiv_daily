<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.01022" target="_blank" rel="noreferrer">2512.01022</a></span>
        <span>作者: Wei, Yi-Lin, Liao, Haoran, Lin, Yuhao, Wang, Pengyue, Liang, Zhizhao, Liu, Guiliang, Zheng, Wei-Shi</span>
        <span>日期: 2025/11/30</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前机器人操作领域的主流方法是模仿学习（IL）和视觉-语言-动作（VLA）模型，它们擅长基于当前观察预测后续动作，在顺序任务中表现优异。然而，这些方法在处理循环任务时存在明显局限。循环任务（如摇晃瓶子、敲钉子）要求机器人执行重复动作并在预期时刻停止，其本质是非马尔可夫过程，正确决策不仅依赖当前观察，更依赖于循环内累积的进度。现有模仿策略通常依赖短观察窗口进行动作预测，导致模型在面对循环间相似的观察时无法区分当前阶段，从而陷入无限循环或提前终止，如图2(a)所示。此外，该领域缺乏包含充足数据和自动评估工具的基准测试，阻碍了有效解决方案的发展。</p>
<p>本文针对机器人循环操作任务，提出了两个核心挑战：1）模仿方法因历史信息利用效率低下而无法在预期时间内完成任务；2）缺乏基准测试。为解决这些问题，本文提出了CycleManip框架，其核心思路是通过成本感知的采样策略增强有效历史感知，并通过多任务学习提升历史理解，从而以端到端的模仿方式实现循环任务操作。</p>
<h2 id="方法详解">方法详解</h2>
<p>CycleManip框架的目标是让机器人基于自然语言指令执行指定次数的循环操作动作。框架采用模仿学习范式，学习一个策略π，根据历史观察预测下一个动作：a_t = π(lan, {o_i}_{i=1}^t)。其核心创新在于两个组件：有效历史感知和有效历史理解。</p>
<p><img src="https://arxiv.org/html/2512.01022v1/x3.png" alt="方法整体框架"></p>
<blockquote>
<p><strong>图3</strong>：CycleManip整体框架。给定用户指令和机器人观察，框架旨在执行包含循环动作的操作任务。首先通过成本感知采样策略对不同开销的观察进行差异化采样，实现有效历史感知。然后将所有观察和语言指令编码为扩散条件以预测机器人动作。此外，利用观察特征预测任务进度以促进历史理解。</p>
</blockquote>
<p><strong>整体流程</strong>：输入为用户语言指令<code>lan</code>和历史观察<code>{o_i}</code>，观察被分为高开销（如图像/点云）和低开销（如本体感觉）。首先应用成本感知采样策略得到采样后的观察。语言特征由CLIP编码器编码，高开销观察特征由点编码器编码，低开销观察特征由Transformer编码器编码。融合后的特征<code>f_lh</code>一方面作为扩散模型的条件以预测动作，另一方面用于辅助任务（进度预测）。最终损失函数结合了动作预测的MSE损失和进度预测的交叉熵损失。</p>
<p><strong>核心模块1：有效历史感知（成本感知采样策略）</strong><br>为解决扩展观察视野带来的计算开销问题，该方法对不同类型的观察采用不同的采样策略。</p>
<ul>
<li><strong>低开销观察</strong>：如机械臂末端执行器的位姿差。因其编码成本低，采用<strong>密集且广泛的采样策略</strong><code>H_l</code>，将所有过去的低开销观察纳入采样过程。使用位姿差能更直接地反映整体运动模式，并减轻绝对位置带来的偏差。</li>
<li><strong>高开销观察</strong>：如RGB图像或点云。采用<strong>启发式帧采样策略</strong><code>H_h</code>，在保持总帧数<code>K_high</code>（实验中为6）不变的前提下，扩展时间视野。具体策略为：以第一帧为0，当前帧为t，进行右侧二分采样收集0.5·<code>K_high</code>帧；再从<code>K_high</code>帧开始，按规则<code>K_high - 2^k</code>进行指数采样，收集另外0.5·<code>K_high</code>帧。<br>通过此策略，策略公式更新为：a_t = π( H_h({o^h_i}), H_l({o^l_i}) )。</li>
</ul>
<p><strong>核心模块2：有效历史理解（多任务学习）</strong><br>仅依靠模仿学习监督信号（如图2(b)所示，每次敲击的监督信号都是“执行敲击”）难以让模型真正理解循环任务的内在时序过程。为此，引入一个<strong>辅助任务</strong>——预测当前任务进度（例如当前循环计数或任务进度百分比）。这鼓励模型为循环的不同阶段学习具有区分性的特征表示。<br>具体实现：对融合特征<code>f_lh</code>应用一个单层MLP来预测当前进度<code>b_t</code>。进度真值由当前帧号除以任务总帧数得到。将区间[0,1]均匀划分为10个区间，将<code>b_t</code>离散化为对应的类别标签<code>y_t</code>，用于10分类的交叉熵损失。为防止多任务头过拟合，在预测进度前先使用多层MLP进行特征融合（该融合特征也用于扩散决策）。</p>
<p><strong>创新点</strong>：</p>
<ol>
<li><strong>差异化历史采样</strong>：首次根据观察信息的编码成本（高/低开销）设计不同的历史信息融合策略，在有效扩展时间感知范围的同时控制了计算开销。</li>
<li><strong>面向循环理解的辅助任务</strong>：通过多任务学习显式地建模任务进度，使策略从被动“感知”历史转变为主动“理解”循环阶段，从而做出更准确的终止或继续决策。</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准测试</strong>：提出了基于RoboTwin 2.0平台的CycleManip基准测试，包含8个模拟循环任务（如图4所示），并设计了自动循环评估系统。</li>
<li><strong>对比基线</strong>：DP、DP3、RDT、Pi-0。</li>
<li><strong>评估指标</strong>：循环任务成功率（<code>Suc.</code>）、循环次数偏差（<code>Cyc.</code>）；通用任务成功率。</li>
<li><strong>实验环境</strong>：模拟实验（CycleManip基准、RoboTwin 2.0基准）和真实世界实验（在单/双臂夹爪、灵巧手、人形机器人等多种平台上进行6项任务）。</li>
</ul>
<p><img src="https://arxiv.org/html/2512.01022v1/x4.png" alt="基准测试任务可视化"></p>
<blockquote>
<p><strong>图4</strong>：CycleManip基准测试中包含的8个模拟循环操作任务可视化。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><p><strong>模拟循环任务性能对比（表1）</strong>：CycleManip在全部8个任务上显著优于所有基线方法。例如，在“block hammering”任务上，成功率达到86%，而最好的基线DP3仅为23%；平均循环次数偏差为0.25，远低于基线的5.55。这表明本文方法能更准确地控制循环次数。</p>
</li>
<li><p><strong>真实世界实验结果（表2）</strong>：在多种机器人平台上，CycleManip（Ours）同样大幅优于基线DP3。消融实验（Ours w/o Task，即仅使用历史感知组件）表明，两个核心组件均有效，且结合后性能最佳。例如，在“drum beating”任务中，完整方法成功率达90%，而仅使用历史感知时为60%，基线DP3为0。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2512.01022v1/x5.png" alt="真实世界硬件设置"></p>
<blockquote>
<p><strong>图5</strong>：真实世界实验的硬件设置。(a) 用于单臂和双臂任务的AgileX Piper机器人（夹爪和BrainCO Revo2灵巧手）及感知相机。(b) 真实世界任务物体集。(c) 用于全身循环任务的Unitree G1人形机器人。</p>
</blockquote>
<ol start="3">
<li><p><strong>通用操作任务性能（表3）</strong>：在RoboTwin 2.0基准的7个通用操作任务上，CycleManip也取得了最佳或极具竞争力的成功率，证明了其良好的泛化能力。</p>
</li>
<li><p><strong>即插即用能力（表4）</strong>：将CycleManip的历史感知与理解模块集成到VLA模型Pi-0中，能使其在循环任务上的性能获得巨大提升（如“bottle shaking”任务从19%提升至72%），证明了该方法的模块化和兼容性。</p>
</li>
<li><p><strong>效率分析（表5）</strong>：与强基线DP3相比，CycleManip在训练/测试时间和GPU内存消耗上仅有微小增加，表明其以可忽略的额外开销换取了强大的历史感知与理解能力。</p>
</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了CycleManip框架，首次通过成本感知的历史采样和多任务驱动的历史理解，以端到端模仿方式有效解决了机器人循环操作任务的关键挑战。</li>
<li>构建了一个包含多样化循环任务、自动数据生成与评估工具的CycleManip基准测试，为领域发展提供了基础。</li>
<li>通过大量模拟与真实世界实验，验证了该方法的高成功率、强泛化性、即插即用能力以及对多种异构机器人平台的广泛适用性。</li>
</ol>
<p><strong>局限性</strong>：论文自身未明确陈述局限性，但根据方法描述，其性能依赖于高质量的专家演示数据收集。此外，进度预测辅助任务的真值依赖于任务的总时间步长，在开放环境中可能需要进行调整。</p>
<p><strong>后续研究启示</strong>：</p>
<ol>
<li><strong>历史信息的高效利用</strong>：本文提出的按信息编码成本进行差异化处理的思路，可为其他需要长时序建模的机器人任务（如长视野任务、交互式任务）提供借鉴。</li>
<li><strong>循环与进度感知</strong>：将循环结构理解和进度估计作为显式学习目标，是提升策略在非马尔可夫性任务中决策可靠性的有效途径。</li>
<li><strong>基准测试的构建</strong>：针对特定挑战性子任务（如循环操作）构建专门的基准测试，能有效推动该细分领域的研究进展。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人循环任务操作中的核心挑战：现有模仿方法因历史信息利用不足而难以在预期时间内完成任务，且缺乏专门基准。提出了CycleManip框架，其关键技术是通过**成本感知采样策略**增强历史感知，并利用**多任务学习**提升历史理解，实现了端到端的循环任务模仿。实验表明，该方法在循环任务中取得高成功率，展现出强大的通用任务适应性、对VLA等策略的即插即用能力，并能跨双爪、灵巧手、人形机器人等多种平台应用。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.01022" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>