<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>KAN We Flow? Advancing Robotic Manipulation with 3D Flow Matching via KAN & RWKV - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>KAN We Flow? Advancing Robotic Manipulation with 3D Flow Matching via KAN & RWKV</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.01115" target="_blank" rel="noreferrer">2602.01115</a></span>
        <span>作者: Ziyang Wang Team</span>
        <span>日期: 2026-02-01</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>基于生成模型的视觉运动策略在机器人模仿学习中占据主导地位，主要包括扩散模型和流匹配两种范式。扩散模型通过迭代去噪建模多模态动作分布，性能强大但推理效率低下，需要多步采样和庞大的UNet骨干网络，导致高延迟，难以部署在资源受限的机器人上。流匹配方法通过直接学习一个连续向量场，通常能实现一步生成动作，缓解了采样负担，但其现有实现大多仍沿用大型的UNet风格架构，参数量依然庞大，限制了在边缘设备上的部署。本文旨在解决现有生成式策略在保持高精度和快速推理的同时，模型参数量过大的痛点，提出了结合RWKV（Receptance Weighted Key Value）和KAN（Kolmogorov-Arnold Networks）来构建轻量级、高表达能力骨干网络的新视角。本文的核心思路是：设计一个名为RWKV-KAN块的轻量级模块，结合RWKV的线性复杂度序列建模能力和KAN基于可学习样条的紧凑函数表达能力，并引入动作一致性正则化来稳定训练，从而在显著减少参数量的同时，实现高性能的单步动作生成。</p>
<h2 id="方法详解">方法详解</h2>
<p>KAN-We-Flow的整体框架是一个基于条件一致性流匹配的单步动作生成策略。输入包括一个加噪的动作轨迹、由单视角点云编码得到的视觉感知嵌入、机器人状态嵌入以及时间嵌入。这些条件被拼接后，送入一个轻量级的RWKV-KAN U型骨干网络（而非大型UNet）进行处理。该网络预测一个一步速度场，通过一致性流匹配学习一条直线流，最终在推理时以单步解码的方式实时生成动作序列。额外的动作一致性正则化（ACR）通过欧拉外推将预测轨迹与专家演示对齐，以稳定训练。</p>
<p><img src="https://arxiv.org/html/2602.01115v1/image/fig2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：KAN-We-Flow方法总览。策略接收一个加噪动作和一个由点云感知嵌入、机器人状态嵌入及时间嵌入拼接而成的条件。该表示由一个轻量级RWKV-KAN U型骨干网络（替代大型UNet）处理；RWKV以线性复杂度混合长程时间/通道上下文，而KAN执行基于可学习样条的特征校准。然后，通过条件一致性流匹配学习直线流以产生一步速度场，最终以实时推理速度生成动作；额外的动作一致性正则化将欧拉外推轨迹与演示对齐以稳定训练。</p>
</blockquote>
<p>核心模块是<strong>RWKV-KAN UNet</strong>，它是一个三阶段的编码器-解码器，每个阶段堆叠RWKV-KAN块。</p>
<ol>
<li><strong>RWKV模块</strong>：包含时间混合（TM）和通道混合（CM）操作。时间混合通过具有指数时间衰减的递归公式（前向和后向扫描）高效聚合序列信息，实现线性复杂度的长程上下文传播。通道混合则对每个令牌应用门控MLP。两者通过前置层归一化和残差连接结合。</li>
<li><strong>GroupKAN模块</strong>：这是对经典KAN的改进。首先，将输入特征在通道维度上分成G组（实践中G=4），每组由一个独立的KAN子网络处理，该子网络由可学习的单变量函数（如样条）矩阵构成，取代了传统MLP中的权重矩阵和固定激活函数。然后，引入一个轻量级的通道亲和力调制（CAM）模块，它通过对序列进行时间池化并经过一个小型前馈网络，生成一个通道门控向量，用于自适应地重新加权GroupKAN的输出。最后，通过DropPath和残差连接得到最终输出。</li>
</ol>
<p><img src="https://arxiv.org/html/2602.01115v1/image/fig3.png" alt="GroupKAN架构"></p>
<blockquote>
<p><strong>图3</strong>：GroupKAN的架构示意图。展示了分组处理、每个组内的KAN函数矩阵以及通道亲和力调制（CAM）模块的组成。</p>
</blockquote>
<p>与现有方法相比，创新点具体体现在：1) <strong>首次将RWKV和KAN架构引入机器人视觉运动策略学习</strong>，用高效的RWKV-KAN块替代了参数庞大的UNet骨干网络；2) 提出了<strong>动作一致性正则化（ACR）</strong>，这是一种轻量级的辅助损失，通过欧拉外推强制策略预测的动作轨迹终点与专家演示对齐，为训练提供了额外的监督，提高了策略精度和稳定性，且不增加推理开销。</p>
<p>训练目标包括<strong>多段一致性流匹配损失（ℒ_MFM）</strong>和<strong>动作一致性正则化损失（ℒ_ACR）</strong>。ℒ_MFM将时间区间[0,1]划分为K段（实践中K=2），在每段内分别强制执行解码终点和瞬时速度的一致性。ℒ_ACR则计算单步解码得到的动作轨迹在特定控制窗口内与专家动作的均方误差。最终损失为两者加权和（ℒ = ℒ_MFM + λ_ACR * ℒ_ACR，λ_ACR设为1）。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>本文在三个广泛使用的机器人操作基准上进行了评估：<strong>Adroit</strong>（3个任务：Hammer, Door, Pen）、<strong>DexArt</strong>（4个任务：Laptop, Faucet, Toilet, Bucket）以及<strong>Meta-World</strong>（34个任务，按难度分为Easy-21个、Medium-4个、Hard-4个、Very Hard-5个）。</p>
<p>对比的基线方法包括：</p>
<ul>
<li><strong>扩散策略</strong>：DP3、Simple-DP3、MambaPolicy、Diffusion Policy、BCRNN、IBC。</li>
<li><strong>流匹配策略</strong>：Adaflow、FlowPolicy、MP1。<br>其中DP3、MambaPolicy和FlowPolicy由作者在相同环境和专家数据下重新实现（标记为†）以确保公平比较。</li>
</ul>
<p>关键实验结果如下表所示，KAN-We-Flow在绝大多数任务和难度等级上取得了最佳成功率。</p>
<p><img src="https://arxiv.org/html/2602.01115v1/image/fig6.png" alt="定量结果对比表"></p>
<blockquote>
<p><strong>图5</strong>：在模拟环境中的定量对比结果表（对应论文表I）。数据显示，KAN-We-Flow在Adroit、DexArt和Meta-World的所有领域均达到了最佳性能。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.01115v1/image/fig1.png" alt="性能、参数量、推理时间对比"></p>
<blockquote>
<p><strong>图1</strong>：KAN-We-Flow与SOTA方法FlowPolicy和DP3在准确率、参数量和推理时间上的对比。(a) 在不同基准的困难任务上，KAN-We-Flow取得了更高的成功率；(b) 与FlowPolicy和DP3相比，本文方法实现了86.8%的参数量削减；(c) 在Adroit-Pen任务中，相比DP3，KAN-We-Flow实现了92.6%的推理时间下降，支持实时控制。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.01115v1/image/fig4.png" alt="推理时间对比"></p>
<blockquote>
<p><strong>图6</strong>：在Meta-World基准上各方法的推理时间对比（对应论文表II）。由于多步去噪过程，基于扩散的方法比基于流的方法慢。KAN-We-Flow在所有子任务上达到了最优的推理速度。</p>
</blockquote>
<p>消融实验总结了每个组件的贡献：</p>
<ul>
<li><strong>移除ACR</strong>：在所有测试任务中性能下降，例如在Meta-World Hard任务上成功率下降6.7%，证明了ACR对于提升策略精度的有效性。</li>
<li><strong>将RWKV-KAN替换为Transformer</strong>：导致参数量增加约3.2倍，同时在Adroit Pen和Meta-World Hard任务上成功率分别下降9.0%和7.5%，验证了RWKV-KAN设计在参数效率和性能上的优势。</li>
<li><strong>将GroupKAN替换为MLP</strong>：在保持参数量相近的情况下，模型在多项任务上的性能下降，表明KAN基于可学习函数的表达方式比固定激活函数的MLP更具优势。</li>
</ul>
<p><img src="https://arxiv.org/html/2602.01115v1/image/fig7.png" alt="定性结果可视化"></p>
<blockquote>
<p><strong>图4</strong>：操作结果可视化。展示了在Meta-World（Assembly, Disassemble）、Adroit（Hammer）和DexArt（Laptop）上的代表性任务执行过程。KAN-We-Flow策略预测未来的动作序列并持续发出指令，直至任务成功完成。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) 提出了一种新型的流匹配策略<strong>KAN-We-Flow</strong>，首次将高效的RWKV序列模型和紧凑的KAN函数网络集成到机器人视觉运动策略学习中，在保持高成功率的同时，大幅降低了模型参数量（减少86.8%）并实现了实时推理；2) 引入了<strong>动作一致性正则化（ACR）</strong>，这是一种轻量级的辅助训练目标，通过锚定预测轨迹终点来稳定训练并提高策略精度，且不增加推理成本；3) 在Adroit、Meta-World和DexArt等多个基准测试上进行了广泛实验，证明了该方法相比现有SOTA基线在成功率和效率上的综合优势。</p>
<p>论文自身提到的局限性包括：尽管RWKV-KAN骨干网络显著减少了参数量，但在处理极高维状态或极长序列时，其计算开销仍需进一步优化；此外，方法在跨领域、零样本泛化能力方面尚未得到充分验证。</p>
<p>本文对后续研究的启示在于：为机器人策略网络的设计提供了新的高效架构选择（RWKV与KAN），证明了在生成式策略中，通过精心设计轻量级但高表达力的骨干网络，可以同时达成高性能、高效率和低资源消耗的目标。未来工作可以探索该框架在更复杂的多模态指令跟随、长时程任务规划以及现实世界机器人部署中的潜力。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对基于扩散模型的机器人操作策略参数量大、推理效率低的问题，提出KAN-We-Flow方法。其核心是构建了轻量化的RWKV-KAN主干网络：RWKV模块高效融合时空与通道信息，GroupKAN层则通过可学习的样条函数进行特征非线性校准。此外，引入动作一致性正则化（ACR）损失来稳定训练。该方法无需大型UNet，在保持高速运行的同时，将参数量降低了86.8%，并在Adroit等多个标准测试集上取得了最优成功率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.01115" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>