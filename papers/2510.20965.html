<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.20965" target="_blank" rel="noreferrer">2510.20965</a></span>
        <span>作者: Axel Krieger Team</span>
        <span>日期: 2025-10-23</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人缝合是一项典型的长时序、高灵巧性操作任务，需要协调的针抓取、精确的组织穿透和牢固的打结。尽管已有诸多面向端到端自主性的努力，但一个完全自主的缝合流程尚未在物理硬件上得到验证。当前主流方法主要包括：1）混合控制方法，结合运动规划、计算机视觉和机械引导（如STAR、SNAP、STITCH），虽能实现高精度但泛化性和错误恢复能力差，且未展示端到端流程；2）模型预测控制（MPC），已在dVRK上实现自主缝线放置，但缺乏处理不可预测组织相互作用的灵活性，且未用于拾针或打结；3）模仿学习（IL），直接从人类演示中学习，具有鲁棒性和适应性，在单个子任务（如拾针、打结）上取得成功，但未解决长时序协调和缝合所需的精度问题。此外，现有公开的缝合专用数据集规模很小（总计不足200条轨迹），极大地限制了在真实世界解决这一经典手术任务的进展，也缺乏用于评估超越粗略任务完成率的精度指标基准。</p>
<p>本文针对缺乏完整的端到端缝合自主性、高质量数据集和精度基准的痛点，提出了一个名为SutureBot的自主缝合基准和框架。核心思路是：通过收集大规模、高保真的真实世界缝合演示数据集，并引入一个显式优化插入点精度的目标条件化模仿学习框架，来推动可重复的、高精度的端到端缝合策略研究。</p>
<h2 id="方法详解">方法详解</h2>
<p>SutureBot采用分层策略架构，整体流程如图1所示。高层策略负责根据视觉观察选择当前任务并生成对应的语言指令；低层策略接收语言指令、实时图像（腕部摄像头和立体内窥镜）、目标条件以及机器人运动学数据，输出精确的连续控制命令。用户通过图形界面指定目标针插入点和穿出点，用于生成目标条件。</p>
<p><img src="https://arxiv.org/html/2510.20965v1/images/architecture_overview.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：用于长时序、灵巧手术任务的精度条件化控制框架概览。图像观察由高层语言策略处理，选择当前任务并生成关联的语言条件。用户通过图形界面指定目标针插入点和穿出点，用于生成目标条件。这些输入（语言条件、目标条件、实时运动学数据）随后由低层策略处理，产生精确、连续的机器人控制命令。</p>
</blockquote>
<p><strong>核心模块与技术细节：</strong></p>
<ol>
<li><strong>数据集与任务描述</strong>：系统基于da Vinci研究套件（dVRK）搭建，使用软组织缝合垫。将缝合过程分解为三个任务：<strong>拾针</strong>（左夹具抓针尖，交接给右夹具抓针基）、<strong>抛针</strong>（右夹具驱动针穿过伤口后壁，旋转，再穿过前壁，然后拉出缝线）和<strong>打结</strong>（右夹具顺时针绕左夹具缠线，左夹具抓住线头拉紧）。数据收集不仅包括专家演示，还包含了<strong>恢复演示</strong>，即从常见失败状态开始并成功完成的演示，以增加数据多样性并提升策略的鲁棒性。最终数据集包含1，890条演示轨迹（含454条恢复演示），每条都包含同步的视觉和运动学数据，并为每次抛针演示手动标注了插入点和穿出点的图像坐标。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.20965v1/images/scene_setup.jpg" alt="实验设置"></p>
<blockquote>
<p><strong>图2</strong>：展示Da Vinci研究套件（dVRK）、远程运动中心固定装置和缝合垫的实验设置。数据收集使用伤口一，伤口二至六用于泛化测试。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.20965v1/images/task_breakdown.png" alt="任务分解"></p>
<blockquote>
<p><strong>图3</strong>：缝合过程被分解为三个任务：拾针、抛针和打结。此任务划分用于数据收集、策略训练和评估。</p>
</blockquote>
<ol start="2">
<li><p><strong>策略架构</strong>：高层策略基于Swin Transformer，将视觉观察编码为token，由Transformer解码器处理以生成语言指令。低层策略方面，本文比较了三种先进的视觉-语言-动作（VLA）模型：π₀、GR00T N1和OpenVLA-OFT，以及作为非VLA基线<strong>的多任务动作分块Transformer（ACT）</strong>。这些模型接收语言指令、图像和目标条件，输出相对机器人动作块。</p>
</li>
<li><p><strong>目标条件表示（创新点）</strong>：为了引导针的精确放置，本文探索了三种目标条件格式（图4）：</p>
<ul>
<li><strong>点标签</strong>：在内窥镜图像上，在插入点和穿出点位置叠加不透明的蓝色和绿色像素。</li>
<li><strong>二值掩码</strong>：一个三通道图像，通道2和3分别表示插入和穿出掩码。</li>
<li><strong>距离图</strong>：一个三通道图像，前两个通道编码指向插入点的归一化像素偏移向量，第三通道是标量热图。<br>此外，还设置了<strong>无目标条件</strong>的基线，仅依赖训练数据中插入点的分布。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2510.20965v1/images/goal_conditions.png" alt="目标条件"></p>
<blockquote>
<p><strong>图4</strong>：为使策略能够接近目标点，我们利用从目标点生成的目标条件，在训练和推理时作为模型输入。评估了三种目标条件：内窥镜图像上的点标签、带有掩码的额外图像输入、以及带有距离图的额外图像输入。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：基准建立在dVRK物理硬件上，使用自收集的SutureBot数据集。评估了四种低层策略：ACT、π₀、GR00T N1和OpenVLA-OFT。评估指标包括各子任务（拾针、抛针、拉出、打结）的成功率、<strong>插入/穿出误差</strong>（使用紫外线标记物理测量，图5）、整个流程耗时以及端到端成功率（无需人工干预完成所有三个任务）。</p>
<p><img src="https://arxiv.org/html/2510.20965v1/images/UV_Mark_Eval.png" alt="UV评估"></p>
<blockquote>
<p><strong>图5</strong>：利用紫外线（UV）标记来测量策略的精度。标记伤口后，在UV灯下于内窥镜视图中选择目标点。执行时关闭UV灯，标记不可见。任务完成后打开UV灯，测量缝线与标记之间的距离。</p>
</blockquote>
<p><strong>关键实验结果：</strong></p>
<ol>
<li><p><strong>目标条件表示消融</strong>：在ACT和π₀上测试不同目标条件。<strong>点标签</strong>方法取得了最低的平均插入误差（ACT: 1.3±0.9 mm， π₀: 1.0±1.3 mm），且统计显著性分析表明，点标签在精度上显著优于距离图、掩码和无目标基线。因此后续实验均采用点标签。</p>
</li>
<li><p><strong>低层策略对比</strong>：结果如表2所示。<strong>ACT在任务完成率上表现最佳</strong>（拾针9/10，抛针8/10，打结9/10），并实现了3/10的端到端成功率。在插入误差方面，ACT（1.5±0.8 mm）和π₀（1.9±1.0 mm）表现接近且最优。统计检验表明ACT显著优于GR00T N1和OpenVLA-OFT，但与π₀无显著差异。OpenVLA-OFT在所有任务上均失败。</p>
</li>
<li><p><strong>高层策略与预训练评估</strong>：高层策略在离线验证中任务预测F1分数为0.92。通过“预言家”对比实验（人工提供语言指令），发现高层策略的性能与人工操作员相当。预训练方面，标准的π₀检查点略优于在SRT-H数据集上后训练的变体（π₀ Chole）和从PaliGemma初始化的版本（π₀ Scratch）。</p>
</li>
<li><p><strong>泛化能力</strong>：在未见过的伤口类型（训练用伤口一，测试用伤口二至六）、不同的光照条件和不同的工具配置下测试ACT和π₀。结果显示，π₀在未见伤口类型上表现与训练伤口相当，而ACT性能下降明显。在光照和工具变化下，两者的成功率均进一步下降，表明泛化能力仍是挑战。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2510.20965v1/images/val_confusion_matrix_epoch_282.png" alt="混淆矩阵"></p>
<blockquote>
<p><strong>图6</strong>：高层策略在验证集上的混淆矩阵，展示了其在细分任务（如“拾针开始”、“抛针开始”等）上的预测准确性。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1）提出了首个针对灵巧手术操作的<strong>长时序缝合基准</strong>（SutureBot）及<strong>最大的公开真实世界缝合数据集</strong>（1，890条演示）；2）引入了一种<strong>目标条件化的模仿学习框架</strong>，显式优化插入点精度，将瞄准精度相对于仅任务基线提高了59%-74%；3）对最先进的VLA模型在该基准上进行了<strong>全面评估</strong>，为未来研究建立了性能基线。</p>
<p><strong>局限性</strong>：1）端到端成功率仍然较低（最佳模型为3/10）；2）策略对光照、工具等场景变化的泛化能力有限；3）所有模型缺乏历史上下文，导致当针在组织内被遮挡时，穿出点精度控制面临挑战。</p>
<p><strong>对后续研究的启示</strong>：1）<strong>目标条件化</strong>是提升模仿学习策略空间精度的有效途径，其中将目标直接叠加在任务图像上的“点标签”表示法最为直观有效。2）大规模、高质量、包含恢复演示的<strong>专用数据集</strong>对于推动此类复杂长时序任务至关重要。3）当前最先进的通用VLA模型在专用、小规模数据集上不一定优于更简单的架构（如ACT），表明<strong>领域适配</strong>和<strong>数据特性</strong>需要仔细考量。4）未来工作需关注如何为策略引入<strong>历史记忆</strong>、提升<strong>泛化鲁棒性</strong>，并进一步整合各子任务以实现更高的端到端成功率。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出SutureBot框架，旨在解决机器人实现端到端自主缝合手术的难题，该任务需要完成针抓取、组织穿刺和打结等长时程灵巧操作。核心方法是设计了一个目标条件控制框架，通过显式优化插入点精度来提升定位准确性。实验表明，该框架在达芬奇研究平台（dVRK）上将目标定位精度较仅任务优化的基线提升了59%-74%，并发布了包含1890次演示的高保真数据集用于可重复评估。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.20965" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>