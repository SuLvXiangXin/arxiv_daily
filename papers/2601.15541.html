<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.15541" target="_blank" rel="noreferrer">2601.15541</a></span>
        <span>作者: Arash Ajoudani Team</span>
        <span>日期: 2026-01-21</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作（VLA）模型（如RDT、Pi0、OpenVLA-oft）通过大规模预训练获得了强大的语义理解和动作生成能力，已成为机器人操作的主流方法。然而，这些模型本质上基于位置或轨迹控制，将机器人视为刚性的位置跟踪系统，缺乏对接触式任务中物理交互动力学的考量。这导致在执行涉及接触、顺应性或不确定性的物理任务时，由于缺乏力感知和适应能力，容易产生不安全的交互或任务失败。现有VLA模型在考虑接触力阈值（如&lt;30N）时，在接触式任务中的性能受到严重限制，安全问题凸显。</p>
<p>本文针对VLA模型在物理交互中“语义理解”与“力感知控制”脱节的核心痛点，提出了一种新视角：利用视觉语言模型（VLM）的语义理解能力，为可变阻抗控制（VIC）生成情境感知的阻抗参数，从而为VLA模型赋予顺应性物理交互能力。本文的核心思路是：在保留VLA模型泛化优势的同时，通过一个即插即用的适配器（CompliantVLA-adaptor），利用VLM将高层语义理解转化为底层控制参数（刚度、阻尼），并结合实时力反馈进行调节，以实现安全、自适应的接触式操作。</p>
<h2 id="方法详解">方法详解</h2>
<p>CompliantVLA-adaptor的整体框架旨在增强VLA模型，为其配备VLM增强的情境感知可变阻抗控制。系统包含三个关键组件：1) 混合VLA-VIC控制架构；2) 基于VLM的、从视觉-语言情境生成阻抗参数的模块；3) 实时力调节安全层。</p>
<p><img src="https://arxiv.org/html/2601.15541v1/figs/overview.png" alt="方法总览图"></p>
<blockquote>
<p><strong>图2</strong>：CompliantVLA-adaptor系统概述。VLM处理视觉观测、语言指令和实时力反馈ℱ，生成情境感知的阻抗参数𝒦, 𝒟。这些参数调制一个可变阻抗控制器（VIC），该控制器执行由VLA模型生成的动作，确保安全、自适应的接触式操作。</p>
</blockquote>
<p><strong>整体流程</strong>：给定任务的语言指令𝒯、手腕RGB图像𝐈_w、全局视野图像𝐈_f以及外部力/力矩反馈ℱ，系统首先通过VLM识别当前任务执行阶段（如自由运动、接近、接触、撤回）。然后，VLM结合阶段信息、视觉情境和力反馈，推理生成各向异性的刚度矩阵𝒦和阻尼矩阵𝒟参数。这些参数与VLA模型生成的期望末端执行器位移动作𝐱_d一同输入给VIC控制器，最终生成安全的关节力矩命令。系统运行在三个时间尺度：VLM阻抗生成（<del>1 Hz）、VLA动作块生成（</del>3 Hz）和底层VIC控制（1000 Hz）。</p>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>接触阶段识别</strong>：纯视觉的阶段检测存在局限，因此采用混合方法，结合VLM的视觉理解与力传感器反馈。通过设计特定的提示词（Prompt），让VLM能根据任务描述、力测量值和预定义的阶段列表，区分“自由运动”、“接近”、“接触”、“撤回”四个阶段。这为后续阻抗参数的层次化调整提供了语义依据。</li>
<li><strong>多模态信息驱动的阻抗参数生成</strong>：这是方法的核心创新。VLM根据注入物理情境的提示词，综合任务描述、当前阶段、速度、力测量值以及预设的阻抗范围，推理生成最优的各向异性阻抗参数。其策略包括：<strong>阶段分层</strong>（如接触阶段刚度最低，自由运动阶段刚度最高）和<strong>运动方向适应</strong>（沿预期运动方向降低阻抗，在约束轴向上提高阻抗以保持对齐）。最终馈入VIC控制器的参数还会根据实时力反馈进行缩放：𝐊_p^final = 𝐊_p^VLM ⋅ α_force，其中α_force ∈ [0.2, 1]是一个基于力的缩放因子，当测量力超过安全阈值时降低刚度，确保安全。</li>
<li><strong>混合VLA-VIC控制架构</strong>：该架构无缝集成了VLA的动作生成和VIC的顺应性执行。它保持了VLA的泛化优势，同时通过VIC增加了顺应性安全层。阻尼参数𝐃_p^final根据生成的刚度和有效质量计算，以确临界阻尼。</li>
</ol>
<p><strong>与现有方法的创新点</strong>：</p>
<ul>
<li><strong>语义到阻抗的零样本映射</strong>：不同于需要手动调参、任务特定调度或大量演示数据的传统VIC方法，本文利用预训练VLM的常识和推理能力，实现了从视觉-语言情境到阻抗参数的零样本生成，具备处理新物体和新场景的泛化能力。</li>
<li><strong>多模态融合与实时安全层</strong>：将VLM的语义理解与实时力/力矩反馈深度融合，不仅基于情境“预测”合适的阻抗，还能根据实际交互力“反应性”地调节阻抗，构成了预测与反应相结合的双重安全保障。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准与数据集</strong>：仿真实验在LIBERO和ManiSkill基准的8个代表性接触式任务上进行（如插销插入、关闭抽屉、将杯子放入微波炉等，详见论文表I）。真实实验使用7自由度Franka Emika Panda机械臂。</li>
<li><strong>对比基线</strong>：与三种先进的VLA模型对比：Pi0（流匹配）、RDT-1B（扩散模型）和OpenVLA-oft。</li>
<li><strong>安全准则</strong>：为所有任务设定统一的接触力阈值30N。若连续三次超过阈值，则任务终止并记为失败。</li>
<li><strong>协议</strong>：分两阶段评估：1) 基线VLA模型使用其默认位置控制；2) 将基线模型与CompliantVLA-adaptor集成，使用VLM增强的VIC控制器。</li>
</ul>
<p><strong>关键实验结果</strong>：<br>在仿真中，CompliantVLA-adaptor在大多数接触式操作任务（7/8）中取得了显著更高的任务成功率和更少的力违规。基线VLA模型在考虑30N力阈值时，性能极不稳定，部分任务成功率为0%。集成适配器后，任务性能得到一致提升。</p>
<p><img src="https://arxiv.org/html/2601.15541v1/x3.png" alt="仿真任务成功率对比"></p>
<blockquote>
<p><strong>图4</strong>：在30N接触力约束下，8个仿真任务的执行成功率对比。每个子图标题中的“T”后数字代表任务编号（对应表I），“-R”、“-P”、“-O”后缀分别代表使用RDT、Pi0、OpenVLA-oft作为底层VLA模型。不同颜色表示是否使用CompliantVLA-adaptor。结果表明，适配器在绝大多数任务和模型上带来了成功率提升。</p>
</blockquote>
<p><strong>具体数值</strong>：所有任务的平均成功率从基线模型的9.86%提升至使用CompliantVLA-adaptor后的17.29%。涉及机械约束（如抽屉、旋钮）的任务改善最为显著。基线模型的最高成功率仅为54%，而使用适配器后最高达到76%。</p>
<p><strong>定性结果与消融分析</strong>：<br>真实世界实验进一步验证了方法的有效性。下图展示了在“推盘子”任务中，VLM根据识别出的不同阶段自适应调整阻抗参数（刚度）的过程。</p>
<p><img src="https://arxiv.org/html/2601.15541v1/figs/push_freemotion.jpg" alt="自由运动阶段"></p>
<blockquote>
<p><strong>图5</strong>：自由运动阶段，VLM建议高刚度以实现精确的位置控制。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.15541v1/figs/push_approaching_.jpg" alt="接近阶段"></p>
<blockquote>
<p><strong>图6</strong>：接近阶段，VLM建议中等刚度，为即将发生的接触做准备。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.15541v1/figs/push_contact.jpg" alt="接触阶段"></p>
<blockquote>
<p><strong>图7</strong>：接触阶段，VLM建议低刚度（特别是沿运动方向），以在施加推力的同时保持顺应性，避免过大接触力。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.15541v1/figs/heavy_dumbbel.jpg" alt="处理重物"></p>
<blockquote>
<p><strong>图8</strong>：真实世界任务展示：将重哑铃放入纸箱。VLM根据“重物”的语义和力反馈，生成了较低的阻抗参数，实现了安全放置。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.15541v1/x4.png" alt="消融实验"></p>
<blockquote>
<p><strong>图9</strong>：消融实验展示了不同组件对任务成功率的贡献。其中“w/ VLM+VIC”是完整方法，“w/ fixed Impedance”使用固定阻抗，“w/o force feedback”关闭力反馈调节。结果显示，完整的VLM语义指导结合力反馈调节（即完整方法）取得了最佳性能，证明了各核心组件的必要性。</p>
</blockquote>
<p><strong>消融实验总结</strong>：消融研究表明，完整的VLM引导（提供情境感知参数）与力反馈调节（提供实时安全保证）相结合至关重要。仅使用固定阻抗或仅使用VLM而不结合力反馈，性能均有下降，验证了方法中预测性语义推理与反应性力调节协同工作的价值。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>CompliantVLA-adaptor框架</strong>，首次将VLM的语义理解能力用于引导VIC，为VLA模型赋予了安全、顺应性的物理交互能力，弥合了高层任务理解与底层力安全执行之间的鸿沟。</li>
<li>实现了<strong>从多模态情境到阻抗参数的零样本映射</strong>，利用预训练VLM的常识，无需针对具体任务进行训练，即可根据视觉、语言和力反馈生成各向异性的适配阻抗。</li>
<li>开发了<strong>混合VLA-VIC控制架构</strong>，这是一个即插即用的模块化解决方案，在保留现有VLA模型泛化优势的同时，通过引入实时力调节安全层，显著提升了接触式操作的成功率和安全性。</li>
</ol>
<p><strong>局限性</strong>：论文提到，VLM推理存在延迟（~1 Hz），可能无法应对极高速的接触事件。此外，基于力反馈的调节策略可能在某些需要较大力的任务中显得保守。</p>
<p><strong>研究启示</strong>：本文为基于大模型的机器人系统安全部署提供了一个重要方向。它表明，将大型基础模型（如VLM）的语义推理能力与经典控制理论（如VIC）相结合，是构建既能理解复杂指令又能安全进行物理交互的下一代机器人的有效途径。未来工作可探索更高效的VLM推理、更精细的力-语义融合策略，以及将此框架扩展到更动态的双臂或移动操作场景中。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对现有视觉-语言-动作模型在接触密集型操作任务中缺乏力感知与调节能力，导致操作不安全或失败的问题，提出CompliantVLA-adaptor方法。该方法利用视觉语言模型解析图像与语言指令以理解任务上下文，进而自适应地调整可变阻抗控制器的刚度与阻尼参数，并结合实时力/力矩反馈确保交互力处于安全阈值。实验表明，该方法在模拟与真实硬件的一系列复杂接触任务上均优于基线VLA模型，整体任务成功率从9.86%提升至17.29%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.15541" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>