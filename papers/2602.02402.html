<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.02402" target="_blank" rel="noreferrer">2602.02402</a></span>
        <span>作者: Jiangmiao Pang Team</span>
        <span>日期: 2026-02-02</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人软体操纵（如布料折叠、柔性物体操作）的具身学习高度依赖大量交互数据，但在真实世界中采集此类数据成本高昂且风险大。真实到仿真（R2S）模拟通过将真实物体行为复现到虚拟环境中，为数据合成和策略学习提供了可扩展的解决方案。一个实用的仿真器需要在物理保真度和长期交互一致性之间取得平衡。现有方法主要沿两个方向展开：基于物理的仿真器（如FEM、MPH）能保证长期交互一致性，但依赖难以从视觉数据中推断的预定义物理模型和参数；神经网络动力学建模和4D重建方法直接从数据学习运动，但主要关注再现观测轨迹，对机器人条件交互和训练分布外泛化的支持有限。因此，两者均无法完全满足复杂机器人操纵中的R2S需求。</p>
<p>本文针对上述痛点，提出了一种新的视角：重新思考可变形物体仿真的表示与学习方式。核心思路是提出SoMA，一个基于3D高斯泼溅（Gaussian Splatting）的软体操纵神经仿真器，将可变形物体动力学、环境力和机器人关节动作耦合在一个统一的潜在神经空间中，进行端到端的真实到仿真模拟，从而实现可控、稳定的长时域操纵仿真，且无需预定义物理模型。</p>
<h2 id="方法详解">方法详解</h2>
<p>SoMA是一个用于软体机器人操纵的统一神经仿真器，旨在机器人关节空间控制和环境交互下建模可变形物体动力学。其整体框架接受从真实世界操纵收集的RGB观测和机器人关节状态作为输入，通过端到端训练，输出模拟出的物体状态并渲染为图像。</p>
<p><img src="https://arxiv.org/html/2602.02402v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：SoMA整体框架。左侧输入为多视角RGB观测和机器人关节动作；中间部分将物体重建为层次化高斯泼溅，并通过神经仿真器在渲染和动力学监督下进行传播；右侧展示了物体运动由基于力的交互驱动，环境和机器人诱导的力作用于泼溅点产生形变。</p>
</blockquote>
<p>框架包含三个核心组件：</p>
<ol>
<li><strong>通过R2S映射进行场景初始化</strong>：为了在机器人运动学、被操纵物体和物理参考系之间建立统一的仿真空间，本模块首先利用多视角几何和3D高斯泼溅从RGB图像重建初始物体状态 <code>G0</code>。关键步骤是进行机器人条件对齐：通过强制重建几何与已知参考尺寸之间的度量一致性来恢复全局尺度因子 <code>s</code>，并估计将机器人基座标系变换到仿真空间的刚体变换 <code>(R, t)</code>。结合机器人正向运动学，可将任意时刻的末端执行器位姿 <code>𝐓_rob^ee(t)</code> 映射到仿真空间 <code>𝐓_sim^ee(t)</code>。同时，通过拟合支撑桌面法向来定义重力方向 <code>g</code>，解决了重力符号的歧义。</li>
<li><strong>力驱动的高斯泼溅动力学建模</strong>：与现有主要基于状态的神经动力学模型不同，SoMA将物体运动建模为由接触力驱动。对于每个高斯泼溅节点或簇 <code>i</code>，其线速度和角速度由神经网络 <code>ψ_θ</code> 根据其历史状态和总作用力 <code>𝐟_i</code> 预测。总作用力 <code>𝐟_i = 𝐟_i^env + 𝐟_i^rob</code> 由两部分组成：<ul>
<li>**环境力 <code>𝐟_i^env</code>**：包括作用于所有节点的重力 <code>g</code>，以及对靠近支撑表面的节点额外施加的支持力 <code>𝐬_i</code>。</li>
<li>**机器人力 <code>𝐟_i^rob</code>**：通过在高斯泼溅节点和机器人控制点之间构建交互图来建模。图神经网络 <code>Φ_θ</code> 根据泼溅节点状态、邻近机器人控制点状态和夹爪开合状态 <code>c_t</code> 来预测机器人施加的力。<br>这些力在构建的层次化图结构（由底向上聚类形成）中自底向上聚合，动力学则通过图神经网络自顶向下传播，确保全局运动一致性和局部形变。</li>
</ul>
</li>
<li><strong>用于长时域学习的多分辨率训练与混合监督</strong>：<ul>
<li><strong>多分辨率训练</strong>：为解决长时域模拟中误差累积和稳定性问题，采用从粗到细的时间训练策略。第一阶段使用较大的时间步长 <code>k·dt</code> 捕捉长程动力学；第二阶段使用原始分辨率 <code>dt</code> 并随机采样子序列进行细粒度动力学学习。同时，在图像维度上，几何重建使用高分辨率图像以保留细节，而动力学训练则使用原始分辨率以降低计算成本。</li>
<li><strong>混合监督</strong>：针对交互中常见的遮挡问题，设计了混合监督策略。<ul>
<li><strong>遮挡感知的图像监督</strong>：仅在物体可见区域（通过二值掩码 <code>𝐌_t</code> 定义）计算图像重建损失 <code>ℒ_img</code>，避免遮挡区域引入虚假梯度。</li>
<li><strong>动量一致性正则化</strong>：为约束无直接视觉反馈的遮挡区域运动，引入动量守恒正则化 <code>ℒ_mom</code>，强制相邻层次簇节点与子节点之间的动量守恒，作为自监督的物理一致性约束，缓解长时域漂移。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>与现有方法相比，SoMA的核心创新在于：1) <strong>机器人动作直接耦合</strong>：通过R2S映射将关节空间动作直接锚定到仿真空间，实现因果、运动学一致的交互；2) <strong>力驱动的交互建模</strong>：将环境和机器人交互显式建模为力，作用于高斯泼溅表示，提高了对接触和遮挡的鲁棒性；3) <strong>稳定性保障机制</strong>：多分辨率训练和混合监督策略专门针对长时域、遮挡严重的机器人操纵场景设计，确保了仿真的数值稳定性和物理合理性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在ARX-Lift平台上收集了包含绳子、玩偶、布料和T恤四类可变形物体的真实世界机器人操纵数据集。图像分辨率为640×480，30 FPS，同步记录机器人关节状态。每类物体收集30-40个序列，按7:3划分训练集和测试集。评估两项任务：<strong>重仿真</strong>（在训练轨迹上评估）和<strong>泛化</strong>（在未见过的测试序列上评估）。对比的基线方法包括基于可微分物理的 <strong>PhysTwin</strong> 和基于神经动力学的 <strong>GausSim</strong>。评估指标涵盖图像质量（PSNR、SSIM、LPIPS）和代理几何精度（深度图的Abs Rel、RMSE）。</p>
<p><strong>关键实验结果</strong>：<br>SoMA在重仿真和泛化任务上均取得了最佳性能。如表1所示，在重仿真任务中，SoMA在各项指标上全面领先，例如在PSNR上达到33.51，优于PhysTwin的28.77和GausSim的31.69。在更具挑战性的泛化任务中，SoMA同样保持优势，PSNR为32.89，而基线方法性能均有下降。论文指出，SoMA相比基线方法实现了约20%的性能提升。</p>
<p><img src="https://arxiv.org/html/2602.02402v1/x3.png" alt="定性结果"></p>
<blockquote>
<p><strong>图3</strong>：SoMA在机器人操纵下的定性重仿真（左）与泛化（右）结果。对于绳子、布料、玩偶等物体，SoMA能产生稳定、长时域的仿真，与真实动态高度匹配。PhysTwin在复杂或未见交互下出现偏差，GausSim则在挑战性场景中经常保持静态或变得不稳定。</p>
</blockquote>
<p>在涉及长时域、大形变和频繁自接触的<strong>T恤折叠</strong>复杂任务中（表2），SoMA的优势更加明显。它能稳定模拟整个折叠过程，而PhysTwin则出现明显的伪影和不一致的形变。SoMA在PSNR上达到27.57，显著高于PhysTwin的22.85。</p>
<p><strong>消融实验</strong>（表3）总结了各组件贡献：</p>
<ul>
<li><strong>完整模型</strong>：取得最佳综合性能。</li>
<li><strong>联合训练（Jointly）</strong>：在所有物体域上联合训练，略微降低了重仿真精度，但提升了泛化性能，表明其具有提升泛化能力的潜力。</li>
<li><strong>仅图像监督（Img-only）</strong>：移除混合监督损失（动量正则化），性能下降，证明了物理一致性约束对稳定学习的重要性。</li>
<li><strong>无多分辨率训练（w/o MRT）</strong>：禁用多分辨率训练策略，性能显著降低，突显了该策略对于高效、稳定学习长时域动力学的关键作用。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：</p>
<ol>
<li><strong>提出了一种新的R2S神经仿真范式</strong>：首次将可变形物体、机器人动作和环境统一在基于高斯泼溅的仿真空间中，支持长时域、交互一致的软体操纵模拟。</li>
<li><strong>设计了一系列使能该仿真的关键机制</strong>：包括机器人条件对齐、力驱动的高斯泼溅动力学模型，以及结合多分辨率训练和混合监督的稳定化策略。</li>
<li><strong>在真实机器人操纵数据集上进行了全面验证</strong>：在重仿真、泛化及复杂任务（T恤折叠）上均显著优于现有基于物理和神经网络的仿真器，展示了其实际应用潜力。</li>
</ol>
<p>论文自身提到的局限性包括：仿真依赖于从视觉观测进行的初始重建，重建质量会影响后续模拟；方法在计算成本上可能较高。</p>
<p>本文对后续研究的启示在于：为机器人软体操纵的仿真提供了一条融合数据驱动与物理直觉的新路径。其力驱动的交互建模思想、针对遮挡和长时域稳定性设计的训练策略，可启发更鲁棒、更通用的具身智能仿真器的开发。未来工作可探索如何进一步降低对高质量初始重建的依赖，以及将此类仿真器用于闭环策略学习与优化。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出SoMA，一个用于机器人软体操作的真实到仿真神经模拟器。核心解决现有模拟器依赖预定义物理模型或缺乏机器人条件控制，导致准确性、稳定性和泛化能力不足的问题。其关键技术是在统一潜在神经空间中，耦合可变形物体动力学、环境力与机器人关节动作，并基于学习的3D高斯泼溅进行端到端模拟。该方法无需预定义物理模型，实现了可控、稳定的长时程操作与轨迹外泛化。实验表明，SoMA在真实机器人操作任务上，将重新模拟准确性与泛化能力提升了20%，并能稳定模拟如长时程布料折叠等复杂任务。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.02402" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>