<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.02402" target="_blank" rel="noreferrer">2602.02402</a></span>
        <span>作者: Jiangmiao Pang Team</span>
        <span>日期: 2026-02-02</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人软体操作（如布料折叠、柔性物体处理）的具身学习需要大规模交互数据，但真实世界数据采集成本高且风险大。因此，从真实到仿真（R2S）的模拟器至关重要，它需要在物理保真度和长时程交互一致性之间取得平衡。现有方法主要分为两类：基于物理的仿真器（如FEM、MPM）能保证长时程一致性，但依赖难以从视觉数据推断的预定义物理模型和参数；可微分仿真器通过优化少量参数缓解此问题，但仍受限于简化的物理假设。另一类是神经动力学建模和4D重建方法，它们直接从数据学习运动，但主要侧重于复现观测到的轨迹，对机器人条件交互和超出训练分布的泛化支持有限。因此，现有方法均难以胜任复杂机器人操作下的R2S仿真。</p>
<p>本文针对这一痛点，提出了一种新的视角：重新思考可变形物体仿真的表示和学习方式。核心思路是提出SoMA，一个直接在学习的3D高斯溅射（Gaussian Splat）表示上操作的神经仿真器，它将可变形物体、机器人动作和环境效应建模在一个统一的潜在神经空间中，实现因果动作驱动的动力学和稳定的长时程交互，而无需预定义物理规则。</p>
<h2 id="方法详解">方法详解</h2>
<p>SoMA是一个用于软体机器人操作的统一神经仿真器，旨在机器人关节空间控制和环境交互下建模可变形物体动力学。其整体框架（Pipeline）如论文图2所示：输入为从真实世界操作收集的多视角RGB观测和机器人关节状态；首先通过场景初始化模块将观测提升到统一的仿真空间；然后通过一个基于层次化图的仿真器建模机器人-物体-环境交互；最后通过多分辨率训练策略和混合监督方案进行优化，以实现高效稳定的长时程仿真。</p>
<p><img src="https://arxiv.org/html/2602.02402v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：SoMA框架概览。左侧输入为真实世界操作收集的RGB观测和机器人关节动作。中间部分将可变形物体重建为层次化高斯溅射，并通过神经仿真器在渲染和动力学监督下进行传播。右侧展示了物体运动由基于力的交互驱动，环境和机器人诱导的力作用于溅射以产生形变。</p>
</blockquote>
<p><strong>核心模块与技术细节：</strong></p>
<ol>
<li><p><strong>场景初始化与R2S映射</strong>：为了解决真实世界视觉重建、机器人运动学和物理参考系存在于异构坐标系和度量尺度中的问题，SoMA构建了一个与机器人运动学、操作物体和物理参考框架一致的统一仿真空间。具体包括：</p>
<ul>
<li><strong>重建</strong>：利用多视角几何估计相机位姿，并使用3D高斯溅射技术重建被操作物体，得到相机坐标系下的初始高斯溅射表示 <code>G_0</code>。</li>
<li><strong>机器人条件对齐</strong>：通过强制重建几何与已知参考尺寸（如机器人连杆长度）之间的度量一致性，恢复全局尺度因子 <code>s</code> 和刚性变换参数 <code>(R, t)</code>。这使得机器人关节动作 <code>R_t</code> 可以直接应用于仿真空间，驱动物体运动。</li>
</ul>
</li>
<li><p><strong>基于层次化图的神经仿真器</strong>：</p>
<ul>
<li><strong>表示</strong>：将可变形物体表示为一组高斯溅射 <code>g_i = {x_i, Σ_i, m_i, a_i}</code>，分别编码空间位置、各向异性协方差、质量和附加物理属性。为提高效率并更好地捕捉连续动力学，这些溅射被组织成一个层次化图结构，通过自底向上的聚类形成不同空间尺度的节点。</li>
<li><strong>动力学传播</strong>：动力学通过图神经网络在层次结构中自上而下传播。在每一层，为聚类节点预测潜在运动和形变状态，随后通过学习的变换传递给其子节点。节点状态（位置 <code>x</code>、协方差 <code>Σ</code>）的更新遵循公式(2)和(3)，确保了全局运动的一致性和局部形变的保持。</li>
<li><strong>力驱动的交互建模</strong>：物体运动由基于力的交互驱动。仿真器显式地计算环境力（如重力）和机器人诱导的接触力，这些力作用于高斯溅射，进而通过层次化图传播以产生形变。这种设计允许局部接触效应在物体内部传播，即使视觉观测存在部分遮挡。</li>
</ul>
</li>
<li><p><strong>多分辨率训练与混合监督</strong>：</p>
<ul>
<li><strong>多分辨率训练策略</strong>：采用两阶段训练。第一阶段使用大的时间间隔（<code>ΔT_large</code>）捕捉全局运动；第二阶段使用小的时间间隔（<code>ΔT_small</code>）在遮挡和接触条件下细化细粒度动力学。这平衡了时间覆盖率和计算效率，有助于稳定长时程性能。</li>
<li><strong>混合监督方案</strong>：训练损失结合了遮挡感知的图像重建损失和物理启发的动力学一致性约束。<ul>
<li><strong>渲染损失</strong> (<code>L_render</code>): 最小化渲染图像与真实观测图像之间的差异，包括RGB和深度（如果可用）的L1损失，以及结构相似性（D-SSIM）损失。</li>
<li><strong>动力学一致性损失</strong> (<code>L_dyn</code>): 包括动量守恒约束（鼓励预测的状态变化与施加的力一致）和应变能正则化（惩罚非物理的过度形变）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>创新点</strong>：与现有方法相比，SoMA的创新主要体现在：1) 提出了一个支持机器人关节空间条件控制、端到端的R2S神经仿真范式；2) 通过机器人条件对齐、力驱动的高斯溅射动力学模型以及多分辨率混合监督等机制，实现了交互一致且稳定的长时程仿真；3) 直接在学习的3D高斯表示上进行仿真，统一了物体、机器人和环境的表示。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>数据集</strong>：在公开基准数据集（如 <strong>DeformThings4D</strong>）和一个新的真实世界机器人操作数据集 <strong>RobotDeform</strong> 上进行评估。RobotDeform包含多视角RGB-D视频和同步的机器人关节状态，涵盖多种软体物体（毛巾、玩偶、海绵）和交互任务（拖动、折叠、按压）。</li>
<li><strong>对比方法</strong>：与多种基线方法对比，包括基于物理的仿真器（<strong>FEM</strong>）、可微分仿真器（<strong>DiffSim</strong>）、4D高斯重建方法（<strong>4D-GS</strong>）以及神经仿真器（<strong>GausSim</strong>, <strong>GS-Dynamics</strong>）。</li>
<li><strong>评估指标</strong>：图像层面的PSNR、SSIM、LPIPS；深度层面的绝对深度误差（Abs.Depth）；以及用于衡量长时程仿真稳定性的指标（如最终位置误差）。</li>
</ul>
<p><strong>关键实验结果</strong>：<br>SoMA在RGB和深度重建质量上均达到最先进水平。在RobotDeform数据集上，与最佳基线相比，PSNR提升超过2 dB，深度误差降低超过20%。在长时程任务（如布料折叠）中，SoMA能保持稳定的仿真，而基线方法会出现明显的漂移或崩溃。</p>
<p><img src="https://arxiv.org/html/2602.02402v1/x3.png" alt="定性结果对比"></p>
<blockquote>
<p><strong>图3</strong>：在真实世界RobotDeform数据集上的定性对比。SoMA（最后一行）在长时程布料折叠任务中，能够最准确地复现物体的几何形状和动力学，特别是在存在严重遮挡和复杂接触的区域（如红色箭头所示），而其他方法（前四行）则出现明显的形变错误或失真。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02402v1/x4.png" alt="定量结果与消融实验"></p>
<blockquote>
<p><strong>图4</strong>：左图展示了在RobotDeform数据集上不同仿真步长（horizon）下的定量结果，SoMA在长时程仿真中性能下降最小，表现出优越的稳定性。右图的消融实验表明，机器人条件对齐（R2S Map）、力驱动动力学（Force）和多分辨率训练（Multi-res）三个核心组件都对最终性能有重要贡献，缺一不可。</p>
</blockquote>
<p><strong>消融实验总结</strong>：<br>论文对三个核心设计进行了消融研究：1) <strong>机器人条件对齐（R2S Mapping）</strong>：移除后，由于仿真空间与机器人运动学不一致，性能显著下降；2) <strong>力驱动的动力学（Force-driven Dynamics）</strong>：替换为直接状态回归后，在遮挡和接触区域的仿真质量变差；3) <strong>多分辨率训练（Multi-resolution Training）</strong>：仅使用单一时间分辨率训练会导致长时程仿真不稳定。实验证实每个组件都是必要的，共同作用实现了SoMA的高精度和稳定性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了SoMA，一个新颖的、支持长时程交互一致仿真的R2S神经仿真范式，用于软体机器人操作。</li>
<li>设计了一系列关键机制使其可行，包括机器人条件对齐、力驱动的高斯溅射动力学模型，以及用于稳定长时程性能的多分辨率混合监督策略。</li>
<li>在公开基准和新的真实数据集上进行了广泛评估，证明了其在RGB/深度重建精度（提升20%）和持续交互操作方面的显著优势。</li>
</ol>
<p><strong>局限性</strong>：<br>论文提到，SoMA目前主要处理准静态或中等速度的操作。对于涉及极高速度、剧烈形变或材料断裂的极端动力学场景，其性能可能受限。此外，仿真器的计算成本随着场景复杂度和仿真时长的增加而增长。</p>
<p><strong>对后续研究的启示</strong>：<br>SoMA的工作展示了将神经表示与物理启发的归纳偏置相结合，构建实用R2S仿真器的潜力。未来方向可能包括：扩展以处理更广泛的材料属性和更极端的动力学；进一步优化计算效率以实现实时仿真；以及探索将此类仿真器用于闭环机器人策略学习与训练。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出SoMA，一种用于机器人软体操作的真实到仿真神经模拟器。核心问题是解决现有模拟器依赖预定义物理模型或缺乏机器人动作条件控制，导致精度、稳定性和泛化性不足的挑战。关键技术采用基于3D高斯泼溅的神经模拟方法，在统一潜在神经空间中耦合变形动力学、环境力和机器人关节动作，实现端到端仿真。实验表明，SoMA在真实机器人操作任务中将重模拟精度和泛化能力提升20%，并能稳定模拟长时程复杂任务（如布料折叠）。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.02402" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>