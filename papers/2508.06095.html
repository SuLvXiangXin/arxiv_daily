<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Incremental Language Understanding for Online Motion Planning of Robot Manipulators - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Incremental Language Understanding for Online Motion Planning of Robot Manipulators</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.06095" target="_blank" rel="noreferrer">2508.06095</a></span>
        <span>作者: Matthias Scheutz Team</span>
        <span>日期: 2025-08-08</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，语言引导的机器人运动规划方法通常假设指令是完全指定的，并在文本形式下进行处理。这导致机器人在执行过程中若遇到人类对指令的纠正或澄清时，必须采取低效的“停止-重规划”行为。现有方法或缺乏对实时语音的增量处理，或仅能纠正错误动作而无法动态改变任务，难以实现流畅的人机交互。本文针对机器人需要实时处理动态语音输入并连续调整动作这一具体痛点，提出将增量语言理解与在线运动规划在认知架构层面紧密结合的新视角。核心思路是设计一个基于推理的增量解析器，使其能够处理部分完成的语句，并与在线运动规划器协同工作，从而实现无需停止执行即可动态更新运动计划的能力。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的框架旨在实现增量语言理解与在线运动规划的紧密集成，使机器人能够根据持续演变的语音指令实时调整其运动。</p>
<p><img src="https://arxiv.org/html/2508.06095v1/schematic.pdf" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：增量运动规划框架示意图。在时间 $t_0$，自然语言指令 $\mathcal{L}<em>{t</em>{0}}$ 被解析为 $\mathcal{P}^{*}(\mathcal{L}<em>{t</em>{0}})$，解析器将其转换为目标位姿 $\mathbf{p}<em>{\mathrm{f}}(\mathcal{L}</em>{t_{0}})$ 和约束集 $\mathcal{C}(\mathcal{L}<em>{t</em>{0}})$。基于此，BoundPlanner 计算可允许状态集 $\mathcal{X}(\mathcal{L}<em>{t</em>{0}})$ 和成本函数参数 $\phi(\mathcal{L}<em>{t</em>{0}})$，并传递给以 10 Hz 频率计算关节输入 $\mathbf{u}(t)$ 的 BoundMPC。在时间 $t_1 &gt; t_0$，人类发出纠正指令 $\mathcal{L}<em>{t</em>{1}}$，系统在位置 $\mathbf{p}<em>{1}$ 处触发重规划，最终到达新目标位姿 $\mathbf{p}</em>{\mathrm{f}}$。</p>
</blockquote>
<p>整体流程如<strong>图1</strong>所示，包含四个核心阶段：1) <strong>增量语言解析</strong>：系统持续接收语音单词，并利用增量图表解析算法（Algorithm 1）构建句法-语义结构；2) <strong>解析</strong>：当解析出一个有意义的短语 $\mathcal{P}^{*}(\mathcal{L}<em>{t</em>{k}})$ 时，解析器将其映射为机器人运动规划所需的具体目标位姿 $\mathbf{p}_{\mathrm{f}}$ 和约束集 $\mathcal{C}$；3) <strong>全局路径规划</strong>：BoundPlanner 根据目标与约束，在笛卡尔空间规划一条有界的参考路径 $\pi$，并输出定义在路径上的可允许状态集 $\mathcal{X}$ 和成本参数 $\phi$；4) <strong>在线轨迹优化</strong>：BoundMPC 基于 $\mathcal{X}$ 和 $\phi$，通过求解一个有限时域的优化问题（公式2）在线生成关节空间的控制指令 $\mathbf{u}(t)$。</p>
<p>核心模块之一是<strong>增量语言解析器</strong>。它采用类似于CYK的图表解析算法，但以增量方式运行。算法初始化或扩展一个图表（chart），每个传入的单词通过查词典获得其语法条目（如组合范畴语法CCG规则）并作为节点插入图表对角线。随后，算法自底向上动态地组合相邻区间的节点，形成更大的短语结构。该解析器能维护同一段词语的多个候选解析（如<strong>表I</strong>所示），允许系统在获得更多上下文后再进行消歧。例如，对于指令“grab the mug by the top”，解析器最终在图表单元[0][5]中保留两种解读：一种将“by the top”视为修饰动词“grab”的方式状语，另一种将其视为修饰名词“mug”的定语。这种设计实现了模块性（部分解析）、粒度性（与运动规划集成）和可修订性（实时计划更新）。</p>
<p>另一个核心是<strong>与在线运动规划的集成</strong>。解析器将语言指令映射为运动规划器的输入。本文扩展了 BoundPlanner 以处理方向约束，并使用 BoundMPC 进行在线轨迹优化。语言引入的约束被系统地转换为规划问题中的数学集合或参数，主要分为三类适配：目标位姿变化对应任务状态集 $\mathcal{X}<em>{\mathrm{task}}$ 的更新；新增约束（如避障、保持直立）对应安全状态集 $\mathcal{X}</em>{\mathrm{safe}}$ 的更新；而方式约束（如“更快”）则通过调整成本函数参数 $\phi$ 来实现。论文还提出了一个<strong>增量约束分类法</strong>（表II），将语言中可能出现的动态约束分为方式、目标、对象、动作、安全和顺序六类，并明确了每类约束在运动规划优化问题中的具体影响。</p>
<p>本方法的创新点具体体现在：1) 设计了一个专门用于机器人运动规划的增量语言解析器，能够输出结构化的语义表示（如一阶逻辑形式）并维护多个候选解释；2) 首次将该类解析器与 BoundMPC/BoundPlanner 这套能严格处理笛卡尔空间约束的在线运动规划方法进行深度集成，实现了语言指令到运动约束的实时、无缝转换。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在一个7自由度机器人操纵器上进行，使用了真实世界的物体和人机交互场景。基线对比方法为离线运动规划器 VP-STO。实验旨在展示系统处理三种动态语言指令的能力：1) 改变抓握方向；2) 添加运动约束（保持杯子直立、避开笔记本电脑）；3) 调整运动速度。</p>
<p><img src="https://arxiv.org/html/2508.06095v1/x1.png" alt="实验1场景"></p>
<blockquote>
<p><strong>图2</strong>：实验1场景设置，机器人抓取杯子。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.06095v1/x2.png" alt="实验1时间对比"></p>
<blockquote>
<p><strong>图3</strong>：实验1（抓取杯子并改变抓握方向）中，本文方法与VP-STO的规划时间、轨迹持续时间和总任务时间对比。本文方法因在线规划优势，总任务时间显著更短。</p>
</blockquote>
<p>关键定量结果如<strong>表III</strong>（对应<strong>图3</strong>数据）所示。在抓取杯子实验中，当需要中途改变抓握方向时，本文方法的两次规划时间仅为 0.02 秒，而 VP-STO 则需要约 5.6 秒。尽管 VP-STO 生成的轨迹本身稍快（2.89 秒 vs. 3.10 秒），但其“停止-重规划”模式导致总任务时间长达 17.08 秒，远高于本文方法的 7.84 秒。这凸显了在线增量规划在交互效率上的巨大优势。</p>
<p><img src="https://arxiv.org/html/2508.06095v1/x3.png" alt="实验2初始状态"></p>
<blockquote>
<p><strong>图4</strong>：实验2初始状态，机器人抓取装有液体的杯子。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.06095v1/x4.png" alt="实验2添加直立约束"></p>
<blockquote>
<p><strong>图5</strong>：实验2中，当人类指令“保持杯子直立”时，机器人实时调整末端执行器方向以满足新约束。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.06095v1/x5.png" alt="实验2添加区域避障约束"></p>
<blockquote>
<p><strong>图6</strong>：实验2中，添加“不要经过笔记本电脑上方”的约束后，机器人重新规划路径以避开指定区域。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.06095v1/x6.png" alt="实验2完整轨迹"></p>
<blockquote>
<p><strong>图7</strong>：实验2的完整运动序列，展示了机器人如何依次响应初始指令、直立约束和区域避障约束。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.06095v1/x7.png" alt="实验3场景"></p>
<blockquote>
<p><strong>图8</strong>：实验3场景，机器人向人类传递螺丝刀。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.06095v1/x8.png" alt="实验3速度调整"></p>
<blockquote>
<p><strong>图9</strong>：实验3中，根据人类“快一点”和“慢一点”的指令，通过调整成本函数参数 $\phi$ 在线改变轨迹速度。</p>
</blockquote>
<p>定性实验展示了系统处理多种增量约束的灵活性。实验2（<strong>图4-图7</strong>）表明，系统能成功处理“保持杯子直立”和“避开笔记本电脑区域”这类在运动中途添加的安全约束。实验3（<strong>图8-图9</strong>）则证明，系统可通过调整优化问题中的成本函数参数 $\phi$，实时响应人类发出的“快一点”、“慢一点”等速度控制指令。这些实验共同验证了所提框架处理目标、安全和方式等各类增量约束的能力。</p>
<p>消融实验体现在与离线规划器 VP-STO 的对比中，结果明确显示了在线规划对于实现流畅、高效增量交互的必要性。离线规划器因较长的重规划时间，无法实现真正的实时适应。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献有两点：1) 提出了一种新颖的、专门为与机器人运动规划交互而设计的增量语言解析器，它能够进行部分解析、维护多种解释并与动作提交紧密集成；2) 实现了该增量解析器与基于 BoundMPC 和 BoundPlanner 的在线运动规划框架的紧密集成，使机器人能够根据动态的语言输入实时调整运动计划，而无需停止执行。</p>
<p>论文提到的局限性在于，当前系统假设目标位姿和障碍物位置是已知的，解析器仅是将语言映射到这些已知的几何信息。未来工作需要结合视觉感知来动态识别和定位物体。</p>
<p>这项工作对后续研究的重要启示在于：为实现自然流畅的人机协作，需要将增量语言处理深度整合到机器人的感知-规划-行动循环中。未来的方向包括将系统扩展到多模态输入（如结合手势和视线），处理更复杂的语言现象（如指代和省略），以及探索如何将此类增量推理模块与更大型的认知架构或基础模型进行集成。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人运动规划中无法实时处理动态语音指令、导致低效“停止-重规划”的问题，提出一种基于推理的增量解析器。该方法将在线运动规划算法集成到认知架构中，通过维护多候选解析和符号推理机制，实现运动计划的连续适应与更新，无需中断执行。实验表明，该系统能在真实人机交互场景中在线适应目标姿态、约束或任务变化，提升了协作的自然性和流畅性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.06095" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>