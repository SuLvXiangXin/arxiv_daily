<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.01023" target="_blank" rel="noreferrer">2510.01023</a></span>
        <span>作者: D. Tsetserukou Team</span>
        <span>日期: 2025-10-01</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>基于动作捕捉的遥操作是机器人模仿学习数据收集的主流方法，其通过逆运动学将人体动作映射到机器人。然而，该方法存在一个关键局限：在物体操作过程中缺乏力反馈。这导致操作员和后续训练的神经网络模型可能施加过大的抓握力，从而损坏或变形物体。本文针对这一具体痛点，提出了一种集成了实时力反馈的低成本、开源遥操作系统，旨在提高操作精度和数据质量。本文的核心思路是设计一个定制化的力反馈控制器和带有力传感器的夹爪，将抓握物体的压缩力实时反馈给操作员，从而实现对抓握力的精确感知与控制。</p>
<h2 id="方法详解">方法详解</h2>
<p>Prometheus系统的整体框架（Pipeline）由三个主要硬件组件构成：一个定制的力反馈控制器、一个UR3机械臂以及一个配备了定制手指的Robotiq 2F-85夹爪。操作流程为：操作员手持控制器，控制器上集成的HTC Vive Tracker 2.0用于捕捉手部位置和姿态；系统通过逆运动学计算并控制UR3机械臂末端执行器（夹爪）跟随该姿态；当夹爪抓取物体时，嵌入手指的力传感器测量压缩力，该数据被实时发送至控制器，控制器驱动电机产生相应的反作用扭矩，使操作员感受到抓握力。视觉反馈由一个安装在夹爪上的USB摄像头提供。</p>
<p>系统的核心模块包括定制控制器和力敏手指。</p>
<ol>
<li><strong>定制控制器</strong>：该控制器（图2）的核心是一个基于牛顿第三定律的扭矩产生机制。如图3所示，电机通过轴承安装，其轴和壳体分别连接两个杠杆。当电机轴旋转产生扭矩时，电机的壳体受到一个大小相等、方向相反的反作用扭矩，由于电机未被固定，导致两个杠杆朝相反方向旋转。这种设计将电机的旋转运动转化为对操作员手部的扭矩反馈。控制器同时作为HTC Vive追踪器的安装基座。</li>
<li><strong>力敏手指</strong>：为了测量抓握力并提供有效的力反馈，论文设计了一种特殊的夹爪手指（图5, 图6）。其核心机制（图7）是将一个覆盖有防滑硅胶垫的压板通过导杆和弹簧与力传感器（RP-C7.6-LT）耦合。当物体被夹持时，力通过硅胶垫和压板均匀传递至导杆，导杆再通过一块橡胶片将力施加到力传感器上。弹簧用于在力移除后使压板复位。这种设计保护了传感器，并允许从整个接触面获取力反馈，而非单个点。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.01023v1/images/222.png" alt="系统架构"></p>
<blockquote>
<p><strong>图8</strong>：系统整体架构图。展示了硬件组件（控制器、机械臂、夹爪）之间的连接关系，以及力传感器板与电机控制板之间的数据流（RS-485协议）和与上位机的通信（USB）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.01023v1/x1.png" alt="控制器工作原理"></p>
<blockquote>
<p><strong>图3</strong>：控制器工作原理示意图。展示了电机轴扭矩与电机壳体反作用扭矩如何导致两个杠杆产生相反方向的旋转，从而向操作员手部传递力觉。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.01023v1/images/scheme_of_pad2.png" alt="手指机制示意图"></p>
<blockquote>
<p><strong>图6</strong>：机器人手指机械结构示意图。详细展示了压板、导杆、弹簧、橡胶片和力传感器之间的装配关系，说明了力从接触面到传感器的传递路径。</p>
</blockquote>
<p>系统的创新点主要体现在：1) <strong>低成本与开源</strong>：全部采用消费级（HTC Vive）和可3D打印的组件，硬件设计和软件完全开源。2) <strong>有效的力反馈机制</strong>：提供了真实的扭矩反馈，而非大多数VR控制器采用的简单振动反馈。3) <strong>集成的力传感方案</strong>：设计了保护传感器且能均匀感知接触面压力的夹爪手指，解决了力传感器在末端执行器上的集成难题。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在UR3机械臂和Robotiq 2F-85夹爪搭建的平台上进行。研究包含两部分：用户研究（评估力反馈对操作员的影响）和与视觉-语言-动作（VLA）模型的兼容性评估。</p>
<p><strong>用户研究</strong>：15名参与者执行鸡蛋抓取-放置任务，分别在有/无力反馈的条件下进行。实验设置如图9所示。</p>
<p><img src="https://arxiv.org/html/2510.01023v1/images/333.png" alt="鸡蛋实验场景"></p>
<blockquote>
<p><strong>图9</strong>：用户研究实验场景。操作员使用Prometheus系统抓取一颗鸡蛋。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.01023v1/x2.png" alt="抓握力对比"></p>
<blockquote>
<p><strong>图10</strong>：有/无力反馈条件下的夹爪压缩力对比。箱线图显示，启用力反馈后，操作员施加的抓握力平均降低了**35.77%**。</p>
</blockquote>
<p><strong>VLA模型评估</strong>：使用Prometheus系统收集了一个包含300条轨迹的数据集，涉及三种物体（番茄、牙膏、洗发水瓶）。基于Octo-Small模型微调了三种策略：仅位置(P)、仅力(F)、位置与力结合(P+F)。在每种物体上各进行10次试验评估成功率。</p>
<p><img src="https://arxiv.org/html/2510.01023v1/images/Success_rates.png" alt="成功率对比"></p>
<blockquote>
<p><strong>图13</strong>：三种策略在不同物体上的成功率。对于<strong>番茄</strong>（易变形），P+F策略成功率最高（<strong>90%<strong>），而P策略因用力过猛导致20%的试验发生不可逆变形，F策略有20%打滑。对于</strong>牙膏</strong>（弹性好），三种策略性能接近（80-90%）。对于<strong>洗发水瓶</strong>（刚性），F策略表现最差（<strong>30%</strong> 成功率，因用力不足打滑），P和P+F策略均达到90%成功率。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.01023v1/images/models_comparison.png" alt="抓取动态时间序列"></p>
<blockquote>
<p><strong>图14</strong>：三种策略在执行任务时的夹爪位置和接触力随时间变化曲线（标准化到[0,1]）。该图直观展示了不同策略的抓握模式差异，例如在番茄任务中，P策略（橙色）施加的力明显高于其他策略。</p>
</blockquote>
<p><strong>消融实验总结</strong>：通过对比P、F、P+F三种策略的表现，证明了力反馈信息对于处理<strong>易变形物体</strong>（如番茄）至关重要，能有效防止损坏；对于<strong>刚性物体</strong>，位置信息是主导，力反馈贡献有限；对于<strong>弹性物体</strong>，力反馈有助于精细调节，但对任务成功率的直接影响较小。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出并开源了<strong>Prometheus</strong>，一个集成真实力反馈的低成本、通用动作捕捉遥操作系统，用于高质量机器人学习数据收集。2) 通过用户实验证明，力反馈能使操作员平均减少<strong>35.77%</strong> 的抓握力，提升对脆弱物体的操作精度。3) 通过微调VLA模型证明，融合力感知数据能显著提高策略在易变形物体操作上的成功率（如番茄任务达**90%**），丰富了机器人多模态学习的数据维度。</p>
<p>论文自身提到的局限性包括：系统目前主要针对UR3和Robotiq 2F-85平台，移植到其他机器人需要调整；用于VLA微调的数据集规模较小（300条轨迹）；未测量系统延迟，可能影响动态场景的实时性；定制PCB的制造对非专业用户可能存在门槛。</p>
<p>这项工作对后续研究的启示包括：1) <strong>系统可移植性</strong>：可将Prometheus的硬件和软件方案适配到双臂或其他机器人平台，以支持更复杂的操作任务。2) <strong>多模态集成</strong>：在现有力反馈基础上，可探索集成触觉纹理或振动反馈，提供更丰富的感官信息。3) <strong>混合学习策略</strong>：利用收集的力反馈数据，可以结合模仿学习与强化学习，加速在接触丰富任务上的策略优化。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出Prometheus系统，解决基于动作捕捉的机器人遥操作中缺乏力反馈、易导致抓取力过大损坏物体的问题。该系统采用消费级HTC Vive追踪器、定制控制器与UR3机械臂，通过定制夹爪与嵌入式力传感器实现均匀压力感知与实时力反馈。关键技术包括3D打印与商用组件结合、定制PCB设计，并全面开源。实验表明，该系统能提升任务成功率，为大规模模仿学习数据收集提供了低成本解决方案。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.01023" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>