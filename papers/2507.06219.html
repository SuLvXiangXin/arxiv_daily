<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Is Diversity All You Need for Scalable Robotic Manipulation? - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Is Diversity All You Need for Scalable Robotic Manipulation?</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.06219" target="_blank" rel="noreferrer">2507.06219</a></span>
        <span>作者: Hongyang Li Team</span>
        <span>日期: 2025-07-08</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>自然语言处理和计算机视觉领域的基础模型取得了显著成功，其关键驱动力在于系统性的数据扩展。然而，机器人操作领域有效数据扩展的原则仍未被充分理解。当前，机器人社区为应对数据稀缺，正致力于大规模数据收集，如Bridge Data、DROID、Open X-Embodiment (OXE)和AgiBot World等数据集。这些方法主要遵循“越多越好”的理念，依赖于暴力收集或简单聚合，并未深入思考何种数据对机器人学习真正有效。例如，OpenVLA发现移除DROID数据反而提升了模型性能，这引发了对有效数据构成及如何战略性扩展数据的根本性质疑。本文针对“数据多样性是否总是有益”这一具体痛点，系统性地探究了机器人学习中三个未被充分探索的多样性维度——任务（做什么）、具身（用哪个机器人）和专家（谁演示），挑战了“越多样越好”的传统直觉。本文的核心思路是：通过精心设计的实验揭示不同维度多样性对机器人学习的复杂且非均一的影响，为高效扩展机器人操作数据集提供新的视角和实践指导。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文并未提出一个统一的全新算法框架，而是通过三个独立但系统的实验模块，分别探究任务、具身和专家三个维度的多样性。整体研究思路如图1所示，即分别构建不同特性的预训练或微调数据集，基于现有的先进策略架构（如GO-1、RDT）进行训练和评估，通过对比实验得出关于各维度多样性作用的结论。</p>
<p><img src="https://arxiv.org/html/2507.06219v1/x1.png" alt="研究概览"></p>
<blockquote>
<p><strong>图1</strong>：研究概览。系统性地探究机器人操作数据多样性的三个关键方面：(a) 任务多样性有利于策略学习，并呈现可预测的幂律扩展关系。(b) 多具身预训练数据对于跨具身迁移能力是可选的——在单具身数据上预训练的模型能高效适应不同平台，且在微调阶段展现出比多具身预训练模型更理想的扩展特性。(c) 专家多样性会混淆机器人学习，为此我们基于GO-1设计了一种分布去偏方法；由此产生的GO-1-Pro在预训练和微调阶段均实现了卓越的数据效率，获得了15%的显著性能提升，相当于使用了2.5倍的预训练数据。</p>
</blockquote>
<p><strong>1. 任务多样性实验设计</strong>：使用GO-1作为策略架构，利用AgiBot World数据集。采用两阶段流程：先在大规模操作数据集上预训练，然后在目标评估任务上微调。为探究任务多样性的作用，从AgiBot World Beta数据集中通过两种采样策略构建了规模相同但任务分布不同的预训练数据集：(1) <strong>任务采样</strong>：人工选择10%与下游任务最相关的任务，形成任务多样性有限但相关性高的数据集；(2) <strong>片段采样</strong>：从原始数据集的每个任务中随机采样10%的片段，保留了完整的任务多样性但减少了总数据量。随后在相同的四个下游任务（擦桌子、叠短裤、倒水、做三明治）上微调并评估模型性能。</p>
<p><strong>2. 具身多样性实验设计</strong>：旨在验证单具身预训练是否可实现有效的跨具身迁移。使用大规模单具身数据集AgiBot World（来自AgiBot G1机器人）预训练模型（RDT-AWB），并与在包含多具身数据的OXE数据集上预训练的模型（RDT-OXE）进行对比。随后在两个模型上，使用不同数量的微调数据或训练步数，在三个与预训练机器人不同的平台上进行评估：ManiSkill（Franka机械臂）、RoboTwin（Arx机械臂）和真实世界的Agilex（Piper机械臂）。</p>
<p><strong>3. 专家多样性分析与去偏方法</strong>：论文指出，专家多样性表现为<strong>空间多模态</strong>（不同的轨迹路径选择）和<strong>速度多模态</strong>（以不同速度执行相似轨迹）。前者是应保留的有意义任务策略，而后者是应消除的干扰噪声。</p>
<p><img src="https://arxiv.org/html/2507.06219v1/x2.png" alt="专家行为多模态"></p>
<blockquote>
<p><strong>图2</strong>：Push-T任务中多模态专家行为的图示。机器人（蓝色圆圈）需要将灰色的T移动到绿色目标区域。专家演示在空间和速度维度上都表现出多模态：(a) 空间多模态源于不同的轨迹选择，机器人可以从左侧或右侧接近T，导致不同的空间路径；(b) 速度多模态发生在机器人以不同速度执行相似轨迹时，随时间产生完全不同的演示曲线。</p>
</blockquote>
<p>基于此洞察，本文提出了一种<strong>分布去偏方法</strong>，旨在消除速度多模态同时保留空间多模态。该方法的核心是一个<strong>速度模型</strong>，其具体技术细节在论文附录中描述（正文未详述）。简言之，该模型对演示数据的动作序列进行预处理，以标准化或消除速度变化带来的分布偏差。将这种方法应用于GO-1模型，得到了改进版本GO-1-Pro。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验平台与基准</strong>：实验主要基于AgiBot World数据集和GO-1、RDT策略架构。评估涵盖仿真和真实世界。任务多样性实验在真实机器人上评估四个任务。具身多样性实验在ManiSkill（5个任务）、RoboTwin（4个任务）仿真环境和真实世界Agilex平台（4个任务）上进行。</p>
<p><strong>对比方法</strong>：</p>
<ul>
<li>任务多样性：对比了“任务采样”与“片段采样”两种预训练数据构建策略。</li>
<li>具身多样性：对比了在OXE上预训练的RDT-OXE与在AgiBot World上预训练的RDT-AWB。</li>
<li>专家多样性：对比了原始GO-1与经过分布去偏的GO-1-Pro。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>任务多样性</strong>：如图4所示，在数据量相同的情况下，采用“片段采样”（高任务多样性）预训练的模型，其平均得分比“任务采样”模型高0.1。其中，“做三明治”任务提升0.26，“倒水”任务提升0.14。这表明任务多样性比单任务演示数量更重要。</li>
</ol>
<p><img src="https://arxiv.org/html/2507.06219v1/x4.png" alt="任务多样性评估结果"></p>
<blockquote>
<p><strong>图4</strong>：GO-1在不同数据集预训练后在四个挑战性任务上的真实机器人评估结果。片段采样（10% Episode）在相同数据量下优于任务采样（10% Task）0.1平均分，且在保证足够任务多样性的前提下，性能随预训练数据增加持续提升。</p>
</blockquote>
<ol start="2">
<li><strong>任务数据幂律关系</strong>：如图5所示，在保持足够任务多样性的前提下，模型性能随预训练数据量增加而提升，遵循幂律关系。拟合优度gap与数据量的幂律曲线，相关系数达-0.99。</li>
</ol>
<p><img src="https://arxiv.org/html/2507.06219v1/x5.png" alt="预训练数据缩放定律"></p>
<blockquote>
<p><strong>图5</strong>：在保持足够任务多样性的前提下，性能随预训练数据规模扩展，遵循可预测的幂律关系。左：GO-1性能随预训练数据规模扩展。右：预训练数据规模与模型性能间的幂律关系。</p>
</blockquote>
<ol start="3">
<li><strong>具身多样性</strong>：<ul>
<li><strong>向Franka迁移（ManiSkill）</strong>：如图6左图，当每个任务的微调数据量较少（125条）时，RDT-OXE（预训练包含测试具身）表现稍好；当数据量达到250条时，RDT-AWB（单具身预训练）与之持平；数据量继续增加，RDT-AWB反超并拉开差距，且性能与数据量呈幂律关系（图6右）。图7显示，在训练步数较少时（约1万步），RDT-OXE收敛更快，但随着训练步数增加，RDT-AWB最终超越RDT-OXE。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2507.06219v1/x6.png" alt="向Franka迁移（数据量变化）"></p>
<blockquote>
<p><strong>图6</strong>：向ManiSkill中Franka机械臂的跨具身适应（微调数据量变化）。左：性能 vs. 微调数据中每个任务的演示数量。右：下游性能与微调数据规模间的幂律关系。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.06219v1/x7.png" alt="向Franka迁移（训练步数变化）"></p>
<blockquote>
<p><strong>图7</strong>：向ManiSkill中Franka机械臂的跨具身适应（训练步数变化）。左：性能 vs. 训练步数（每任务1000个微调片段）。右：性能 vs. 训练步数（每任务500个微调片段）。</p>
</blockquote>
<ul>
<li><strong>向Arx迁移（RoboTwin）</strong>：如图8所示，RDT-AWB仅需少量微调数据即可达到与RDT-OXE相当的性能，并成功适应Arx机械臂。</li>
<li><strong>向真实Piper迁移（Agilex）</strong>：如表I所示，在每任务100条演示的相同微调数据量下，RDT-AWB在4个任务中的3个上表现优于RDT-OXE，平均得分0.45 vs. 0.40。</li>
</ul>
<p><img src="https://arxiv.org/html/2507.06219v1/x8.png" alt="向Arx迁移"></p>
<blockquote>
<p><strong>图8</strong>：模型如何随着数据量增加跨越具身鸿沟适应RoboTwin中的Arx机械臂。左：性能 vs. 微调数据中每个任务的演示数量。右：下游性能与微调数据规模间的幂律关系。</p>
</blockquote>
<ol start="4">
<li><strong>专家多样性去偏</strong>：<ul>
<li><strong>定性分析</strong>：图9、10、11展示了原始演示数据及经过速度模型处理后的动作分布对比，可见速度维度上的分布偏差被有效消除。</li>
<li><strong>定量结果</strong>：如图12所示，GO-1-Pro在预训练阶段数据效率显著高于GO-1。如图13所示，在四个下游任务微调后，GO-1-Pro相比GO-1实现了平均15%的性能提升。如图14所示，这一提升幅度相当于使用了2.5倍于原始数据的预训练数据量。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2507.06219v1/x9.png" alt="速度去偏效果"></p>
<blockquote>
<p><strong>图9</strong>：原始演示动作序列及其在位置、速度维度的分布可视化。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.06219v1/x11.png" alt="速度模型处理后的动作分布"></p>
<blockquote>
<p><strong>图11</strong>：经过速度模型处理后的动作序列分布，速度维度的多模态/偏差被消除。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.06219v1/x12.png" alt="预训练数据效率对比"></p>
<blockquote>
<p><strong>图12</strong>：GO-1-Pro与GO-1在预训练阶段的数据效率对比。GO-1-Pro收敛更快，达到相同性能所需数据更少。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.06219v1/x13.png" alt="微调性能提升"></p>
<blockquote>
<p><strong>图13</strong>：GO-1-Pro与GO-1在四个下游任务上微调后的性能对比。GO-1-Pro实现了平均15%的性能提升。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.06219v1/x14.png" alt="等效数据量增益"></p>
<blockquote>
<p><strong>图14</strong>：GO-1-Pro的性能增益相当于使用了2.5倍的预训练数据量。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>证明了任务多样性对机器人学习有益，且当保持足够多样性时，预训练数据量与下游性能之间存在幂律缩放关系。</li>
<li>揭示了多具身数据对于实现跨具身迁移是“可选的”，单具身预训练模型能够高效适应不同机器人平台，且在微调阶段展现出比多具身预训练模型更理想的扩展特性。</li>
<li>发现专家多样性（特别是速度多模态）会混淆模仿学习过程，并提出一种针对性的分布去偏方法，显著提升了模型性能和数据效率。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，其发现并不意味着单具身预训练优于多具身方法，而是提供了另一种可行的路径。此外，关于专家多样性的研究基于特定任务的分析，其普遍性有待进一步验证。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>重新思考“多样性”</strong>：研究呼吁社区超越“越多越好”的简单思维，需要细致地辨别何种多样性有益、何种可能有害。数据质量与针对性可能比纯粹的规模和广度更重要。</li>
<li><strong>数据集构建指南</strong>：为构建高效的大规模机器人数据集提供了具体指导：应优先保证任务多样性；在资源有限时，集中高质量的单具身数据可能是实现广泛泛化的有效起点；在收集数据时需关注并处理专家引入的速度噪声。</li>
<li><strong>关注数据本身属性</strong>：研究强调了机器人动作数据与图像/文本数据的根本区别，指出当前模仿学习的瓶颈可能在于被忽视的数据特性，而非模型容量或数据集规模的不足。这启发后续工作应更深入地分析数据分布，并设计相应的预处理或学习算法。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文探讨机器人操作数据扩展的核心问题，挑战“多样性越多越好”的直觉。通过系统分析任务、体现和专家三个维度的数据多样性，发现：任务多样性比单任务数据量更重要；多体现预训练对跨平台迁移非必需；专家多样性（尤其是速度多模态）会干扰策略学习。为此提出分布去偏方法GO-1-Pro，缓解速度歧义，在性能上实现15%提升，等效于使用2.5倍预训练数据。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.06219" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>