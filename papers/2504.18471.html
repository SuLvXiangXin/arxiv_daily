<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Action Flow Matching for Continual Robot Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Action Flow Matching for Continual Robot Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2504.18471" target="_blank" rel="noreferrer">2504.18471</a></span>
        <span>作者: Murillo-Gonzalez, Alejandro, Liu, Lantao</span>
        <span>日期: 2025/04/25</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在机器人持续学习领域，一个核心挑战是让机器人能够不断适应动态变化的环境和任务。基于模型的强化学习（MBRL）方法通常依赖动力学模型进行规划和探索。主流做法是利用最新版本的模型来指导探索，以收集数据并更新模型。然而，当模型与真实环境动态未对齐时（源于简化假设、未建模因素、数据不完整或参数不确定性），基于未对齐模型生成的计划往往是次优甚至错误的，这导致探索效率低下，数据信息量不足，从而延缓了模型的重新对齐过程。</p>
<p>本文针对“在模型未对齐时如何进行高效探索以加速模型学习”这一具体痛点，提出了一个新颖的视角：与其使用未对齐的模型进行探索，不如直接对模型规划出的动作进行变换，使其更接近机器人“本意”（即若模型对齐时应执行的动作）。本文的核心思路是利用流匹配（Flow Matching）框架，学习一个从“基于未对齐模型规划的动作”到“更可能实现预期状态转移的动作”的生成式映射，从而引导机器人执行更具信息量的动作，加速动力学模型的在线对齐。</p>
<h2 id="方法详解">方法详解</h2>
<p>Action Flow Matching (AFM) 的整体流程如图所示：在每一个时间步，规划器使用当前（可能未对齐的）动力学模型 (f_{\theta_t}) 和期望目标，规划出初始动作 (\mathbf{a}_t^0)。当检测到模型存在不可接受的未对齐情况时，AFM 模块将 (\mathbf{a}_t^0) 变换为修正后的动作 (\mathbf{a}_t^1)。执行 (\mathbf{a}_t^1) 有望产生更具信息量的状态转移，从而更快地重新对齐动力学模型。</p>
<p><img src="https://arxiv.org/html/2504.18471v2/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：AFM 在持续学习中的作用。规划器使用最新动力学模型和期望目标选择下一个动作 (\mathbf{a}_t^0)。当模型与环境之间的未对齐不可接受时，AFM 将 (\mathbf{a}_t^0) 变换为 (\mathbf{a}_t^1)。执行 (\mathbf{a}_t^1) 有望引导智能体执行更具信息量的动作，从而加速模型重新对齐。</p>
</blockquote>
<p>AFM 方法建立在三个关键见解之上，对应其核心模块：</p>
<ol>
<li><strong>高效动态空间约简</strong>：利用初始可用的（可能不完美的）动力学模型，将巨大的状态-动作空间约简到一个动态可行的区域。这避免了通过随机轨迹生成来捕获该区域的低效性。</li>
<li><strong>无需真实模型的动态机制表示</strong>：通过关注<strong>状态演化模式</strong>（即状态变化的重复模式，而非底层的系统动力学），可以学习表示不同的动态机制，而无需一个准确的真实模型。</li>
<li><strong>用于加速学习的意图映射</strong>：在约简的动态空间和动态机制表示的基础上，利用流匹配生成引导信号，使智能体能够利用这些信号，通过变换后的动作收集更具信息量的转移信息，从而加速学习。</li>
</ol>
<p><img src="https://arxiv.org/html/2504.18471v2/x2.png" alt="AFM流程"></p>
<blockquote>
<p><strong>图2</strong>：AFM 流程。训练时，我们利用反事实启发的转移：用一个随机采样的动作模拟状态演化，但将另一个不同的随机动作记录为原因。部署时，智能体尝试识别当前的动态机制，并基于此将规划的动作 (\mathbf{a}_t^0) 变换为 AFM 认为有更高几率实现期望状态转移的修正或“本意”动作 (\mathbf{a}_t^1)。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ul>
<li><p><strong>动态空间约简与反事实训练</strong>：为了解决无法获得真实目标动作分布（Q1）的问题，AFM 采用了一种创新的训练策略。它利用初始模型 (f_{\theta_0}) 来定义一个“可行动态空间”的近似。如图3所示，白色区域是真实的动态可行区域，橙色区域是模型近似的可行区域。</p>
<p><img src="https://arxiv.org/html/2504.18471v2/x3.png" alt="动态空间直觉"></p>
<blockquote>
<p><strong>图3</strong>：可行动态空间直觉。蓝色：状态-动作空间。白色：动态可行区域。橙色：使用动力学模型近似的可行区域。</p>
</blockquote>
<p>训练数据通过一种“反事实”方式生成：从模型近似可行区域采样一个动作 (\mathbf{a}^0)，用它和当前状态通过模型预测下一个状态 (\mathbf{s}^<em>)；同时，从同一区域独立采样另一个动作 (\mathbf{a}^1)。训练时，将 ((\mathbf{a}^0, \mathbf{s}^</em>)) 对作为源，而将 (\mathbf{a}^1) 作为目标，学习一个映射，使得变换后的动作能引导状态向 (\mathbf{s}^*) 演化。这模拟了“用动作A计划到达状态S，但实际执行动作B也能到达S”的情况，从而在不知道真实动力学的情况下，学习对规划动作的修正。</p>
</li>
<li><p><strong>动态机制识别（解决Q2）</strong>：AFM 通过一个编码器网络来识别当前的动态机制。该编码器以最近的状态-动作-下一状态转移序列为输入，输出一个表征当前动态机制的潜在向量。这个向量将作为条件，输入到后续的流匹配模型中，使动作变换适应不同的环境动态。</p>
</li>
<li><p><strong>基于流匹配的意图映射</strong>：AFM 模型 (g_\phi) 本质上是一个条件流匹配模型。它将规划的动作 (\mathbf{a}_t^0) 作为源分布 (p) 的样本，将“本意动作”作为目标分布 (q) 的样本（通过上述反事实策略近似）。模型学习一个时间依赖的速度场 (u^\phi_\tau)，通过求解 ODE 将 (\mathbf{a}_t^0) 变换为 (\mathbf{a}_t^1)。训练损失采用条件流匹配损失（CFM），如论文公式(8)所示，它允许在不知道真实速度场的情况下进行训练。在部署时，将规划动作 (\mathbf{a}_t^0) 和当前动态机制表征输入训练好的流模型，通过数值积分ODE得到修正后的动作 (\mathbf{a}_t^1)。</p>
</li>
</ul>
<p><strong>与现有方法的创新点</strong>：传统MBRL在模型未对齐时，仍使用该模型进行探索，效率低下。AFM 的核心创新在于<strong>不直接依赖未对齐模型进行探索，而是将其作为规划源，并学习一个生成式模型来“校准”输出的动作</strong>。这种“动作空间修正”的思路，结合反事实训练策略，使得方法能够在没有真实模型或目标动作分布的情况下进行学习，更高效地产生信息量丰富的交互数据。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验平台与数据集</strong>：方法在两个机器人平台上进行验证：一个无人地面车辆（UGV）和一个四旋翼飞行器。实验涉及动态环境变化，例如UGV从高摩擦地面切换到低摩擦地面（模拟结冰），四旋翼的质量发生未知变化。</p>
<p><strong>对比的Baseline方法</strong>：</p>
<ol>
<li><strong>MBRL</strong>：标准的基于模型的强化学习，使用最新模型进行规划和探索。</li>
<li><strong>RMA</strong>：快速运动适应系列方法，通过离线学习潜在表征来适应环境变化。</li>
<li><strong>Oracle</strong>：使用真实对齐动力学模型的规划器，作为性能上界。</li>
<li><strong>MPC</strong>：仅使用初始未更新模型的模型预测控制，作为性能下界。</li>
</ol>
<p><strong>关键实验结果</strong>：<br>在UGV的导航任务中，当环境动态从正常变为低摩擦时，AFM实现了最高的任务成功率。具体而言，AFM取得了**94.2%<strong>的成功率，相比最好的基线方法（MBRL）的</strong>60.0%<strong>，绝对提升达到了</strong>34.2%**。同时，AFM在收敛速度和稳定性方面也显著优于基线。</p>
<p><img src="https://arxiv.org/html/2504.18471v2/x4.png" alt="UGV成功率"></p>
<blockquote>
<p><strong>图4</strong>：UGV在动态变化环境中的任务成功率对比。AFM（红色）在摩擦系数变化后，成功率达到94.2%，显著且更快地超越了所有基线方法。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.18471v2/x5.png" alt="四旋翼跟踪误差"></p>
<blockquote>
<p><strong>图5</strong>：四旋翼在质量突变情况下的位置跟踪误差。AFM（红色）在变化发生后，能快速将跟踪误差降低并稳定在最低水平，表现出优异的适应能力。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.18471v2/x6.png" alt="消融实验"></p>
<blockquote>
<p><strong>图6</strong>：AFM关键组件的消融研究。完整AFM性能最佳。移除动态机制识别（w/o context）或流匹配变换（w/o FM，即直接执行规划动作）都会导致性能显著下降，证明了各组件的重要性。</p>
</blockquote>
<p><strong>消融实验总结</strong>：<br>论文通过消融实验验证了各个核心组件的贡献：</p>
<ol>
<li><strong>移除动态机制识别（w/o context）</strong>：性能下降，表明适应特定动态机制的必要性。</li>
<li><strong>移除流匹配变换（w/o FM）</strong>：性能大幅下降至接近基线水平，证明了对规划动作进行生成式变换是性能提升的关键。</li>
<li><strong>完整AFM</strong>：取得最佳性能，说明动态空间约简、机制识别和意图映射三者协同工作的有效性。</li>
</ol>
<p><img src="https://arxiv.org/html/2504.18471v2/x7.png" alt="定性结果"></p>
<blockquote>
<p><strong>图7</strong>：UGV的定性轨迹对比。在低摩擦环境下，MPC（蓝）因模型未对齐而严重偏离，MBRL（绿）有所改进但仍有偏差，而AFM（红）的轨迹最接近使用真实模型的Oracle（黄）。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>本文核心贡献</strong>：</p>
<ol>
<li>提出了 <strong>Action Flow Matching (AFM)</strong> 这一新颖框架，用于机器人动力学模型的持续学习。其核心思想是通过流匹配直接变换基于未对齐模型规划的动作，而非依赖该模型进行探索，从而更高效地收集数据。</li>
<li>设计了一种 <strong>反事实训练策略</strong>，能够在无法获取真实动力学或目标动作分布的情况下，有效训练流匹配模型，解决了持续学习中关键的数据生成难题。</li>
<li>通过整合 <strong>动态空间约简</strong>、<strong>动态机制表示学习</strong> 和 <strong>条件流匹配</strong>，实现了一个高效的系统，在无人车和无人机平台上验证了其卓越的适应性和学习效率，取得了显著的任务成功率提升。</li>
</ol>
<p><strong>论文提到的局限性</strong>：</p>
<ol>
<li>方法性能依赖于初始动力学模型的质量。如果初始模型过于不准确，其定义的“近似可行区域”可能无法提供有意义的约束。</li>
<li>当前框架依赖于采样-based规划器（如MPPI、CEM）来生成初始动作序列。规划器的选择及其超参数可能会影响整体性能。</li>
</ol>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>“校准”动作而非模型的思路</strong>：AFM 提供了一种不同于传统模型更新范式的新视角——在模型和真实世界之间增加一个“动作适配层”。这种思路可能适用于其他存在模拟到真实差距或模型不准确的场景。</li>
<li><strong>流匹配在机器人学习中的应用</strong>：展示了流匹配作为一种强大的生成模型，可用于学习复杂的、与物理相关的映射，为机器人控制中的分布变换问题提供了新工具。</li>
<li><strong>持续学习的数据效率</strong>：通过引导智能体执行更具信息量的动作来加速学习，这一原则可以推广到更广泛的持续学习设定中，特别是那些需要在线、非回合制交互的任务。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出动作流匹配方法，用于解决机器人持续学习中动力学模型与环境不匹配的核心问题。该方法通过流匹配框架在线调整模型：不直接使用未对齐模型进行探索，而是将规划动作转换为更接近对齐模型预期的动作，从而高效收集数据、加速模型重新对齐。实验在无人车和四旋翼平台上验证，任务成功率提升34.2%，并减少了对经验回放缓冲区的依赖。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2504.18471" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>