<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Computer Vision and Pattern Recognition (cs.CV)</span>
      <h1>Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2511.21663" target="_blank" rel="noreferrer">2511.21663</a></span>
        <span>作者: Zhang, Naifu, Tao, Wei, Xiao, Xi, Sun, Qianpu, Zheng, Yuxin, Mo, Wentao, Wang, Peiqiang, Zhang, Nan</span>
        <span>日期: 2025/11/26</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>近年来，具身智能领域的视觉-语言-动作模型发展迅速。然而，现有的对抗攻击方法（如UADA）通常需要昂贵的端到端训练来生成无约束的、可见的对抗补丁，存在训练耗时、补丁视觉上显眼、且缺乏在感知关键的特征空间层面进行系统探索等局限性。本文针对VLA模型对抗攻击面临的三大挑战——如何高效生成对抗样本、如何实现低幅度且不易察觉的扰动、以及如何聚焦于模型敏感区域以实现稀疏高效攻击——提出了在VLA视觉编码器的投影特征空间进行灰盒攻击的新视角。本文的核心思路是，在灰盒设定下，利用投影梯度下降方法直接在视觉编码器输出的、对齐到文本空间的特征上施加扰动，并结合注意力引导实现扰动的聚焦与稀疏化，从而高效、隐蔽地破坏下游动作预测。</p>
<h2 id="方法详解">方法详解</h2>
<p>ADVLA是一个在VLA视觉编码器特征空间实现的对抗攻击框架。攻击者在灰盒设定下可以访问视觉编码器及其投影层的参数和梯度，并能获取中间投影特征和注意力图，但无法触及下游LLM和动作头的内部参数。攻击目标是特征空间的无目标攻击，即通过最小化对抗图像与干净图像在视觉→文本投影特征空间中的相似性，引发融合表征的偏移，进而干扰后续动作预测。</p>
<p><img src="https://arxiv.org/html/2511.21663v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：ADVLA的整体流程。(a) 主体攻击方法：在每个VLA控制步，获取原始图像并初始化噪声，通过视觉骨干网络和投影层计算干净视觉特征作为参考。随后迭代地将对抗图像输入视觉编码器生成对抗特征，计算相似性损失，并基于投影梯度下降方法更新对抗图像。(b) 注意力掩码生成：从视觉骨干（DinoV2和SigLIP）中的一个ViT提取注意力图，将其调整至图像分辨率，根据Top-K权重生成二值空间掩码。(c) 三种策略：分别展示了三种注意力引导策略在噪声更新和损失计算上的应用方式。</p>
</blockquote>
<p>整体流程如算法1所示：在每个时间步，首先计算并固定当前帧的干净投影特征 <code>F_clean</code>；然后进行T次PGD内层迭代来生成对抗图像。每次迭代中，计算对抗图像的投影特征 <code>F_t</code> 与 <code>F_clean</code> 之间的余弦相似度损失 <code>L_t</code>，并计算损失相对于输入图像的梯度 <code>G_t</code>；随后可选择性地应用注意力引导策略对梯度或损失进行调制；最后用符号梯度更新对抗图像并裁剪到有效像素范围[0,1]和扰动幅度约束内（如 <code>L_∞ ≤ 4/255</code>）。</p>
<p>核心模块是三种独立的注意力引导策略，旨在增强攻击的敏感性、强制稀疏性和集中扰动：</p>
<ol>
<li>**ADVLA-AW (Attention-Weighted Gradient)**：从ViT中提取注意力图 <code>A</code>，插值到图像分辨率得到 <code>Ã</code>。在梯度更新时，将梯度 <code>G_t</code> 与 <code>Ã</code> 进行逐元素相乘（<code>G_t^AW = G_t ⊙ Ã</code>），使扰动更新更集中于模型关注的区域。</li>
<li>**ADVLA-TKM (Top-K Masked Gradient)**：根据注意力分数选择Top-K个图像块，生成二值空间掩码 <code>M_topk</code>。更新梯度时，仅保留这些关键区域的梯度（<code>G_t^TKM = G_t ⊙ M_topk</code>），将扰动范围限制在少数块内，实现空间稀疏性并降低视觉显著性。</li>
<li>**ADVLA-TKL (Top-K Loss)**：不直接掩码梯度，而是将投影特征 <code>F_t</code> 和 <code>F_clean</code> 与展平的Top-K块掩码 <code>M_topk-flat</code> 相乘，仅计算关键块特征之间的相似度损失（公式9）。通过优化该损失，迫使特征差异集中在选定的敏感补丁上。</li>
</ol>
<p>与现有需要端到端训练的补丁攻击方法相比，ADVLA的创新点在于：1) 直接在投影特征空间进行基于梯度的优化，避免了昂贵的训练过程；2) 利用模型自身的注意力机制来引导和稀疏化扰动，实现了在极低修改比例下的高效攻击。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在LIBERO仿真基准上进行，该基准包含Spatial, Object, Goal, Long四个任务套件，每个套件10个任务。目标模型是开源的OpenVLA，并针对四个套件分别训练了变体。评估指标采用任务执行失败率（FR = 1 - 成功率）。对比的基线方法包括随机噪声和最新的VLA补丁攻击方法UADA。</p>
<p>关键定量结果如下：在最大扰动约束 <code>ε = 4/255</code>、迭代6次的设置下，ADVLA及其变体均能有效提升任务失败率。如表1所示，ADVLA、ADVLA-AW和ADVLA-TKM在四个套件上的平均失败率均达到100%，与UADA性能相当，而ADVLA-TKL也达到了99.6%。这表明所提方法能近乎完全破坏模型性能。</p>
<p><img src="https://arxiv.org/html/2511.21663v1/x2.png" alt="定性结果对比"></p>
<blockquote>
<p><strong>图2</strong>：不同攻击方法的可视化对比（为清晰起见，扰动已放大显示）。(a) UADA方法生成的无限定训练补丁非常显眼。(b) ADVLA施加的全局噪声仍可感知。(c) ADVLA-TKM（基于注意力权重选择Top-10%的块）产生的噪声几乎不可见，仅集中在关键区域。最后一列展示了VLA中视觉骨干的注意力权重可视化，显示ViT主要关注机械臂区域。</p>
</blockquote>
<p>敏感性分析（表2）显示，攻击成功率随扰动幅度 <code>ε</code> 增大而稳定上升，当 <code>ε = 8/255</code> 时，所有方法在多个套件上均达到100%失败率。迭代次数分析（表3）表明，在 <code>ε = 4/255</code> 下，仅需5-6次迭代即可获得接近最优的攻击效果。消融实验（隐含在表1-3中）表明，三种注意力引导策略均能有效提升攻击效果，其中ADVLA-AW和ADVLA-TKM在多数设置下表现略优于基础ADVLA和ADVLA-TKL。</p>
<p>时间效率方面，ADVLA每次内层迭代平均仅需约0.06秒，实现了快速的对抗评估。相比之下，UADA为LIBERO-Spatial套件生成一个补丁需要在单张H100上训练约15小时，ADVLA实现了数个数量级的加速。</p>
<p>定性结果（图2）直观对比了不同攻击的隐蔽性。UADA的补丁非常醒目；ADVLA的全局噪声仍可察觉；而ADVLA-TKM（修改少于10%的块）产生的稀疏块状扰动几乎不可感知，同时保持了强大的攻击效果。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出了首个针对VLA模型视觉特征空间的灰盒对抗攻击框架ADVLA，通过投影梯度下降直接优化特征相似性，避免了昂贵的端到端训练；2) 设计了三种注意力引导策略（AW, TKM, TKL），实现了扰动在关键区域的聚焦与空间稀疏化，在极低修改比例下达到高攻击成功率；3) 实验证明ADVLA在严格扰动约束下能近乎崩溃模型性能，且速度远快于传统补丁攻击，同时具备更高的隐蔽性。</p>
<p>论文自身提到的局限性包括：攻击仅在数字仿真域进行测试，未在物理机器人上验证；攻击效果依赖于从视觉骨干提取的注意力图。</p>
<p>本工作对后续研究的启示在于：揭示了VLA模型在其视觉特征投影空间存在脆弱性，这种高效、隐蔽的攻击方式凸显了开发更强防御机制的迫切性。未来的工作可以探索针对此类特征空间攻击的防御策略，或研究在更严格的黑盒设定或物理世界中的攻击与鲁棒性评估。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出ADVLA框架，旨在以低强度、稀疏的对抗扰动高效攻击视觉-语言-动作模型，避免传统块攻击的高训练成本和明显扰动。核心方法是在视觉特征投影至文本空间后直接施加扰动，通过注意力引导与三种策略（增强敏感性、强制稀疏性、集中扰动）实现聚焦式稀疏攻击。实验表明，在L∞=4/255约束下，结合Top-K掩码仅需修改不到10%的图像块即可实现接近100%的攻击成功率，单次迭代仅需约0.06秒，显著优于传统块攻击方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2511.21663" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>