<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Towards Safe Imitation Learning via Potential Field-Guided Flow Matching - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Towards Safe Imitation Learning via Potential Field-Guided Flow Matching</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.08707" target="_blank" rel="noreferrer">2508.08707</a></span>
        <span>作者: Yoshihiko Nakamura Team</span>
        <span>日期: 2025-08-12</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>深度生成模型，特别是扩散模型和流匹配模型，已成为模仿学习中学习复杂策略的强大工具。然而，这些方法主要关注于准确建模和复现专家演示，往往忽视了生成策略的安全性，尤其是在存在固有障碍物的复杂环境中。当前基于流匹配的模仿学习方法尚未有效解决策略安全问题，而在扩散模型领域，已有工作通过手动定义的安全目标函数梯度来引导生成过程以提升安全性。</p>
<p>本文针对现有流匹配策略在安全性方面的不足，提出了一种新视角：从同一组成功的演示数据中，不仅学习任务策略，还提取与环境障碍物相关的信息，并将其表示为势场。核心思路是利用核密度估计从演示数据中学习一个势场，在推理阶段使用该势场来调制流匹配的向量场，从而引导策略生成远离障碍物的安全轨迹。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的潜在场引导流匹配策略（PF2MP）框架包含两个从同一组演示数据中训练的组件：1）一个基础流匹配策略（FMP），用于建模专家行为；2）一个估计的势场，用于编码环境约束（如障碍物）。在推理时，将学习到的流匹配向量场与势场结合，生成安全的动作序列。</p>
<p><img src="https://arxiv.org/html/2508.08707v1/img/overview_f.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：PF2MP框架概览。流程从演示数据（左）开始。基础流匹配策略（FMP）被训练（中上）以建模专家行为，同时使用密度图学习一个势场（中下）。在推理阶段（右），PF2MP框架集成了来自FMP的学习向量场和障碍物感知的势场，以生成安全轨迹。</p>
</blockquote>
<p><strong>基础流匹配策略（FMP）</strong>：该方法采用简化的条件流匹配来学习一个观察条件下的向量场。给定演示数据集 ( D = { \bm{o}^\tau, \bm{a}^\tau }_{\tau=1}^T )，其中 ( \bm{o}^\tau ) 为观察，( \bm{a}^\tau ) 为动作。目标是从先验分布（如高斯分布）采样 ( \bm{A}_0 ) 和从目标分布（演示数据）采样目标动作序列 ( \bm{A}_1 )，并定义条件向量场 ( u_t(\bm{A} | \bm{z}, \bm{o}^\tau) = \bm{A}_1 - \bm{A}<em>0 )，其中 ( \bm{z} = (\bm{A}<em>0, \bm{A}<em>1) )。随后，训练一个神经网络 ( v</em>{\theta}(\bm{A}, t; \bm{o}) ) 来回归该向量场，损失函数为 ( \mathcal{L}</em>{\text{FMP}}(\bm{\theta}) = \mathbb{E} || v</em>{\theta}(\bm{A}, t; \bm{o}) - u_t(\bm{A} | \bm{z}, \bm{o}) ||^2 )。推理时，使用欧拉方法从 ( \bm{A}<em>0 ) 开始，沿学习到的向量场 ( v</em>{\theta} ) 积分得到最终动作序列 ( \bm{A}_1 )。</p>
<p><strong>势场构建与安全策略生成</strong>：为了引入安全性，PF2MP利用演示数据隐含的环境约束信息。首先，使用核密度估计（KDE）基于演示数据估计动作空间的密度 ( \hat{p}(\bm{a}) )。然后，基于此估计密度构建一个势函数 ( \phi(\bm{a}) = \log(\hat{p}(\bm{a})) + \alpha d(\bm{a}, \mathcal{H}) )，其中第一项鼓励动作处于高密度（安全）区域，第二项是一个基于距离的惩罚项（( \alpha &lt; 0 )），( \mathcal{H} ) 定义为估计密度超过预设阈值的“更安全”区域。该势函数在整个动作序列上的梯度构成了势场 ( \Phi(\bm{A}) )。</p>
<p>在PF2MP的推理过程中，基础FMP的向量场更新公式被修改为：( \bm{A}_{t+\Delta t} = \bm{A}<em>t + [ v</em>{\theta}(\bm{A}_t, t; \bm{o}) + \lambda \Phi(\bm{A}_t) ] \Delta t )。其中，( \lambda ) 是一个超参数，用于权衡流匹配动态和势场引导。势场 ( \Phi(\bm{A}_t) ) 作为一个修正项，将生成的动作从低密度（不安全）区域推开，并拉向高密度（安全）区域。</p>
<p><strong>创新点</strong>：与现有基于扩散模型、需要手动定义安全目标函数的方法不同，PF2MP的创新在于能够从专家演示数据中自动推导出安全约束（通过KDE估计的势场），并将这些约束无缝集成到流匹配的推理过程中，从而在保持任务性能的同时显著提升策略的安全性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在模拟和真实世界环境中进行，评估了PF2MP在任务空间和关节空间控制中的有效性。</p>
<p><strong>使用的Benchmark/数据集/实验平台</strong>：</p>
<ol>
<li><strong>2D迷宫导航任务</strong>：基于D4RL和Mujoco物理引擎的“中型”和“大型”迷宫环境。</li>
<li><strong>模拟机器人操作任务</strong>：使用Gymnasium Robotics中的Fetch机器人模拟器，执行“Reach”（到达）和“Push”（推动）任务。</li>
<li><strong>真实世界机器人任务</strong>：在Franka Emika Panda机械臂上执行避障到达任务。</li>
</ol>
<p><strong>对比的Baseline方法</strong>：</p>
<ul>
<li>基础流匹配策略（FMP）</li>
<li>扩散策略（DP）</li>
<li>扩散策略+势场引导（DPPF，作为对比，将PF2MP中相同的势场引导集成到DP的去噪过程中）</li>
</ul>
<p><strong>关键实验结果</strong>：<br>在2D迷宫导航和Fetch机器人操作任务中，PF2MP在保持与基线方法相当甚至略优的任务成功率的同时，显著降低了碰撞率。</p>
<p><img src="https://arxiv.org/html/2508.08707v1/img/2Dmaze/middle.png" alt="结果对比表"></p>
<blockquote>
<p><strong>表I</strong>：2D迷宫导航和Fetch机器人操作任务上不同模型的性能对比。PF2MP在大型迷宫中将碰撞率从FMP的9.2%降至3.2%，在Fetch Reach任务中将碰撞率从34%降至18%，且任务成功率与基线相当或更优。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.08707v1/img/2Dmaze/large.png" alt="2D迷宫定性对比"></p>
<blockquote>
<p><strong>图2</strong>：2D迷宫导航任务定性示例。(a) 迷宫环境；(b) 从演示数据（红点）估计的密度图；(c) 导出的势场（蓝色箭头）；(d) 基线FMP产生碰撞的失败案例；(e) 在相同起始和目标条件下，PF2MP生成的无碰撞轨迹。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.08707v1/img/2Dmaze/ablation_potential_field_weight.png" alt="消融实验"></p>
<blockquote>
<p><strong>图12</strong>：势场权重 ( \lambda ) 对PF2MP在大型迷宫任务中性能的影响。当 ( \lambda ) 适中（如0.4, 0.8）时，碰撞率显著下降且成功率保持稳定；( \lambda ) 过低则接近基线FMP，过高则因安全区域过窄导致性能下降。</p>
</blockquote>
<p><strong>消融实验总结</strong>：对势场引导权重 ( \lambda ) 的消融研究表明，其取值对性能至关重要。适中的 ( \lambda ) 值能有效平衡任务完成与安全性，而过大或过小的 ( \lambda ) 都会导致性能下降，这凸显了仔细调整该超参数的必要性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了PF2MP，一种新颖的框架，首次将安全考虑系统地集成到基于流匹配的模仿学习中。</li>
<li>方法能够从同一组成功的专家演示中自动学习任务策略和障碍物感知的势场，无需手动定义安全目标函数。</li>
<li>通过广泛的模拟和真实世界实验验证了PF2MP的有效性，在多种任务中显著降低了碰撞率，且不牺牲任务成功率。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ol>
<li>势场权重 ( \lambda ) 需要仔细调整以获得最佳性能。</li>
<li>该方法依赖于演示数据覆盖了所有安全区域。如果演示未探索某些安全区域，这些区域在估计的密度图中可能表现为低密度，从而被势场视为“不安全”。</li>
<li>论文提到，在非常复杂的任务（如Fetch Push）中，所有方法的绝对成功率都相对较低，表明生成复杂、长程策略本身仍具挑战性。</li>
</ol>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li>PF2MP展示了从数据中自动学习安全约束的潜力，这为在其他生成模型或更复杂、动态的环境中集成安全机制提供了新思路。</li>
<li>未来工作可以探索更先进的密度估计技术，或结合在线安全验证模块，以处理演示数据未覆盖的安全区域。</li>
<li>将势场引导的思想与模型预测控制或其他安全滤波器结合，可能进一步提升在极端安全临界场景下的鲁棒性。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对模仿学习中生成运动的安全性问题，特别是在有障碍物的复杂环境中，提出了Potential Field-Guided Flow Matching Policy (PF2MP)方法。该方法同时从成功演示中学习基础流匹配策略和障碍物相关的势场，在推理时通过势场调制流匹配向量场，以生成安全轨迹。实验在模拟和真实世界的导航及机器人操作任务中进行，结果表明PF2MP显著减少了碰撞，提升了安全性而不影响任务成功率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.08707" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>