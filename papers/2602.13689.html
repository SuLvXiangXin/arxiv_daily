<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Symmetry-Aware Fusion of Vision and Tactile Sensing via Bilateral Force Priors for Robotic Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Symmetry-Aware Fusion of Vision and Tactile Sensing via Bilateral Force Priors for Robotic Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.13689" target="_blank" rel="noreferrer">2602.13689</a></span>
        <span>作者: Tao Yu Team</span>
        <span>日期: 2026-02-14</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人插入任务需要精确、接触丰富的交互，仅凭视觉难以解决。当前主流方法依赖基于CNN或Transformer的视觉策略，擅长全局场景理解，但难以捕捉接触时的微观滑动、顺应性或未对准等物理交互，且对遮挡、光照和几何不完整敏感。触觉感知能直接测量局部接触状态，补充视觉信息。然而，现有研究表明，简单的视觉-触觉特征拼接融合往往无法带来一致的性能提升，甚至可能产生负面影响，这凸显了异质表征同步困难以及模态特定信号被稀释的问题。</p>
<p>本文针对视觉-触觉融合在接触丰富操作中效果不佳的具体痛点，提出了一种新的视角：将人类运动控制中的双边力平衡原理作为物理先验，融入到多模态融合学习中。核心思路是：1）设计一个跨模态Transformer，通过结构化的自注意力和交叉注意力层次化地融合视觉与触觉信号；2）引入一个基于物理的双边力对称正则化项，稳定触觉嵌入并鼓励平衡的抓取，从而提升插入操作的鲁棒性和成功率。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架是一个用于机器人插入策略学习的视觉-触觉融合模型。输入是腕部相机RGB图像和夹爪手指的触觉力场，输出是机器人末端执行器的连续动作。策略通过近端策略优化进行训练，并额外施加一个基于物理的对称性正则化损失。</p>
<p><img src="https://arxiv.org/html/2602.13689v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：视觉-触觉融合架构概览。(a) 嵌入的简单拼接，存在稀释模态特定信号的风险。(b) 使用线性层自适应加权神经元贡献的门控融合。(c) 提出的跨模态Transformer，它嵌入了对称感知的触觉编码，并通过交叉注意力整合视觉和触觉。</p>
</blockquote>
<p>核心模块包括残差触觉编码、跨模态注意力融合和物理正则化。首先进行问题建模，将任务表述为部分可观测马尔可夫决策过程。</p>
<p><strong>1. 残差触觉编码与对称先验</strong>：原始触觉力为 <code>f_bar_t^L, f_bar_t^R</code>。为处理可能的物体不对称性，定义相对于校准参考信号的残差力：<code>f_t^L = f_bar_t^L - f_ref^L</code>, <code>f_t^R = f_bar_t^R - f_ref^R</code>。其中参考力 <code>f_ref</code> 可通过短暂的校准接触获得，对于对称物体可设为零。这种残差公式推广了对称感知平衡的核心思想。残差力通过编码器骨干网络转换为嵌入 <code>h_t^L, h_t^R</code>。为捕获双边一致性，对拼接的触觉特征执行自注意力：<code>z_t^T = Attn(W_q[h_t^L; h_t^R], W_k[h_t^L; h_t^R], W_v[h_t^L; h_t^R])</code>，得到一个残差感知的触觉表征，用于后续融合。</p>
<p><strong>2. 视觉-触觉交叉注意力</strong>：视觉观测 <code>v_t</code> 被编码为 <code>z_t^V</code>。随后应用以视觉为查询（提供全局对齐指导）、触觉为键/值（提供精细局部校正）的交叉注意力：<code>z_t^VT = Attn(W_q^V z_t^V, W_k^T z_t^T, W_v^T z_t^T)</code>。这种不对称性反映了设计选择：视觉提供全局上下文，触觉提供局部修正。通过堆叠触觉内自注意力和视觉-触觉交叉注意力，CMT实现了层次化融合，结构化地建模了每个模态的角色。</p>
<p><strong>3. 基于物理的对称正则化</strong>：受生物运动控制原理启发，引入一个辅助损失来强制双边力平衡。具体而言，将右侧触觉图垂直翻转并编码为 <code>~h_t^R</code>，然后与 <code>h_t^L</code> 比较：<code>L_sym = E_{t~D}[ || h_t^L - ~h_t^R ||_2^2 ]</code>。该正则化有两个作用：(i) 在插入前，抑制不对称的抓取力并稳定初始接触；(ii) 在插入过程中，减少导致卡住的横向未对准。它作为一个物理驱动的归纳偏置，将物理一致性注入到学习到的策略中。</p>
<p><img src="https://arxiv.org/html/2602.13689v1/x3.png" alt="对称正则化示意图"></p>
<blockquote>
<p><strong>图3</strong>：基于物理的对称正则化。右侧触觉图被垂直翻转并编码为 <code>~h_t^R</code>，然后与 <code>h_t^L</code> 比较。均方误差损失惩罚偏差，鼓励双边一致性。这个辅助目标在插入前稳定抓取力，并在插入过程中减少横向未对准。</p>
</blockquote>
<p><strong>4. 策略优化</strong>：整体训练目标为 <code>L = L_PPO + λ_sym * L_sym</code>，其中 <code>L_PPO</code> 是PPO的裁剪替代目标，<code>λ_sym</code> 平衡任务奖励与正则化。策略输出高斯动作，其方差被裁剪以确保训练稳定性。</p>
<p>与现有方法相比，创新点体现在：1) 提出了结合层次化自注意力与交叉注意力的跨模态Transformer进行结构化融合，而非简单拼接或门控加权；2) 首次将双边力对称作为物理先验正则化项直接用于策略学习，而不仅仅是用于状态估计或物体重建；3) 通过残差触觉编码泛化了对称性处理，使其能适应不对称物体。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在TacSL基准的机器人插入任务上进行，使用IsaacGym仿真环境。传感器配置包括腕部相机和夹爪触觉力阵列。对比的基线方法包括：仅视觉、仅触觉、特权配置（腕部+接触力）、简单拼接融合、门控融合，以及本文提出的CMT（有无对称正则化）。评估指标为插入成功率。</p>
<p><strong>关键定量结果</strong>（基于表I）：</p>
<ul>
<li>特权配置（腕部+接触力）达到96.09%的成功率，比仅视觉（93.23%）提升+2.86%，证明了接触反馈的必要性。</li>
<li>仅触觉策略成功率为91.41%，表明其在视觉受限时仍具鲁棒性。</li>
<li>简单拼接融合成功率为92.97%，提升有限。门控融合（无正则化）为94.53%。</li>
<li>提出的CMT（无正则化）达到96.22%，显著超越基线，并接近特权配置性能。</li>
<li>添加对称正则化后，门控融合提升至95.05%，CMT提升至**96.59%**，成为性能最佳的方法，甚至略微超过特权配置。</li>
</ul>
<p><img src="https://arxiv.org/html/2602.13689v1/figures/figure4_Steps.png" alt="不同融合策略的性能分布"></p>
<blockquote>
<p><strong>图5</strong>：简单（蓝）、门控（橙）和CMT（绿）融合的插入性能分布。散点表示单个试验，核密度轮廓表示在成功率（x轴）和成功所需步数（y轴）方面的结果分布。CMT不仅成功率最高，且平均所需步数（108.48步）少于简单融合（111.63步），表明其轨迹更高效。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.13689v1/x4.png" alt="插入过程中双边力场演化对比"></p>
<blockquote>
<p><strong>图4</strong>：两种融合策略下插入过程中双边力场的演化。上图：简单融合不强制对称性；与插座接触引发明显的左右不平衡，导致不稳定校正和偶尔的重新抓取。下图：提出的对称感知CMT在整个过程中保持平衡的力分布，减少不必要的横向接触，产生更直、更平滑的插入轨迹。这说明了显式建模双边对称性如何稳定接触丰富的操作。</p>
</blockquote>
<p><strong>消融实验分析</strong>：表I的结果本身构成了一个消融研究。关键组件的贡献可总结为：1) <strong>跨模态注意力结构</strong>：CMT（96.22%）相比简单拼接（92.97%）和门控融合（94.53%）带来了显著提升（+3.25%），表明结构化融合的有效性。2) <strong>对称正则化</strong>：该组件为CMT带来了额外的+0.37%提升（从96.22%到96.59%），并为门控融合带来了+0.52%提升（从94.53%到95.05%），验证了其作为稳定归纳偏置的价值。</p>
<p><strong>计算效率分析</strong>（表II）：CMT的延迟为6.52毫秒（153 fps），内存占用21.45 MB，虽高于简单融合（5.42 ms, 184.5 fps）和门控融合（5.51 ms, 181.5 fps），但仍远高于实时控制所需的60 Hz，在性能大幅提升的前提下，计算开销是可接受的。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) <strong>方法论创新</strong>：提出了一种用于视觉-触觉融合的跨模态Transformer，通过层次化自注意力与交叉注意力解决异质信号同步难题。2) <strong>物理先验引入</strong>：创新地将人类运动控制中的双边力平衡原理转化为一个物理启发的对称性正则化损失，用于稳定策略学习。3) <strong>实验验证</strong>：在TacSL基准上实现了96.59%的插入成功率，显著优于基线方法，并接近需要额外接触力传感器的特权配置性能，证明了所提框架的有效性。</p>
<p>论文提到的局限性包括：当前评估主要集中于对称物体插入任务，尽管残差编码设计旨在泛化至不对称情况；此外，CMT带来了一定的计算开销。</p>
<p>对后续研究的启示：1) 证明了将物理原理（如对称性）作为归纳偏置直接嵌入策略学习框架的潜力，可推广至其他接触丰富的操作任务。2) 跨模态Transformer的结构化融合范式为处理其他异质传感器组合（如视觉-听觉、视觉-本体感知）提供了参考。3) 触觉感知被确立为接触丰富操作的核心模态，未来工作可探索其在更复杂、非对称的实物装配场景中的应用。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人插入任务中视觉无法处理精确接触交互、现有视觉-触觉融合方法效果不佳的问题，提出对称感知的融合方法。关键技术为Cross-Modal Transformer (CMT)，通过自注意力和交叉注意力融合手腕摄像头与触觉信号，并引入基于物理的双边力平衡正则化以稳定触觉嵌入。在TacSL基准测试中，该方法实现96.59%的插入成功率，超越朴素与门控融合基线，接近特权配置的96.09%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.13689" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>