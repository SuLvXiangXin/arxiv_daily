<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Computer Vision and Pattern Recognition (cs.CV)</span>
      <h1>LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.03827" target="_blank" rel="noreferrer">2510.03827</a></span>
        <span>作者: Zhou, Xueyang, Xu, Yangming, Tie, Guiyao, Chen, Yongchao, Zhang, Guowen, Chu, Duanfeng, Zhou, Pan, Sun, Lichao</span>
        <span>日期: 2025/10/04</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，Vision-Language-Action (VLA) 模型已成为具身智能的核心范式，其发展严重依赖于标准化的评估基准。其中，LIBERO 基准因其标准化的任务套件和统一的报告指标，已成为该领域事实上的评估标准，几乎所有近期研究都在此基准上报告性能。然而，当前的 LIBERO 训练-评估设置存在严重缺陷：评估任务与训练任务几乎完全相同，唯一的区别是物体初始状态的微小扰动（人眼几乎无法察觉）。这导致模型只需死记硬背训练集中的动作序列和环境布局，就能在评估中获得超过90%的高成功率，但这种高分反映的是机械记忆，而非真正的任务理解或环境感知能力。</p>
<p>本文针对当前评估协议高估模型真实能力、阻碍公平比较和误导研究方向的关键痛点，提出了一个全新的视角：通过系统性地引入合理扰动来检验模型的泛化与理解能力，而非记忆能力。本文的核心思路是扩展 LIBERO 基准，提出 LIBERO-PRO，在操作对象、初始状态、任务指令和环境四个维度上引入精心设计的扰动，构建一个更全面、更合理的评估套件，以暴露并量化现有模型对记忆的依赖。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的方法是一个基于扰动的评估框架，而非一个新的VLA模型。其整体目标是对给定的原始VLA任务 τ = (ℓ, 𝒪, ℰ, p0, G) 施加可控扰动，生成一系列新的评估任务 τ(k)，以测试策略 πθ(a|s,ℓ) 的鲁棒性。</p>
<p><img src="https://arxiv.org/html/2510.03827v1/x3.png" alt="方法框架"></p>
<blockquote>
<p><strong>图3</strong>：LIBERO-PRO基准任务概览。我们在LIBERO原有的四个任务类别基础上，引入了物体属性扰动、初始位置扰动、指令扰动和环境扰动。</p>
</blockquote>
<p>该框架的核心是四个正交维度的扰动算子 ϕk，k ∈ {O, I, L, E}：</p>
<ol>
<li>**物体属性扰动 (k=O)**：修改物体的非本质属性（如颜色、纹理、大小），同时保持语义等价（例如将红色杯子改为蓝色杯子）。旨在测试模型对表面视觉变化的鲁棒性。扰动后任务为：τ(O) = (ℓ, 𝒪(O), ℰ, p0, G)。</li>
<li>**初始位置扰动 (k=I)**：改变物体的初始位置，修改其绝对和相对布局，同时保证物理合理性（例如移动杯子相对于盘子的位置）。旨在探究模型在不同布局下的空间推理能力。扰动后任务为：τ(I) = (ℓ, 𝒪, ℰ, p0(I), G)。</li>
<li>**指令扰动 (k=L)**：在语义和任务两个层面进行扰动。<ul>
<li><strong>语义扰动</strong>：调整语言表达但保持原任务意图（例如将“pick up the bottle”改述为“grab the bottle”）。评估智能体对语言和语义的理解。扰动后任务为：τ(L) = (ℓ(L), 𝒪, ℰ, p0, G)。</li>
<li><strong>任务扰动</strong>：合理地修改任务本身，例如替换目标物体或改变动作（例如将“pick up the bottle”改为“pick up the bowl”）。为确保评估公平，所有新引入的动作和物体均出现在训练集中。扰动后任务为：τ(L) = (ℓ(L), 𝒪(L), ℰ, p0, G(L))。</li>
</ul>
</li>
<li>**环境扰动 (k=E)**：修改背景外观（例如更换工作空间），而不影响任务可行性，以评估模型对环境变化的鲁棒性。扰动后任务为：τ(E) = (ℓ, 𝒪, ℰ(E), p0, G)。</li>
</ol>
<p>为确保每个扰动任务 τ(k) 语义有效，框架施加了两大约束：首先，扰动被限制在维度特定的邻域内，由 δk 控制扰动幅度；其次，要求扰动后任务与原始任务在分布上存在实质性偏差（dTV(τ, τ(k)) &gt; ε），以避免无意义的微小变动。</p>
<p>基于此框架，本文构建了 <strong>LIBERO-PRO</strong> 基准。这是一个即插即用的评估基准，支持对上述四个维度（物体、位置、指令、环境）及其任意组合进行系统评估。具体实现上，为物体变化创建了新资源，为位置变化定义了替代空间区域，为指令变化提供了三种不同的改述版本，为任务变化重新设计了任务，并利用LIBERO内置的五类环境进行随机替换。为避免无意义组合，限制任务级扰动不与其他类型组合，而其他维度的扰动可自由随机组合，以实现更全面的评估。</p>
<p>与现有方法相比，本文的创新点在于首次系统性地提出了一个多维度、可组合的扰动评估框架，将评估重点从“记忆再现”转向“泛化理解”，旨在提供更忠实、更公平的模型能力衡量标准。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在提出的 LIBERO-PRO 基准上进行，该基准从物体属性、初始位置、任务指令（涵盖语义和结构变化）和环境四个视角施加受控扰动。评估了三个代表性模型：OpenVLA、pi0 和 pi0.5。为公平起见，OpenVLA 使用在四个不同 LIBERO 套件上训练的官方检查点进行评估，而 pi0 和 pi0.5 使用单个官方检查点。每个任务的评估 episode 数设置为 50，与原始 LIBERO 协议一致。</p>
<p><img src="https://arxiv.org/html/2510.03827v1/x1.png" alt="轨迹一致性"></p>
<blockquote>
<p><strong>图1</strong>：在物体和指令修改下的模型轨迹一致性。“原始任务”表示标准评估，而“替换”、“改变位置”、“移除”和“混乱指令”则对目标物体或指令引入扰动。在所有设置下，模型产生几乎相同的轨迹，表明其缺乏真正的任务理解和环境感知。</p>
</blockquote>
<p>主要实验结果总结如下：</p>
<ol>
<li><strong>在简单扰动下失败</strong>：尽管在标准 LIBERO 基准上成功率超过90%，模型在物体位置变化或轻微任务修改下性能近乎崩溃至0%，即使这些新任务由训练集中出现的组件构成。</li>
<li><strong>虚假的鲁棒性</strong>：模型对物体和指令扰动表现出的表面稳定性，主要是由于过拟合而非真正的任务理解。如图1所示，即使目标物体被替换、移除或指令被破坏，模型仍输出几乎相同的轨迹。</li>
<li><strong>模型特定的敏感度</strong>：环境扰动对不同模型的影响不同，取决于环境差异程度和对记忆上下文的依赖。</li>
<li><strong>被掩盖的能力差异</strong>：虽然大多数模型在扰动下失败，但 pi0.5 在 <code>libero-goal</code> 任务的位置变化下取得了 0.38 的成功率，而 OpenVLA 和 pi0 为 0，这揭示了被标准基准分数掩盖的差异。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.03827v1/x2.png" alt="位置扰动下的成功率"></p>
<blockquote>
<p><strong>图2</strong>：OpenVLA、pi0、pi0.5 和 univla 在物体位置扰动下的成功率。在标准评估中表现出色的模型，在物体初始位置发生微小变化时，成功率急剧下降至接近零。</p>
</blockquote>
<p>关键定量结果体现在四个子基准的详细表格中（论文中表2-表5）：</p>
<ul>
<li><strong>libero-goal（表2）</strong>：OpenVLA、pi0、pi0.5在原始任务上的平均成功率分别为0.98, 0.92, 0.97。在位置扰动下，OpenVLA和pi0平均成功率降至0.00，pi0.5降至0.38。在任务级指令扰动下，所有模型成功率均为0.00。</li>
<li><strong>libero-spatial（表3）</strong>：三模型原始成功率分别为0.98, 0.97, 0.98。位置扰动下，平均成功率分别降至0.00, 0.00, 0.20。</li>
<li><strong>libero-10（表4）</strong>：原始成功率分别为0.93, 0.82, 0.93。位置扰动下，平均成功率降至0.00, 0.00, 0.08。</li>
<li><strong>libero-object（表5）</strong>：原始成功率分别为0.99, 0.99, 0.98。位置扰动下，平均成功率降至0.00, 0.02, 0.15。</li>
</ul>
<p>这些结果一致表明，当前在标准LIBERO上表现出色的VLA模型，缺乏真正的鲁棒性和泛化能力。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：</p>
<ol>
<li><strong>揭示了当前评估协议的缺陷</strong>：通过大量实验，证明了当前广泛使用的LIBERO评估协议存在根本性缺陷，其报告的高分主要反映的是对训练数据的机械记忆，而非真正的任务理解或执行能力。</li>
<li><strong>提出了新的评估基准</strong>：引入了LIBERO-PRO，一个即插即用的基准，它包含了在操作对象、初始状态、任务指令和环境四个维度上精心设计的扰动，并支持这些维度的随机组合，以实现更忠实的评估。</li>
<li><strong>量化了现有模型的脆弱性</strong>：在LIBERO-PRO上对包括OpenVLA、pi0和pi0.5在内的先进模型进行了基准测试，结果显示它们性能低下，从而凸显了当前LIBERO协议的不足，并呼吁将LIBERO-PRO作为更公平、更可靠的评估标准。</li>
</ol>
<p>论文自身提到的一个局限性是，为避免无意义组合，任务级扰动不与其他类型的扰动进行组合。这在一定程度上限制了评估的复杂性，但确保了评估任务的可执行性和逻辑一致性。</p>
<p>本文对后续研究的重要启示在于：它强烈呼吁社区放弃可能产生误导的评估方法，转向采用能够系统检验模型泛化与理解能力的鲁棒评估标准。研究重点应从单纯追求在静态基准上刷高分，转向开发能够适应合理且必要的现实世界扰动的、真正鲁棒的VLA系统。LIBERO-PRO的提出为这一方向的公平比较和持续进步提供了必要的工具。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对LIBERO基准测试评估视觉-语言-动作（VLA）模型时存在的缺陷，即模型可能通过记忆训练集中的动作序列和环境布局获得高准确率，而非真正理解任务，导致性能估计过高和公平比较受阻。为此，作者提出LIBERO-PRO扩展基准，通过在操纵对象、初始状态、任务指令和环境四个维度引入系统扰动，以评估模型的鲁棒性和泛化能力。实验结果显示，现有模型在标准LIBERO下准确率超过90%，但在LIBERO-PRO的广义设置下性能崩溃至0.0%，例如目标对象被替换时模型仍执行抓取动作，指令破坏时输出不变，这揭示了模型严重依赖记忆而非理解的根本问题。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.03827" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>