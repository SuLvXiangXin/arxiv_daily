<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.07865" target="_blank" rel="noreferrer">2510.07865</a></span>
        <span>作者: Weibing Li Team</span>
        <span>日期: 2025-10-09</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人操作要求控制策略能够捕捉和利用多模态动作分布，同时满足实时控制约束。基于生成模型（如扩散模型和流模型）的控制器在此背景下受到关注。扩散策略具有强大的表达能力，但每个控制步骤需要50-100次神经网络前向传播，无法满足实时需求。基于流的策略（如FlowPolicy, ReinFlow）减少了采样步数，但仍需20-100步，存在计算开销。为了追求一步生成，MeanFlow等方法通过直接预测动作轨迹的平均速度场，实现了单步推理。然而，这种计算效率带来了一个关键代价：其严格的数学约束导致不同的观测被映射到过度相似的嵌入中，即“表示坍塌”问题。这限制了模型捕捉多样化多模态行为的能力，尤其不利于需要区分细微变化的精细操作任务（例如抓取不同方向的物体）。</p>
<p>本文针对一步流模型（如MeanFlow）中存在的表示坍塌问题，提出了将“分散正则化”集成到训练过程中的新视角。其核心思路是：在训练过程中，对网络多个中间嵌入层的特征施加正则化，强制同一批次内的特征在潜在空间中保持足够的距离，从而从源头防止表示坍塌，同时不引入额外的网络模块或牺牲一步生成的高效性。</p>
<h2 id="方法详解">方法详解</h2>
<p>DM1框架将MeanFlow的一步生成能力与分散正则化相结合，其整体架构如下图所示。</p>
<p><img src="https://arxiv.org/html/2510.07865v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：DM1框架架构。左上：一步动作生成，展示了MeanFlow通过平均速度场直接生成轨迹的核心原理；左下：视觉Transformer编码器，处理输入图像；右上：分散损失组件，应用于不同模态的嵌入以鼓励特征分离；右下：完整的DM1计算流程，整合视觉输入、状态输入和时间条件，并施加分散损失和MeanFlow损失。</p>
</blockquote>
<p>整体流程的输入是视觉观测、本体感知状态和噪声，输出是预测的动作轨迹。框架包含四个关键组件：</p>
<ol>
<li><strong>一步动作生成</strong>：基于MeanFlow，通过学习的平均速度场将高斯噪声直接转换为目标动作轨迹，避免了迭代去噪过程，实现了单步高质量动作合成。</li>
<li><strong>视觉Transformer编码器</strong>：使用基于patch的ViT架构处理视觉观测，提取全局视觉特征作为流匹配模型的条件输入。</li>
<li><strong>分散损失模块</strong>：这是防止表示坍塌的核心贡献。分散正则化被应用于多个嵌入层，包括噪声嵌入 $\mathbf{H}^{(R)}$、时间嵌入 $\mathbf{H}^{(T)}$ 和条件嵌入 $\mathbf{H}^{(\text{Cond})}$，以强制表征多样性。</li>
<li><strong>完整架构</strong>：整合了视觉编码器输出、本体状态输入和时间嵌入。系统使用MeanFlow损失进行速度场学习，并使用分散损失进行正则化。</li>
</ol>
<p><strong>核心技术细节</strong>：</p>
<ul>
<li><strong>MeanFlow训练目标</strong>：遵循整流流公式，采用线性插值 $z_t = (1-t)\epsilon + ta$，其中 $\epsilon$ 是噪声，$a$ 是目标动作。平均速度场定义为 $u(z_t, r, t) = \frac{1}{t-r}\int_{r}^{t}v(z_{\tau},\tau)d\tau$。最终的训练损失 $\mathcal{L}<em>{\text{MF}}$ 是网络预测的平均速度 $u</em>{\theta}(z_t, r, t, o_t)$ 与目标 $u_{\text{tgt}}$ 之间的均方误差，其中 $u_{\text{tgt}}$ 包含了速度场及其对时间和状态的导数项。</li>
<li><strong>分散正则化</strong>：为防止表示坍塌，对中间特征 $\mathbf{H} = {\mathbf{h}_1, ..., \mathbf{h}_B} \subset \mathbb{R}^d$ 施加正则化。论文系统评估了四种变体：<ul>
<li><strong>InfoNCE-L2</strong>：基于InfoNCE损失，最大化特征间的欧氏距离。</li>
<li><strong>InfoNCE-Cosine</strong>：最大化特征方向之间的角度多样性。</li>
<li><strong>Hinge Loss</strong>：强制特征间距离大于一个最小边界值 $\delta$。</li>
<li><strong>Covariance-Based</strong>：鼓励特征维度间去相关，并维持方差。</li>
</ul>
</li>
<li><strong>总损失函数</strong>：结合了MeanFlow损失和多层分散正则化损失：$\mathcal{L}<em>{\text{total}} = \mathcal{L}</em>{\text{MF}} + \alpha_{\text{disp}} [\mathcal{L}<em>{\text{disp}}(\mathbf{H}^{(T)}) + \mathcal{L}</em>{\text{disp}}(\mathbf{H}^{(R)}) + \mathcal{L}<em>{\text{disp}}(\mathbf{H}^{(\text{Cond})})]$，其中 $\alpha</em>{\text{disp}}$ 是平衡系数。</li>
</ul>
<p><strong>创新点</strong>：与现有方法相比，DM1的创新性在于首次将分散正则化系统性地集成到MeanFlow框架中，用于解决基于视觉的机器人操作中的表示坍塌问题。该方法无需修改网络架构，仅通过在训练目标中增加对多个中间嵌入层的正则化项，即可在保持一步生成效率的同时，显著提升模型的表达能力和任务性能。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在RoboMimic基准的四个操作任务上进行：Lift（基础抓取）、Can、Square和Transport（复杂多阶段序列）。实验平台为MuJoCo仿真，使用NVIDIA RTX 4090 GPU。对比的基线方法包括：ReFlow (RF，128步)、ShortCut Flow (SC，32步)、它们的分散正则化变体 (SC-L2, SC-Cos, SC-H, SC-Cov) 以及原始MeanFlow (MF)。</p>
<p><img src="https://arxiv.org/html/2510.07865v1/x3.png" alt="成功率与去噪步数关系"></p>
<blockquote>
<p><strong>图3</strong>：不同去噪步数下各方法的成功率。结果表明，基于MeanFlow的方法（MF, MF+Disp）仅需5步即可达到与基线方法（需32-128步）相当或更优的性能，实现了6-25倍的推理步数缩减。在复杂任务（如Transport）上，MF+Disp相比MF有显著提升。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.07865v1/x4.png" alt="成功率与推理频率权衡"></p>
<blockquote>
<p><strong>图4</strong>：各方法在成功率与推理时间上的权衡散点图。DM1（MF+Disp）始终位于左上区域（高成功率、低耗时），推理时间仅需0.07–0.09秒，相比基线方法（0.6–3.5秒）实现了20–40倍的加速，同时在多数任务上获得了10–20个百分点的成功率提升。</p>
</blockquote>
<p><strong>关键实验结果总结</strong>：</p>
<ol>
<li><strong>效率与性能</strong>：DM1在保持高成功率的同时，实现了极快的推理速度。例如，在Can任务上，MF+Disp以0.07秒达到75–80%成功率，而基线方法需要2-3秒才达到60–70%成功率。在Transport任务上，MF+Disp以0.07秒达到40–50%成功率，而基线方法在2-3秒内仅能达到20–25%成功率。</li>
<li><strong>分散正则化的效果</strong>：消融实验表明，添加分散正则化（MF+Disp）相比原始MeanFlow (MF) 能带来一致性的性能提升，尤其在复杂任务上效果显著。例如，在Transport任务上，MF+Disp相比MF有10–20个百分点的成功率提升。</li>
<li><strong>不同正则化变体比较</strong>：根据论文中的奖励分析表（表1），不同分散正则化变体在不同任务和权重下的表现各有优劣，但整体上，集成分散正则化的DM1框架在1步和5步去噪设置下，奖励值和成功率均优于或与基线方法相当，证明了该策略的有效性。</li>
<li><strong>最优配置结果</strong>：在最优步数配置下（表2），DM1（MF+Disp）在几乎所有任务和权重设置下都取得了最高的成功率。例如，在 $\alpha_{\text{disp}}=0.1$ 时，Lift任务成功率高达97%，远超RF的78.5%和SC的84%；Transport任务成功率达到53%，显著高于RF的39%和SC的34%。</li>
<li><strong>真实世界部署</strong>：物理实验在Franka-Emika-Panda机器人上进行，验证了DM1能够从仿真有效迁移到现实世界，并实现超过50Hz的控制频率，满足实时控制需求。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：</p>
<ol>
<li><strong>打破速度-准确性权衡</strong>：提出DM1，首次将分散正则化与MeanFlow结合，在保持一步生成（0.07秒）超高效率的同时，显著提升了模型在复杂操作任务上的成功率（提升10-20个百分点）。</li>
<li><strong>解决表示坍塌问题</strong>：提出了一种无需改变网络架构的解决方案，通过在多个中间嵌入层施加分散正则化，从源头有效防止了一步流模型中的特征崩溃问题。</li>
<li><strong>系统评估与验证</strong>：对四种分散正则化变体进行了详细评估，并完成了从仿真基准到真实机器人部署的全面验证，证明了方法的有效性和实用性。</li>
</ol>
<p><strong>局限性</strong>：论文自身未明确阐述局限性，但根据方法描述，分散正则化引入了额外的超参数（如权重 $\alpha_{\text{disp}}$ 和各变体的内部参数），可能需要针对不同任务进行调整。此外，虽然防止了坍塌，但一步生成模型的理论表达能力上限可能仍低于多步扩散模型。</p>
<p><strong>启示</strong>：本工作表明，通过精心设计的正则化策略，可以显著改善高效生成模型（如一步流）的表示能力。这为后续研究提供了启示：在追求推理效率的同时，应关注模型内部表示的质量，而分散正则化是一种简单有效的工具。未来工作可以探索更高效或自适应的正则化方法，并将此框架应用于更广泛的序列生成和决策任务中。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对流式策略在机器人操作中存在的“表示崩溃”问题，即无法区分相似视觉表示导致精确操作失败，提出DM1框架。该方法在MeanFlow中集成分散正则化，通过在多个中间嵌入层施加正则化变体，防止表示崩溃，同时保持一步生成的高效性。实验表明，DM1在RoboMimic基准上实现了20-40倍的推理加速（0.07s vs. 2–3.5s），并将任务成功率提升10-20个百分点，其中Lift任务达到99%成功率（基线85%），并成功从仿真迁移到真实机器人。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.07865" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>