<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Learning Dexterous Manipulation with Quantized Hand State - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Learning Dexterous Manipulation with Quantized Hand State</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.17450" target="_blank" rel="noreferrer">2509.17450</a></span>
        <span>作者: Cewu Lu Team</span>
        <span>日期: 2025-09-22</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>灵巧机械手使机器人能够执行需要精细控制和适应性的复杂操作。然而，实现此类操作具有挑战性，因为高自由度（DoF）使手部和手臂运动紧密耦合，导致学习和控制困难。成功的灵巧操作不仅依赖于精确的手部运动，还依赖于手臂的精确空间定位以及协调的手臂-手部动力学。</p>
<p>目前，大多数现有的视觉运动策略将手臂和手部动作在一个单一的联合动作空间中表示。这种方法的局限性在于，高维度的手部动作往往会主导这个耦合的动作空间，从而损害手臂控制的精确性，导致学习不平衡。</p>
<p>本文针对上述“手部动作主导联合动作空间，损害手臂定位精度”的具体痛点，提出了新的视角：将手臂和手部的功能进行区分——机器人手臂主要负责空间定位，而灵巧手则负责执行细粒度的动作模式。因此，视觉运动策略应专注于手臂的空间定位，同时记忆灵巧手的动作模式。</p>
<p>本文的核心思路是：将手部状态量化为紧凑的、任务相关的模式，从而简化手部动作预测；同时，引入连续松弛过程，使手臂动作能够与这些量化后的手部状态联合扩散，从而在保持手臂-手部协调性的同时，防止手部动作淹没动作空间。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的方法DQ-RISE，是对基础视觉运动策略RISE的扩展，旨在为灵巧操作引入结构化的动作预测。整体流程分为四个主要步骤：1）使用演示数据训练残差VQ-VAE对手部状态进行量化；2）对量化得到的离散手部状态码进行重新索引，实现连续松弛；3）用重新索引后的状态替换原始演示数据集中的手部动作；4）在转换后的数据集上训练视觉运动策略，使其能够联合预测手臂动作和连续化的手部状态索引。</p>
<p><img src="https://arxiv.org/html/2509.17450v1/x3.png" alt="方法框架"></p>
<blockquote>
<p><strong>图3</strong>：DQ-RISE策略架构。① 使用演示中的手部状态数据训练残差VQ-VAE进行手部状态量化；② 训练后的码本产生K个量化手部状态，对其进行重新索引以保持代码间的连续性和顺序一致性；③ 用这些重新索引后的状态替换演示数据集中的原始手部状态/动作；④ 在转换后的数据集上训练视觉运动策略，联合扩散手臂和手部动作；推理时，将预测的连续手部动作投影到最近的量化动作上执行。</p>
</blockquote>
<p><strong>核心模块一：手部状态量化</strong><br>作者认为，不应量化联合的手臂-手部动作块，而应仅量化单步的手部动作（即手部状态）。原因在于：1）手臂和手部功能不同，手臂负责定位，手部负责交互，量化手部动作更自然；2）量化手部动作块会直接编码时间运动模式，导致码本迅速膨胀，且与手臂动作块的扩散生成方式不匹配，可能破坏协调性。具体实现是，从演示数据集𝒟中提取手部状态𝑠(ℎ)，训练一个两层残差VQ-VAE将其离散化。损失函数采用标准VQ-VAE损失，包括重建损失、承诺损失和码本使用损失。</p>
<p><strong>核心模块二：连续松弛</strong><br>将手部状态量化后，一个直接的想法是将手部动作预测视为分类问题。但这会导致手臂和手部动作生成解耦，可能引发动作不匹配。受夹爪控制（仅关注开/合，但策略预测连续值）的启发，作者提出对离散手部状态进行连续松弛。具体做法是：对原始的6自由度手部状态应用主成分分析（PCA），并投影到第一主成分上，得到一个一维表示。然后，沿着这个轴对量化手部状态进行顺序重新索引。这确保了重新索引序列中相邻的状态对应于原始手部状态空间中相似的手部配置，从而产生了手势的连贯顺序，使得离散状态能够以连续的方式被预测并融入扩散过程。</p>
<p><strong>核心模块三：策略学习</strong><br>完成重新索引后，将数据集中的每个手部动作𝑎(ℎ)重新标记为其对应的量化、有序索引𝑧(ℎ)。随后，使用观测𝑜𝑖作为输入，以未来一段时间的拼接手臂动作和重新索引的手部动作{ (𝑠𝑖+𝑘(𝑎), 𝑧𝑖+𝑘(ℎ)) }𝑘=1𝐶作为输出，来训练基础视觉运动策略（采用RISE）。在推理时，将预测的连续手部动作索引𝑧̂ (ℎ)映射到其最接近的量化代码idx，并检索对应的手部状态𝑠idx(ℎ)来执行。</p>
<p><img src="https://arxiv.org/html/2509.17450v1/x4.png" alt="不同预测框架"></p>
<blockquote>
<p><strong>图4</strong>：不同的动作预测框架。本文选择RISE（联合预测）、RISE-S（分离扩散）、DQ-RISE-C（扩散+分类）作为基线，并与本文的DQ-RISE（联合扩散量化状态）进行比较。</p>
</blockquote>
<p><strong>创新点</strong></p>
<ol>
<li><strong>目标创新</strong>：仅量化手部状态，而非手臂-手部联合动作或手部动作块，明确了手臂定位、手部执行模式的功能划分。</li>
<li><strong>过程创新</strong>：通过PCA和重新索引，对离散手部状态进行连续松弛，使其能够与手臂动作在同一个扩散过程中联合生成，保持了协调性，避免了分类目标带来的梯度不一致问题。</li>
<li><strong>系统创新</strong>：设计了一套VR手柄-数据手套混合的灵巧遥操作系统，支持手臂运动暂停和重定位，便于数据收集。</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>任务</strong>：设计了6个真实世界任务进行评估，涵盖拾取放置、关节物体操作、需要大旋转的任务和长视野任务（见图5）。</li>
<li><strong>基线方法</strong>：RISE（基础策略，联合预测）、RISE-S（手臂和手部分离扩散）、DQ-RISE-C（扩散手臂动作，分类手部量化动作）。</li>
<li><strong>平台与数据</strong>：使用Flexiv机械臂和ROHand灵巧手。每个任务收集50条遥操作演示用于训练。每个策略在每个任务上进行20次试验评估。</li>
</ul>
<p><img src="https://arxiv.org/html/2509.17450v1/x5.png" alt="任务描述"></p>
<blockquote>
<p><strong>图5</strong>：任务描述。评估了六个任务，包括拾取放置、关节物体操作、需要大旋转的任务和一个长视野任务。蓝色高亮阶段用于成功率评估。</p>
</blockquote>
<p><strong>关键实验结果</strong>：<br>DQ-RISE在各项任务上均取得了最高的成功率，平均成功率达到85.83%，显著优于其他基线（见表1）。特别是在需要紧密手臂-手部协调的任务（如Open Jar）和长视野复杂任务（Toast Bread）上表现出色。这验证了量化手部状态能使策略更专注于挑战性的手臂定位问题，同时记忆的手部模式足以完成复杂操作。</p>
<table>
<thead>
<tr>
<th align="left">Policy</th>
<th align="left">Pull Tissue</th>
<th align="left">Open Jar</th>
<th align="left">Collect Toy</th>
<th align="left">Pour Rice</th>
<th align="left">Open Oven</th>
<th align="left">Toast Bread</th>
<th align="left">Avg.</th>
</tr>
</thead>
<tbody><tr>
<td align="left">RISE</td>
<td align="left">55.00%</td>
<td align="left">55.00%</td>
<td align="left">75.00%</td>
<td align="left">85.00%</td>
<td align="left">87.50%</td>
<td align="left">0.00%</td>
<td align="left">55.00%</td>
</tr>
<tr>
<td align="left">RISE-S</td>
<td align="left">61.67%</td>
<td align="left">45.00%</td>
<td align="left">82.50%</td>
<td align="left">90.00%</td>
<td align="left">95.00%</td>
<td align="left">20.00%</td>
<td align="left">61.67%</td>
</tr>
<tr>
<td align="left">DQ-RISE-C</td>
<td align="left">2.50%</td>
<td align="left">0.00%</td>
<td align="left">0.00%</td>
<td align="left">2.50%</td>
<td align="left">12.50%</td>
<td align="left">0.00%</td>
<td align="left">2.50%</td>
</tr>
<tr>
<td align="left"><strong>DQ-RISE (ours)</strong></td>
<td align="left"><strong>85.83%</strong></td>
<td align="left"><strong>90.00%</strong></td>
<td align="left"><strong>92.50%</strong></td>
<td align="left"><strong>100%</strong></td>
<td align="left"><strong>100%</strong></td>
<td align="left"><strong>60.00%</strong></td>
<td align="left"><strong>85.83%</strong></td>
</tr>
</tbody></table>
<blockquote>
<p><strong>表1</strong>：评估结果。DQ-RISE在所有任务上均优于其他动作预测变体，并能有效完成各种灵巧操作任务。</p>
</blockquote>
<p><strong>消融实验分析</strong>：</p>
<ol>
<li><strong>连续松弛的必要性（图6B）</strong>：在Open Jar任务中，移除重新索引（即不进行连续松弛）会导致策略性能大幅下降。这表明连续松弛对于实现稳定学习和协调手臂-手部动作至关重要，它使相邻代码索引对应相似的手部状态，提高了策略的容错性和鲁棒性。</li>
<li><strong>DQ-RISE-C失败原因（图6A）</strong>：实验表明，DQ-RISE-C性能极差。作者排除了手臂动作条件导致分布偏移的原因。主要归因于手臂扩散头和手部分类头之间的梯度流不一致，阻碍了有效的联合优化，这与多任务学习中分类和回归目标相互干扰的观察一致。</li>
<li><strong>量化状态的可解释性（图7）</strong>：通过UMAP可视化显示，经过重新索引后，相邻的代码索引确实对应着平滑变化的手部姿势，代码间的过渡是连续且可解释的，这支持了联合扩散的可行性。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.17450v1/x6.png" alt="消融实验"></p>
<blockquote>
<p><strong>图6</strong>：(A) DQ-RISE-C中手臂条件化的消融。无论是否在分类时应用手臂条件化，策略表现相似。(B) DQ-RISE中连续松弛的消融。进行连续松弛（即重新索引）能显著提升性能。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.17450v1/x7.png" alt="量化状态可视化"></p>
<blockquote>
<p><strong>图7</strong>：重新索引后的量化手部状态。手部状态通过UMAP投影为3D点，注释了对应手部姿势。重新索引使代码转换在手部状态空间中连续且可解释。</p>
</blockquote>
<p><strong>用户研究</strong>：<br>对比耦合控制、离散手势控制和无暂停机制的变体，本文的VR-手套混合遥操作系统在完成Open Jar任务时取得了最高的成功率（6/6）和最短的平均完成时间，被用户评为最直观和方便的控制方式。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>提出了手部状态量化与连续松弛的框架</strong>：明确区分手臂（定位）和手部（模式）的功能，通过量化手部状态简化学习，并通过连续松弛将其融入扩散过程，实现了高效且协调的手臂-手部动作生成。</li>
<li><strong>设计了混合灵巧遥操作系统</strong>：结合VR手柄和数据手套，并引入暂停机制，为单臂灵巧操作提供了直观的数据收集接口。</li>
<li><strong>通过详实实验验证了有效性</strong>：在多个真实世界灵巧任务上，DQ-RISE显著优于现有动作预测方案，证明了结构化动作预测的优势。</li>
</ol>
<p><strong>局限性</strong>：<br>论文提到，量化过程可能会损失手部动作的一些细微变化。虽然对于许多任务来说记忆的模式已经足够，但这可能限制需要极其精细、连续手部控制的操作。</p>
<p><strong>启示</strong>：<br>本文的工作为灵巧操作提供了一种新的结构化动作预测范式。将高维、连续的控制问题分解为定位（连续）和模式选择（离散/连续化）的子问题，这种思想可能推广到其他需要精细协调的多自由度机器人控制领域。同时，在策略训练阶段而非数据收集阶段进行自动量化，减轻了操作员负担并保留了演示的自然性，这对基于模仿学习的系统设计具有启发意义。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对灵巧操作中手臂与手部动作在高维耦合空间内学习不平衡的问题，提出 DQ-RISE 方法。其核心是将手部状态量化以简化预测并保留关键模式，同时应用连续松弛技术，使手臂动作能与量化后的紧凑手部状态联合优化。该方法旨在防止手部动作主导整个动作空间，从而促进策略学习协调的臂-手控制。实验表明，DQ-RISE 实现了更平衡、高效的学习。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.17450" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>