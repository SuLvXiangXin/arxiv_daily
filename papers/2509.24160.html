<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.24160" target="_blank" rel="noreferrer">2509.24160</a></span>
        <span>作者: Yang You Team</span>
        <span>日期: 2025-09-29</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，大型语言模型（LLM）在机器人操作领域得到广泛应用，能够生成人类可读的计划和可执行的控制代码片段。然而，现有方法在适应新环境方面存在显著局限。主流方法主要分为两类：一类需要针对特定环境进行策略训练，限制了方法的可移植性；另一类则依赖于固定的提示词或单次代码生成，当环境发生变化时，往往需要手动调整提示词以维持性能，导致适应性差且效率低下。</p>
<p>本文针对机器人操作代码在新环境中“一次性生成、难以复用”的痛点，提出了一个新颖的视角：将过往成功的、可执行的控制代码及其执行轨迹视为可重用的“程序性知识”，并将其作为上下文引导，来增强LLM驱动的规划过程。本文的核心思路是构建一个包含成功代码的记忆库，当初始计划失败时，系统能够从中检索相似的成功案例，并通过上下文感知的代码适应技术将其调整至目标环境，进而指导LLM进行重新规划，整个过程无需更新模型参数。</p>
<h2 id="方法详解">方法详解</h2>
<p>Memory Transfer Planning（MTP）框架旨在通过重用先前的执行记忆，跨任务和环境指导代码生成与重新规划。其整体流程包含三个核心组件：代码生成、记忆检索以及基于迁移记忆的重新规划。</p>
<p><img src="https://arxiv.org/html/2509.24160v1/figures/MTP_fig1_v2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：MTP方法整体框架。左侧展示了在源环境中成功生成的代码被存储到记忆库中。右侧展示了在目标环境中执行任务时，若初始代码失败，系统会从记忆库中检索高相似度的代码，经过适应转换后用于重新规划。</p>
</blockquote>
<p><strong>1. 代码生成</strong><br>该方法沿用并扩展了VoxPoser的代码生成流程，使用LLM生成可由解释器执行的Python代码。该流程分为三步：</p>
<ul>
<li><strong>规划器</strong>：将语言指令 <code>l</code> 分解为子任务指令序列 <code>(l1, l2..., ln)</code>。</li>
<li><strong>作曲器</strong>：针对每个子任务指令 <code>li</code>，调用相应的底层语言模型程序（LMP）。每个LMP负责特定功能，如解析查询对象、生成可操作图等。</li>
<li><strong>执行</strong>：执行这些LMP，与感知API交互，生成价值图（如可操作图、避障图），并最终合成机器人末端执行器的轨迹序列 <code>τl</code>。</li>
</ul>
<p><strong>2. 记忆构建与检索</strong><br>记忆模块专注于存储和检索<strong>规划器级别</strong>的代码，因为这部分代码更具多样性和灵活性。</p>
<ul>
<li><strong>记忆构建</strong>：仅存储成功执行的日志 <code>L</code>。每条日志包含环境 <code>E</code>、指令 <code>l</code> 和规划器代码 <code>c</code>。<br><img src="https://arxiv.org/html/2509.24160v1/figures/memory_adaptation.png" alt="记忆格式"><blockquote>
<p><strong>图2</strong>：存储在记忆中的成功任务示例格式，包含环境、查询指令和生成的代码。</p>
</blockquote>
</li>
<li><strong>记忆检索</strong>：当面对新任务指令 <code>l</code> 时，计算其与记忆中每条日志指令 <code>lj</code> 的文本嵌入余弦相似度 <code>cos_sim(l, lj)</code>。使用sentence-transformers生成嵌入向量，并检索相似度最高的前 <code>k</code> 个代码 <code>c1:k</code>。</li>
</ul>
<p><strong>3. 记忆适应与重新规划</strong><br>这是MTP的核心创新点，使检索到的代码能够有效应用于新环境。</p>
<ul>
<li><strong>记忆适应</strong>：检索到的源代码 <code>csrc</code> 可能包含源环境特有的初始化、坐标、尺度等信息。MTP利用目标环境的固定提示 <code>P_Etgt</code> 和少量目标环境代码示例，通过LLM将源代码转换成适应目标环境的代码 <code>c̃tgt</code>。<br><img src="https://arxiv.org/html/2509.24160v1/figures/replanning.png" alt="记忆适应过程"><blockquote>
<p><strong>图3</strong>：记忆适应过程。使用目标环境的代码示例（黄色块）作为参考提示，将源环境的代码（蓝色块）转换为适应后的代码（绿色块）。</p>
</blockquote>
</li>
<li><strong>重新规划</strong>：如果初始生成的代码 <code>c</code> 执行失败，系统将启动重新规划循环。新的规划提示结合了三部分信息：目标环境的示例、适应后的记忆代码 <code>c̃tgt</code> 以及之前失败的代码 <code>cfail</code>。LLM基于此上下文生成新的代码 <code>c_newtgt</code> 进行尝试。<br><img src="https://arxiv.org/html/2509.24160v1/figures/ur5_lidtask3.png" alt="重新规划提示"><blockquote>
<p><strong>图4</strong>：用于重新规划的提示结构，包含目标环境示例（黄）、适应后的记忆代码（蓝）和失败代码（红）。</p>
</blockquote>
</li>
</ul>
<p>与现有方法相比，MTP的创新性体现在：1）将成功代码视为可迁移的程序性知识并构建记忆库；2）设计了上下文感知的代码适应机制，而非简单地拼接检索结果；3）形成了“生成-失败-检索-适应-再生成”的闭环优化流程，无需模型微调即可实现跨环境知识迁移。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>本文在RLBench、CALVIN两个模拟基准以及UR5真实机器人平台上评估了MTP的有效性。实验使用GPT-4.1-mini作为LLM。</p>
<p><strong>1. 对比方法</strong></p>
<ul>
<li><strong>基线</strong>：VoxPoser（单次代码生成）。</li>
<li><strong>重新规划基线</strong>：Retry（失败后原代码重试）、Self-reflection（基于环境观察生成新计划）。</li>
<li><strong>模仿学习基线</strong>：CALVIN环境中的MCIL。</li>
</ul>
<p><strong>2. 关键实验结果</strong></p>
<ul>
<li><strong>RLBench</strong>：在9个任务上，MTP取得了64.4%的平均成功率，显著高于VoxPoser（39.3%）、Retry（55.6%）和Self-reflection（60.7%）。特别是在Button和Drawer等任务上优势明显。<table>
<thead>
<tr>
<th align="left">Method</th>
<th align="left">BballHoop</th>
<th align="left">Buzz</th>
<th align="left">Drawer</th>
<th align="left">LampOff</th>
<th align="left">Bottle</th>
<th align="left">Button</th>
<th align="left">TrashBin</th>
<th align="left">LidOff</th>
<th align="left">Umbrella</th>
<th align="left">mean ± std</th>
</tr>
</thead>
<tbody><tr>
<td align="left">VoxPoser</td>
<td align="left">20.0</td>
<td align="left">20.0</td>
<td align="left">13.3</td>
<td align="left">60.0</td>
<td align="left">40.0</td>
<td align="left">0.0</td>
<td align="left">93.3</td>
<td align="left">33.3</td>
<td align="left">73.3</td>
<td align="left">39.3 ± 3.4</td>
</tr>
<tr>
<td align="left">Retry</td>
<td align="left">40.0</td>
<td align="left">26.7</td>
<td align="left">53.3</td>
<td align="left">66.7</td>
<td align="left">93.3</td>
<td align="left">0.0</td>
<td align="left">93.3</td>
<td align="left">40.0</td>
<td align="left">86.7</td>
<td align="left">55.6 ± 6.7</td>
</tr>
<tr>
<td align="left">Self-reflection</td>
<td align="left">26.7</td>
<td align="left">20.0</td>
<td align="left">80.0</td>
<td align="left">73.3</td>
<td align="left">86.7</td>
<td align="left">33.3</td>
<td align="left">100.0</td>
<td align="left">33.3</td>
<td align="left">93.3</td>
<td align="left">60.7 ± 5.6</td>
</tr>
<tr>
<td align="left"><strong>MTP(Ours)</strong></td>
<td align="left"><strong>13.3</strong></td>
<td align="left"><strong>33.3</strong></td>
<td align="left"><strong>86.7</strong></td>
<td align="left"><strong>60.0</strong></td>
<td align="left"><strong>100.0</strong></td>
<td align="left"><strong>73.3</strong></td>
<td align="left"><strong>100.0</strong></td>
<td align="left"><strong>33.3</strong></td>
<td align="left"><strong>80.0</strong></td>
<td align="left"><strong>64.4 ± 2.2</strong></td>
</tr>
</tbody></table>
</li>
</ul>
<blockquote>
<p><strong>表1</strong>：RLBench上的成功率(%)。MTP在总体成功率上表现最佳。</p>
</blockquote>
<ul>
<li><strong>CALVIN</strong>：在50个单任务上，使用原始指令时，MTP成功率为67.3%，优于Retry（59.3%）和Self-reflection（62.7%）。当使用LLM生成的转述指令增加复杂性时，MTP（59.3%）的鲁棒性依然优于其他方法。<table>
<thead>
<tr>
<th align="left">Method</th>
<th align="left">Single Instruction</th>
<th align="left">Paraphrased Instructions</th>
</tr>
</thead>
<tbody><tr>
<td align="left">MCIL</td>
<td align="left">32.0</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">VoxPoser</td>
<td align="left">52.0 ± 2.0</td>
<td align="left">47.3 ± 2.3</td>
</tr>
<tr>
<td align="left">Retry</td>
<td align="left">59.3 ± 1.2</td>
<td align="left">53.3 ± 2.3</td>
</tr>
<tr>
<td align="left">Self-reflection</td>
<td align="left">62.7 ± 1.2</td>
<td align="left">56.0 ± 5.3</td>
</tr>
<tr>
<td align="left"><strong>MTP(Ours)</strong></td>
<td align="left"><strong>67.3 ± 3.1</strong></td>
<td align="left"><strong>59.3 ± 3.1</strong></td>
</tr>
</tbody></table>
</li>
</ul>
<blockquote>
<p><strong>表2</strong>：CALVIN上的成功率(%)。MTP在原始指令和转述指令评估中均保持领先。</p>
</blockquote>
<ul>
<li><strong>真实机器人</strong>：在UR5机器人上执行4个任务，MTP取得了75%的整体成功率，远高于VoxPoser的30%。具体任务成功率见下表。<table>
<thead>
<tr>
<th align="left">Tasks</th>
<th align="left">VoxPoser</th>
<th align="left">MTP</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Rotate box</td>
<td align="left">0/5</td>
<td align="left">5/5</td>
</tr>
<tr>
<td align="left">Move object</td>
<td align="left">1/5</td>
<td align="left">3/5</td>
</tr>
<tr>
<td align="left">Remove lid</td>
<td align="left">3/5</td>
<td align="left">4/5</td>
</tr>
<tr>
<td align="left">Push button</td>
<td align="left">0/5</td>
<td align="left">2/5</td>
</tr>
<tr>
<td align="left"><strong>Overall Success Rate</strong></td>
<td align="left"><strong>30%</strong></td>
<td align="left"><strong>75%</strong></td>
</tr>
</tbody></table>
</li>
</ul>
<blockquote>
<p><strong>表4</strong>：UR5真实机器人上的任务成功率（5次尝试中的成功次数）。MTP显著提升了真实世界的任务完成率。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.24160v1/figures/ur5_tasks.jpg" alt="真实机器人任务"></p>
<blockquote>
<p><strong>图5</strong>：UR5机器人使用MTP执行各种真实世界任务。</p>
</blockquote>
<p><strong>3. 消融实验分析</strong></p>
<ul>
<li><strong>记忆适应的必要性</strong>：移除记忆适应组件后，MTP在RLBench上的性能从64.4%下降至49.3%，在CALVIN上从67.3%下降至60.0%。这证实了将检索到的代码上下文适应到目标环境是性能提升的关键，而非简单检索。</li>
<li><strong>记忆配置的影响</strong>：使用RLBench构建的记忆库，不仅在RLBench任务上表现更好（68.9%），在CALVIN任务上也取得了最高成功率（67.3%）。这表明记忆库的质量和任务多样性对迁移效果有重要影响。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）提出了Memory Transfer Planning框架，将成功的可执行代码作为程序性知识进行存储、检索和上下文适应，以增强LLM规划器的跨环境适应性；2）设计了一个即插即用的循环（代码生成、记忆检索、重新规划）以及具体的代码适应方法（如重定向、参数缩放、前后条件编辑）；3）在模拟和真实机器人实验中验证了MTP的有效性，相比固定提示生成、简单检索和无记忆重新规划等方法，取得了显著且一致的成功率提升。</p>
<p>论文自身提到的局限性包括：当前记忆库是静态构建的，缺乏动态增长或剪裁机制，可能限制长期部署的可扩展性；此外，MTP完全基于文本（代码）表示运行，未在执行的不同阶段整合视觉或多模态输入（如图像、点云）。</p>
<p>这项工作对后续研究的启示在于：探索动态记忆管理机制，使系统能在运行中持续学习和更新知识库；将多模态信息（如场景的视觉特征）纳入记忆构建、检索和适应过程，可能进一步提升系统在复杂、开放环境中的 grounding 能力和鲁棒性。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对LLM驱动的机器人操作在新环境中适应性的问题，提出**记忆迁移规划（MTP）**框架。该方法通过**检索代码记忆中的成功示例**，并对其进行**上下文感知的适配**，以指导LLM重新规划，无需更新模型参数。在RLBench、CALVIN仿真和物理机器人上的实验表明，MTP相比固定提示生成、简单检索等方法，**持续提升了任务成功率和适应性**，有效实现了跨环境的鲁棒规划。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.24160" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>