<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>OpenCUA: Open Foundations for Computer-Use Agents - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Artificial Intelligence (cs.AI)</span>
      <h1>OpenCUA: Open Foundations for Computer-Use Agents</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.09123" target="_blank" rel="noreferrer">2508.09123</a></span>
        <span>作者: Wang, Xinyuan, Wang, Bowen, Lu, Dunjie, Yang, Junlin, Xie, Tianbao, Wang, Junli, Deng, Jiaqi, Guo, Xiaole, Xu, Yiheng, Wu, Chen Henry, Shen, Zhennan, Li, Zhuokai, Li, Ryan, Li, Xiaochuan, Chen, Junda, Zheng, Boyuan, Li, Peihang, Lei, Fangyu, Cao, Ruisheng, Fu, Yeqiao, Shin, Dongchan, Shin, Martin, Hu, Jiarui, Wang, Yuyan, Chen, Jixuan, Ye, Yuxiao, Zhang, Danyang, Du, Dikang, Hu, Hao, Chen, Huarong, Zhou, Zaida, Yao, Haotian, Chen, Ziwei, Gu, Qizheng, Wang, Yipu, Wang, Heng, Yang, Diyi, Zhong, Victor, Sung, Flood, Charles, Y., Yang, Zhilin, Yu, Tao</span>
        <span>日期: 2025/08/12</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，由视觉语言模型驱动的计算机使用代理在自动化多样化的计算机任务方面展现出巨大潜力。然而，最先进的CUA系统（如Claude 4 Sonnet）的关键细节，包括训练数据、架构和开发过程，通常是封闭和专有的。这种缺乏透明度的现状不仅限制了技术进步，也引发了安全担忧。现有的开源CUA尝试面临显著挑战：首先，缺乏用于收集多样化、大规模计算机使用数据的可扩展基础设施；其次，现有的图形用户界面数据集要么局限于特定领域（如移动端、网页），要么缺乏足够的多样性和规模；此外，许多工作对其建模策略和训练方案的细节披露不足，导致难以复现。这些限制共同阻碍了通用CUAs的发展，并限制了对其可扩展性、泛化性和潜在学习方法的深入探索。本文旨在填补这一空白，提出了OpenCUA，一个用于扩展CUA数据和基础模型的全面开源框架。其核心思路是：通过一个创新的注释工具收集大规模、跨平台、真实的人类计算机使用演示数据，并设计一套包含反射式长链思考推理合成、上下文编码和混合数据训练的方法论，将这些原始演示转化为可训练的轨迹，从而构建出性能强大的开源CUA模型。</p>
<h2 id="方法详解">方法详解</h2>
<p>OpenCUA框架是一个端到端的系统，旨在规模化地收集计算机使用数据并训练基础模型。其整体流程包括数据收集、数据处理、模型训练和评估。</p>
<p><img src="https://arxiv.org/html/2508.09123v3/x1.png" alt="方法框架总览"></p>
<blockquote>
<p><strong>图2</strong>：OpenCUA框架概览。<strong>左上</strong>：AgentNet工具捕获跨操作系统的用户交互（屏幕视频和动作流）。<strong>右上</strong>：原始演示被处理为带有推理和历史的状态-动作轨迹。<strong>右下</strong>：AgentNet数据集和基准测试提供多样化任务及带有黄金标准动作的离线评估。<strong>左下</strong>：OpenCUA模型被训练并能在真实环境中执行。</p>
</blockquote>
<p><strong>核心模块1：数据收集基础设施与AgentNet数据集</strong><br>为解决数据收集难题，论文开发了AgentNet工具，这是一个用户友好的、跨操作系统（Windows, macOS, Ubuntu）的计算机任务注释应用。它能在后台无缝记录自然的人类演示（屏幕视频、鼠标键盘信号、无障碍树），而不干扰用户工作流。基于此工具，论文收集了首个大规模桌面代理任务数据集AgentNet，包含22.6K个开放域计算机任务轨迹，涵盖100多个应用程序和200多个网站，平均每个轨迹18.6步，体现了任务的复杂性。该数据集的特点是真实、复杂、多样且多模态，并首次在个人化环境中收集桌面级轨迹。</p>
<p><strong>核心模块2：从原始演示到状态-动作轨迹的数据处理管道</strong><br>原始演示包含高频率的屏幕录像和细粒度的交互信号，不适合直接训练。为此，论文开发了数据处理管道：1) <strong>动作压缩</strong>：通过基于规则的方法将密集的底层信号（如鼠标移动、连续按键）压缩、合并为更高层级的操作（如点击、拖拽、输入文本、热键），与PyAutoGUI动作空间对齐。2) <strong>状态-动作匹配</strong>：为每个动作<code>a_i</code>匹配一个有代表性的状态<code>s_i</code>（截图）。为避免信息泄露（如鼠标已悬停在按钮上），对于鼠标点击等动作，会回溯到鼠标移动开始前的最后一个视觉上不同的帧作为状态。</p>
<p><strong>核心模块3：合成反射式长链思考推理</strong><br>论文发现，仅在状态-动作对上进行训练，即使数据规模扩大，性能提升也有限。关键见解是：扩展代理能力需要为这些轨迹<strong>增强反射式的长链思考推理</strong>。因此，论文提出了一种多阶段的CoT合成框架，为每个状态-动作对<code>&lt;s_i, a_i&gt;</code>生成结构化的推理。</p>
<p><img src="https://arxiv.org/html/2508.09123v3/x2.png" alt="反射式长链思考合成管道"></p>
<blockquote>
<p><strong>图5</strong>：反射式长链思考合成管道：生成器和反射器迭代地生成和验证观察与真实动作之间的推理组件。</p>
</blockquote>
<p>该管道包含三个组件：1) <strong>反射器</strong>：检查每一步的正确性和冗余性，比较动作前后的截图，判断动作代码和生成的CoT是否正确对齐。如果步骤有误，反射器会阐述原因，该步骤在训练时将被忽略；如果正确，则解释动作带来的状态变化。这教会模型识别和纠正错误。2) <strong>生成器</strong>：基于完整的代理上下文（先前的反思、动作历史、任务目标、截图、动作代码）生成结构化的CoT。3) <strong>总结器</strong>：将模糊的用户目标提炼为更精确的任务目标，并对轨迹进行评分。<br>生成的CoT包含三个层次：L3（上下文观察，捕捉显著的视觉和文本元素）、L2（反思推理，分析状态转换、回忆先前步骤、纠正错误、规划后续行动）和L1（简洁的可执行动作）。这种L3→L2→L1的结构模拟了从感知到决策的流程。</p>
<p><strong>核心模块4：上下文编码与训练策略</strong></p>
<ul>
<li><strong>上下文编码</strong>：1) <strong>文本历史</strong>：采用结构化的“内心独白”框架，以对话形式表示模型的历史响应和对应的屏幕截图，使用L1 CoT（动作）表示先前步骤以提高令牌效率。2) <strong>视觉历史</strong>：使用多张截图（默认三张）作为历史的无损视觉表示，提供比文本摘要更可靠的上下文。</li>
<li><strong>训练数据混合</strong>：1) <strong>CoT数据混合</strong>：使用L1、L2、L3三个层次的CoT数据混合训练，以强化不同层次概念间的连接。2) <strong>领域数据混合</strong>：为了构建通用CUA基础模型，训练数据混合了计算机使用数据（规划与基础数据）和通用视觉语言监督微调数据（如指令遵循、数学推理、OCR等），以同时增强GUI基础能力和高级推理能力。</li>
<li><strong>训练策略</strong>：根据计算资源和目标，论文探索了三种策略：仅阶段2（有限资源，专注CUA）、阶段1+阶段2（更多资源，分阶段提升基础和规划能力）以及联合训练（构建具有强CUA能力的通用VLM）。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准测试</strong>：<ul>
<li>在线代理评估：<strong>OSWorld-Verified</strong> (369个任务)、<strong>WindowsAgentArena</strong> (154个Windows任务)。</li>
<li>离线代理评估：<strong>AgentNetBench</strong> (100个保留任务)。</li>
<li>GUI基础评估：<strong>UI-Vision</strong>、<strong>ScreenSpot-Pro</strong>、<strong>ScreenSpot-V2</strong>、<strong>OSWorld-G</strong>。</li>
</ul>
</li>
<li><strong>基线模型</strong>：对比了包括CogAgent、Aguvis、OpenVLA在内的多个开源CUA模型，以及闭源模型Claude 4 Sonnet。</li>
<li><strong>训练模型</strong>：基于Qwen2.5-VL和Kimi-VL系列模型进行监督微调，得到OpenCUA-7B、OpenCUA-32B、OpenCUA-72B、OpenCUA-Qwen2-7B和OpenCUA-A3B。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>主要性能对比</strong>：OpenCUA-72B在OSWorld-Verified上达到了45.0%的平均成功率（100步限制），在开源模型中创造了新的SOTA，并与Claude 4 Sonnet（46.9%）性能接近。在WindowsAgentArena上，OpenCUA-72B也取得了最佳的开源模型成绩（36.7%）。</li>
</ol>
<p><img src="https://arxiv.org/html/2508.09123v3/images/scale_fig.png" alt="OSWorld-Verified性能"></p>
<blockquote>
<p><strong>图1</strong>：<strong>左图</strong>：OpenCUA方案帮助性能随数据规模和模型规模扩展。仅使用状态-动作对的基础方案性能提升有限，而加入反射式长链思考后性能持续增长。<strong>右图</strong>：OpenCUA-72B超越了当前的开源模型，并与Claude 4 Sonnet表现相当。</p>
</blockquote>
<ol start="2">
<li><strong>GUI基础能力</strong>：OpenCUA-72B在UI-Vision上达到37.3%（SOTA），在ScreenSpot-Pro上达到60.8%，展示了强大的GUI基础能力。</li>
<li><strong>消融实验与贡献分析</strong>：<ul>
<li><strong>反射式长链思考</strong>：是性能提升的关键驱动力。没有反射器的模型性能显著下降。</li>
<li><strong>上下文编码</strong>：使用多图像历史（3张截图）比单图像或纯文本历史带来显著性能提升。在测试时使用L2 CoT格式比L1格式能更好地利用增加的推理步骤（Pass@n）。</li>
<li><strong>训练数据混合</strong>：混合通用SFT数据对代理性能有积极影响；混合L1/L2/L3 CoT数据训练优于仅使用单一层次。</li>
<li><strong>测试时计算可扩展性</strong>：OpenCUA模型在增加测试步数或使用Pass@n评估时，成功率显示出良好的可扩展性，表明其推理能力能够有效利用更多的计算机会。</li>
</ul>
</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>开源框架与基础设施</strong>：提出了首个全面的开源CUA框架OpenCUA，包括用于自然收集人类演示的跨平台注释工具AgentNet Tool。</li>
<li><strong>大规模多样化数据集</strong>：创建了AgentNet，这是首个大规模、跨操作系统、覆盖广泛应用和网站的桌面级计算机使用任务数据集。</li>
<li><strong>创新的方法论</strong>：提出了将原始演示转化为可训练轨迹的管道，其核心是合成反射式长链思考推理，这是实现性能随数据规模稳健扩展的关键。同时，论文详细阐述了上下文编码、数据混合和训练策略等重要设计选择。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，数据收集过程复杂且成本高昂；尽管性能领先，但代理的成功率仍有很大提升空间（例如OSWorld上45%）；模型在处理非常见或高度专业化的软件时可能仍会面临挑战。</p>
<p><strong>对后续研究的启示</strong>：<br>OpenCUA的开源释放（工具、数据、代码、模型）为社区提供了坚实的基础，将极大促进对CUA能力、局限性和风险的透明化研究。其方法论强调了高质量、富含推理的注释数据的重要性，而非单纯追求数据量。反射机制和结构化CoT的引入，为构建更鲁棒、能自我纠错的智能体提供了新思路。未来工作可以在此基础上，探索更高效的数据收集方法、更强大的基础模型架构，以及针对长程、复杂工作流的规划与执行能力。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对当前先进计算机使用代理（CUA）系统关键细节封闭、缺乏开源研究框架的问题，提出了OpenCUA开源框架。其核心技术包括：1）用于捕获人机交互演示的标注基础设施；2）首个跨3个操作系统、覆盖200+应用的大规模数据集AgentNet；3）将演示转化为具反思性长链思维推理的状态-动作对的可扩展流程。实验表明，该框架能随数据与模型规模提升性能，其中OpenCUA-72B在OSWorld-Verified基准上达到45.0%的平均成功率，创开源模型新纪录。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.09123" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>