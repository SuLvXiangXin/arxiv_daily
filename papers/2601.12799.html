<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.12799" target="_blank" rel="noreferrer">2601.12799</a></span>
        <span>作者: Li, Peng, Zhuang, Zihan, Gao, Yangfan, Dong, Yi, Li, Sixian, Jiang, Changhao, Dou, Shihan, Xi, Zhiheng, Zhou, Enyu, Huang, Jixuan, Li, Hui, Gong, Jingjing, Ma, Xingjun, Gui, Tao, Wu, Zuxuan, Zhang, Qi, Huang, Xuanjing, Jiang, Yu-Gang, Qiu, Xipeng</span>
        <span>日期: 2026/01/19</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前人形机器人（如Unitree H1和G1）能够执行问候、跳舞甚至后空翻等动作，但这些能力通常通过硬编码轨迹或针对特定任务的强化学习实现，并由手持设备控制。这种方法限制了机器人自主感知和与外部世界（尤其是人类）交互的通用性。本文旨在解决的核心问题是：如何让人形机器人理解多样的自然语言指令，并在真实物理世界中执行相应的全身运动。</p>
<p>实现该目标面临两大挑战：第一，实现通用的语言理解和运动生成需要大规模数据和大模型训练，但缺乏将语言指令与人形机器人全身运动配对的大规模数据集。第二，即使训练出能从自然语言生成机器人运动的基础模型，由于重力和动态不确定性，直接在物理双足人形机器人上执行这些运动很可能导致不稳定和摔倒。</p>
<p>本文提出<strong>FRoM-W1</strong>框架，其核心思路是：首先利用丰富的人体运动数据训练一个大规模语言驱动的人体全身运动生成模型（H-GPT），将语言指令转化为人体运动；然后通过运动重定向和强化学习训练的运动控制器（H-ACT），使不同形态的人形机器人能够稳定、准确地执行这些运动。</p>
<h2 id="方法详解">方法详解</h2>
<p>FRoM-W1框架将任务分解为两个顺序阶段：H-GPT（语言到人体全身运动）和 H-ACT（人体运动到人形机器人执行）。整体映射为：Π(I) = 𝒜_H-ACT(𝒢_H-GPT(I))。</p>
<p><img src="https://arxiv.org/html/2601.12799v1/x1.png" alt="推理流程"></p>
<blockquote>
<p><strong>图1</strong>: FRoM-W1的推理流程。(a) H-GPT首先通过思维链（CoT）将语言指令转化为细粒度动作描述，然后生成相应的人体全身运动序列。(b) 通过逆向运动学获得人体SMPL-X运动后，H-ACT将生成的人体运动序列重定向为机器人特定运动。随后，通过一个经过强化学习预训练和微调的全身运动控制器，H-ACT使人形机器人在物理世界中执行相应动作。</p>
</blockquote>
<p><strong>H-GPT模块详解</strong>：<br>该模块学习映射 𝒢_H-GPT: ℐ → ℳ_h，其训练与推理流程如图2所示。</p>
<p><img src="https://arxiv.org/html/2601.12799v1/x2.png" alt="H-GPT概览"></p>
<blockquote>
<p><strong>图2</strong>: H-GPT概览。训练阶段，数据三元组&lt;指令ℐ, 思维链𝒞𝒪𝒯, 人体运动ℳ_h&gt;被分词化后送入运动生成器，其中运动序列由全身运动分词器的编码器ℰ和量化器Q进行编码和离散化。推理阶段，运动生成器根据给定指令生成CoT和运动词元，这些运动词元随后由分词器的解码器𝒟解码为运动序列。</p>
</blockquote>
<ol>
<li><strong>数据集增强与丰富</strong>：针对原始人体运动数据集（如HumanML3D）中指令语义范围狭窄的问题，利用GPT-4o为每个样本生成<strong>思维链（CoT）</strong>序列，将指令分解为具有明确时间结构的身体层面运动基元。由此得到增强数据集𝒟_enriched = {(I_i, CoT_i, M_i)}。CoT作为语义中介，将高级或抽象语言与低级运动模式对齐。</li>
<li><strong>全身人体运动分词器</strong>：采用VQ-VAE技术训练一个分词器，将连续的人体运动序列M_h离散化为词元序列Ĉ。过程包括：编码器ℰ进行时空下采样，量化器𝒬将潜在向量映射到可学习码本中的最近条目以生成离散运动词元，解码器𝒟从码本向量重建原始运动序列。训练目标为重构损失、承诺损失和码本损失的加权和。</li>
<li><strong>全身人体运动生成器</strong>：基于LLaMA-3.1等预训练LLM，通过扩展词汇表（V = V_text ∪ V_motion）将文本和运动词元统一表示。采用LoRA进行参数高效微调。训练时，模型处理“[Instruction] I [Chain-of-Thought] CoT [Motion Tokens] Ĉ”格式的序列，使用标准语言建模目标最大化给定指令下目标序列（CoT和运动词元）的似然。推理时，模型以两阶段自回归生成：首先生成CoT，然后基于指令和CoT生成运动词元序列，最后通过分词器解码器得到连续人体运动序列。</li>
</ol>
<p><strong>H-ACT模块详解</strong>：<br>该模块旨在使机器人稳定执行H-GPT生成的运动序列M̃_h，主要包括运动重定向、基于RL的运动模仿器（预训练与微调）以及模块化部署框架。</p>
<p><img src="https://arxiv.org/html/2601.12799v1/x3.png" alt="人形机器人运动重定向流程"></p>
<blockquote>
<p><strong>图3</strong>: 人体到人形机器人运动重定向流程概览。(a) 首先将全身关键点的3D坐标转换为以轴角格式表达的SMPL-X表示。(b) 对于身体重定向，遵循PHC对齐全局身体姿态，并额外加入旋转损失来计算手腕关节朝向。(c) 对于手部重定向，构建一个对齐指尖位置的优化目标并求解以获得最终手部姿态。</p>
</blockquote>
<ol>
<li><strong>人体到人形机器人全身运动重定向器</strong>：通过两阶段过程将人体关键点运动M̃_h转化为机器人关节角度轨迹M̃_r。首先，基于HybrIK方法，通过逆向运动学从3D关键点位置重建SMPL-X人体姿态序列{q̂_h,1,...,q̂_h,T}。然后，通过优化求解机器人关节角度q̂_r,t，使其在选定的对应关节上最小化与人体关节的位置和方向差异，同时满足机器人约束（公式4）。对于身体重定向，遵循PHC方法并加入手腕旋转损失；对于手部重定向，通过优化对齐指尖位置来求解。</li>
<li><strong>基于RL的运动模仿器：预训练与微调</strong>：采用两阶段RL框架在IsaacGym模拟器中学习控制策略π_θ。</li>
</ol>
<p><img src="https://arxiv.org/html/2601.12799v1/x4.png" alt="H-ACT概览"></p>
<blockquote>
<p><strong>图4</strong>: H-ACT概览。在预训练和微调阶段，使用模拟器中重定向的运动数据集训练一个具备特权信息的教师跟踪策略。通过DAgger蒸馏，使用简化的运动目标训练一个模拟到真实的学生策略。在部署阶段，生成的人形机器人运动被适配为不同策略变体的运动目标。解耦的设计与统一接口实现了无缝的模拟到模拟迁移以及模拟到真实部署。</p>
</blockquote>
<pre><code>*   **RL预训练（RPT）**：使用来自AMASS的大规模重定向人体运动数据集𝒟_pt，采用师生蒸馏范式。教师策略π_ϕ基于特权信息训练，最大化包含模仿奖励（惩罚与参考运动的偏差）、稳定性奖励（鼓励平衡）和正则化项的累积奖励（公式5）。可部署的学生策略π_θ则通过监督学习（最小化与教师策略输出的动作差异，公式6）模仿教师，仅使用现实车载观测。
*   **RL微调（RFT）**：在推理时，针对H-GPT生成的**特定**目标运动序列M̃_r，在模拟环境中对预训练的学生策略π_θ进行短时微调。微调阶段重用预训练的奖励函数，但只在该单一运动序列上优化策略参数。这使策略能专门适应目标运动的动态特性，从而提高跟踪精度和鲁棒性。
</code></pre>
<ol start="3">
<li><strong>模块化模拟到现实部署</strong>：设计了一个轻量级、解耦的部署框架，将训练好的策略（支持多种变体如默认策略、HugWBC、TWIST）与机器人中间件分离，通过统一接口实现高效部署。</li>
</ol>
<p><strong>创新点</strong>：1) 利用人体运动作为连接语言与机器人控制的、语义丰富的中间表示。2) 在H-GPT中引入CoT技术，将抽象指令转化为结构化运动基元，增强了模型的泛化理解能力。3) 在H-ACT中提出RL微调策略，使通用预训练控制器能针对特定生成运动进行优化，提升了跟踪精度。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>运动生成基准</strong>：构建了<strong>HumanML3D-X</strong>基准（基于HumanML3D和Motion-X，扩展了手部标注）用于评估语言到人体全身运动生成。此外，构建了<strong>δ-HumanML3D-X</strong>基准用于评估泛化能力。</li>
<li><strong>机器人平台</strong>：Unitree H1和G1人形机器人。</li>
<li><strong>对比方法</strong>：在运动生成方面，与T2M-GPT对比。在运动控制方面，与直接使用预训练策略（无微调）进行对比。</li>
<li><strong>评估指标</strong>：运动生成使用Fréchet Inception Distance、R Precision等。运动控制使用运动跟踪成功率、平均每关节位置误差（MPJPE）等。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<p><img src="https://arxiv.org/html/2601.12799v1/x5.png" alt="HumanML3D-X基准上的定量结果"></p>
<blockquote>
<p><strong>图5</strong>: 在HumanML3D-X基准上的定量结果。FRoM-W1 (H-GPT)在主要指标FID上达到4.97，相比基线T2M-GPT (12.44)有2.5倍的提升，并且在R Precision、多样性等指标上均表现更优。</p>
</blockquote>
<p>在HumanML3D-X基准上，FRoM-W1的H-GPT模型在核心指标FID上达到4.97，相比基线T2M-GPT（12.44）提升了2.5倍，证明了其生成高质量全身运动的能力。</p>
<p><img src="https://arxiv.org/html/2601.12799v1/x6.png" alt="δ-HumanML3D-X基准上的泛化评估"></p>
<blockquote>
<p><strong>图6</strong>: 在δ-HumanML3D-X基准上的泛化评估。加入CoT技术的H-GPT在FID和R Precision指标上均优于无CoT的版本，验证了CoT对理解新指令的有效性。</p>
</blockquote>
<p>在δ-HumanML3D-X泛化基准上，引入CoT的H-GPT模型性能优于未使用CoT的版本，验证了CoT技术对提升模型理解新指令泛化能力的有效性。</p>
<p><img src="https://arxiv.org/html/2601.12799v1/x7.png" alt="RL微调对运动跟踪性能的影响"></p>
<blockquote>
<p><strong>图7</strong>: RL微调（RFT）对运动跟踪性能的影响。经过RFT后，机器人的运动跟踪成功率（Success Rate）一致提升，同时平均每关节位置误差（MPJPE）降低了约15%，表明微调显著提高了跟踪精度和鲁棒性。</p>
</blockquote>
<p>对于运动控制，RL微调策略带来显著提升：在运动跟踪成功率上实现了一致性提高，同时将MPJPE指标降低了约**15%**，表明微调有效提升了动作执行的准确性和稳定性。</p>
<p><img src="https://arxiv.org/html/2601.12799v1/x8.png" alt="模拟环境中不同策略的跟踪误差比较"></p>
<blockquote>
<p><strong>图8</strong>: 模拟环境中，经过RFT微调的策略相比预训练策略（RPT）在跟踪各种运动时的关节位置误差显著降低。</p>
</blockquote>
<p>消融实验证实了各核心组件的贡献：CoT增强了指令理解的泛化能力；RL微调阶段是提升运动跟踪精度的关键；模块化部署框架支持了多种控制策略的顺利迁移。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>H-GPT</strong>，一个90亿参数的模型，能够从自然语言指令生成高质量的全身人体运动。通过集成CoT技术，实现了对多样化指令的泛化理解，并在HumanML3D-X基准上取得了最先进的性能。</li>
<li>提出了<strong>H-ACT</strong>模块，涵盖了从人体到人形机器人运动重定向、到基于强化学习的控制策略预训练与微调、再到真实机器人部署的完整流程。新颖的两阶段RL策略（预训练+微调）使机器人能更精准地跟踪生成的运动。</li>
<li>将整个框架（包括模型、代码、基准和部署模块）完全开源，以促进语言引导的人形机器人全身控制研究。</li>
</ol>
<p><strong>局限性</strong>：<br>论文提到，框架性能依赖于大规模人体运动数据的质量与多样性；模拟到现实的差距仍需通过更好的动力学校准和控制器鲁棒性来缓解；大模型推理和RL微调带来一定的计算成本。</p>
<p><strong>后续研究启示</strong>：<br>FRoM-W1展示了利用人体运动作为“运动文本”来桥接语言与机器人控制的可行路径。后续工作可探索：1) 结合视觉等多模态输入进行更细粒度的运动生成与控制；2) 开发更高效、普适的人体-机器人运动重定向方法；3) 研究更高效的在线适应算法以降低微调成本；4) 将框架扩展至更复杂的动态交互任务中。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出FRoM-W1框架，旨在解决人形机器人如何理解多样化自然语言指令并执行相应全身动作的核心问题。方法采用两阶段流程：H-GPT利用大规模人类数据训练语言驱动的全身运动生成模型，结合思维链技术提升指令理解泛化能力；H-ACT通过运动重定向与强化学习预训练及微调的控制器，实现动作在物理世界的稳定执行。实验在Unitree H1/G1机器人上验证，该框架在HumanML3D-X基准上表现优异，且强化学习微调持续提升了运动跟踪精度与任务成功率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.12799" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>