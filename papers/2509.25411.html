<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Boolean Satisfiability via Imitation Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Boolean Satisfiability via Imitation Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.25411" target="_blank" rel="noreferrer">2509.25411</a></span>
        <span>作者: Xiangyu Xu Team</span>
        <span>日期: 2025-09-29</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>布尔可满足性问题（SAT）是现代求解器的核心，冲突驱动子句学习（CDCL）是主导框架。在CDCL中，分支规则（选择下一个赋值的变量及其极性）很大程度上决定了搜索轨迹，而单元传播通常主导运行时间。传统分支启发式（如VSIDS）是手工设计的，适应性有限。近期基于学习的方法试图改进求解器性能，但存在关键局限性：例如，SATformer学习实例级信号来初始化调整变量活跃度，但一旦分支循环开始就不再施加影响；Graph-Q-SAT在CDCL中引入在线强化学习（RL）智能体，但需要大量探索，且由于奖励稀疏和反馈延迟可能导致训练不稳定，同时它没有利用完整的CDCL执行历史，每个分支决策仅基于当前状态的紧凑图快照。本文针对现有学习方法缺乏密集、决策级监督来直接优化分支决策，以及RL方法探索成本高、不稳定的痛点，提出了基于模仿学习的新视角。本文的核心思路是：从专家求解轨迹中提取一个名为KeyTrace的、近乎无冲突的存活决策序列，通过模仿学习训练一个自回归模型来直接预测高质量的分支决策，从而减少冗余传播，提升求解效率。</p>
<h2 id="方法详解">方法详解</h2>
<p>ImitSAT的整体框架包含两个核心组件：1）专家KeyTrace构建，用于从原始求解轨迹中提取干净、密集的监督信号；2）自回归学习器，用于模仿KeyTrace序列以预测下一个分支决策。</p>
<p><strong>专家KeyTrace构建</strong>：原始CDCL运行轨迹冗长，包含大量因回溯而被撤销的决策。KeyTrace通过压缩轨迹，仅保留那些在回溯后仍然“存活”的决策和传播赋值，从而消除了搜索中的“弯路”。具体提取算法如论文公式(7)所示：从左到右扫描原始轨迹，遇到决策（D）或传播（A）事件则追加到序列K中；遇到回溯（BT）事件，则截断K中决策级别高于当前级别h_i的所有后缀，然后将回溯后新的决策追加到K后。这样得到的KeyTrace序列K_t远短于原始轨迹，并且在相同实例上回放此决策序列时，求解过程几乎无冲突，能大幅减少传播次数。</p>
<p><img src="https://arxiv.org/html/2509.25411v1/x1.png" alt="从CDCL运行到KeyTrace"></p>
<blockquote>
<p><strong>图1</strong>：从CDCL运行到KeyTrace的构建过程示意图。左侧展示了包含回溯的完整运行过程，右侧展示了通过压缩回溯、仅保留存活决策得到的紧凑KeyTrace，该序列作为模仿学习的专家演示。</p>
</blockquote>
<p><strong>自回归模仿学习</strong>：分支决策本质上是前缀条件化的（当前决策依赖于之前的赋值历史）。因此，本文将分支任务建模为序列预测问题。首先，将CNF公式F（DIMACS格式）和当前的KeyTrace前缀K_t序列化为一个确定的令牌序列z(F, K_t)，格式为：[CNF] + F_DIMACS + [SEP] + enc(K_t) + [D]，其中enc(K_t)将KeyTrace编码为决策字面量及其引发的传播字面量序列，[D]是决策探针标记。学习器是一个自回归模型（采用Perceiver AR架构），其目标是在给定序列化前缀z(F, K_t)的条件下，预测下一个令牌，即下一个带符号的变量（分支决策）。训练采用行为克隆范式，最小化专家决策的负对数似然损失（公式14）。该设计提供了密集的、决策级的监督，使学习器无需探索即可复制高质量决策，实现了快速收敛和稳定训练。</p>
<p><strong>在线集成到CDCL</strong>：在推理时，ImitSAT在每次分支点被调用（有较小的查询预算）。它将当前求解器轨迹实时压缩为KeyTrace前缀，序列化后输入模型，模型预测下一个带符号变量作为分支决策。如果预测合法（变量在范围内且未赋值），求解器则采纳该决策并消耗一次查询预算；否则，立即回退到原生的VSIDS启发式。这种设计保持了求解器的完备性，且开销很小。论文指出，采用前期集中查询的策略尤为有效，因为早期决策强烈影响后续大部分搜索。</p>
<p>与现有方法相比，ImitSAT的创新点具体体现在：1）<strong>监督信号</strong>：不同于间接影响分支的实例级信号（SATformer）或稀疏的RL奖励（Graph-Q-SAT），ImitSAT直接从近乎最优的专家轨迹中获得密集的、决策级的监督。2）<strong>问题建模</strong>：将分支明确建模为前缀条件化的序列预测问题，并利用KeyTrace自然对齐这一结构，避免了RL所需的探索和不稳定性。3）<strong>效率</strong>：通过压缩轨迹和轻量级自回归模型，在保持有效长程依赖建模的同时，控制了每次查询的计算成本。</p>
<p><img src="https://arxiv.org/html/2509.25411v1/x2.png" alt="传播主导CDCL时间"></p>
<blockquote>
<p><strong>图2</strong>：MiniSAT求解器中各组件时间占比分析。单元传播（Propagation）占据了约88.9%的运行时间，是主要开销，因此减少传播是提升运行效率的主要途径。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.25411v1/x3.png" alt="紧凑KeyTrace回放"></p>
<blockquote>
<p><strong>图3</strong>：专家KeyTrace回放与原始MiniSAT运行的事件数量对比。KeyTrace回放仅产生了原始运行中0.2%的冲突、19.6%的决策和4.3%的传播，验证了其高效性。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验使用了随机3-SAT测试集（变量数5-100）以及来自SATLIB的结构化SAT家族（JNH, AIM, PARITY, PHOLE, PRET），涵盖可满足与不可满足实例、3-SAT和非k-SAT公式。基线方法包括SATformer和Graph-Q-SAT。CDCL求解器基于Python重写的MiniSAT 2.2。主要评估指标是<strong>中位数相对传播百分比（MRPP，越低越好）</strong>，即与原生MiniSAT相比，传播次数的中位数比率；以及<strong>1%胜率（W_1%，越高越好）</strong>，即传播减少至少1%的实例比例。由于传播主导运行时间，减少传播直接关联性能提升。</p>
<p><strong>关键实验结果</strong>：<br>在随机3-SAT测试集上（表1），ImitSAT在几乎所有变量规模区间上都取得了最低的MRPP（例如，在5-15变量上，3次查询的MRPP为0.75，5次查询为0.73），表明其能有效减少传播。在1%胜率上，ImitSAT（3次查询）在所有规模区间均取得最高胜率（如0.68 @ 5-15），显著优于基线。</p>
<p><img src="https://arxiv.org/html/2509.25411v1/x4.png" alt="表1：3-SAT测试集上的MRPP和胜率"></p>
<blockquote>
<p><strong>表1</strong>：在随机3-SAT测试集上的性能对比。ImitSAT（Ours）在大多数变量规模区间上取得了最低的中位数相对传播百分比（MRPP，↓更好）和最高的1%胜率（W_1%，↑更好），表明其在不同规模实例上均能稳定减少传播次数。</p>
</blockquote>
<p>在泛化到结构化SAT家族的实验中（表2），ImitSAT同样表现优异。它在PARITY和PRET数据集上取得了大幅的传播减少（MRPP低至0.30），并且在JNH、AIM等数据集上优于或持平最佳基线。值得注意的是，ImitSAT<strong>仅使用随机3-SAT数据训练，未经过任何微调</strong>，就在这些结构迥异的数据集上展现了强大的泛化能力。而Graph-Q-SAT在JNH和AIM上甚至增加了传播次数，SATformer仅在PARITY上表现较好。</p>
<p><img src="https://arxiv.org/html/2509.25411v1/x5.png" alt="表2：结构化SAT家族上的MRPP和胜率"></p>
<blockquote>
<p><strong>表2</strong>：在结构化SAT家族上的泛化性能。ImitSAT在大多数数据集上取得了最低或并列最低的MRPP，以及最高或并列最高的胜率，展示了其从随机3-SAT到结构化问题的强大泛化能力，而无需重新训练。</p>
</blockquote>
<p><strong>消融实验与贡献分析</strong>：论文通过KeyTrace回放实验（图3）验证了其作为专家监督的有效性，能极大减少冲突和传播。Perceiver AR架构的选择是为了平衡长序列建模能力和查询时的计算效率（O(N)复杂度）。查询策略上，前期集中查询被证明更有效，因为早期决策对搜索树形状影响更大。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：1）<strong>提出了首个基于模仿学习的CDCL分支策略ImitSAT</strong>，利用从专家求解轨迹提取的密集、决策级监督进行训练，避免了强化学习的不稳定性和高探索成本。2）<strong>创新性地将分支建模为序列预测问题</strong>，通过将求解器运行轨迹压缩为“存活决策”序列（KeyTrace），为自回归模型提供了干净、对齐的训练目标。3）<strong>实验证明了方法的有效性和强泛化能力</strong>：ImitSAT在随机和结构化SAT实例上均能显著减少传播次数，且仅用随机3-SAT训练即可泛化至未见过的结构化问题家族。</p>
<p>论文自身提到的局限性在于训练数据仅包含随机3-SAT实例，尽管泛化表现良好，但在更广泛、更复杂的工业实例上的性能仍有待进一步验证。</p>
<p>本文对后续研究的启示在于：模仿学习为组合优化问题（如SAT）中学习复杂决策策略提供了一个高效、稳定的替代范式。将求解过程压缩为关键决策序列的思路，可能适用于其他基于搜索的精确求解算法（如混合整数规划的分支定界法）。此外，如何将更丰富的求解器状态信息高效地集成到序列化表示中，以进一步提升模型决策质量，是一个值得探索的方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对布尔可满足性问题中CDCL求解器的分支决策优化问题，提出ImitSAT方法。该方法基于模仿学习，从专家KeyTrace学习存活决策序列，重放时几乎无冲突，提供密集决策级监督以直接减少传播。技术上将分支建模为前缀条件的自回归序列，使用Transformer学习器捕获长上下文依赖。实验表明，ImitSAT能有效减少传播次数和运行时，优于现有学习型方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.25411" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>