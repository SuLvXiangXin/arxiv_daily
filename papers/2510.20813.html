<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.20813" target="_blank" rel="noreferrer">2510.20813</a></span>
        <span>作者: Xiaolong Wang Team</span>
        <span>日期: 2025-10-23</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人操作策略的训练通常依赖于三种数据源：仿真、人类视频和真实遥操作，每种都存在显著局限。仿真提供了与机器人完全对齐的动作空间，但存在较大的仿真到真实差距。人类视频提供了逼真的场景和真实物理，但缺乏时间上对齐的机器人动作且动作空间不匹配。遥操作虽然对齐了感知和动作，但成本高昂且难以扩展。现有基于3D高斯溅射的仿真器要么针对单一场景，要么缺乏可移植的资产标准，限制了可复现的跨本体基准测试和面向部署的策略上数据收集。</p>
<p>本文旨在解决这些权衡问题，提出了GSWorld，一个将3D高斯溅射与物理引擎耦合的“闭环”逼真仿真套件。“闭环”意味着同一个环境可用于训练、评估、诊断故障和重新标注，从而实现快速迭代。其核心思路是通过一种名为GSDF的统一资产格式，将逼真的3D高斯视觉表示与精确的物理模拟相结合，构建与真实环境高度对齐的数字孪生，以支持零样本仿真到真实转移和高效的策略适应。</p>
<h2 id="方法详解">方法详解</h2>
<p>GSWorld的整体框架是在现有物理仿真器之上提供一个逼真渲染接口。其核心是提出了一种新的资产格式——高斯场景描述文件，它融合了基于网格的高斯表示、机器人URDF和其他物体。GSDF资产与现有仿真器兼容，使用标准格式进行物理碰撞计算，同时通过一个渲染封装器使RGB渲染达到逼真效果，以支持各种领域随机化和应用。</p>
<p><img src="https://arxiv.org/html/2510.20813v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：GSWorld在现有仿真器之上提供接口以渲染逼真资产。GSDF资产与现有仿真器兼容，用于渲染视觉（如深度、分割）和计算物理碰撞。GSWorld提供一个渲染封装器，使RGB渲染逼真化。</p>
</blockquote>
<p>创建GSDF资产的“真实到仿真”重建流程包含几个关键步骤。首先，使用机器人传感器和手机摄像头采集多视角RGB图像，并同步记录机器人关节姿态。为解决尺度模糊问题，在采集时在桌面上放置打印的ArUco标记，利用其已知尺度对3D高斯点云进行缩放，并辅助识别支撑面和重力方向。然后，给定静态机器人的度量尺度GSDF表示和仿真中的度量尺度机器人URDF，通过对URDF视觉网格采样点云与GSDF点云进行迭代最近点配准，计算刚性变换，从而对齐仿真与真实世界的关节位置。相较于先前方法，由于尺度已固定，此处的ICP自由度更少。对齐后，使用K近邻算法在GSDF中分割机器人连杆。对于可移动物体，可以集成现有大规模数据集（如DTC、YCB）或通过2DGS等方法重建自定义物体，并通过ICP对齐其姿态。物体的质量可通过称重估计，未观测到的底部区域可选择使用非模态重建或3D物体生成方法进行修复。</p>
<p>通过将GSDF与物理引擎结合，GSWorld实现了多种应用，核心是“闭环”开发视觉操作策略。例如，在闭环DAgger训练中，给定目标部署环境的GSDF和带有脚本策略的任务，可以在GSWorld中运行策略。对于失败的记录，可以均匀采样一个任务仍可完成的恢复状态，并运行动态规划器来获取纠正数据，从而实现自动化的高质量DAgger数据收集，用于策略适应。</p>
<p><img src="https://arxiv.org/html/2510.20813v1/x2.png" alt="DAgger数据收集"></p>
<blockquote>
<p><strong>图2</strong>：仿真中的DAgger数据收集。利用仿真提供的特权信息，可以记录并重现 rollout 中的失败案例，并生成用于策略适应的纠正数据。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p>实验使用了三个机器人平台进行评估：配备UMI夹爪的Franka Research 3、配备平行夹爪的UF xArm6以及配备两个6自由度手臂的双臂Galaxea R1机器人。在FR3上设计了4个操作任务，在xArm6上设计了3个任务。使用了ACT和Pi0两种策略架构来证明GSWorld的策略无关性。</p>
<p><img src="https://arxiv.org/html/2510.20813v1/x3.png" alt="硬件平台"></p>
<blockquote>
<p><strong>图3</strong>：真实世界硬件平台。FR3设置了前视第三人称摄像头和腕部摄像头；xArm6设置了侧视第三人称摄像头和腕部摄像头。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.20813v1/x4.png" alt="FR3任务"></p>
<blockquote>
<p><strong>图4</strong>：FR3任务可视化。设计了4个涉及不同操作技能和多样化物体的真实世界机器人任务。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.20813v1/x5.png" alt="xArm任务"></p>
<blockquote>
<p><strong>图5</strong>：xArm任务可视化。在xArm6上设计了3个操作任务。</p>
</blockquote>
<p><strong>零样本仿真到真实模仿学习</strong>：实验表明，仅使用仿真数据训练的策略能够零样本转移到真实世界。例如，在FR3的四个任务上，经过DAgger迭代改进的策略取得了显著的成功率。</p>
<p><strong>闭环DAgger持续策略改进</strong>：对于仿真到真实场景，从100条专家轨迹开始，后续迭代中评估当前策略，识别失败轨迹，并从前一可解状态收集纠正数据。经过多轮DAgger迭代，所有任务性能均有显著提升，优于从头开始训练。DAgger也可用于改进真实世界策略（真实到仿真再到真实），即先使用少量真实演示训练一个策略，然后以此检查点为起点在GSWorld中进行DAgger学习，实验结果显示性能得到提升。</p>
<p><img src="https://arxiv.org/html/2510.20813v1/x6.png" alt="仿真到真实DAgger"></p>
<blockquote>
<p><strong>图6</strong>：FR3上的闭环仿真到真实DAgger训练。策略使用仿真数据训练，并部署在仿真和真实环境中。DAgger持续提升策略性能，且优于从头训练。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.20813v1/x7.png" alt="真实到仿真再到真实DAgger"></p>
<blockquote>
<p><strong>图7</strong>：xArm上的闭环真实到仿真再到真实DAgger。DAgger也可用于改进真实世界策略。</p>
</blockquote>
<p><strong>视觉基准测试</strong>：在FR3上，通过使用不同策略和不同数据量训练的策略进行测试，发现仿真与真实世界的性能存在强相关性。仿真性能越高，真实世界成功率也越高，这表明GSWorld能够可靠地预测真实世界结果，为策略评估提供了可复现的视觉基准。</p>
<p><img src="https://arxiv.org/html/2510.20813v1/x8.png" alt="视觉基准测试"></p>
<blockquote>
<p><strong>图8</strong>：FR3的视觉基准测试。在真实和仿真中运行各种策略。有意使用不同策略和数据量来展示仿真-真实性能的正相关性，与策略质量无关。</p>
</blockquote>
<p><strong>虚拟遥操作</strong>：演示了通过键盘和鼠标在具有逼真渲染的仿真中进行遥操作以收集数据，展示了仿真数据收集的可扩展性。</p>
<p><img src="https://arxiv.org/html/2510.20813v1/x9.png" alt="虚拟遥操作"></p>
<blockquote>
<p><strong>图9</strong>：Galaxea R1虚拟遥操作。使用键盘遥操作R1并渲染逼真视频。</p>
</blockquote>
<p><strong>视觉强化学习</strong>：使用非对称SAC在GSWorld中训练视觉RL策略，仅使用颜色抖动作为领域随机化。实验旨在证明GSWorld能减小RL的视觉差距。在“抓取香蕉”和“整理桌子”任务中，真实世界成功率分别达到30%和20%，而基线ManiSkill的成功率分别为0%和5%。</p>
<p><img src="https://arxiv.org/html/2510.20813v1/x10.png" alt="强化学习结果"></p>
<blockquote>
<p><strong>图10</strong>：SAC训练结果。结果汇总了3次运行。作为对比，也绘制了直接在ManiSkill中训练的结果。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）提出了一个坚实的“真实到仿真再到真实”流程及GSDF资产格式，能够精确对齐仿真与真实环境；2）展示了该仿真套件支持多种下游应用，包括零样本仿真到真实模仿学习、闭环DAgger策略改进、可复现的视觉基准测试、虚拟遥操作以及视觉强化学习，有效缩小了仿真与真实的视觉和动作空间差距。</p>
<p>论文自身提到的局限性包括：在视觉RL实验中，腕部摄像头在RL探索期间仍显示出显著差距，因此仅使用了第三人称视角。</p>
<p>这项工作启示后续研究，构建高保真、物理精确且与真实环境度量对齐的数字孪生，是推动机器人学习算法发展、实现高效仿真到真实迁移的关键。统一的资产标准和自动化的重建流程对于该方向的规模化应用至关重要。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>GSWorld旨在解决机器人操作策略训练中仿真视觉不真实、动作空间不对齐以及真实数据成本高的核心问题。它结合3D高斯溅射与物理引擎，提出GSDF资产格式融合高斯表示与机器人URDF，并通过双向管道实现闭环仿真：从真实场景重建数字孪生，支持策略直接部署到硬件。该套件支持零样本sim2real策略学习、自动化DAgger数据收集和可重复评估等应用，有效缩小sim-to-real差距，促进快速迭代。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.20813" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>