<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.10158" target="_blank" rel="noreferrer">2507.10158</a></span>
        <span>作者: Monowar Bhuyan Team</span>
        <span>日期: 2025-07-16</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人抓取是机器人操作中的核心任务，在仓储自动化、制造业等领域有广泛应用。当前机器人抓取算法主要集中于单机训练或基于云的集中式训练。单机训练无法实现机器人间的协作与知识共享；而云训练虽能协作，但存在数据隐私风险和通信负载高的问题。联邦学习作为一种折中方案，允许设备在本地数据上训练模型，并通过聚合更新实现协作，同时保护数据隐私，因此在机器人领域受到关注。</p>
<p>然而，将联邦学习应用于机器人抓取面临数据异构性的关键挑战。具体而言，不同机器人拥有的数据可能来自不同分布（非独立同分布，non-IID），且数据量也可能存在巨大差异（数量不平衡）。这种数量不平衡的数据会导致联邦学习模型精度下降、泛化能力有限，尤其对于数据量少的机器人，其本地模型容易过拟合。在机器人抓取等复杂任务中，收集新数据成本高昂，数据增强也颇具挑战，因此数据稀缺问题尤为突出。</p>
<p>本文针对机器人抓取联邦学习中由数据非独立同分布（特别是数量不平衡）导致的模型性能下降问题，提出了一种新的多层级联邦学习视角。其核心思路是：根据数据质量和数量对机器人进行排名，选出数据分布更均衡、样本数更多的“顶级”机器人来训练初始“种子”模型，然后将这些种子模型分发给数据稀缺的“低级”机器人进行后续训练，以此作为知识转移机制，降低低级机器人模型过拟合的风险。</p>
<h2 id="方法详解">方法详解</h2>
<p>MTF-Grasp的整体框架是一个包含客户端排名和两级训练-聚合流程的多层级联邦学习系统。其输入是各机器人的本地数据集、全局通信轮数等参数，输出是最终的全局抓取模型。</p>
<p><img src="https://arxiv.org/html/2507.10158v2/extracted/6628071/MTF_Grasp.png" alt="MTF-Grasp过程"></p>
<blockquote>
<p><strong>图2</strong>：MTF-Grasp流程示意图。(a) 机器人计算并发送DDS分数，服务器计算每个机器人的IS并选择顶级机器人。(b) 服务器发送初始模型给顶级机器人训练。(c) 顶级机器人将训练后的模型发送给其关联的低级机器人训练。(d) 执行两级聚合。</p>
</blockquote>
<p>整体流程如下：</p>
<ol>
<li><strong>初始化与客户端排名</strong>：服务器启动训练，每个机器人<code>r</code>计算其数据分布分数<code>DDS_r</code>，并将其与本地数据量<code>|𝒟^r|</code>一同发送给服务器。服务器根据<code>DDS_r</code>和数据量信息，为每个机器人计算重要性分数<code>IS_r</code>，并据此选出排名靠前的<code>j</code>个机器人作为顶级机器人集合<code>𝒯</code>。剩余机器人被分配给各个顶级机器人<code>t</code>，形成低级机器人子集<code>ℒ_t</code>（每个顶级机器人自身也包含在其<code>ℒ_t</code>中）。</li>
<li><strong>多层级训练</strong>：<ul>
<li><strong>顶级机器人训练</strong>：服务器将初始化的全局模型<code>𝐰_0</code>发送给所有顶级机器人<code>t ∈ 𝒯</code>。每个顶级机器人使用本地数据对模型进行<code>e_t</code>轮本地训练，得到中间模型<code>𝐰̃_i^t</code>。</li>
<li><strong>低级机器人训练</strong>：每个顶级机器人<code>t</code>将其训练后的中间模型<code>𝐰̃_i^t</code>发送给其关联的所有低级机器人<code>r ∈ ℒ_t</code>。每个低级机器人以此模型为起点，使用自己的本地数据再进行<code>e_r</code>轮训练，得到更新后的模型<code>𝐰_{i+1}^r</code>，并将其发回给对应的顶级机器人<code>t</code>。</li>
</ul>
</li>
<li><strong>两级模型聚合</strong>：<ul>
<li><strong>第一级聚合（在顶级机器人处）</strong>：每个顶级机器人<code>t</code>聚合从其关联的所有低级机器人（包括自己）收到的模型。若采用FedAvg策略，则按各机器人数据量加权平均（公式8）。</li>
<li><strong>第二级聚合（在服务器处）</strong>：服务器聚合从所有顶级机器人收到的模型。同样采用FedAvg，按各顶级机器人所辖低级机器人总数据量进行加权平均（公式9）。</li>
</ul>
</li>
<li><strong>迭代</strong>：重复步骤2和3，直至完成预设的全局通信轮数<code>E</code>。</li>
</ol>
<p><strong>核心模块与技术细节</strong>：</p>
<ul>
<li><strong>客户端排名机制</strong>：这是MTF-Grasp的关键创新。排名依据是结合了数据质量和数据数量的重要性分数<code>IS_r</code>。<ul>
<li>**数据质量 (<code>DDS_r</code>)**：衡量机器人内部数据分布的均衡性。首先计算机器人<code>r</code>中样本数最多的类别的样本数<code>HCS_r</code>（公式3），然后<code>DDS_r</code>定义为该机器人所有类别的样本数分别除以<code>HCS_r</code>后的总和（公式4）。<code>DDS_r</code>越高，表明该机器人内部各类数据量越均衡，数据质量被认为越好。</li>
<li>**数据数量 (<code>DQS_r</code>)**：衡量机器人拥有的绝对数据量。首先找到所有机器人中最大的数据量<code>HRS</code>（公式5），然后<code>DQS_r</code>定义为机器人<code>r</code>的数据量除以<code>HRS</code>（公式6）。</li>
<li>**重要性分数 (<code>IS_r</code>)**：<code>IS_r = λ_DDS * DDS_r + λ_DQS * DQS_r</code>（公式7），其中<code>λ_DDS</code>和<code>λ_DQS</code>为可调节的超参数，用于控制数据质量和数量在排名中的权重。</li>
</ul>
</li>
<li><strong>本地训练</strong>：遵循标准的梯度下降法（公式1），本地损失函数<code>l</code>基于机器人的本地数据集<code>𝒟^r</code>计算。</li>
<li><strong>聚合策略</strong>：文中默认采用FedAvg算法进行加权平均聚合，权重为各参与方数据量占总数据量的比例。</li>
</ul>
<p><strong>与现有方法的创新点</strong>：<br>与传统的单层联邦学习（所有客户端直接与服务器交互）相比，MTF-Grasp的创新在于引入了<strong>层级化的知识转移</strong>。它没有让所有数据稀缺的“弱”客户端直接基于可能不佳的全局模型进行训练，而是先让数据质量高、数量多的“强”客户端（顶级机器人）训练出更好的初始模型，再将这些模型分发给“弱”客户端作为训练起点。这相当于在联邦学习框架内构建了一个“导师-学徒”机制，旨在缓解非独立同分布数据，特别是数量不平衡数据带来的性能下降问题。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>数据集</strong>：使用Cornell抓取数据集（885张RGB-D图像）和Jacquard抓取数据集（约54,000张图像）。</li>
<li><strong>数据划分</strong>：模拟两种非独立同分布场景：(a) 基于类别的非独立同分布：每个客户端只拥有整个数据集中部分类别的数据。(b) <strong>数量不平衡的非独立同分布</strong>：客户端数据总量服从幂律分布，差异巨大（这是本文主要关注的场景）。实验设置包含10个客户端。</li>
<li><strong>对比基线</strong>：传统的（vanilla）联邦学习方法（FedAvg）。</li>
<li><strong>评估指标</strong>：抓取成功率。</li>
</ul>
<p><img src="https://arxiv.org/html/2507.10158v2/extracted/6628071/label_distribution.png" alt="客户端间基于类别和数量不平衡的非独立同分布实验数据划分"></p>
<blockquote>
<p><strong>图3</strong>：展示了在基于类别的非独立同分布和数量不平衡的非独立同分布实验设置中，数据在客户端间的划分情况。左图显示每个客户端仅持有部分类别的数据；右图显示客户端数据量呈不平衡分布。</p>
</blockquote>
<p><strong>关键实验结果</strong>：<br>在数量不平衡的非独立同分布设置下，MTF-Grasp在两个数据集上均显著优于传统联邦学习。</p>
<ul>
<li>在<strong>Cornell数据集</strong>上，MTF-Grasp取得了**85.4%<strong>的抓取成功率，而传统联邦学习为</strong>77.4%<strong>，绝对性能提升</strong>8%**。</li>
<li>在<strong>Jacquard数据集</strong>上，MTF-Grasp取得了**86.5%<strong>的抓取成功率，相比传统联邦学习的</strong>83.7%<strong>，提升</strong>2.8%**。</li>
</ul>
<p><img src="https://arxiv.org/html/2507.10158v2/extracted/6628071/skewed_distribution.png" alt="数量不平衡实验的结果"></p>
<blockquote>
<p><strong>图4</strong>：数量不平衡实验的结果图。该图清晰地显示，在Cornell和Jacquard数据集上，MTF-Grasp（橙色曲线）的抓取成功率在所有通信轮次中均稳定高于传统的联邦学习方法（蓝色曲线），最终达到更高的性能峰值。</p>
</blockquote>
<p><strong>消融实验总结</strong>：<br>论文通过消融实验验证了MTF-Grasp两个核心组件的贡献：</p>
<ol>
<li><strong>多层级训练结构</strong>：即使不使用排名机制（随机选择顶级机器人），多层级训练结构本身也能带来性能增益，因为它促进了从数据丰富客户端到数据稀缺客户端的知识转移。</li>
<li><strong>基于<code>IS</code>的客户端排名</strong>：采用基于重要性分数<code>IS</code>的智能排名选择顶级机器人，相比随机选择，能带来进一步的性能提升。实验表明，在排名中<strong>数据质量 (<code>DDS</code>) 比数据数量 (<code>DQS</code>) 的影响更大</strong>，即选择数据分布均衡的客户端作为“导师”比单纯选择数据量大的客户端更为重要。<br>此外，论文还进行了通信成本分析，指出尽管MTF-Grasp采用多层结构，但其通信轮次与单层联邦学习相同，因此<strong>并未引入额外的通信开销</strong>。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>MTF-Grasp</strong>，这是一个新颖的多层级联邦学习框架，专门设计用于应对机器人应用中常见的非独立同分布数据分布和数据稀缺挑战。</li>
<li>在该框架内提出了一种<strong>客户端排名机制</strong>，通过综合考虑数据质量和数量，智能地选择顶级客户端进行初始模型训练，以减轻数据稀缺客户端低质量模型对全局模型的影响。</li>
<li>通过在两个主流抓取数据集上的实验，<strong>实证评估</strong>证明了MTF-Grasp在数量不平衡场景下优于传统联邦学习方法，性能提升最高达8%，并进行了详细的消融实验和通信成本分析。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到的局限性包括：1) 当前方法假设客户端的数据质量是静态的，未考虑在联邦学习过程中数据质量可能随时间动态变化的情况。2) 主要关注数据异构性，未深入探讨系统异构性（如客户端计算能力差异）带来的挑战。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>动态排名</strong>：未来的工作可以探索动态的客户端排名策略，能够适应客户端数据分布随时间变化的情况。</li>
<li><strong>结合其他技术</strong>：可以将MTF-Grasp的层级化思想与其他处理非独立同分布数据的联邦学习算法（如FedProx、SCAFFOLD等）相结合，可能产生更强大的方法。</li>
<li><strong>扩展应用场景</strong>：此多层级知识转移框架不仅适用于抓取任务，也可推广到其他数据异构性严重的机器人学习任务，如导航、操作技能学习等。</li>
<li><strong>考虑系统异构性</strong>：在现实机器人集群中，需要进一步研究如何将计算资源、通信延迟等系统异构性因素整合到多层级联邦学习框架的设计中。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出MTF-Grasp方法，旨在解决机器人抓取任务中联邦学习面临的数据非独立同分布且数量不足导致的性能下降问题。该方法采用多层联邦学习框架，依据数据质量和数量筛选出“顶级”机器人训练初始种子模型，再分发给“低级”机器人以提升整体训练效果。实验表明，该方法在Cornell和Jacquard抓取数据集上比传统联邦学习性能提升最高达8%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.10158" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>