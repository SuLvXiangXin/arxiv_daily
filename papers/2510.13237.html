<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.13237" target="_blank" rel="noreferrer">2510.13237</a></span>
        <span>作者: Jingfeng Zhang Team</span>
        <span>日期: 2025-10-15</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>视觉-语言-动作模型通过在大型视觉-语言模型基础上构建，使机器人能够根据自然语言指令执行复杂的物理任务，展现了强大的泛化能力。然而，其对抗鲁棒性尚未得到充分探索。现有研究（如Wang等人，2024）提出了针对OpenVLA模型和特定7自由度机械臂的对抗补丁攻击，但这些方法存在关键局限性：攻击者需要预先知晓受害模型的完整架构、机械臂平台细节，并能访问所有模型参数以计算梯度。这些严格的先决条件极大地限制了攻击在现实场景中的实用性。</p>
<p>本文针对现有攻击方法“模型相关”的痛点，提出了“模型无关”的新视角。核心思路是：绕过对VLA主干网络和机器人平台的依赖，直接攻击视觉编码器产生的潜在表示，通过破坏视觉-语言语义对齐并最大化干净与对抗视觉输入之间的表示差异，来误导模型生成错误动作。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的方法包含两个核心部分：模型无关的嵌入破坏补丁攻击及其对应的防御策略。</p>
<p><img src="https://arxiv.org/html/2510.13237v1/VLA_Overview.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：OpenVLA架构概览及不同补丁攻击的要求对比。VLA模型首先将视觉观察和语言指令编码为令牌级潜在表示，经LVLM处理生成动作令牌，最终解码为可执行动作。虚线标出了不同攻击所需访问的模块：绿色为EDPA，紫色为UADA，红色为UPA。EDPA仅需访问编码器参数。</p>
</blockquote>
<p><strong>整体框架</strong>：EDPA攻击的目标是生成一个通用的对抗补丁δ，该补丁可被放置在相机视野内的任意位置。其生成过程不依赖于VLA的主干网络或机器人平台，仅需访问视觉编码器和语言编码器的参数。防御策略则是对视觉编码器进行对抗性微调，使其对对抗补丁扰动具有鲁棒性。</p>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><p><strong>嵌入破坏补丁攻击</strong>：EDPA通过优化两个互补的损失函数来生成补丁。</p>
<ul>
<li><strong>图像-指令对齐损失</strong>：旨在破坏视觉潜在表示与对应语言指令潜在表示之间的语义对齐。该损失衡量了在嵌入空间中，对抗视觉输入与语言指令的余弦相似度相对于干净视觉输入的变化。公式定义为所有图像块嵌入与语言令牌嵌入的余弦相似度差异的绝对值平均。</li>
<li><strong>补丁对比损失</strong>：旨在直接最大化干净视觉输入与对抗视觉输入的潜在表示之间的差异。该损失采用InfoNCE形式，鼓励对抗样本的块嵌入远离其对应的干净块嵌入，同时靠近其他不匹配的块嵌入。<br>最终的补丁生成通过联合最大化这两个损失来完成，其中超参数α1控制两者的权重。</li>
</ul>
</li>
<li><p><strong>视觉编码器的对抗性微调</strong>：这是一种防御策略，旨在提升视觉编码器对EDPA类攻击的鲁棒性。其优化目标包含两项：</p>
<ul>
<li>鼓励微调后的编码器对对抗视觉输入产生的潜在表示，接近于原始编码器对干净输入产生的表示。</li>
<li>确保微调后的编码器对干净输入产生的表示，与原始编码器的输出保持一致。<br>训练过程中，利用EDPA优化过程中生成的所有中间补丁来构造对抗样本，并定期重置补丁以防止过拟合。该防御的优点是微调后的视觉编码器可直接替换原VLA中的编码器，无需修改或微调LVLM主干。</li>
</ul>
</li>
</ol>
<p><strong>创新点</strong>：与现有方法（UADA, UPA）相比，EDPA的核心创新在于其“模型无关”特性。它无需知晓受害VLA模型的具体设计（如动作解码方式）或所控制的机器人平台（如自由度），仅通过攻击视觉和语言编码器共有的嵌入空间来实现攻击，大大提升了攻击的普适性和现实可行性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>数据集与基准</strong>：使用机器人操作模拟数据集LIBERO，包含Spatial, Object, Goal, Long四个任务套件，每个套件10个任务。</li>
<li><strong>受害模型</strong>：评估了OpenVLA、OpenVLA-OFT和π0等开源VLA模型。</li>
<li><strong>基线方法</strong>：对比了随机噪声补丁，以及专门为OpenVLA设计的UADA和UPA攻击。</li>
<li><strong>评估指标</strong>：任务失败率（FR = 1 - 成功率），在每种条件下进行3次随机实验取平均。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>对单相机VLA（OpenVLA）的攻击与防御</strong>：<ul>
<li>如表2所示，EDPA对原始OpenVLA的攻击极其有效，在Spatial、Object、Goal套件上均将失败率提升至100%，在Long套件上提升至91.2%，平均相对干净条件提升约74.7%。</li>
<li>与UADA和UPA相比，EDPA达到了相当甚至更优的攻击效果，证明了其有效性。</li>
<li>对抗性微调防御显著降低了模型在攻击下的失败率。例如，针对EDPA攻击，微调后的OpenVLA在Spatial套件的失败率从100%降至39.4%。同时，该防御也提升了对UADA和UPA攻击的鲁棒性，且对干净性能的影响较小（平均失败率仅上升1.6%）。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2510.13237v1/EDPA_patches.png" alt="攻击补丁示例"></p>
<blockquote>
<p><strong>图2</strong>：EDPA生成的对抗补丁可视化示例。这些补丁具有可解释的模式，与随机噪声明显不同。</p>
</blockquote>
<ol start="2">
<li><strong>对多相机VLA的攻击</strong>：<ul>
<li>如表3所示，EDPA同样能有效攻击依赖主摄像头和腕部摄像头的多相机VLA模型（OpenVLA-OFT和π0）。虽然由于多视角的冗余性，攻击成功率低于对单相机OpenVLA的攻击，但EDPA仍能显著提升任务的失败率。例如，对OpenVLA-OFT在Goal套件上，失败率从2.8%提升至80.0%。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2510.13237v1/alpha1.png" alt="消融实验-超参数α1"></p>
<blockquote>
<p><strong>图3</strong>：超参数α1（控制两个损失权重）的消融实验。当α1=0.8时，EDPA攻击在OpenVLA上达到最优性能，表明结合两个损失比单独使用任何一个更有效。</p>
</blockquote>
<p><strong>消融实验</strong>：论文探讨了关键超参数的影响。如图3所示，控制攻击损失权重的α1设置为0.8时效果最佳，验证了联合优化两个目标的必要性。此外，补丁尺寸实验（图6）表明，在一定范围内（如50x50像素），更大的补丁能导致更高的失败率。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>提出了模型无关的对抗补丁攻击（EDPA）</strong>：该方法仅需访问编码器参数，无需知晓VLA架构或机器人平台细节，通过破坏嵌入空间的语义对齐和一致性来实施攻击，显著提升了攻击的实用性和普适性。</li>
<li><strong>提出了对应的对抗性微调防御策略</strong>：通过微调视觉编码器使其对对抗扰动不敏感，同时保持干净输入的性能，有效提升了VLA模型对EDPA及其他补丁攻击的鲁棒性。</li>
<li><strong>进行了全面的实验验证</strong>：在LIBERO基准上系统评估了EDPA对多种SOTA VLA模型的攻击效力，并验证了防御策略的有效性，揭示了VLA模型在此类攻击下的脆弱性。</li>
</ol>
<p><strong>局限性</strong>：论文提到，对于多相机VLA模型，由于腕部相机视角动态变化且难以与主相机实时对齐补丁，攻击效果弱于对单相机模型的攻击。这为攻击在多模态输入下的有效性设定了边界。</p>
<p><strong>后续研究启示</strong>：本文工作表明，针对模型中间表示（嵌入）的攻击是绕过模型具体细节、实现通用攻击的有效途径。未来的防御研究可能需要更多地关注于提升编码器层的鲁棒性。此外，如何将此类防御与VLA模型的多模态训练更紧密结合，以及在更复杂的物理环境中评估攻击与防御，是值得探索的方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对视觉-语言-动作（VLA）模型对抗鲁棒性未充分探索的问题，提出模型无关的攻击与防御方法。攻击方面，提出嵌入破坏补丁攻击（EDPA），通过破坏视觉与文本潜在表示的语义对齐、并最大化对抗与干净视觉输入的表示差异，生成可直接放置的对抗补丁。防御方面，采用对抗性微调视觉编码器，优化其使干净和对抗输入产生相似表示。在LIBERO基准上的实验表明，EDPA能显著提高尖端VLA模型的任务失败率，而所提防御有效缓解了性能下降。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.13237" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>