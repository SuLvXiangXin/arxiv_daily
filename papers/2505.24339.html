<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Imitation Learning-Based Path Generation for the Complex Assembly of Deformable Objects - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Imitation Learning-Based Path Generation for the Complex Assembly of Deformable Objects</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.24339" target="_blank" rel="noreferrer">2505.24339</a></span>
        <span>作者: Christoffer Sloth Team</span>
        <span>日期: 2025-05-30</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，可变形物体的装配任务路径生成主要有两种主流方法。一种是基于详细物理模型的方法，通过精确建模物体动力学并利用轨迹优化来生成参考路径。然而，这种方法存在模型与真实世界之间的固有差异，且往往过于定制化，难以适应其他复杂的工业应用。另一种是数据驱动的方法，如直接从人类演示中学习轨迹。虽然这种方法更直观，但在高度复杂的装配任务中可能难以实施，并且通常需要设置额外的遥操作或视觉反馈设备，以及大量耗时的演示数据。</p>
<p>本文针对上述痛点，提出了一种结合传统路径规划与模仿学习的新视角。核心思路是：首先利用基于简单物理模型的离线路径规划算法生成大量初始参考路径；然后通过少量的人类演示（对路径进行微调）来弥补模型与现实的差距；最后，通过数据增强和模仿学习，训练一个能够生成高质量装配路径的策略网络。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的方法整体框架包含三个核心阶段：离线路径生成、人类引导修正以及基于增强数据集的策略学习。</p>
<p><img src="https://arxiv.org/html/2505.24339v1/extracted/6496210/outline.jpg" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：结合学习生成参考轨迹的方法概述。左侧展示了虚拟人类修正数据集的生成过程：将原始的离线路径进行多项式拟合得到新路径，并与纯人类修正（人类修正路径减去原始路径）相加，生成虚拟修正路径。右侧展示了整体流程：从离线路径生成，到人类修正，再到虚拟数据集生成，最终通过行为克隆学习策略。</p>
</blockquote>
<p><strong>1. 基于TrajOpt的离线路径生成</strong><br>该方法使用轨迹优化算法TrajOpt来生成初始的无碰撞路径。优化问题旨在最小化关节空间中的路径长度，并施加多种约束。针对橡胶带装配到两个滑轮上的特定任务，关键的创新在于引入了力约束，以确保在整个装配过程中皮带保持张力。力约束通过两个不等式实现（公式2a, 2b），其中皮带力 ( F(\mathbf{x}) ) 使用Hunt-Crossley接触力模型（公式3a）进行计算。该模型的参数通过非线性最小二乘法（Levenberg-Marquardt算法）进行估计。最终生成的离线路径是机器人末端执行器在任务时间内的位姿序列 ( Path = {p_0, p_1, ..., p_T} )，其中每个 ( p_T ) 包含位置和欧拉角。</p>
<p><strong>2. 人类引导的路径修正</strong><br>当机器人沿着生成的离线路径运动时，采用位置/力混合控制实现柔顺控制，允许人类操作者通过轻微的外力引导来修正机器人的实际路径。这种修正仅针对那些仿真与现实存在偏差的部分，无需对所有路径进行完整演示。修正后的路径表示为 ( Path^* = {p^*_0, p^*_1, ..., p^*_T} )，其中修正量体现在位置 ( (\Delta x, \Delta y, \Delta z) ) 和姿态 ( (\Delta roll, \Delta pitch, \Delta yaw) ) 上。</p>
<p><strong>3. 虚拟数据集的生成与策略学习</strong><br>为了克服人类演示数据稀缺的问题，本文提出了一种基于多项式拟合的数据增强方法。如图1左侧所示，首先对一条原始的离线路径进行高阶多项式拟合，产生一条新的、独立的离线路径。然后，计算“纯人类修正”（即人类修正路径减去对应的原始离线路径）。最后，将这条纯人类修正加到新拟合出的离线路径上，从而生成一条“虚拟人类修正路径”。通过这种方式，可以基于有限的人类演示，扩增出大量的训练数据。</p>
<p>策略学习采用行为克隆方法。状态 ( s_T ) 定义为末端执行器相对于待装配滑轮中心的位置 ( {x, y, z} )，动作 ( a_T ) 定义为相对于机器人基座的末端执行器位姿。演示数据集 ( \mathcal{D}_{set} ) 由多条状态-动作序列构成。使用神经网络作为策略函数，以均方误差作为损失函数，学习从状态到动作的映射，从而模仿所有演示数据（包括真实的和虚拟的）中的行为，最终得到一个能够生成高质量参考轨迹的“灵巧策略”。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：任务为世界机器人峰会（WRS2020）中的橡胶带插入滑轮装配。仿真环境基于Gazebo 9搭建，真实机器人使用Universal Robot UR10e，并通过500Hz频率的位置/力混合控制器实现柔顺控制以收集人类修正数据。学习算法使用PyTorch实现。</p>
<p><strong>关键结果</strong>：学习到的策略能够成功生成完成装配任务的参考路径。实验中，由于离线路径生成的方向轨迹已经足够好，因此人类修正仅针对末端执行器的位置进行。</p>
<p><img src="https://arxiv.org/html/2505.24339v1/extracted/6496210/action_4_copy.png" alt="学习到的路径"></p>
<blockquote>
<p><strong>图2</strong>：通过结合100条虚拟演示和10条人类演示，学习到的策略生成的用于完成皮带插入任务的路径（红色线）。该结果表明，所提出的结合方法能够学习复杂装配任务的轨迹，而无需从零开始的大量人类演示或外部系统。</p>
</blockquote>
<p>论文将学习到的策略路径与10条人类演示路径进行了比较。结果表明，本文提出的结合方法能够在不需要大量从零开始的人类演示，也无需依赖遥操作等外部系统的情况下，成功学习到高度复杂装配任务的轨迹。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一种新颖的框架，将基于模型的离线路径规划、少量人类引导修正和数据驱动的模仿学习相结合，用于生成可变形物体复杂装配的高质量路径。</li>
<li>引入了基于多项式拟合的虚拟数据生成方法，有效缓解了模仿学习中人类演示数据稀缺的问题，使得仅需少量真实修正即可进行有效学习。</li>
<li>整个方法不依赖于遥操作或基于视觉的运动捕捉等外部系统，简化了系统配置，更易于在实际工业场景中应用。</li>
</ol>
<p><strong>局限性</strong>：论文中提到，在实验中仅对路径的位置部分进行了人类修正，因为离线生成的方向轨迹已被认为足够好。这表明方法可能依赖于离线路径在某个维度（如姿态）上具有较高的初始质量。</p>
<p><strong>启示</strong>：这项工作展示了一种有效的“模型先行，数据微调”的范式，为处理仿真与现实差距以及数据收集成本高的复杂机器人操作任务提供了新思路。后续研究可以探索将此框架应用于其他类型的可变形物体或更复杂的装配序列，并研究更先进的虚拟数据生成或领域自适应技术以进一步提升策略的泛化能力。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对可变形物体复杂装配任务中高质量路径规划困难的问题，提出了一种基于模仿学习的路径生成方法。该方法首先利用简单动力学模型进行离线无碰撞路径规划，生成大量参考路径；然后通过机器人顺应控制执行这些路径，并由人类操作员进行微调修正；最后基于虚拟路径与人工修正数据集，采用行为克隆（BC）技术训练出能够跟随参考路径完成任务的灵巧策略。该方法旨在减少对复杂物理模型的依赖，通过结合人类演示与学习来提升路径规划的实用性与适应性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.24339" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>