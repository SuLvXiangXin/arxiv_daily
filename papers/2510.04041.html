<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>SITCOM: Scaling Inference-Time COMpute for VLAs - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>SITCOM: Scaling Inference-Time COMpute for VLAs</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.04041" target="_blank" rel="noreferrer">2510.04041</a></span>
        <span>作者: Saxena, Ayudh, Shah, Harsh, Routray, Sandeep, Shah, Rishi Rajesh, Pahwa, Esha</span>
        <span>日期: 2025/10/05</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前机器人学习领域，视觉-语言-动作（VLA）模型通过将自然语言指令转化为单步控制命令，展现出巨大潜力。然而，主流VLA模型（如OpenVLA、RT-1-X、Octo）通常缺乏前瞻机制，在动态、多步骤任务中难以规划长时程行为，且容易因误差累积而失败。这些模型本质上是“一次性”的，给定当前观察和指令，直接输出一个动作，没有评估动作序列长期后果的能力。</p>
<p>本文针对VLA模型在长时程规划、从复合错误中恢复以及动态环境中决策方面的关键局限性，提出了一个新视角：将模型预测控制（MPC）的思想引入VLA的推理过程。核心思路是：在推理时，利用一个学习到的动力学模型对VLA提出的多个候选动作序列进行多步模拟推演，并使用奖励函数对这些模拟轨迹进行评分，选择最优序列执行，从而将单步预测的VLA转变为具有前瞻能力的规划器。</p>
<h2 id="方法详解">方法详解</h2>
<p>SITCOM框架旨在增强任何预训练的VLA模型，使其具备基于模型的推演和奖励排序能力。其整体流程是一个在线的、迭代的规划-执行循环。</p>
<p><strong>整体流程</strong>：在每个决策步骤，给定初始图像观察 ℐ₀ 和任务文本指令 𝒯，框架首先从VLA策略 π_VLA 中以高采样温度采样 n 个候选初始动作。对于每个候选动作，使用学习到的动力学模型 f_dyn 从当前状态开始，进行长度为 l 步的自回归推演来模拟未来状态。在推演的每一步，根据动力学模型预测出的下一帧图像，VLA策略会决定后续动作（实验中采用贪心策略 arg max）。生成了 n 条长度为 l 的模拟轨迹后，一个奖励模型 r 根据每条轨迹的初始状态和最终模拟状态计算奖励值。最后，选择奖励最高的轨迹，将其对应的真实动作序列在真实环境中执行。执行后，获取新的环境观察，重复此过程直至任务完成。</p>
<p><img src="https://arxiv.org/html/2510.04041v1/model_arch1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：SITCOM整体架构示意图。给定初始帧和文本目标描述，VLA预测动作，该动作被输入动力学模型以获得下一帧。然后，利用动力学模型的输出迭代重复此过程以生成动作序列推演。最后，使用奖励模型对动作序列进行排序，并选择其中最佳的在现实世界中执行。</p>
</blockquote>
<p><strong>核心模块1：Transformer动力学模型</strong>。该模型采用编码器-解码器架构，用于预测给定当前状态和动作后的下一个状态（图像）。</p>
<p><img src="https://arxiv.org/html/2510.04041v1/dynamics_model.png" alt="动力学模型架构"></p>
<blockquote>
<p><strong>图2</strong>：动力学模型架构。编码器处理图像块，并与动作信息拼接；解码器预测下一个状态（图像）的块。</p>
</blockquote>
<p>具体而言，编码器处理当前图像块，并将动作信息（例如机器人末端执行器的位姿）与之拼接。解码器则输出下一时刻图像的块预测。为了应对在推理时需要模型进行多步自回归推演而导致的分布偏移问题（即用模型自身的预测结果作为下一步的输入），模型在训练时就被设计为预测多步未来（l_train步）。损失函数结合了L1像素损失和感知损失（LPIPS），以在像素级精确度和感知真实性之间取得平衡。该模型首先在大型真实世界数据集BridgeV2（约25,000条轨迹）上进行预训练，以获得通用的动力学先验，随后在目标仿真环境（SIMPLER）的轨迹上进行微调，以缩小“现实到仿真”（Real2Sim）的差距。此外，论文采用了DAgger风格的适应策略，在训练中使用模型自身的预测作为输入，以更好地适应长时程推演。</p>
<p><strong>核心模块2：VLA策略与微调</strong>。SITCOM兼容任何预训练的VLA。在实验中，作者选择OpenVLA作为基础模型。由于缺乏SIMPLER环境的公开专家数据，且预训练的真实世界模型在仿真中表现不佳，作者自行策划了一个包含100条专家轨迹的数据集用于微调OpenVLA，以缩小Real2Sim差距并提升其在目标环境中的单步策略性能。</p>
<p><strong>核心模块3：奖励模型</strong>。在实验设置中，奖励函数基于仿真器状态计算，包含了夹爪-物体距离、物体-目标点距离以及抓取成功指示器。虽然这依赖于仿真器的完美知识（被称为“预言机”奖励），但论文指出这提供了可解释的信号，并有效支撑了推演选择。</p>
<p><strong>创新点</strong>：1) <strong>推理时计算扩展</strong>：将MPC的“规划-执行”循环应用于VLA，在测试时通过模拟推演增加计算量来提升决策质量，而非修改模型本身。2) <strong>高效、通用的动力学模型</strong>：采用基于Transformer的像素空间预测模型，在大型真实数据上预训练后针对目标环境微调，平衡了效率与泛化能力。3) <strong>针对长时程推演的DAgger适应</strong>：在动力学模型训练中引入自预测输入，缓解多步推演中的分布偏移问题。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：评估在SIMPLER仿真环境中进行，这是一个用于评估通用机器人操作策略的开源套件。使用了7自由度WidowX机械臂，在四个任务上进行测试（见图3）。</p>
<p><img src="https://arxiv.org/html/2510.04041v1/simpler.png" alt="SIMPLER环境与任务"></p>
<blockquote>
<p><strong>图3</strong>：SIMPLER环境及WidowX机械臂的四个不同任务示例。</p>
</blockquote>
<p><strong>基线方法</strong>：对比了当前领先的预训练VLA架构：OpenVLA、RT-1-X和Octo。由于OpenVLA的开源性和流行度，将其作为主要基线，并报告了其经过SIMPLER数据微调后的版本（OpenVLA-SFT）。</p>
<p><strong>关键实验结果</strong>：<br>主要性能对比如表2所示。SITCOM有两种变体：SITCOM (EnvSim) 使用仿真器本身作为完美的“动力学模型”进行推演；SITCOM (World Model) 使用论文中训练的学习型动力学模型。两者均配置为推演长度10步，候选轨迹数5条。</p>
<ul>
<li>SITCOM (EnvSim) 取得了平均76%的成功率，SITCOM (World Model) 取得了72%的成功率。</li>
<li>两者均显著优于基线OpenVLA（1%）及其微调版本OpenVLA-SFT（48%）。</li>
<li>这证明了通过推理时模拟推演进行规划的有效性，即使使用学习到的、不完美的动力学模型，也能带来巨大性能提升。</li>
</ul>
<p><strong>消融与分析</strong>：</p>
<ol>
<li><strong>推演候选数（广度）的影响</strong>：如图4所示，增加候选轨迹数量（n）能持续提升任务成功率，直到25条候选在某些任务上收益开始饱和。但同时，规划时间也随之线性增长（见表4）。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.04041v1/rollout_candidates_plot.png" alt="推演候选数缩放"></p>
<blockquote>
<p><strong>图4</strong>：SITCOM-EnvSim和SITCOM-Dynamics模型随推演候选数增加的性能变化。增加候选数能提升成功率，但收益会饱和。</p>
</blockquote>
<ol start="2">
<li><strong>推演长度（深度）的影响</strong>：如图5所示，不同任务的最佳推演长度（l）不同。复杂任务（如“将茄子放入篮子”）从更长的推演中获益更多，而简单任务可能在较短推演后性能达到平台甚至因误差累积而下降。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.04041v1/roll_out_lengths.png" alt="推演长度缩放"></p>
<blockquote>
<p><strong>图5</strong>：随推演长度变化的性能。对于“Put Eggplant in Basket”等挑战性任务，模型受益于更长的推演。</p>
</blockquote>
<ol start="3">
<li><p><strong>动力学模型质量</strong>：通过FID（越低越好）和OFL（光学流损失，越低越好）指标评估。如表3所示，在SIMPLER轨迹上微调后，动力学模型的FID从17.0提升至11.2，OFL从1.665降至0.992，表明微调显著提升了预测的真实性和时间一致性。</p>
</li>
<li><p><strong>定性分析与失败案例</strong>：</p>
<ul>
<li>VLA策略的失败常源于Real2Sim差距和有限泛化能力，例如在精细抓取任务中因微小偏差导致物体滑落（图6）。</li>
<li>动力学模型在长时程推演中会出现物体重建错误和预测漂移。采用DAgger风格适应训练后，重建质量得到明显改善（图7），但偶尔的失败仍然存在（图8）。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2510.04041v1/merged_frames.jpg" alt="VLA失败案例"></p>
<blockquote>
<p><strong>图6</strong>：失败案例：使用OpenVLA基模型时，机械臂未能成功接近源物体胡萝卜。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.04041v1/traj_comparison.png" alt="动力学模型推演质量对比"></p>
<blockquote>
<p><strong>图7</strong>：世界模型推演的定性比较。顶行：真实轨迹。中行：未经DAgger风格适应的世界模型推演。底行：经过DAgger风格适应的世界模型推演。未适应模型的对象重建问题被高亮显示。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.04041v1/poor_reconst.png" alt="对象重建失败"></p>
<blockquote>
<p><strong>图8</strong>：世界模型推演中对象重建差的示例。尽管DAgger风格适应带来了改进，但在更长的推演视野上，对象一致性的偶然失败仍然明显。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了SITCOM框架，一种通用的推理时规划方法，通过模拟多步动作推演和奖励机制选择最优序列，将单步VLA增强为鲁棒的长时程规划器。</li>
<li>开发并训练了一个高效的、基于Transformer的动力学模型，采用BridgeV2预训练和SIMPLER微调的两阶段策略，并结合DAgger适应以缓解长时程推演误差。</li>
<li>在SIMPLER环境中进行了全面评估，证明了SITCOM能显著提升任务完成率（从48%至72%），并系统分析了推演广度和深度等参数的影响。</li>
</ol>
<p><strong>局限性</strong>（论文自身指出）：</p>
<ol>
<li><strong>对失败状态接触有限</strong>：动力学模型和VLA策略主要在使用成功轨迹策划的数据集上训练，可能导致对分布外（失败）状态的建模和泛化能力不足。</li>
<li><strong>现实世界部署挑战</strong>：当前工作完全在仿真中进行，存在“仿真到现实”（Sim2Real）差距，包括视觉外观和物理动力学差异。</li>
<li><strong>确定性动力学模型</strong>：使用的确定性模型难以捕捉真实世界中的随机性和不确定性。</li>
<li><strong>推理时瓶颈</strong>：多步推演和排序增加了单步决策的计算时间，可能限制现实世界中的控制频率。</li>
</ol>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li>探索在训练数据中引入失败轨迹，以提高模型对错误恢复和分布外状态的鲁棒性。</li>
<li>研究面向真实世界的域适应技术、闭环重规划策略以及概率性（如扩散模型）动力学模型，以应对不确定性和Sim2Real挑战。</li>
<li>通过并行化推演生成、动作块预测或使用单次前向传播即可生成多帧的视频扩散模型，来优化推理时计算效率，以满足高频控制需求。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对Vision-Language-Action模型在机器人控制中缺乏前瞻机制、难以处理长时程规划和动态任务错误累积的核心问题，提出SITCOM框架。该方法基于模型预测控制思想，通过集成预训练VLA、学习动力学模型进行多步动作rollout模拟，并利用奖励函数进行轨迹选择。关键要点包括训练Transformer动力学模型以桥接真实与仿真差距。在SIMPLER环境的多任务评估中，SITCOM结合有效奖励函数，将任务完成率从48%提升至72%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.04041" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>