<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Computer Vision and Pattern Recognition (cs.CV)</span>
      <h1>SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2504.04893" target="_blank" rel="noreferrer">2504.04893</a></span>
        <span>作者: Westerhoff, Justus, Purelku, Erblina, Hackstein, Jakob, Loos, Jonas, Pinetzki, Leo, Rodner, Erik, Hufe, Lorenz</span>
        <span>日期: 2025/04/07</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，以CLIP和SigLIP为代表的视觉语言模型（VLMs）及其扩展的大型视觉语言模型（LVLMs）在多模态任务中表现出色，广泛应用于图像分类、检索和生成。然而，这些模型被发现容易受到“排版攻击”的影响，即通过在图像中嵌入具有误导性语义的可读文本，使模型做出错误预测。现有用于研究此类漏洞的数据集（如PAINT、Materzynska+、RTA-100）在规模和多样性上存在局限，对象和攻击词数量较少，难以全面、可靠地评估模型的脆弱性。本文针对缺乏大规模、多样化真实世界排版攻击数据集的痛点，提出了SCAM数据集，旨在为模型鲁棒性评估提供更全面的资源。本文的核心思路是构建一个包含真实、干净和合成三个对齐版本的大规模排版攻击数据集，并利用其系统地评估当前多模态基础模型的脆弱性，探究影响其鲁棒性的关键因素。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文方法的核心是构建SCAM数据集及配套的评估流程，而非提出新的模型架构。</p>
<p>整体框架分为数据集构建和模型评估两部分。数据集构建的输入是现实世界中的物体图像，输出是三个对齐的数据集变体：1) <strong>SCAM</strong>：包含物体及旁边贴有手写无关攻击词的便利贴的真实攻击图像；2) <strong>NoSCAM</strong>：通过覆盖便利贴区域得到的干净图像，作为基线；3) <strong>SynthSCAM</strong>：在NoSCAM图像上以数字方式（使用Roboto字体）重新嵌入原始攻击词得到的合成攻击图像。这种三部分对齐的设计允许对排版攻击效果进行精确、可控的测量，并能在干净、真实和合成条件之间进行直接比较。模型评估则分别对VLMs和LVLMs进行：VLMs采用零样本分类任务，计算图像嵌入与物体/攻击词文本嵌入的余弦相似度；LVLMs采用基于提示的生成式分类，让模型在物体标签和攻击词之间进行选择。</p>
<p><img src="https://arxiv.org/html/2504.04893v6/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：SCAM评估框架概览。a) 构建三种图像变体：真实攻击（SCAM）、干净基线（NoSCAM）和数字模拟攻击（SynthSCAM）。b) VLM评估：通过计算图像嵌入与文本标签的余弦相似度进行零样本分类。c) LVLM评估：使用提示进行基于生成的分类。结果表明，误导性文本会显著改变预测，模型对文本线索存在过度依赖。</p>
</blockquote>
<p>核心模块包括数据收集与处理。数据由9位贡献者使用不同的智能手机在多样化的室内外环境中采集，确保了图像质量、光照、背景和笔迹的自然变化。所有图像被统一调整至512×512像素。数据标注通过Label Studio手动完成，包括物体标签、攻击词标签以及便利贴所占图像面积百分比。SCAM数据集共包含1162张图像，涵盖660个独特物体标签和206个独特攻击词，形成了1147个独特的物体-词组合，在多样性和规模上显著超越现有数据集。</p>
<p><img src="https://arxiv.org/html/2504.04893v6/x2.png" alt="数据集示例"></p>
<blockquote>
<p><strong>图2</strong>：SCAM数据集的裁剪示例，展示了九位不同贡献者带来的自然多样性，包括不同的智能手机、手写风格和拍摄环境。</p>
</blockquote>
<p>本文的创新点具体体现在：1) <strong>数据集规模与多样性</strong>：SCAM是目前最大、最多样化的真实世界排版攻击数据集。2) <strong>三部分对齐设计</strong>：首次同时提供真实攻击、其干净对应版本以及合成攻击版本，支持跨领域的系统性分析。3) <strong>综合评估</strong>：对大量（111个）VLMs和LVLMs进行了广泛的基准测试，并深入分析了训练数据、模型架构等因素对脆弱性的影响。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：使用了本文提出的SCAM、NoSCAM、SynthSCAM数据集，以及PAINT和RTA-100数据集进行额外评估。实验平台涉及A100和H100 GPU，并通过API评估了闭源模型。</p>
<p><strong>对比方法</strong>：评估了广泛的基线模型。VLMs方面，通过OpenCLIP套件评估了包括CLIP、SigLIP及其不同变体（如RN50, ViT-B/32/16/L/14-336/g/bigG等）在内的99个模型。LVLMs方面，评估了LLaVA系列（7B, 13B, 34B）、Gemma3系列（4B, 12B, 27B）、Llama3.2-vision:90B、Llama4:scout以及通过API访问的GPT-4o、GPT-4o-mini和Claude Sonnet 4，共11个模型。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>普遍脆弱性</strong>：如表1所示，几乎所有模型在面对SCAM攻击时准确率均显著下降。VLMs在SCAM上的准确率平均下降约26个百分点（从NoSCAM的高准确率），在SynthSCAM上下降更甚，达36个百分点。LVLMs也表现出类似脆弱性，例如llava:7b-v1.6和gemma3:4b等较小模型准确率下降超过40-60个百分点。</li>
<li><strong>合成攻击的有效性</strong>：图4和表4表明，合成攻击（SynthSCAM）与真实攻击（SCAM）对模型的影响高度相似，验证了使用合成数据进行可扩展鲁棒性评估的可行性。<br><img src="https://arxiv.org/html/2504.04893v6/x4.png" alt="准确率分布"><blockquote>
<p><strong>图4</strong>：99个VLMs在NoSCAM、SCAM和SynthSCAM数据集上的准确率分布。SCAM有效降低了准确率，且其与SynthSCAM的相似性表明合成攻击能复现真实攻击效果。<br><img src="https://arxiv.org/html/2504.04893v6/x8.png" alt="混淆矩阵对比"><br><strong>表4</strong>：真实攻击与合成攻击之间的对齐情况。平均混淆矩阵显示，合成攻击与真实攻击的结果高度相似，表明合成攻击能紧密复现真实攻击的效果。</p>
</blockquote>
</li>
<li><strong>影响因素分析</strong>：<ul>
<li><strong>训练数据</strong>：如表3所示，训练数据的选择显著影响脆弱性。在LAION数据集上训练的ViT-B模型非常脆弱，而某些经过筛选的CommonPool变体（如基于文本或图像重叠筛选的）则表现出较低的脆弱性。</li>
<li><strong>模型架构</strong>：如表5所示，SigLIP-ViT平均比CLIP-ViT更鲁棒，CLIP-ViT又比CLIP-RN更鲁棒。对于ViT架构，较小的patch size通常导致更高的脆弱性（表5b）。</li>
<li><strong>模型规模</strong>：对于VLMs，模型参数量与对排版攻击的脆弱性之间没有明显相关性（图5）。对于LVLMs，使用更大的LLM主干（如llava:34b-v1.6, gemma3:27b）可以减轻脆弱性，但规模并非唯一决定因素（如llama3.2-vision:90b比llava:34b-v1.6更脆弱）。闭源大模型如Claude Sonnet 4和GPT-4o表现出极强的鲁棒性（准确率下降仅约8%和3%）。<br><img src="https://arxiv.org/html/2504.04893v6/x5.png" alt="模型规模与脆弱性"><blockquote>
<p><strong>图5</strong>：VLMs对排版攻击的脆弱性（SCAM准确率）与模型参数量无关。</p>
</blockquote>
</li>
</ul>
</li>
<li><strong>攻击尺寸的影响</strong>：如图6所示，模型在SCAM上的准确率随着便利贴面积的增加而下降，表明攻击文本的尺寸会影响攻击效果。<br><img src="https://arxiv.org/html/2504.04893v6/x6.png" alt="攻击尺寸影响"><blockquote>
<p><strong>图6</strong>：模型在SCAM上的准确率随便利贴面积增大而下降。阴影区域表示所有99个评估VLMs的均值±标准差。</p>
</blockquote>
</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) <strong>提出了SCAM数据集</strong>：这是目前规模最大、最多样化的真实世界排版攻击数据集，并创新性地提供了真实、干净和合成三个对齐版本，为鲁棒性评估建立了更坚实的基础。2) <strong>验证了合成攻击的有效性</strong>：通过实证表明合成排版攻击能紧密复现真实攻击的效果，支持了使用合成数据进行可扩展评估的现有做法。3) <strong>深入分析了脆弱性根源</strong>：系统性地揭示了训练数据、模型架构（如SigLIP优于CLIP，ViT优于ResNet，小patch更脆弱）以及对于LVLMs而言，视觉编码器的脆弱性和更大LLM主干的缓解作用对模型抗排版攻击能力的影响。</p>
<p>论文自身提到的局限性包括：对LVLMs的评估主要依赖“朴素提示”策略，采用更先进的多提示评估策略可能得到更可靠的鲁棒性度量；研究仅关注英语攻击，未探讨语言特异性因素的影响。</p>
<p>本文的发现对后续研究有多方面启示：首先，SCAM数据集可作为未来研究防御机制和评估模型鲁棒性的重要基准。其次，研究指出LVLMs的脆弱性与其视觉编码器相关，但简单地替换为SCAM评估中更鲁棒的编码器并未可靠地转移鲁棒性，这表明未来需要系统地重新训练LVLMs以评估视觉编码器的作用，并探索是否需要额外的适应步骤。最后，随着多模态模型在安全关键领域的部署，确保其对排版攻击的鲁棒性至关重要，需要进一步研究对齐训练或机制性防御技术等增强鲁棒性的方法。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对多模态基础模型易受“排版攻击”的问题，构建了大规模真实世界攻击数据集SCAM，包含1162张图像及其清洁基线、数字模拟变体，用于系统评估模型鲁棒性。实验表明，排版攻击显著降低视觉-语言模型的性能，且模型训练数据与架构影响其脆弱性；采用更大型语言模型主干能减轻此类攻击的负面影响，同时增强对排文本理解。研究还验证了合成攻击与真实手写攻击效果相近，为后续鲁棒性研究提供了可靠资源与实证依据。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2504.04893" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>