<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.11337" target="_blank" rel="noreferrer">2602.11337</a></span>
        <span>作者: Ranjay Krishna Team</span>
        <span>日期: 2026-02-11</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，为了评估日益通用的、支持开放词汇的机器人策略（如VLA模型），研究社区严重依赖仿真平台进行可扩展、可重复的测试。然而，现有的仿真框架和基准存在显著局限：它们通常只包含几十到几百个场景或物体，缺乏物理真实感或视觉真实感，且支持的任务范围狭窄（多为单场景、短视距技能）。这导致现有基准难以充分评估策略在面对真实世界长尾分布（如多样的场景布局、物体几何和任务指令）时的泛化能力。有效的仿真评估需要同时支持大规模场景多样性、物理真实性、关节交互以及在真实室内环境中的长视距组合任务，并且仿真结果应与真实世界性能强相关。</p>
<p>本文针对现有仿真生态系统在规模、多样性和任务覆盖度上的不足，提出了一个全新的一体化解决方案。核心思路是构建一个完全开源、大规模、支持多种物理仿真器、并提供丰富场景、物体、抓取数据与基准测试套件的生态系统（MolmoSpaces），以支持机器人导航与操作策略的大规模训练与评估，并验证其仿真到真实世界的强相关性。</p>
<h2 id="方法详解">方法详解</h2>
<p>MolmoSpaces是一个端到端的开源生态系统，旨在为机器人学习研究提供可扩展的数据生成、策略训练和基准创建基础。其整体框架由五个核心部分组成：大规模场景数据集（MolmoSpaces-Scenes）、高质量物体数据集（MolmoSpaces-Objects）、大规模抓取标注数据集（MolmoSpaces-Grasp）、基准测试套件（MolmoSpaces-Bench）以及支持多仿真器的工具链。</p>
<p><img src="https://arxiv.org/html/2602.11337v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：MolmoSpaces生态系统概览。它包含大量仿真环境、3D关节物体以及用于大规模训练和评估机器人导航与操作的任务。提供物体元数据、抓取和工具，以生成训练数据、创建基准，并以与真实世界性能相关的方式评估策略。</p>
</blockquote>
<p><strong>1. 大规模场景数据集 (MolmoSpaces-Scenes)</strong><br>该部分包含超过23万个多样化的室内环境，涵盖从手工制作的家庭场景到程序生成的多房间房屋。具体包括五个子数据集：</p>
<ul>
<li><strong>MSCrafted</strong>: 120个手工制作的单房间场景（厨房、卧室等）。</li>
<li><strong>MSProc</strong>: 1.2万个程序生成的住宅场景（1-10个房间）。</li>
<li><strong>MSProcObja</strong>: 11万个包含THOR和Objaverse物体的场景。</li>
<li><strong>MSMultiType</strong>: 11万个通过LLM引导程序生成的多样化场景类型（如艺术工作室、猫咖、博物馆）。</li>
<li><strong>MSTwin</strong>: 1个真实厨房的高保真数字孪生。<br>所有场景都经过物理验证，确保物体稳定、可拾取、可交互（关节可动）。验证包括稳定性测试、相交测试、提升测试和关节测试。在MuJoCo中，超过95%的环境通过了稳定性和操作检查（关节测试通过率最低，在MSMultiType中为65%）。场景支持在MuJoCo、IsaacSim和ManiSkill等多种仿真器中加载。</li>
</ul>
<p><img src="https://arxiv.org/html/2602.11337v1/x2.png" alt="场景示例"></p>
<blockquote>
<p><strong>图2</strong>：来自MolmoSpaces-Scenes-MultiType的多样化场景环境示例，使用Filament渲染引擎渲染。生态系统包含艺术工作室、猫咖、休息室、博物馆等多种场景，所有场景都预置了可操作物体。</p>
</blockquote>
<p><strong>2. 高质量物体数据集 (MolmoSpaces-Objects)</strong><br>该部分包含超过13万个高质量刚体和关节物体模型，具有丰富的语义和物理元数据。物体来源包括1.6k个来自AI2-THOR的物体和12.9万个来自Objaverse的物体。Objaverse物体涵盖了近2.8k个WordNet同义词集，并经过筛选以确保尺度一致性、纹理质量、文件大小和碰撞体质量。所有物体都附带了物理属性（质量、密度估计）、语义标签、凸包碰撞体以及规范的坐标定义，并转换为兼容MuJoCo、IsaacSim和ManiSkill的格式。</p>
<p><img src="https://arxiv.org/html/2602.11337v1/x3.png" alt="物体示例"></p>
<blockquote>
<p><strong>图4</strong>：生态系统中物体类型的随机采样，展示了不同尺寸、形状和关节类型的物体。这些示例使用Filament渲染。</p>
</blockquote>
<p><strong>3. 大规模抓取数据集 (MolmoSpaces-Grasp)</strong><br>该部分为4.8万个可交互物体提供了超过4200万个6自由度抓取姿态标注。抓取生成流程针对刚性物体和关节物体分别处理。对于刚性物体，在整个网格表面采样基于Robotiq 2F-85夹持器的对映接触点；对于关节物体，采样限制在对应于把手或其他功能交互点的叶子组件上。采样后，通过聚类确保多样性，并进行物理仿真验证以过滤掉不稳定的抓取。最终，每个物体保留最多1000个多样且稳健的抓取。</p>
<p><img src="https://arxiv.org/html/2602.11337v1/x4.png" alt="抓取生成流程"></p>
<blockquote>
<p><strong>图5</strong>：抓取生成流程包含针对刚性资产和关节资产的独立流程。生成了超过4200万个经过验证的抓取，可用于创建脚本化的交互策略。抓取可在不同的仿真环境中使用，右侧展示了在Isaac中的示例。</p>
</blockquote>
<p><strong>4. 基准测试套件与仿真基础设施 (MolmoSpaces-Bench)</strong><br>基于上述资产，论文构建了MolmoSpaces-Bench，一个包含8个基础任务的基准套件：导航到（<code>navigate-to</code>）、拾取（<code>pick</code>）、拾取放置（<code>pick-and-place</code>）、拾取放置到旁边（<code>pick-and-place-next-to</code>）、按颜色拾取放置（<code>pick-and-place-color</code>）、打开（<code>open</code>）、关闭（<code>close</code>）和开门（<code>open-door</code>）。该基准旨在零样本（无需在基准数据上微调）评估策略在未见过的环境和物体上的表现。基础设施提供了任务组合、基准创建和可重复评估的工具，并支持生成用于训练的大规模交互数据。</p>
<p>与现有方法相比，MolmoSpaces的核心创新在于其前所未有的规模（场景、物体、抓取数量）、多样性（涵盖家庭与非家庭场景）、物理真实性（经过严格验证）、以及对多仿真器的原生支持（MuJoCo, IsaacSim, ManiSkill），同时提供了即用型的大规模抓取数据和基准测试。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验主要基于MolmoSpaces-Bench进行，在超过2万个多样化的室内场景（验证集）和超过2.2万个可交互物体上，对多种先进的零样本机器人策略进行了评估。</p>
<p><strong>对比的基线方法</strong>包括：经典的模块化方法（Modular），以及多代视觉-语言-动作（VLA）模型，如<code>RT-2-X</code>、<code>Pi0-1B</code>、<code>Pi0-4B</code>、<code>Pi0.5-4B</code>和<code>Pi0.5-13B</code>。</p>
<p><strong>关键实验结果总结如下</strong>：</p>
<ol>
<li><strong>仿真到真实（Sim-to-Real）相关性</strong>：在等效的实物拾取任务上，策略在仿真基准中的表现与其实物成功率强相关（皮尔逊相关系数 R^2 ≈ 0.92）。这验证了高保真仿真可以作为真实世界性能的可靠代理。</li>
<li><strong>基准性能区分度</strong>：MolmoSpaces-Bench能够有效区分不同策略的性能。例如，在<code>pick-and-place</code>任务中，<code>Pi0.5-13B</code>的成功率为73.1%，显著高于<code>Pi0-1B</code>的48.5%。更新的、能力更强的VLA模型在大多数任务上都优于早期版本和模块化基线。</li>
<li><strong>对干扰的敏感性分析</strong>：通过系统性地扰动场景参数和传感器输入，研究揭示了策略的脆弱性。例如，改变语言指令的措辞、初始关节位置或造成相机遮挡，都会导致某些策略（尤其是早期VLA模型）的成功率显著下降。</li>
</ol>
<p><img src="https://arxiv.org/html/2602.11337v1/x8.png" alt="基准任务性能对比"></p>
<blockquote>
<p><strong>图19</strong>：不同策略在MolmoSpaces-Bench 8个任务上的零样本成功率。展示了VLA模型（Pi0， Pi0.5）和模块化基线（Modular）的性能，可见更新、更大的模型普遍表现更好。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.11337v1/x9.png" alt="仿真到真实相关性"></p>
<blockquote>
<p><strong>图20</strong>：仿真到真实性能相关性分析。左图展示了在仿真基准（x轴）与真实世界（y轴）评估中，不同策略的拾取任务成功率呈强线性关系。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.11337v1/x10.png" alt="指令扰动分析"></p>
<blockquote>
<p><strong>图21</strong>：对语言指令进行扰动（如改变介词、同义词）对<code>Pi0-4B</code>和<code>Pi0.5-4B</code>模型在<code>pick-and-place-next-to</code>任务上成功率的影响。结果表明模型对指令措辞变化敏感。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.11337v1/x11.png" alt="初始位置扰动分析"></p>
<blockquote>
<p><strong>图22</strong>：改变机器人初始关节位置对<code>Pi0-4B</code>和<code>Pi0.5-4B</code>模型在<code>pick</code>任务上成功率的影响。初始位姿的微小变化可能导致性能显著下降。</p>
</blockquote>
<p><strong>消融实验</strong>：论文通过在不同场景数据集（MSCrafted, MSProc, MSMultiType）上评估策略，展示了场景多样性对泛化能力测试的重要性。在相对简单、分布内的MSCrafted场景上，所有策略的性能都最高；而在更具挑战性、分布外的MSMultiType多样化场景上，性能普遍下降，这凸显了在多样化环境中评估的必要性。</p>
<p><img src="https://arxiv.org/html/2602.11337v1/x13.png" alt="场景多样性影响"></p>
<blockquote>
<p><strong>图24</strong>：<code>Pi0.5-4B</code>模型在不同场景数据集（MSCrafted， MSProc， MSMultiType）上的任务成功率。在更复杂、多样化的MSMultiType场景上，性能通常更低，表明其泛化挑战。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：第一，构建并开源了一个迄今为止规模最大、最多样化的机器人导航与操作仿真生态系统（MolmoSpaces），包含超过23万场景、13万物体和4200万抓取标注。第二，设计并验证了一个基于该生态系统的基准测试套件（MolmoSpaces-Bench），它能够有效区分不同零样本策略的性能，并展现出与真实世界性能的强相关性（R^2≈0.92）。第三，通过系统性评估，揭示了当前先进VLA策略在语言指令鲁棒性、初始状态敏感性和视觉遮挡等方面的脆弱性，为未来改进指明了方向。</p>
<p>论文自身提到的局限性包括：在MSMultiType数据集中，关节物体的测试通过率相对较低（65.2%），这主要是由于场景布局为了确保导航通畅而偏向于放置大型物体，有时会阻碍对关节物体的操作。</p>
<p>MolmoSpaces的发布对后续研究具有重要启示。首先，它为社区提供了一个可扩展的、物理真实的测试平台，能够更严谨地评估策略在长尾分布下的泛化能力，从而推动更鲁棒、更通用的机器人策略发展。其次，其开源特性允许研究人员利用其丰富的资产和工具链生成多样化的训练数据，以解决数据稀缺和多样性不足的问题。最后，其多仿真器支持的特性促进了方法在不同仿真引擎间的可移植性和可比性研究。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人策略在多样化现实环境中泛化能力不足的问题，提出了MolmoSpaces大规模开放生态系统。其关键技术包括：构建了包含超过23万个多样化室内场景和13万个带丰富标注物体资产（含48k可操作物体及42M稳定抓取）的模拟器无关环境，并设计了涵盖导航与操作的MolmoSpaces-Bench基准测试套件。实验表明，该基准测试具备极强的模拟到现实相关性（R=0.96，ρ=0.98），能有效评估策略性能并识别关键敏感因素。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.11337" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>