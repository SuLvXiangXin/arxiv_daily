<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.06048" target="_blank" rel="noreferrer">2509.06048</a></span>
        <span>作者: Zhendong Dai Team</span>
        <span>日期: 2025-09-07</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在仓储物流行业快速发展的背景下，货物的打包逐渐受到学术界和工业界的关注。鞋类产品的打包是成对物品打包任务的典型代表，涉及不规则形状和可变形物体。尽管已有关于鞋类打包的研究，但现有方法未考虑由于鞋子不规则形状导致的不同初始状态，以及标准的打包摆放姿态。当前主流方法通常假设物体可直接抓取和放置，或仅考虑单一初始状态（如鞋面朝上），忽略了将任意初始状态的鞋子对重新定向并摆放到鞋盒内特定相对姿态的需求。此外，鞋子存在较大的类内形状差异，且在操作过程中可能发生变形，这给感知和操作带来了挑战。</p>
<p>本文针对鞋类打包中因初始状态多样、形状不规则且可变形导致的感知与操作难题，提出了一个新的视角：利用语义关键点作为统一且信息丰富的物体表示，并结合环境约束设计高效的重定向策略。核心思路是：提出一个包含基于语义关键点的感知模块、针对不同状态鞋子的重定向规划器以及打包任务规划器的完整机器人操作框架，以完成任意初始状态下成对鞋子的标准化打包。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的机器人操作框架包含三个核心部分：视觉感知模块、鞋子重定向方法和打包任务规划器。整体流程为：首先通过感知模块获取鞋子与鞋盒的关键点、状态及姿态；然后根据鞋子的初始状态，调用相应的重定向方法将其调整至适合打包的状态（主要为侧面状态）；最后，任务规划器基于感知信息和重定向能力，为给定的鞋子对初始状态组合规划最优的状态转换策略和摆放顺序，完成打包。</p>
<p><img src="https://arxiv.org/html/2509.06048v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：视觉感知模块的流程总览。包括物体检测（YOLO）、关键点检测（KeypointNet）以及基于关键点的状态与姿态估计。</p>
</blockquote>
<p><strong>视觉感知模块</strong>：该模块旨在适应鞋子类内差异大且可变形的特性，并提取丰富的任务相关信息。其流程如图2所示：</p>
<ol>
<li><strong>物体检测</strong>：使用YOLO从RGB-D图像中检测鞋子和鞋盒的类别与二维边界框。</li>
<li><strong>关键点检测</strong>：提出一个名为KeypointNet的编解码器结构网络，输入裁剪后的鞋子RGB图像，输出五个语义关键点的像素级热图：鞋头、鞋跟、鞋口、外侧、内侧。网络在编码器和解码器之间插入了五个堆叠的基础残差块以提取更好特征并防止退化。损失函数采用热图均方误差损失（$\mathcal{L}<em>{mse}$）与关键点归一化欧氏距离损失（$\mathcal{L}</em>{ned}$）的线性组合（$\mathcal{L}<em>{all}=\alpha\mathcal{L}</em>{mse}+(1-\alpha)\mathcal{L}_{ned}$），其中$\alpha=0.618$，这种双重损失框架结合了密集热图监督和稀疏关键点回归，加速了收敛。</li>
<li><strong>状态与姿态估计</strong>：基于检测到的关键点，通过几何规则推断信息。<ul>
<li><strong>状态分类</strong>：根据关键点的可见性规则（公式5）将鞋子状态分为顶面（所有关键点可见）、侧面（内侧或外侧关键点不可见）和底面（鞋口关键点不可见）。</li>
<li><strong>姿态与抓取位姿估计</strong>：以鞋头和鞋跟中点为原点，鞋头到鞋跟方向为X轴，垂直于鞋底方向为Z轴建立坐标系。鞋子的偏航角（$\theta_{grasp}$）由当前鞋头-鞋跟向量与初始相机X轴的夹角计算得出（公式6），作为抓取角度。抓取位置设为鞋子坐标系原点。</li>
<li><strong>鞋盒姿态估计</strong>：通过计算鞋盒的最小外接矩形和凸包，提取四个直角角点作为关键点，进而确定鞋盒的位置和方向。</li>
</ul>
</li>
</ol>
<p><strong>鞋子重定向方法</strong>：为了使鞋子达到打包所需的侧面状态及正确配对（内侧对向外侧），设计了两种重定向方法。</p>
<ol>
<li><strong>基于操作基元的推翻方法</strong>：适用于所有三种初始状态，通过机器人推动使鞋子绕一条边（推翻边）旋转并依靠重力落至新状态。该方法利用了软体夹爪的柔顺性来适应鞋子的变形。如图3所示，针对不同状态设计了具体的推动动作，例如从底面到侧面的推动，以及从侧面到顶面（或反向）的旋转动作。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.06048v1/x3.png" alt="重定向基元"></p>
<blockquote>
<p><strong>图3</strong>：用于鞋子重定向的推翻操作基元。(a)将状态从底面改变为侧面的推动动作；(b)和(c)展示用于将状态从侧面改变为顶面及其反向的旋转动作及其运动学模型。</p>
</blockquote>
<ol start="2">
<li><strong>基于接触的高效重定向方法</strong>：专门针对顶面状态的鞋子，提出了一种利用鞋盒边缘接触和重力的快速重定向策略。如图4所示，机器人将顶面状态的鞋子抓起，然后将其鞋口边缘与鞋盒的直立边缘接触并释放，鞋子在重力作用下会自然翻转为侧面状态。这种方法避免了在桌面上进行复杂的推翻操作，显著提高了效率。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.06048v1/x4.png" alt="接触重定向"></p>
<blockquote>
<p><strong>图4</strong>：利用鞋盒边缘接触和重力对顶面状态鞋子进行快速重定向的流程示意图。</p>
</blockquote>
<p><strong>打包任务规划器</strong>：该规划器整合了感知信息与重定向方法。对于任意给定的两只鞋子的初始状态组合，规划器会生成一个最优的状态转换策略序列，将两只鞋子都转换到侧面状态且确保配对正确（一只内侧朝上，另一只外侧朝上）。此外，规划器还确定了鞋子的摆放顺序（例如，先放哪只鞋），以最大化最终打包的成功率。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验平台包括一个6自由度机械臂、一个软体夹爪和一个RGB-D相机。使用了包含1172张图像的多物体数据集（训练912张，测试260张）用于YOLO训练，以及包含557张单鞋图像的数据集（训练367张，测试190张）用于KeypointNet、状态分类和姿态估计模型的训练与测试。真实世界实验涉及多种类型（运动鞋、皮鞋、靴子等）的鞋子。</p>
<p><strong>关键点检测与姿态估计性能</strong>：在测试集上，KeypointNet的平均关键点检测误差为6.02像素（图像尺寸256x256），推理速度约36 FPS。与直接训练ResNet进行状态分类和CenterPose进行姿态估计的基线方法相比，本文提出的基于关键点几何推理的方法在状态分类准确率（98.94% vs. 94.21%）和姿态估计误差（偏航角误差：2.92° vs. 8.33°；翻滚角误差：3.85° vs. 10.26°）上均表现更优。</p>
<p><img src="https://arxiv.org/html/2509.06048v1/x5.png" alt="状态分类与姿态估计对比"></p>
<blockquote>
<p><strong>图5</strong>：状态分类与姿态估计性能对比。基于关键点几何推理的方法（Ours）在准确率和角度误差上均优于直接使用深度学习模型（ResNet, CenterPose）的基线方法。</p>
</blockquote>
<p><strong>重定向方法鲁棒性</strong>：对三种重定向方法（推翻：顶面→侧面，推翻：底面→侧面，接触：顶面→侧面）在多种鞋型上进行了各20次测试。基于接触的方法成功率最高（100%），且平均耗时最短（7.5秒）。基于推翻的方法对顶面和底面状态的成功率分别为85%和80%。</p>
<p><img src="https://arxiv.org/html/2509.06048v1/x6.png" alt="重定向成功率与耗时"></p>
<blockquote>
<p><strong>图6</strong>：不同重定向方法的成功率和平均耗时对比。基于接触的方法（Contact）在成功率和效率上均表现最佳。</p>
</blockquote>
<p><strong>打包策略有效性</strong>：测试了四种不同的鞋子摆放顺序策略。实验表明，采用“先摆放处于正确配对状态的鞋子”的策略（策略C）获得了最高的整体打包成功率（86.7%）。</p>
<p><img src="https://arxiv.org/html/2509.06048v1/x7.png" alt="打包顺序策略成功率"></p>
<blockquote>
<p><strong>图7</strong>：不同鞋子摆放顺序策略的整体打包成功率对比。策略C（先放已处于正确配对状态的鞋）效果最好。</p>
</blockquote>
<p><strong>消融实验</strong>：</p>
<ol>
<li><strong>接触重定向方法的影响</strong>：比较了在打包框架中启用或禁用基于接触的重定向方法的性能。启用后，整体打包成功率从76.7%提升至86.7%，平均任务完成时间从64.0秒减少至51.8秒。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.06048v1/x8.png" alt="接触方法消融实验"></p>
<blockquote>
<p><strong>图8</strong>：消融实验：启用基于接触的重定向方法显著提高了打包成功率和效率。</p>
</blockquote>
<ol start="2">
<li><strong>感知模块组件贡献</strong>：分别评估了仅使用YOLO边界框中心、使用完整感知模块但无状态信息、以及使用完整感知模块（含状态信息）进行打包规划的效果。完整感知模块带来了最高的成功率（86.7%）和最短的耗时。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.06048v1/x9.png" alt="感知模块消融实验"></p>
<blockquote>
<p><strong>图9</strong>：感知模块消融实验：完整感知模块（含状态信息）对打包成功率和效率贡献最大。</p>
</blockquote>
<p><strong>真实世界打包演示</strong>：框架成功处理了多种鞋型和任意初始状态组合的打包任务，图10展示了从初始混乱状态到最终规范打包的完整过程。</p>
<p><img src="https://arxiv.org/html/2509.06048v1/x10.png" alt="真实世界打包流程"></p>
<blockquote>
<p><strong>图10</strong>：真实世界鞋类打包任务流程示例，展示了从初始状态感知、重定向到最终摆放的完整过程。</p>
</blockquote>
<p><strong>与现有方法对比</strong>：与之前仅考虑顶面初始状态的工作相比，本文方法能处理任意初始状态，且因引入了接触重定向，成功率更高（86.7% vs. 70%）。</p>
<p><img src="https://arxiv.org/html/2509.06048v1/x11.png" alt="与现有方法对比"></p>
<blockquote>
<p><strong>图11</strong>：与现有方法（仅处理顶面状态）的对比。本文方法能处理任意初始状态，且打包成功率更高。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) 提出了一个结合语义关键点与类内几何特征的视觉感知模块，不仅能适应大类内差异，还能推断出尺寸、状态、姿态和操作点等多维信息；2) 针对3D可变形物体，提出了基于操作基元（利用软体夹爪顺应性）的重定向方法，并创新性地提出了利用物体间接触（鞋盒边缘）和重力的高效重定向方法，为多物体操作提供了新视角；3) 构建了一个完整的、可处理任意初始状态组合的成对物体打包机器人操作框架，并提供了最优的状态转换与摆放顺序策略。</p>
<p>论文提到的局限性包括：感知模块在严重遮挡或极端变形情况下可能失效；重定向方法（特别是推翻）的成功率仍有提升空间，且可能受桌面摩擦等环境影响。</p>
<p>本工作对后续研究的启示在于：展示了语义关键点作为丰富、紧凑的物体表示在复杂操作任务中的潜力；将环境中的其他物体（如容器）作为操作资源而非障碍的思路，可扩展至更广泛的多物体交互场景；针对刚性-柔性耦合物体的操作策略研究，对处理现实世界中大量存在的类似物体具有参考价值。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对鞋类打包任务中因尺寸、形状和软度差异导致的初始状态多样、无法直接抓取放置的问题，提出基于语义关键点的机器人操作框架。关键技术包括：语义关键点感知模块，通过几何特征推断鞋的状态、姿态和操作点；针对不同状态设计基元重新定向方法，并利用盒边接触和重力实现快速重新定向；基于此的打包规划器提供最优打包策略。真实实验验证了重新定向方法的鲁棒性和打包策略对各种鞋型的有效性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.06048" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>