<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>CoFreeVLA: Collision-Free Dual-Arm Manipulation via Vision-Language-Action Model and Risk Estimation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>CoFreeVLA: Collision-Free Dual-Arm Manipulation via Vision-Language-Action Model and Risk Estimation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.21712" target="_blank" rel="noreferrer">2601.21712</a></span>
        <span>作者: Zhai, Xuanran, Ou, Binkai, Yu, Qiaojun, Hao, Ce, Liu, Yaohua</span>
        <span>日期: 2026/01/29</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作（VLA）模型已成为机器人控制的有力范式，能够根据自然语言指令和视觉观察生成可执行动作。然而，这些模型在单臂操作任务中表现出色，扩展到双臂系统时却面临新挑战。双臂操作需要协调两个高自由度机械臂，使得空间推理和安全规划更加复杂。现有方法主要集中于通过经典轨迹优化来避免与环境的碰撞，但在端到端VLA框架下，双臂之间或手臂与抓取物体之间的自碰撞问题尚未得到充分探索。此类自碰撞可能导致任务失败、硬件损坏或不安全行为，是部署VLA双臂系统的根本障碍。</p>
<p>本文针对双臂VLA操作中自碰撞风险未被显式建模的痛点，提出了一种风险感知的VLA框架。核心思路是：在端到端VLA模型基础上，引入一个短视距自碰撞风险估计器，通过预测当前状态和计划动作的碰撞可能性，在运行时对高风险动作进行阻塞、引导系统恢复至安全状态，并利用风险反馈优化VLA策略本身，从而实现更安全的双臂操作。</p>
<h2 id="方法详解">方法详解</h2>
<p>CoFreeVLA的整体框架是一个集成了风险估计与安全干预的闭环控制系统。其核心流程是：在每个控制步，VLA策略根据当前状态（包括视觉、语言和本体感知）生成一个短视距的动作序列；自碰撞风险估计器评估执行该序列的碰撞风险；根据风险值是否超过阈值，系统决定是正常执行动作、进入保护性恢复模式，或是利用风险信息在线优化动作序列。</p>
<p><img src="https://arxiv.org/html/2601.21712v2/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：CoFreeVLA方法总览。(a) 风险估计器：输入状态-动作对，通过交叉注意力模块和三个预测头输出碰撞风险 r、最小距离 d 和碰撞时间 τ。(b) 数据收集与 (c) 数据集：对每个状态采样候选动作，并通过碰撞检查为其打标签。(d) 运行时系统：持续估计风险，若超过阈值则阻塞策略执行并将手臂恢复至安全配置，之后恢复任务执行。</p>
</blockquote>
<p><strong>核心模块一：自碰撞风险估计器</strong><br>该估计器是CoFreeVLA的核心安全组件。其输入包括：当前本体感知状态（双臂末端位姿 $x_t$ 和夹爪状态 $g_t$）、从VLA主干提取的视觉嵌入 $z_t$，以及VLA策略生成的短视距动作序列 $A_{t:t+H-1}$。输出为校准后的碰撞风险 $\hat{r}<em>t \in [0,1]$，以及可选的几何替代量：预测的最小间距 $\hat{d}</em>{\min}$ (mm) 和首次碰撞时间 $\hat{\tau}<em>{\text{ttc}}$ (s)。网络结构上，输入被分为本体/动作流和视觉流。前者将 $(x_t, g_t)$ 与 $A</em>{t:t+H-1}$ 编码为带位置编码的长度 $H$ 的令牌序列；后者提供紧凑的视觉特征 $z_t$。一个轻量级时序编码器（对于小的 $H$ 使用MLP，$H \geq 5$ 时使用小型Transformer）通过交叉注意力融合两个流，最后通过池化和预测头输出三个目标值。网络被设计为在5毫秒内完成推理，以适应控制频率（10-50 Hz）。</p>
<p><strong>训练数据与策略</strong><br>训练采用两阶段策略。预训练阶段：使用基于模型的碰撞检查器（如网格距离查询）生成合成数据。从状态 $s_t$ 出发，对VLA策略加入抖动和波束变体进行 rollout，采样候选动作序列，并记录三个标签：$H$ 步内是否发生碰撞的二进制指示 $y_t^{\mathrm{bin}}$、整个视距内的最小距离 $y_t^d$ 以及首次碰撞时间 $y_t^{\mathrm{ttc}}$。训练时会对小距离 $y_t^d$（近失样本）进行过采样以强调临界情况。后训练阶段：在真实机器人上，使用VLA策略在安全防护模式下进行 rollout，根据接触事件、扭矩峰值和视觉重叠重新标注数据，以校正预训练模型并适应抓取不确定性。损失函数结合了二元交叉熵（BCE，对假阴性赋予更高权重）和回归损失：$\mathcal{L}=\lambda_{\mathrm{bce}}\mathrm{BCE}(\hat{r}<em>t, y_t^{\mathrm{bin}})+\lambda</em>{d}\lVert\hat{d}<em>{\min}-y_t^{d}\rVert</em>{2}^{2}+\lambda_{\mathrm{ttc}}\lVert\hat{\tau}<em>{\mathrm{ttc}}-y</em>{t}^{\mathrm{ttc}}\rVert_{1}$。训练后，在留出集上应用温度缩放来校准风险值 $\hat{r}_t$。</p>
<p><strong>核心模块二：风险感知的VLA控制与优化</strong><br>风险估计器通过三种方式集成到控制循环中：</p>
<ol>
<li><strong>风险门控以停止危险动作</strong>：在每个控制步，若估计风险 $\hat{r}<em>t$ 超过上限阈值 $\tau</em>{\uparrow}$，则阻塞当前动作 $a_t$ 的执行，系统进入保护模式。仅当 $\hat{r}<em>t$ 降至下限阈值 $\tau</em>{\downarrow}$（$\tau_{\downarrow} &lt; \tau_{\uparrow}$ 以迟滞防止抖动）以下时，才恢复执行。作为软门控，未阻塞时可将指令速度缩放为 $\alpha_t = \mathrm{clip}(1-\hat{r}<em>t / \tau</em>{\uparrow}, 0, 1)$。</li>
<li><strong>恢复至安全状态</strong>：当动作被阻塞时，系统通过优化风险引导的目标来合成一个短时恢复序列 $A^{\mathrm{rec}}<em>{t:t+h-1}$：$A^{\mathrm{rec}}</em>{t:t+h-1}\leftarrow\arg\min_{A};E_{\phi}(s_t, A)+\lambda|A|^{2}$，在关节和速度限制下通过几步投影梯度下降求解，以局部降低预测的碰撞风险。当 $\hat{r}<em>t \leq \tau</em>{\downarrow}$ 连续保持 $K$ 个周期时，恢复终止。</li>
<li><strong>策略优化以实现无碰撞控制</strong>：除了在线干预，还通过安全感知目标对VLA策略进行微调。方法包括：(i) 在过滤后的安全数据集 $\mathcal{D}<em>{\mathrm{safe}}$ 上进行监督微调，损失函数加权 $w(s)=\exp(-\kappa,E</em>{\phi}(s, A_{t:t+H-1}))$，使模型偏向无碰撞的目标分布；(ii) 测试时动作优化：在线求解 $\min_{A^{\prime}}\ \alpha,|A^{\prime}-A_{t:t+H-1}|^{2}+\beta,E_{\phi}(s_{t}, A^{\prime})$，仅执行优化后的第一步动作以保持响应性。</li>
</ol>
<p>与现有方法相比，CoFreeVLA的创新点在于将<strong>短视距、基于学习的自碰撞风险预测</strong>深度集成到端到端VLA的决策循环中，实现了从“事后检查”到“事前预防”的转变，并通过恢复和策略优化形成了完整的安全增强闭环。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在基于PiPER风格的双臂移动操作机器人平台上进行，评估了五个真实机器人双手操作任务。在相同的协议（相同的指令、感知和重置条件）下，将CoFreeVLA与基线方法RDT-1B和APEX进行比较，报告碰撞率（发生自碰撞的试验比例）和总体任务成功率。</p>
<p><img src="https://arxiv.org/html/2601.21712v2/x2.png" alt="实验结果"></p>
<blockquote>
<p><strong>图2</strong>：五个双臂操作任务的实验结果。每个任务进行10次试验，评估碰撞率和成功率。</p>
</blockquote>
<p><strong>关键实验结果总结</strong>：</p>
<ol>
<li><strong>在双臂干扰显著的任务中安全提升明显</strong>：在“倾倒豆子”任务中，双臂交叉动作频繁，CoFreeVLA显著降低了碰撞率（RDT从 8/10 降至 2/10，APEX从 6/10 降至 2/10），证明了短视距风险门控和恢复在必须交叉双臂场景下的有效性。</li>
<li><strong>在精密操作任务中存在校准挑战</strong>：在“笔帽移除”、“工具交接”、“管子放置”、“杯子嵌套”等精密任务中，基线方法本身碰撞率就很低（约 1/10），而CoFreeVLA的当前校准设置有时导致了更高的碰撞率（分别为 4/10, 3/10, 2/10, 5/10）。论文指出这些错误源于保守的阈值、接触转换附近的假阴性以及偶尔的恢复振荡。</li>
<li><strong>任务成功率与效率</strong>：所有方法的任务成功率在本研究中相当（均为 1/10）。风险推断增加的延迟可忽略不计（每步小于5毫秒），通过迟滞阈值控制，被阻塞步骤的比例保持在预算内。</li>
</ol>
<p><strong>消融实验与组件贡献</strong>：<br>虽然论文未以独立图表展示消融实验，但通过方法描述和结果分析可以总结出各组件的作用。风险估计器的预训练提供了初始的碰撞预测能力，是安全干预的基础。真实机器人上的后训练对于校准模型、减少因抓取不确定性和模型误差导致的假阳性/假阴性至关重要。风险门控和恢复机制直接阻止了实验中观察到的大部分高风险碰撞。策略优化则从数据分布层面长期引导VLA生成更安全的动作。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：</p>
<ol>
<li>提出了CoFreeVLA框架，首次在端到端VLA框架中系统性地解决了双臂及臂-物自碰撞这一被忽视的问题。</li>
<li>设计了一个轻量级、短视距的自碰撞风险估计器，能够从视觉观察和动作序列预测碰撞可能性，并将其创新性地集成到执行、恢复和策略优化三个环节中。</li>
<li>在真实机器人双臂任务上进行了广泛实验，验证了CoFreeVLA在降低自碰撞率方面的有效性，特别是在双臂空间干扰显著的任务中。</li>
</ol>
<p>论文自身提到的局限性包括：在精密操作任务中，由于保守的阈值设置和近接触转换时的预测误差，可能导致碰撞率反而高于基线；风险估计器的性能依赖于用于生成预训练标签的几何模型精度。</p>
<p>本工作对后续研究的启示在于：为增强VLA模型的安全性提供了一种可扩展的范式，即通过一个可学习的、轻量的风险预测模块与VLA主干松耦合。两阶段训练策略（模型预训练+真实数据后训练）平衡了数据获取成本与模型适应性。未来工作可探索更精细的风险校准、结合触觉等多模态感知以减少不确定性，以及将类似的风险估计框架扩展到更复杂的多机器人或人机协作场景中。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出CoFreeVLA框架，解决现有视觉-语言-动作模型在双机械臂操作中因自碰撞（机械臂间或与抓持物体碰撞）导致的安全风险问题。核心方法是引入一个短时域自碰撞风险估计器，该模块基于本体感知、视觉嵌入和规划动作预测碰撞概率，并通过拦截危险指令、风险引导恢复及策略优化三重机制保障安全。实验在PiPER机器人上进行五项双机械臂任务，结果表明CoFreeVLA相比RDT和APEX方法，显著降低了自碰撞率并提高了任务成功率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.21712" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>