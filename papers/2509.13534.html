<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.13534" target="_blank" rel="noreferrer">2509.13534</a></span>
        <span>作者: Zheng, Chunxin, Chen, Kai, Bi, Zhihai, Li, Yulin, Pan, Liang, Zhou, Jinni, Li, Haoang, Ma, Jun</span>
        <span>日期: 2025/09/16</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人的全身操控（Whole-Body Manipulation, WBM）为执行涉及笨重物体的拥抱式任务提供了一种有前景的方法。传统的仅依赖末端执行器的抓取方式，由于固有的稳定性和负载限制，在此类场景中能力有限。现有的WBM方法主要分为模型基和基于学习的两类。模型基方法需要指定接触点和接触序列，但由于人形机器人自由度（DoF）高，计算成本昂贵。基于学习的方法通常依赖于精心设计的奖励函数，但在这种接触密集、动态不稳定的场景中难以产生鲁棒且连贯的行为。此外，现有方法通常依赖简化的机器人模型（如将连杆简化为线段）来估计空间位置，无法精确感知连杆表面的几何形状，导致接触丰富的操作任务中位置估计误差大，最终可能导致任务失败。</p>
<p>本文针对人形机器人拥抱笨重物体这一具体的长时程、多接触操作任务，提出了一个整合了预训练人类运动先验（motion prior）与神经符号距离场（Neural Signed Distance Field, NSDF）表示的强化学习框架。核心思路是通过师生架构从大规模人类运动数据中提炼出运动先验，为策略训练提供自然且物理可行的动作分布，并结合NSDF提供精确连续的几何感知，从而引导机器人上半身与物体保持持续接触，实现鲁棒的全身拥抱操控。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架包含数据处理、运动先验蒸馏和拥抱策略训练三个主要阶段，如图2所示。</p>
<p><img src="https://arxiv.org/html/2509.13534v1/images/pipeline2.jpg" alt="系统架构"></p>
<blockquote>
<p><strong>图2</strong>：全身操控拥抱任务的系统架构。(a) 训练框架：包含数据处理和策略训练两部分。数据处理从AMASS动作捕捉数据集开始，使用MaskedMimic过滤违反运动学约束（如自碰撞和脚滑）的序列，并将剩余动作重定向到机器人形态以收集机器人参考轨迹。策略训练首先从收集的轨迹中通过师生策略蒸馏出人类运动先验，然后利用学习到的运动先验指导高层拥抱策略的训练。(b) 运动先验蒸馏：预训练的教师策略通过提供参考动作来指导机器人运动模仿。学生策略基于VAE结构，通过模仿学习学习重建教师的动作分布，从而构建一个可学习的人形运动先验ℛ。(c) 拥抱策略训练：基于学习到的人形运动先验ℛ，训练用于拥抱任务的全身操控策略。</p>
</blockquote>
<p><strong>1. 数据处理</strong>：首先，使用MaskedMimic处理原始的AMASS动作捕捉数据（基于SMPL人体模型），过滤掉物理上不可行的运动，得到干净的人类运动数据集𝒟ₕ。然后，采用H2O的重定向框架，将这些运动转移到目标人形机器人平台上，生成机器人运动数据集𝒟ᵣ，作为后续模仿教师策略的训练目标。</p>
<p><strong>2. 运动先验蒸馏</strong>：目标是基于𝒟ᵣ提炼出既保持人类灵巧性又确保机器人物理可行性的运动先验。采用师生学习方案。</p>
<ul>
<li><strong>教师策略</strong>：使用PHC框架训练一个运动跟踪教师策略π_teacher。其输入为机器人本体感知状态𝐬ₜᵖ（包含根线速度、角速度、投影重力向量、关节位置/速度、上一时刻动作）和来自𝒟ᵣ的目标状态𝐬ₜᵍ（包含位置偏移和目标位姿），输出为参考动作𝐚ₜ*。该策略是一个MLP，使用PPO优化。</li>
<li><strong>学生策略与先验构建</strong>：构建一个VAE框架来蒸馏教师策略的复杂动作空间。编码器ℰ根据𝐬ₜᵖ和𝐬ₜᵍ推断潜在运动变量𝐳ₜ的分布。解码器𝒟将潜在代码映射回动作空间。为了便于仿真到现实的迁移，解码器的输入𝐬ₜᵈ排除了难以在现实中精确测量的根线速度𝐯ₜ。此外，引入一个可学习的先验网络ℛ来近似编码器产生的潜在代码分布。训练损失函数为：ℒ_all = ℒ_action + αℒ_regu + βℒ_KL，其中ℒ_action为动作重建损失，ℒ_regu通过惩罚连续潜在均值之间的突变来确保时间一致性，ℒ_KL使编码器的潜在分布与学习的先验对齐。蒸馏完成后，冻结解码器𝒟和先验ℛ的参数，为下游任务定义一个新的低维动作空间。</li>
</ul>
<p><strong>3. 拥抱策略训练</strong>：为WBM任务（特别是针对笨重物体）训练任务策略π_task。任务分为接近物体、拥抱物体和将物体运输到目标位置三个阶段。采用定制的PPO算法，包含阶段化随机初始化、特定奖励函数和人类运动先验三个关键组件。</p>
<ul>
<li><strong>观察与动作</strong>：任务观察𝐬ₜ^task是解码器输入𝐬ₜᵈ与任务特定特征𝐬ₜˢ的拼接。𝐬ₜˢ包含机器人躯干与箱子中心、目标位置的距离和方向角差异，以及关键的NSDF特征𝐝ₜ。如图3所示，NSDF特征𝐝ₜ由一个预训练网络f_θ计算，它评估了所选目标点（箱子中心）与一组网格片段（机器人的上半身连杆）之间的最短距离，提供了精确的几何接触感知。</li>
</ul>
<p><img src="https://arxiv.org/html/2509.13534v1/x1.png" alt="NSDF示意图"></p>
<blockquote>
<p><strong>图3</strong>：目标物体与机器人上半身之间的NSDF示意图。分布在机器人每个连杆上的点表示从相应关节到物体质心的最近点。虚线表示物体质心与机器人连杆之间的NSDF方向。</p>
</blockquote>
<p>任务策略π_task在潜在空间中运行，根据当前任务状态𝐬ₜˢ产生潜在动作𝐳ₜˢ。如图2(c)所示，可学习先验ℛ生成运动先验μₜᵖ。π_task的输出与此运动先验结合形成新的潜在令牌，最终由解码器𝒟解码为机器人动作𝐚ₜˢ。</p>
<ul>
<li><strong>奖励设计</strong>：奖励函数分为平滑性奖励（惩罚高关节扭矩、大执行器加速度和动作突变）、物理限制奖励（鼓励关节在限位内、增强稳定性、限制脚部接触力）和任务奖励。任务奖励r_task = r_walk + r_carry + r_arm + r_NSDF，并根据机器人是否进入以物体为中心的拾取区（半径d_p=0.35m）来分阶段激活。在接近阶段（拾取区外），r_walk鼓励机器人走向物体；在拥抱和运输阶段（拾取区内），r_carry鼓励箱子移向目标，r_arm调整手臂位置使其靠近物体，r_NSDF则直接利用NSDF特征鼓励上半身与物体保持接触。</li>
<li><strong>随机初始化</strong>：为了应对长时程任务，训练时随机生成三种初始场景：1）机器人在初始生成区，物体在桌上（训练接近阶段）；2）机器人的初始姿态预设为预拥抱姿势，且位置在拾取区内（训练抓取阶段）；3）机器人初始为拥抱姿势，物体已在其手臂中（训练运输阶段）。</li>
</ul>
<p>与现有方法相比，本文的创新点具体体现在：1）首次提出了一个使人形机器人能通过全身操控主动拥抱笨重物体的RL框架；2）将人类运动先验引入策略训练流程，加速了此类多接触、长时程任务的收敛，并赋予了机器人拟人化技能；3）构建了机器人的NSDF表示，用于精确感知机器人-物体交互，并以此设计观察空间和奖励函数，显著增强了操作鲁棒性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在Isaac Sim仿真环境中进行，部署了4096个并行智能体以高效收集数据。目标物体是一个尺寸为Φ 42 cm × 40 cm的圆柱体。初始时物体置于机器人前方4米处，机器人需拥抱并运送该物体至距离物体初始位置4米的目标点。</p>
<p>由于该领域缺乏合适的开源基线方法，实验主要通过对所提模块的消融和比较来验证其有效性和性能。</p>
<p><img src="https://arxiv.org/html/2509.13534v1/images/nsdf_f1.png" alt="NSDF模块有效性验证"></p>
<blockquote>
<p><strong>图4</strong>：NSDF模块有效性验证。左图：没有NSDF引导时，机器人手臂未能有效协调以建立稳固的全身拥抱。右图：引入NSDF后，机器人成功协调手臂和躯干，实现了稳定的多接触拥抱。</p>
</blockquote>
<p>图4通过定性对比，展示了NSDF模块对于引导机器人上半身协调接触物体的关键作用。没有NSDF时，手臂动作不协调，拥抱不稳定；引入NSDF后，实现了稳定的多接触拥抱。</p>
<p><img src="https://arxiv.org/html/2509.13534v1/images/random_2.png" alt="随机初始化策略分析"></p>
<blockquote>
<p><strong>图5</strong>：随机初始化策略分析。曲线显示了在训练过程中，采用阶段化随机初始化（橙色）相比单一初始化（蓝色）能获得更高且更稳定的任务回报。</p>
</blockquote>
<p>图5的曲线表明，采用阶段化随机初始化策略能获得更高且更稳定的任务回报，证明了该方法对于训练长时程任务的有效性。</p>
<p><img src="https://arxiv.org/html/2509.13534v1/images/8.jpg" alt="仿真实验结果"></p>
<blockquote>
<p><strong>图6</strong>：仿真实验结果序列。展示了机器人成功完成接近、拥抱和运输一个笨重圆柱体（尺寸：Φ 42 cm × 40 cm）的全过程。</p>
</blockquote>
<p>图6展示了在仿真中，机器人成功完成整个拥抱运输任务的序列。</p>
<p><img src="https://arxiv.org/html/2509.13534v1/images/real_4.png" alt="真实世界实验"></p>
<blockquote>
<p><strong>图7</strong>：真实世界实验。将仿真中训练的策略成功迁移到真实的Unitree H1人形机器人上，使其能够拥抱并搬运一个尺寸为Φ 42 cm × 40 cm、重约3公斤的圆柱体物体。</p>
</blockquote>
<p>图7展示了成功的仿真到现实迁移。在真实Unitree H1机器人上，无需微调，策略便能控制机器人拥抱并搬运一个重约3公斤的圆柱体，证明了框架的实用性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）提出了一个整合人类运动先验与NSDF的强化学习框架，首次实现了人形机器人对笨重物体的主动全身拥抱操控；2）通过师生蒸馏构建了紧凑的运动先验，加速了训练并赋予了机器人拟人化技能；3）利用NSDF提供了精确的几何感知，设计出相应的观察与奖励，显著提升了多接触操作的鲁棒性，并成功实现了仿真到现实的迁移。</p>
<p>论文自身提到的局限性包括：当前工作主要验证了单一形状（圆柱体）的物体，未来需要扩展到更广泛形状和材质的物体；实验在相对平坦的地面进行，复杂地形下的全身操控是未来的挑战。</p>
<p>本工作对后续研究的启示在于：为复杂、长时程的人形机器人操作任务提供了一种结合先验知识与精细感知的强化学习范式。运动先验的引入为处理高自由度系统控制提供了稳定基础，而NSDF等精确几何表示则指明了提升机器人-环境交互感知能力的方向。如何将该框架推广至更开放的任务定义（如通过语言指令）和更动态的环境，是值得探索的未来方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人拥抱笨重物体时传统末端执行器抓取方法稳定性和负载能力不足的问题，提出一种基于强化学习的全身操作框架。该方法集成预训练的人类运动先验和神经符号距离场（NSDF）表示，通过教师-学生架构蒸馏人类运动数据，生成运动自然且物理可行的全身运动模式，实现手臂与躯干的协调多接触控制以提升稳定性。实验表明，该框架能适应多样物体形状和尺寸，并成功实现仿真到现实的迁移，为人形机器人多接触长时程任务提供了有效解决方案。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.13534" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>