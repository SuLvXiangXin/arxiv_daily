<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Computer Vision and Pattern Recognition (cs.CV)</span>
      <h1>FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.19870" target="_blank" rel="noreferrer">2509.19870</a></span>
        <span>作者: Wang, Xin, Li, Jie, Weng, Zejia, Wang, Yixu, Gao, Yifeng, Pang, Tianyu, Du, Chao, Teng, Yan, Wang, Yingchun, Wu, Zuxuan, Ma, Xingjun, Jiang, Yu-Gang</span>
        <span>日期: 2025/09/24</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作模型通过整合视觉感知、语言理解和动作生成，在机器人领域取得了快速进展，展现出执行复杂、长视野任务的能力。然而，其对抗攻击下的安全性与鲁棒性尚未得到充分探索。现有针对VLA模型的攻击研究主要聚焦于诱导错误的机器人动作序列，例如操纵机械臂姿态或轨迹。一个同样严重但常被忽视的威胁是“不动作”。这种状态可能导致严重后果，例如中断制造流程、停止关键手术或导致车辆因突然停止而碰撞。与易因视角变化而失效的错误动作攻击不同，不动作能保持固定视角，使攻击更稳定和持久。</p>
<p>本文针对这一具体痛点，提出并形式化了一种名为“动作冻结攻击”的对抗性漏洞：对抗性图像可以使VLA模型“冻结”，并导致其忽略后续指令。这种攻击有效地切断了机器人数字思维与物理动作之间的联系，可能在关键干预期间诱发不动作状态。本文核心思路是：通过一个双层（最大-最小）优化框架，生成能够抵御多种“鲁棒提示”的对抗性图像，从而实现对不同用户指令的、具有强迁移性的动作冻结攻击。</p>
<h2 id="方法详解">方法详解</h2>
<p>FreezeVLA 的整体框架是一个双层优化过程，旨在生成能跨不同语言提示诱导VLA模型动作冻结的对抗性图像。</p>
<p><img src="https://arxiv.org/html/2509.19870v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：FreezeVLA 方法概述。<strong>左侧（最小-最大优化）</strong>：内部最大化通过基于梯度的词选择和贪婪同义词替换，搜索一组“最难停止”的任务指令改写。外部最小化则利用这些硬提示集优化对抗性图像，迫使VLA模型进入瘫痪状态。<strong>右侧（跨提示评估）</strong>：生成的对抗性图像在未见过的指令上进行测试，并持续诱导瘫痪状态。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><p><strong>内部最大化（对抗性提示最大化）</strong>：此模块的目标是找到一组能抵抗诱导冻结行为的“硬提示”。流程如下：</p>
<ul>
<li><strong>初始化</strong>：给定输入图像，使用预训练LLM生成一组参考提示，形式如“What action should the robot take to <task>?”。</li>
<li><strong>关键词识别与替换</strong>：对于每个提示中的每个词，计算其关于冻结损失（模型输出与<code>&lt;freeze&gt;</code>令牌的损失）的梯度。选择梯度最大的“高影响力”词，迭代地将其替换为来自WordNet的同义词。</li>
<li><strong>接受准则</strong>：如果替换后的新提示<code>p*</code>导致模型预测<code>&lt;freeze&gt;</code>令牌的概率降低（即<code>Pr(&lt;freeze&gt;|x&#39;, p*; θ) ≤ Pr(&lt;freeze&gt;|x&#39;, p; θ)</code>），则接受此次替换；否则回退。</li>
<li><strong>目标</strong>：通过这种贪婪搜索，优化提示集以覆盖更广阔的提示嵌入空间，创建一组对对抗性图像具有鲁棒性的提示。</li>
</ul>
</li>
<li><p><strong>外部最小化（对抗性图像最小化）</strong>：此模块利用内部最大化得到的“硬提示”集<code>P*</code>来生成对抗性图像。</p>
<ul>
<li><strong>目标</strong>：修改对抗性图像<code>x&#39;</code>，使得当VLA模型以该图像和<code>P*</code>中任何提示为条件时，其输出<code>&lt;freeze&gt;</code>令牌的概率最大化。</li>
<li><strong>更新公式</strong>：使用投影梯度下降进行更新，梯度由所有硬提示的损失梯度聚合而成：<code>x_{n+1}&#39; = x_n&#39; + α · sign(∑_{p*∈P*} ∇_{x_n&#39;} L(F(x_n&#39;, p*), &lt;freeze&gt;))</code>。</li>
<li><strong>约束</strong>：对抗性扰动被限制在<code>L∞</code>范数界<code>ϵ</code>内。</li>
</ul>
</li>
</ol>
<p><strong>创新点</strong>：<br>与现有基线方法（如单提示PGD或多提示联合优化）相比，FreezeVLA 的创新在于其<strong>双层优化框架</strong>。它将攻击形式化为一个最大-最小优化问题：内部最大化寻找最抵抗冻结的提示（与对抗图像的目标相反），外部最小化则针对这些“最难”的提示生成对抗图像。这种设计迫使生成的对抗图像必须克服由鲁棒提示带来的抵抗力，从而显著提升了攻击在跨不同（未见过的）提示时的迁移性和鲁棒性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>数据集</strong>：使用了四个机器人操作基准数据集：LIBERO-10, LIBERO-Goal, LIBERO-Object, LIBERO-Spatial。</li>
<li><strong>模型</strong>：评估了三个先进的VLA模型：SpatialVLA, OpenVLA, π₀。</li>
<li><strong>基线方法</strong>：对比了随机噪声、单提示PGD攻击、使用随机采样提示的多提示攻击、以及使用GPT生成提示的多提示攻击。</li>
<li><strong>评估指标</strong>：攻击成功率，定义为能持续诱导瘫痪状态（输出<code>&lt;freeze&gt;</code>令牌）的对抗图像百分比。</li>
<li><strong>关键参数</strong>：扰动预算<code>ϵ=4/255</code>，图像更新迭代次数<code>K=100</code>，提示优化迭代次数<code>M=10</code>。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<p><img src="https://arxiv.org/html/2509.19870v1/x1.png" alt="主要结果表"></p>
<blockquote>
<p><strong>表1</strong>：不同跨提示对抗攻击在三个VLA模型和四个LIBERO数据集上的攻击成功率。FreezeVLA + GPT 在大多数情况下取得了最佳性能，平均ASR在SpatialVLA、OpenVLA和π₀上分别达到73.3%、95.4%和59.8%，显著超越了所有基线方法。</p>
</blockquote>
<p>如表1所示，FreezeVLA 方法显著优于所有基线。FreezeVLA + GPT（结合GPT生成提示）取得了最高平均攻击成功率：在SpatialVLA上为73.3%（超越最佳基线53.2%），在OpenVLA上为95.4%（超越最佳基线78.4%），在π₀上为59.8%（超越最佳基线57.3%）。结果表明，提示多样化（多提示）能极大提升攻击迁移性，而FreezeVLA的双层优化框架在此基础上带来了进一步的显著增益。</p>
<p><strong>消融实验分析</strong>：</p>
<p><img src="https://arxiv.org/html/2509.19870v1/x3.png" alt="参考提示数量影响"></p>
<blockquote>
<p><strong>图3</strong>：参考提示数量对SpatialVLA模型ASR的影响。随着参考提示数量从1增加到20，两种FreezeVLA变体的ASR均持续上升，但增长呈现边际递减效应，约10个提示后提升趋缓。</p>
</blockquote>
<p>图3展示了参考提示数量对攻击成功率的影响。ASR随着提示数量增加而提升，但增长曲线显示边际收益递减，大约在10个提示后提升趋于平缓。这表明优化对抗更多样化的提示集有助于生成更强、迁移性更好的对抗扰动。</p>
<p><img src="https://arxiv.org/html/2509.19870v1/x4.png" alt="扰动预算影响"></p>
<blockquote>
<p><strong>图4</strong>：扰动预算<code>ϵ</code>对SpatialVLA模型ASR的影响。ASR随着扰动预算增大而单调增加，即使在较小的<code>ϵ=1/255</code>时，FreezeVLA + GPT 仍能取得约40%的ASR，证明了攻击的高效性。</p>
</blockquote>
<p>图4分析了不同扰动预算<code>ϵ</code>下的攻击效果。攻击成功率随<code>ϵ</code>增大而单调增加。值得注意的是，即使在很小的扰动（<code>ϵ=1/255</code>）下，FreezeVLA + GPT 仍能取得约40%的ASR，表明该攻击方法具有高效性。</p>
<p><img src="https://arxiv.org/html/2509.19870v1/x5.png" alt="定性结果"></p>
<blockquote>
<p><strong>图5</strong>：动作冻结攻击的定性结果。对于相同的任务指令（如“拿起胡萝卜”），干净图像能引导模型执行正确动作，而FreezeVLA生成的对抗性图像则导致模型输出<code>&lt;eos&gt;</code>（终止）令牌，机器人停止所有动作。</p>
</blockquote>
<p>图5提供了定性示例。对于“拿起胡萝卜”的指令，干净图像引导模型执行抓取动作，而对抗性图像则导致模型输出<code>&lt;eos&gt;</code>（冻结）令牌，机器人停止响应。</p>
<p><strong>消融实验总结</strong>：<br>关键组件的贡献体现在：1) <strong>多提示优化</strong>是提升跨提示迁移性的基础；2) <strong>GPT生成的多样化提示</strong>进一步丰富了语义攻击空间；3) <strong>最小-最大双层优化框架</strong>是FreezeVLA的核心创新，通过对抗性地寻找并攻击“最难”的提示，显著增强了攻击的鲁棒性和最终性能，与GPT提示结合产生了“1+1&gt;2”的协同效应。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>识别并形式化新漏洞</strong>：首次系统性地研究并形式化了VLA模型中的“动作冻结攻击”漏洞，揭示了一种通过对抗性图像诱导机器人持续不动作的严重安全风险。</li>
<li><strong>提出新型攻击框架</strong>：提出了FreezeVLA，一种基于最小-最大双层优化的新颖攻击框架。该框架通过内部最大化生成对抗性鲁棒提示，外部最小化针对这些提示生成对抗图像，从而实现了强大的跨提示攻击迁移性。</li>
<li><strong>广泛的实验验证</strong>：在三个先进的VLA模型和四个机器人基准上进行了全面实验，证明FreezeVLA能以高成功率实现动作冻结攻击，性能显著超越现有基线。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到的局限性包括：1) 攻击目前主要在模拟环境中进行评估，其在实际物理机器人系统中的效果和潜在挑战（如动态环境、传感器噪声）有待进一步探索；2) 研究主要关注攻击方法，对于如何防御此类冻结攻击的机制探讨有限。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>安全评估的紧迫性</strong>：本研究暴露了VLA模型在动作生成机制中存在此前未受重视的严重漏洞，强调了在部署前对其进行严格对抗鲁棒性评估的紧迫性。</li>
<li><strong>防御机制研究</strong>：亟需开发针对此类“不动作”攻击的防御机制，例如设计能检测异常冻结状态的监控系统，或提高模型对诱导冻结的对抗性输入的鲁棒性。</li>
<li><strong>跨模态攻击的拓展</strong>：FreezeVLA的成功表明，针对多模态系统的攻击可能需要考虑模态间的相互作用。未来的研究可以探索其他模态（如文本指令本身）在诱发类似冻结或故障状态中的作用。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对视觉-语言-动作（VLA）模型的安全漏洞，提出动作冻结攻击问题，即对抗性图像可使模型忽略后续指令，导致机器人行动瘫痪。作者提出FreezeVLA攻击框架，采用min-max双层优化方法生成对抗图像。实验在三个先进VLA模型和四个机器人基准上进行，FreezeVLA平均攻击成功率达76.2%，显著优于现有方法，且对抗图像具有强迁移性，单张图像即可跨不同提示诱导瘫痪。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.19870" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>