<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.02252" target="_blank" rel="noreferrer">2510.02252</a></span>
        <span>作者: Araujo, Joao Pedro, Ze, Yanjie, Xu, Pei, Wu, Jiajun, Liu, C. Karen</span>
        <span>日期: 2025/10/02</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，利用人类动作数据训练人形机器人运动跟踪策略是构建遥操作流水线和分层控制系统的主流方法。标准流程是首先通过运动重定向将人类动作适配到机器人形态，然后训练强化学习策略来模仿这些参考轨迹。然而，现有重定向方法（如PHC、ProtoMotions）在缩放和求解过程中会引入脚部滑动、地面穿透、自穿透和物理上不可行的运动等伪影。这些伪影被留在了参考轨迹中，迫使后续的RL策略在模仿不可行动作的同时还需维持物理约束，这通常需要依赖大量的奖励函数工程和领域随机化才能成功迁移到现实世界。本文针对“重定向质量对策略性能影响”这一具体痛点，提出假设：在抑制过度奖励调优的情况下，重定向结果的质量将起到至关重要的作用。核心思路是提出一种新的通用运动重定向方法GMR，通过一种灵活的非均匀局部缩放和两阶段优化来生成高质量的重定向运动，并系统性地评估不同重定向方法对策略鲁棒性和成功率的影响。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的通用运动重定向方法包含一个清晰的五步流程，其整体框架如下图所示。</p>
<p><img src="https://arxiv.org/html/2510.02252v1/x1.png" alt="GMR方法整体流程"></p>
<blockquote>
<p><strong>图2</strong>：General Motion Retargeting (GMR) 流程概览。包含五个核心步骤：1) 人体-机器人关键身体匹配；2) 静息姿态对齐；3) 人体数据非均匀局部缩放；4) 带旋转约束的机器人逆运动学求解；5) 使用旋转与平移约束进行微调。</p>
</blockquote>
<p><strong>整体流程</strong>：输入为源人类运动数据（BVH或SMPL格式）和目标人形机器人骨架描述（URDF等），输出为机器人各时间步的广义坐标（根部位移、根部旋转、关节角度）。流程依次为：关键身体匹配、静息姿态对齐、非均匀局部缩放、两阶段逆运动学求解、后处理高度校正。</p>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>关键身体匹配</strong>：用户手动定义人体与机器人关键身体（如躯干、头、四肢、手脚）之间的映射关系 $\mathcal{M}$，并为各身体设置位置和方向跟踪误差的权重。</li>
<li><strong>静息姿态对齐</strong>：调整人体各身体的方向（有时包括位置局部偏移），使其与机器人静息姿态对齐，以减轻如内八字步态等伪影。</li>
<li><strong>非均匀局部缩放</strong>：这是GMR的创新核心。首先根据人体骨架高度计算一个全局缩放因子 $h/h_{\text{ref}}$。然后，为每个关键身体 $b$ 定义一个自定义的局部缩放因子 $s_b$。目标位置通过公式 $\mathbf{p}<em>{b}^{\text{target}}=\frac{h}{h</em>{\text{ref}}}s_b(\mathbf{p}<em>{j}^{\text{source}}-\mathbf{p}</em>{\text{root}}^{\text{source}})+\frac{h}{h_{\text{ref}}}s_{\text{root}}\mathbf{p}<em>{\text{root}}^{\text{source}}$ 计算。特别地，根部平移按 $\mathbf{p}</em>{\text{root}}^{\text{target}}=\frac{h}{h_{\text{ref}}}s_{\text{root}}\mathbf{p}_{\text{root}}^{\text{source}}$ 均匀缩放，作者发现这对避免脚滑伪影至关重要。这种非均匀缩放能灵活处理上下肢等部位的不同比例差异。</li>
<li><strong>两阶段逆运动学求解</strong>：<ul>
<li><strong>第一阶段（公式4）</strong>：使用微分IK求解器Mink，优化机器人广义坐标 $\mathbf{q}$，以最小化<strong>所有关键身体的方向误差</strong>和<strong>仅末端执行器（手、脚）的位置误差</strong>。此阶段将根部位置和偏航角初始化为缩放后的人体根部位姿，旨在获得一个合理的初始姿态，避免陷入局部最优。</li>
<li><strong>第二阶段（公式6）</strong>：将第一阶段的解作为初始猜测，进行<strong>微调</strong>。此阶段优化同时考虑<strong>所有关键身体的方向和位置误差</strong>，使用与第一阶段不同的权重 $(w_2)$，以得到更精确的跟踪结果。</li>
</ul>
</li>
<li><strong>序列处理与后处理</strong>：对运动序列逐帧应用上述单姿态重定向方法，并将前一帧的结果作为下一帧优化的初始猜测。完成整个序列后，通过前向运动学计算所有身体的高度，并将全局平移下移最小高度值，以校正可能的地面穿透或漂浮。</li>
</ol>
<p><strong>创新点</strong>：与PHC（依赖SMPL模型拟合和全局优化）和ProtoMotions（使用全局轴对齐缩放）相比，GMR的主要创新在于：1) <strong>非均匀局部缩放策略</strong>，允许为身体不同部位（特别是根部）设置独立的缩放因子，这是解决脚滑等伪影的关键；2) <strong>两阶段优化流程</strong>，先通过方向和末端位置约束获得良好初值，再精细化所有身体的位置和方向，提高了求解质量和鲁棒性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>数据集</strong>：从LAFAN1数据集中选取了21个多样化的序列（排除非脚部接触的复杂交互动作），时长从5秒到2分钟，包括行走、转身、跳跃、舞蹈、武术等。</li>
<li><strong>对比方法</strong>：开源重定向方法 <strong>PHC</strong>、**ProtoMotions (PM)**、本文提出的 <strong>GMR</strong>，以及作为高质量基线的闭源 <strong>Unitree (U)</strong> 重定向数据集。</li>
<li><strong>策略训练与评估平台</strong>：使用 <strong>BeyondMimic</strong> 在IsaacSim中为每个重定向后的序列训练独立的运动模仿策略，并评估其鲁棒性。评估分三种条件：无领域随机化的模拟器（<code>sim</code>, 100次）、带领域随机化的模拟器（<code>sim-dr</code>, 4096次）、以及模拟真实世界控制器与状态估计噪声的MuJoCo/ROS环境（<code>sim2sim</code>, 100次）。</li>
<li><strong>评估指标</strong>：严格的成功率（机器人能完整跟踪完参考动作且高度/方向偏差不超过阈值）、多种运动跟踪误差（全局/相对位置误差、关节旋转误差），以及通过用户研究评估的感知保真度。</li>
</ul>
<p><strong>关键实验结果</strong>：<br>实验的核心结果总结在表I中（此处以文字概括关键数据）。总体而言，GMR在绝大多数动作序列上取得了与闭源Unitree基线相近或更优的成功率，显著优于其他开源方法。</p>
<ul>
<li>对于简单动作（如Walk 1, Walk 2），所有方法在<code>sim</code>条件下成功率都很高（100%或接近）。但在更具挑战性的<code>sim-dr</code>条件下，对于Walk 2，GMR和Unitree保持接近100%的成功率，而PHC降至53.54%。</li>
<li>对于复杂动态动作，差异尤为明显。例如，对于长达118秒的“Dance 1”序列，在<code>sim</code>条件下，PHC的成功率为**0%<strong>，而GMR、PM和Unitree均达到</strong>99-100%**。在<code>sim-dr</code>条件下，GMR（99.46%）和Unitree（99.95%）依然稳健，PHC为0%，PM为99.24%。</li>
<li>在模拟真实部署条件的<code>sim2sim</code>评估中，GMR也表现出高度的稳健性，在几乎所有测试序列上均达到100%或99%的成功率。</li>
</ul>
<p><strong>伪影分析</strong>：论文通过可视化对比了不同方法产生的典型伪影。</p>
<p><img src="https://arxiv.org/html/2510.02252v1/sections/images/artifacts_phc.png" alt="PHC方法产生的伪影"></p>
<blockquote>
<p><strong>图3</strong>：PHC方法产生的伪影示例。左图展示了严重的脚部地面穿透（红色圆圈），右图显示了由于使用SMPL模型拟合机器人形态而导致的身体比例失真和自穿透。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.02252v1/sections/images/artifacts_protomotions.png" alt="ProtoMotions方法产生的伪影"></p>
<blockquote>
<p><strong>图4</strong>：ProtoMotions方法产生的伪影示例。由于使用全局轴对齐缩放，导致运动比例失调，表现为机器人的步幅异常大，与源动作不符。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.02252v1/sections/images/artifacts_gmr.png" alt="GMR方法结果"></p>
<blockquote>
<p><strong>图5</strong>：GMR方法的结果示例。生成的机器人运动避免了地面穿透和明显的比例失真，更贴合源人类动作的形态。</p>
</blockquote>
<p><strong>用户研究结果</strong>：为了评估重定向动作在视觉上对源动作的忠实度（保真度），研究者进行了用户研究。</p>
<p><img src="https://arxiv.org/html/2510.02252v1/sections/images/user_study_results.png" alt="用户研究结果"></p>
<blockquote>
<p><strong>图6</strong>：用户研究结果。柱状图显示了参与者认为GMR相对于其他方法更贴近源动作的比例。GMR在感知保真度上显著优于PHC和ProtoMotions，并且与闭源的Unitree方法结果非常接近（选择“无差异”的比例很高）。</p>
</blockquote>
<p><strong>消融实验启示</strong>：虽然论文未进行传统的消融实验，但通过对比不同重定向方法（PHC的全局优化与不当缩放、ProtoMotions的全局轴对齐缩放、GMR的非均匀局部缩放与两阶段优化）的性能差异，间接证明了<strong>正确的缩放策略</strong>和<strong>分阶段优化</strong>对于消除伪影、提升重定向质量的关键作用。GMR的成功正是其模块化设计有效性的体现。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了 <strong>General Motion Retargeting (GMR)</strong> 方法，通过引入非均匀局部缩放和两阶段优化流程，有效解决了现有开源重定向方法中常见的脚滑、地面穿透、比例失真等伪影问题，能够从广泛的人类动作生成高质量的机器人运动数据。</li>
<li>进行了一项 <strong>系统性的实证研究</strong>，通过严格控制变量（使用无需奖励调优的BeyondMimic策略），清晰揭示了重定向参考运动的质量对人形机器人运动跟踪策略性能的 <strong>关键影响</strong>。研究表明，在没有大量奖励工程的情况下，重定向伪影会显著降低策略的鲁棒性，尤其是在动态或长序列任务中。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，当前工作未包含与物体或复杂场景交互的动作（如爬行、从地面站起），且主要针对Unitree G1这一款机器人进行评估。GMR方法中关键身体匹配和权重设置仍需一定程度的用户输入。</p>
<p><strong>后续研究启示</strong>：</p>
<ol>
<li><strong>重定向质量至关重要</strong>：这项研究强有力地表明，投入精力提升运动重定向的质量，是简化后续强化学习策略训练、降低对奖励工程依赖的有效途径。</li>
<li><strong>缩放策略是核心</strong>：研究指出，许多伪影根源在于不恰当的缩放。GMR的非均匀局部缩放策略为解决形态差异问题提供了一个简单而有效的设计思路。</li>
<li><strong>评估需全面</strong>：除了最终策略成功率，对重定向结果进行感知保真度评估和详细的伪影分析，对于理解方法优劣和指导改进方向同样重要。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形运动跟踪中因人类与机器人形态差异（体现差距）导致重定向数据存在脚滑、自穿透等 artifacts，从而影响策略性能的问题，提出 General Motion Retargeting (GMR) 方法。GMR 通过改进重定向质量减少 artifacts，无需奖励工程。实验在 LAFAN1 数据集上对比开源方法 PHC、ProtoMotions 及闭源 Unitree 基线，使用 BeyondMimic 训练策略。结果表明，GMR 在跟踪性能和运动忠实度上 consistently 优于开源方法，感知保真度与策略成功率接近闭源基线。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.02252" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>