<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Gait-Adaptive Perceptive Humanoid Locomotion with Real-Time Under-Base Terrain Reconstruction - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Gait-Adaptive Perceptive Humanoid Locomotion with Real-Time Under-Base Terrain Reconstruction</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.07464" target="_blank" rel="noreferrer">2512.07464</a></span>
        <span>作者: Song, Haolin, Zhu, Hongbo, Yu, Tao, Liu, Yan, Yuan, Mingqi, Zhou, Wengang, Chen, Hua, Li, Houqiang</span>
        <span>日期: 2025/12/08</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前基于强化学习的人形机器人运动控制方法在平坦或轻度不平坦地形上已能实现稳健的行走和抗扰动。然而，在复杂地形（如长楼梯、宽间隙）上，这些“盲走”策略往往难以实现精确的落脚点规划和步态时序调整，更像防跌倒控制器而非有规划的步态控制器。现有感知方法存在局限：前向深度相机策略视野狭窄且依赖时序记忆，在机器人转向、减速或停止时易丢失脚下地形信息；基于激光雷达的高程图方法需要独立的建图与位姿估计栈，引入延迟和漂移，且足部附近覆盖不全。此外，许多控制器将步态时序作为外部信号（预设或由独立模块生成），导致步频、步相与全身运动解耦，限制了根据当前状态和地形进行端到端步态优化的能力。</p>
<p>本文针对上述痛点，提出一种集成了地形感知、步态调节和全身控制的一体化强化学习框架。其核心思路是：利用一个向下安装的深度相机实时重建机器人脚下及周围的关键地形高度图，并将此感知信息与本体感知信息一同输入到一个统一策略中，该策略同时输出关节指令和一个全局步频动作，从而实现步态时序与全身姿态对指令运动和局部地形的联合自适应。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的框架名为“连续教师-学生”（Successive Teacher-Student, S-TS），其整体流程如图2所示。框架包含一个感知模块和一个控制策略。感知模块将单帧向下深度图像实时（50 Hz）重建为自我中心的高度图。控制策略采用教师-学生架构进行训练：教师使用无噪声的完整观测（包括特权信息）学习强鲁棒性的策略；学生使用带噪声的部分观测（本体感知和重建的高度图），其编码器通过监督学习对齐教师的潜在特征表示。一个“切换门”在训练过程中逐渐将环境交互从教师转移给学生，最终得到一个在部分观测下依然鲁棒的可部署策略。</p>
<p><img src="https://arxiv.org/html/2512.07464v1/x1.png" alt="方法总览"></p>
<blockquote>
<p><strong>图2</strong>：提出的连续教师-学生（S-TS）框架及部署流程总览。教师-学生切换门逐步将环境交互从特权教师转移给学生。统一策略同时输出关节动作和标量步频动作。向下深度图像通过感知模块转换为脚下高度图，该模块与控制策略同频运行（50 Hz）。</p>
</blockquote>
<p><strong>观测空间</strong>：包含三类观测：本体感知观测（用户指令、身体角速度、投影重力、关节位置/速度、上一时刻动作、步态信号）、特权观测（基座线速度、关节扭矩/加速度、足部接触力、足部高度、基座高度）和外感知观测（局部自我中心高度图）。教师和评论家使用所有无噪声观测，学生仅使用注入高斯噪声的本体感知和感知观测。</p>
<p><strong>统一动作空间</strong>：策略网络输出一个32维动作向量 <code>a_t = [a_t^joints, f_t]</code>，其中 <code>a_t^joints</code> 为31个关节的目标位置，<code>f_t</code> 为标量步频。步频控制全局步相 <code>φ_t</code> 的更新速率：<code>φ_t = mod(φ_{t-Δt} + Δt * f_t, 1.0)</code>。左右腿保持0.5的固定相位差以实现交替步态。原始步频输出经过缩放、裁剪和短期平均滤波后处理，以确保稳定平滑。这种设计使策略能够联合推理“何时迈步”和“如何配置身体”。</p>
<p><strong>S-TS训练框架</strong>：教师和学生共享相同的策略头 <code>π_θ</code> 和评论家网络 <code>V_ϕ</code>，仅编码器不同。训练初期，切换门参数 <code>λ=0</code>，仅教师与环境交互并收集数据，策略通过教师数据的PPO损失 <code>L_ppo-T</code> 更新。此阶段，学生不交互，其编码器通过重建损失 <code>L_rec</code>（最小化学生与教师潜在特征 <code>z^T</code> 和 <code>z^S</code> 的均方误差）进行监督学习。随着训练进行，<code>λ</code> 逐渐增大，部分环境由学生控制，进入并行阶段。此时策略的PPO损失为教师和学生数据损失之和：<code>L_ppo = L_ppo-T + L_ppo-S</code>。此外，还使用了镜像损失 <code>L_mir</code> 来增强对称性。</p>
<p><strong>单帧高度图重建</strong>：感知模块专注于机器人基座正下方的关键区域。输入为单帧向下深度图像 <code>I_t</code>，经坐标转换和投影后形成原始的含孔洞（因腿部自遮挡）的高度图 <code>Ĥ_t^raw</code>。</p>
<p><img src="https://arxiv.org/html/2512.07464v1/x2.png" alt="U-Net重建网络"></p>
<blockquote>
<p><strong>图3</strong>：基于U-Net的单帧高度图重建网络。深度图像转换为含噪声的基座中心高度图，由U-Net处理。网络有两个输出头：高度头（用L1损失监督）和边缘头（仅训练时使用，结合BCE和Dice损失）。</p>
</blockquote>
<p>如图3所示，一个轻量级U-Net处理 <code>Ĥ_t^raw</code>。网络共享编码器-解码器结构后接两个分支：高度头预测 refined 高度图 <code>Ĥ^height</code>；边缘头预测边缘图 <code>Ê^edge</code>，用于突出地形不连续性（如楼梯边缘）。训练采用多任务学习，总损失为 <code>L_total = L_height + λ_edge * L_edge</code>，其中 <code>L_height</code> 为L1损失，<code>L_edge</code> 为二元交叉熵与Dice损失之和。部署时仅使用 <code>Ĥ^height</code> 作为策略的感知输入。</p>
<p><strong>奖励设计</strong>：奖励函数综合了线性/角速度跟踪、基座高度（相对于脚）、接触-摆动阶段跟踪、自然手臂摆动、动作平滑性、关节加速度/速度/扭矩/功率限制、关节限位、基座线性加速度/角速度、投影重力、非期望接触、足部打滑/绊倒/空中时间/保持位置奖励，以及针对楼梯地形的足部平坦放置奖励。步频 <code>f_t</code> 通过动作平滑性和限位项进行正则化。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验平台与设置</strong>：使用全尺寸人形机器人“Limx Oli”（高1.65米，重55公斤，31个自由度）。仿真训练在IsaacLab中进行，使用4096个并行环境，地形包括平地、粗糙地形、踏脚石、间隙和金字塔楼梯，并进行了大量的域随机化。真实部署时，控制策略运行在50 Hz，关节PD控制运行在1 kHz。感知模块使用Intel RealSense D435i相机，重建网络处理单帧约11 ms，提供50 Hz的高度图。</p>
<p><strong>训练框架对比</strong>：在仿真中对比了仅用PPO训练的学生基线（Baseline）、本文的S-TS框架以及另一种教师-学生方法CTS。</p>
<p><img src="https://arxiv.org/html/2512.07464v1/x4.png" alt="训练进度对比"></p>
<blockquote>
<p><strong>图6</strong>：不同算法在训练过程中的平均地形等级（越高表示在越复杂地形上成功行走）。阴影区域表示标准差。S-TS方法收敛更快且最终性能更优。</p>
</blockquote>
<p>如图6所示，S-TS方法在训练初期（教师专属阶段）迅速提升性能，并在整个训练过程中保持最高且最稳定的平均地形等级，证明了其高效和稳定的知识迁移能力。</p>
<p><strong>步态自适应分析</strong>：在仿真楼梯地形上，分析了步频动作 <code>f_t</code> 的适应性。</p>
<p><img src="https://arxiv.org/html/2512.07464v1/x5.png" alt="步频自适应"></p>
<blockquote>
<p><strong>图7</strong>：在仿真楼梯上下行走时，步频 <code>f_t</code>（红色）和指令速度 <code>v_x^cmd</code>（蓝色）随时间的变化。策略在爬楼时自动降低步频，在下楼或平地行走时提高步频，展示了其根据地形和指令联合调节步态的能力。</p>
</blockquote>
<p>图7显示，当机器人上楼梯时，策略自动降低步频（约0.8 Hz），以适应更谨慎的踩踏；下楼梯或平地行走时，则提高步频（约1.2 Hz）以实现更快的移动。这验证了统一策略能够根据地形几何和运动指令实时、自适应地调节步态节奏。</p>
<p><strong>真实世界实验</strong>：在真实机器人上进行了多种复杂地形测试。</p>
<p><img src="https://arxiv.org/html/2512.07464v1/figure/exp/pcd2.jpg" alt="真实世界实验点云"></p>
<blockquote>
<p><strong>图8</strong>：真实世界实验中，机器人跨越46厘米间隙时的重建高度图（左）和对应的3D点云（右）。感知模块成功重建了间隙结构，为策略提供了关键地形信息。</p>
</blockquote>
<p>如图8所示，感知模块能够有效重建宽间隙等复杂地形。机器人成功完成了向前/向后上下长楼梯、侧向上楼梯以及跨越46厘米宽间隙等任务（对应图1所示场景）。这些实验证明了整个系统在真实复杂环境中的鲁棒性和适应性。</p>
<p><strong>消融实验</strong>：论文通过消融实验验证了各核心组件的贡献。</p>
<ol>
<li><strong>去除感知模块</strong>：机器人无法可靠地上下楼梯或跨越间隙。</li>
<li><strong>固定步频</strong>：将策略输出的 <code>f_t</code> 固定为1.0 Hz。结果发现，在复杂地形上（尤其是上楼梯）成功率显著下降，机器人的步态无法适应地形变化，导致步态不稳或跌倒。</li>
<li><strong>去除边缘辅助损失</strong>：高度图重建质量下降，特别是在被遮挡的楼梯边缘区域变得模糊，影响了策略在楼梯地形上的性能。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>实时脚下地形感知模块</strong>：提出一种基于轻量U-Net的单帧深度图像重建方法，能在50 Hz控制频率下提供机器人脚下及周围的关键区域高度图，避免了复杂建图栈和时序依赖。</li>
<li><strong>步态自适应的统一策略</strong>：设计了一个输出关节指令和步频的联合动作空间，使策略能够端到端地协调全身运动与步态时序，根据指令和局部地形自动调节步态节奏。</li>
<li><strong>高效的连续教师-学生训练框架</strong>：采用单阶段渐进式知识迁移策略，通过切换门平滑过渡，在保持训练稳定性的同时，高效地将特权教师的知识迁移至仅使用部分观测的学生策略。</li>
</ol>
<p><strong>局限性</strong>：论文提及，感知模块的视野范围有限（基座下方区域），对于更远距离的地形预览或全局路径规划能力不足。此外，方法依赖于仿真训练和域随机化进行sim-to-real迁移。</p>
<p><strong>启示</strong>：本文的工作表明，将关键区域的密集感知与运动控制（包括步态时序）进行紧密的端到端联合优化，是提升人形机器人复杂地形运动能力的有效途径。S-TS训练框架为从特权信息到真实传感器输入的策略学习提供了稳定高效的范式。未来研究可探索如何融合更远距离的感知信息，或结合更高效的在线自适应技术来减少对仿真训练的依赖。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对全尺寸人形机器人在复杂地形（如长楼梯）上运动不可靠的核心问题，提出了一种步态自适应的感知运动框架。该方法融合地形感知、步态调节与全身控制于单一强化学习策略，关键是通过向下深度摄像头和紧凑U-Net实时重建脚下地形高度图，并由统一策略处理以联合调整步态时序和姿势。实验在31自由度、1.65米高的人形机器人上验证了框架的有效性，实现了在仿真和真实环境中向前/向后上下楼梯及跨越46厘米间隙的鲁棒运动。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.07464" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>