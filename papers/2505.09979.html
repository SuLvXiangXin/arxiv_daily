<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Learning Diverse Natural Behaviors for Enhancing the Agility of Quadrupedal Robots - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Learning Diverse Natural Behaviors for Enhancing the Agility of Quadrupedal Robots</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.09979" target="_blank" rel="noreferrer">2505.09979</a></span>
        <span>作者: Fu, Huiqiao, Dong, Haoyu, Xu, Wentao, Zhou, Zhehao, Deng, Guizhou, Tang, Kaiqiang, Dong, Daoyi, Chen, Chunlin</span>
        <span>日期: 2025/05/15</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前四足机器人控制的主流方法包括基于模型的传统控制（如模型预测控制、全身控制）以及基于学习的先进方法，特别是深度强化学习和模仿学习。传统方法依赖于简化模型，在高度动态和复杂的任务中性能受限。DRL能够通过试错学习鲁棒行为，但设计合适的奖励函数复杂且易产生不自然的行为。模仿学习（如行为克隆、对抗模仿学习）旨在复制专家演示，但BC需要大量数据来减轻复合误差，而无监督的AIL方法在从原始数据中解耦多模态行为特征方面存在挑战，容易导致模式崩溃和行为多样性有限。此外，尽管模拟中已能实现高度动态的行为，但由于仿真到现实的差距，将这些行为迁移到真实世界仍是一大难题。域随机化方法部分解决了这一问题，但达到有效的随机化水平困难且需要大量调参。</p>
<p>本文针对两个具体痛点：1）现有模仿学习方法难以从非结构化的原始运动捕捉数据中可控地学习多样、多模态的自然行为；2）仿真到现实的差距阻碍了高性能策略的迁移。受行为神经科学启发，本文提出了一个新视角：构建一个仿生的集成控制器，将高级运动规划与低级行为生成分离。本文的核心思路是：提出一个由基本行为控制器和任务特定控制器组成的集成系统，通过半监督对抗模仿学习从真实狗的数据中提取多样行为风格，并利用进化对抗仿真器识别技术优化仿真器以缩小仿真到现实差距，最终使机器人仅依靠深度感知就能在复杂敏捷任务中自主切换自然行为模式。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的方法是一个三阶段训练框架，旨在训练一个可在仿真中学习并能高效迁移到真实世界的集成腿部运动控制器。</p>
<p><img src="https://arxiv.org/html/2505.09979v1/x7.png" alt="训练过程概述"></p>
<blockquote>
<p><strong>图7</strong>：训练过程概述。a) 基本行为控制器训练：使用半监督InfoGAIL从狗的运动捕捉数据中学习。b) 仿真器识别：使用EASI和少量真实世界数据优化仿真器物理参数。c) 任务特定控制器训练：通过特权学习架构训练，教师策略使用特权信息，学生策略学习模仿教师并使用深度图像作为输入。</p>
</blockquote>
<p><strong>整体框架</strong>：该系统使用IssacGym作为支持GPU并行训练的仿真器。第一阶段，使用半监督InfoGAIL变体训练通用的基本行为控制器，以复制真实狗运动捕捉数据中观察到的常见行为。第二阶段，使用少量真实世界数据通过进化对抗仿真器识别技术来增强仿真器，缩小仿真到现实差距，并在此增强的仿真器中对BBC进行微调。第三阶段，通过特权学习策略训练任务特定控制器，以协调BBC完成各种下游任务（如敏捷挑战）。</p>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><p><strong>基本行为控制器</strong>：BBC模拟低级神经区域（脑干和脊髓），仅以本体感知（关节状态等）为输入。其核心创新在于采用了<strong>半监督InfoGAIL</strong>算法。BBC的输入包括潜在技能变量 <strong>c</strong>（离散，代表五种常见狗行为模式：行走、溜蹄、小跑、慢跑、跳跃）和潜在偏移变量 <strong>ε</strong>（连续，编码连续的行为风格）。网络结构包含策略网络、判别器和预测器。训练目标是最大化潜在变量与状态之间互信息的变分下界，从而使单个策略能够学习多样化的可控行为。为了解决原始运动捕捉数据中行为模式的不平衡问题，训练期间动态调整潜在技能的分布，并结合正则化信息最大化技术，以有效利用未标记的不平衡数据中的内在信息。</p>
</li>
<li><p><strong>仿真器优化</strong>：采用<strong>进化对抗仿真器识别</strong>技术来优化仿真器。该方法将仿真器参数识别构建为一个搜索问题，通过进化策略（作为生成器）与神经网络判别器对抗来解决。判别器根据状态转移与真实数据的匹配程度进行评分，该评分作为ES的适应度函数来引导物理参数的进化。整个过程在基于GPU的物理仿真器上高效并行化，耗时不到10分钟，仅使用80秒的真实世界数据。</p>
</li>
<li><p><strong>任务特定控制器</strong>：TSC模拟高级神经区域（大脑皮层和基底神经节），以深度图像作为外感受感知输入。它采用<strong>特权学习</strong>架构：首先，教师策略使用特权信息（如机器人周围的扫描点、到下一个路点的相对偏航角、当前障碍物类型）并在混合动作空间中使用Hybrid-PPO算法来最大化任务奖励。然后，学生策略仅以深度图像为输入，学习估计特权信息并模仿教师的行为。为了增强对真实世界感知噪声的鲁棒性，对学生策略的深度图像应用随机增强，并采用自监督学习方法Bootstrap Your Own Latent。</p>
</li>
</ol>
<p><strong>创新点</strong>：1) 提出了半监督InfoGAIL框架，以低成本实现可控的多模态自然行为学习，并处理数据不平衡问题；2) 利用EASI技术，用极少量的真实数据快速优化仿真器参数，有效缩小仿真到现实差距；3) 结合了特权学习和自监督对比目标（BYOL）来训练仅使用深度图像的TSC，提升了在噪声干扰下的鲁棒性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验平台与数据集</strong>：使用Unitree Go2四足机器人，仅配备Intel RealSense D435i深度相机。在仿真器IssacGym中进行训练。使用真实狗的运动捕捉数据训练BBC。构建了“四足敏捷挑战”基准测试环境（7m×10m），包含六种随机放置的障碍物：A型架、横杆跳、绕杆、跷跷板、轮胎跳和隧道。</p>
<p><strong>对比基线</strong>：在行为多样性方面，对比了无监督GAIL、InfoGAIL、监督ACGAIL以及本方法的消融实验（移除标签数据、移除RIM）。在敏捷任务方面，对比了最先进的基线方法[21]。在TSC训练中，对比了无特权学习和无BYOL的基线。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>四足敏捷挑战</strong>：机器人首次成功完成了完整的敏捷挑战，平均速度为1.1 m/s。在单一障碍物环境中，本方法接近100%的成功率，且速度高于基线（图2d）。基线方法因缺乏自然行为，无法无接触地越过横杆跳等障碍（图2c）。在完整的随机障碍挑战中，本方法成功率超过78%，而基线成功率和人类远程操作成功率均较低（图2f）。</li>
</ol>
<p><img src="https://arxiv.org/html/2505.09979v1/x2.png" alt="敏捷挑战评估"></p>
<blockquote>
<p><strong>图2</strong>：四足敏捷挑战评估。a) 从起点到终点的完整运动序列。b) 运动过程中的指令变化，灰色和白色阴影区域代表不同的障碍阶段。c) 本方法与基线方法通过横杆跳的对比。d) 本方法与基线方法在单一障碍环境中的成功率和平均速度对比。e) 不同障碍物高度下的成功率。f) 不同方法在完整敏捷挑战中的成功率和平均速度。</p>
</blockquote>
<ol start="2">
<li><strong>高速跨栏</strong>：在跨栏任务中，机器人实现了3.2 m/s的峰值速度，跳跃时最大身体高度达0.54 m（图3c, d）。机器人能根据深度感知在适当时机自主从慢跑切换到跳跃（图3b）。</li>
</ol>
<p><img src="https://arxiv.org/html/2505.09979v1/x3.png" alt="高速跨栏"></p>
<blockquote>
<p><strong>图3</strong>：高速跨栏的自然跳跃。a) 两个跳跃阶段。b) 跨栏期间每条腿的接触序列。c) 指令与实际线速度变化。d) 身体高度变化。</p>
</blockquote>
<ol start="3">
<li><strong>BBC多模态行为评估</strong>：通过调整潜在变量，机器人可以生成五种不同的狗类行为（图4b）及其连续风格变体（图4e）。在命令跟踪方面，平均线速度跟踪误差约为0.04 m/s（图4d）。在行为多样性量化评估中，使用平均熵和归一化互信息作为指标，本方法在所有基线中取得了最低的ENT和最高的NMI（图4g），t-SNE可视化也显示本方法学习到的行为特征区分度更好（图4h）。</li>
</ol>
<p><img src="https://arxiv.org/html/2505.09979v1/x4.png" alt="BBC多模态行为评估"></p>
<blockquote>
<p><strong>图4</strong>：BBC多模态行为评估。a) 常见的狗行为。b) 为四足机器人学习的多模态行为。c) 指令跟随示意图。d) 指令跟随误差。e) 潜在偏移变量变化的影响。f) 运动捕捉数据中5种行为模式的比例。g) 不同算法的NMI和ENT。h) 不同算法行为特征的可视化。</p>
</blockquote>
<ol start="4">
<li><strong>TSC评估</strong>：在敏捷挑战中，采用特权学习和BYOL的本方法成功率达<del>78%，障碍物识别准确率达</del>92%，任务奖励最高（图5b）。无特权学习的方法成功率为0。在噪声干扰下，本方法预测相对偏航角的误差小于无BYOL的基线（图5c）。</li>
</ol>
<p><img src="https://arxiv.org/html/2505.09979v1/x5.png" alt="TSC评估"></p>
<blockquote>
<p><strong>图5</strong>：TSC评估。a) 教师策略观察到的特权信息，以及学生的观察。b) 本方法与两种基线方法（无特权学习、无BYOL）的对比。c) 预测的相对偏航角与真实值之间的误差。</p>
</blockquote>
<ol start="5">
<li><strong>EASI仿真到现实评估</strong>：经过EASI优化后，仿真器中的关节频率谱和运动轨迹与真实世界数据更加吻合（图6c, d）。政策在增强后的仿真器中微调后，能够以最小的性能损失迁移到真实世界。</li>
</ol>
<p><img src="https://arxiv.org/html/2505.09979v1/x6.png" alt="EASI评估"></p>
<blockquote>
<p><strong>图6</strong>：EASI评估。a) 仿真到仿真任务中的参数搜索过程。b) 仿真到真实任务中的参数搜索过程。c) 关节频率谱。d) 关节轨迹。</p>
</blockquote>
<p><strong>消融实验总结</strong>：图4g的消融实验表明，移除标签数据或RIM都会导致性能（NMI和ENT）下降，验证了半监督框架和RIM处理不平衡数据的有效性。图5b的消融实验表明，移除特权学习或BYOL都会显著降低任务成功率和鲁棒性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1) 提出了一个受神经科学启发的集成控制器架构，通过分离基本行为生成与任务规划，使四足机器人能够展现多样、自然的狗类行为。2) 开发了半监督InfoGAIL算法，以低成本从原始、不平衡的运动捕捉数据中学习可控的多模态行为。3) 综合利用EASI优化仿真器、特权学习和自监督学习（BYOL），有效解决了仿真到现实迁移问题，使机器人仅凭深度感知就能完成复杂的敏捷挑战。</p>
<p><strong>局限性</strong>：论文在讨论部分提到，未来可以收集更大规模的户外狗运动捕捉数据来训练更多样、鲁棒的BBC；当前TSC仅使用深度图像，融入更多视觉信息可提升其泛化能力；真实世界的物理参数是动态变化的，EASI可进一步用于模拟这些变化；目前的人机协作仅探索了远程控制模式，可引入语音、手势等多模态交互。</p>
<p><strong>后续启示</strong>：本研究为四足机器人敏捷性设立了“四足敏捷挑战”这一新颖的基准平台，有望推动社区竞争与发展。其方法框架（解耦控制、半监督行为学习、数据驱动的仿真优化）为在其他机器人平台学习复杂、多样的技能提供了可借鉴的路径。对真实生物数据的高效利用和仿真与现实的紧密对齐策略，是提升机器人整体性能和实用性的关键方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对四足机器人在复杂现实环境中难以复现广泛自然行为、缺乏动物级敏捷性的核心问题，提出一种集成控制器。该控制器由基本行为控制器（BBC）与任务特定控制器（TSC）构成：BBC采用半监督生成对抗模仿学习，从真实犬类运动数据中提取多样行为风格，并通过调整潜变量实现平滑切换；TSC基于特权学习处理深度图像以协调任务执行。同时，采用进化对抗模拟器识别优化仿真环境。实验表明，机器人能展现多样自然行为，成功完成敏捷挑战，平均速度达1.1 m/s，跨越障碍时峰值速度达3.2 m/s。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.09979" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>