<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Artificial Intelligence (cs.AI)</span>
      <h1>Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.11480" target="_blank" rel="noreferrer">2509.11480</a></span>
        <span>作者: Taherin, Amir, Lin, Juyi, Akbari, Arash, Akbari, Arman, Zhao, Pu, Chen, Weiwei, Kaeli, David, Wang, Yanzhi</span>
        <span>日期: 2025/09/15</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作（VLA）模型已成为机器人控制的强大通用策略，在从桌面操作到长时程规划的各种任务中展现出卓越的泛化能力。然而，现有研究主要集中在提升模型精度或将视觉-语言架构适配于动作生成，其评估通常仅在单一硬件平台和固定资源配置下进行。因此，对于将VLA模型部署于从功耗受限的边缘设备到高性能数据中心GPU的全谱系计算平台时，在精度、延迟、吞吐量和内存使用之间存在的权衡关系，人们知之甚少。这一认知空白限制了我们在特定环境中做出明智的部署决策和优化模型的能力。</p>
<p>本文旨在系统性地刻画VLA模型在模型架构、硬件类别和功耗预算下的扩展趋势，以填补这一关键空白。本文的核心思路是：通过在一系列边缘和云端GPU平台上评估五种代表性VLA模型的精度、内存、延迟和吞吐量，揭示架构选择、硬件能力与功耗限制之间的相互作用，从而为在不同部署约束下选择和优化VLA模型提供可操作的指导。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文的整体研究框架是一个系统性的评估实验。输入是五种不同的VLA模型，在两类硬件平台（边缘设备与数据中心GPU）上，以标准化的基准任务进行推理。输出是模型在精度、峰值内存使用、延迟和吞吐量等多个维度的量化性能指标。</p>
<p>核心模块包括：</p>
<ol>
<li><strong>评估模型</strong>：选取了五个具有代表性的VLA模型。三个是广泛使用的基线模型：OpenVLA、SpatialVLA和OpenVLA-OFT。另外两个是新提出的架构：VOTE（包含三种配置）和QwenVLA。这些模型在语言骨干网络大小、视觉编码器、动作头设计和输出分块大小上存在差异，如表IV所示。</li>
<li><strong>硬件平台</strong>：<ul>
<li><strong>边缘平台</strong>：采用NVIDIA Jetson AGX Orin系统级芯片，支持多种可配置功耗模式（15W、30W、50W、MAX），以探索性能与能耗的权衡。其在不同功耗模式下的CPU/GPU频率缩放和核心分配情况如表II所示。</li>
<li><strong>数据中心平台</strong>：选用了代表多代架构和性能层级的四款离散式NVIDIA GPU：H100（Hopper）、A100（Ampere）、A6000（Ampere）和V100（Volta）。其关键规格对比如表III所示，突显了与边缘平台在内存、带宽和热设计功耗上的巨大差异。</li>
</ul>
</li>
<li><strong>评估方法</strong>：<ul>
<li><strong>精度基准</strong>：使用LIBERO基准测试，该测试包含四个任务套件（空间、物体、目标、长时程），用于评估模型在多样化机器人操作任务中的成功率。</li>
<li><strong>效率指标</strong>：测量单次推理的<strong>延迟</strong>（生成一个动作块的平均时间）和<strong>吞吐量</strong>（每秒生成的动作数）。测试使用固定的224x224 RGB图像和语言提示，在多次预热后记录100次连续推理的耗时以计算平均值。同时记录<strong>峰值内存使用量</strong>。</li>
</ul>
</li>
</ol>
<p>本文的创新点在于首次系统性地将VLA模型的性能评估从单一的算法精度维度，扩展到涵盖多种硬件平台（特别是功耗可调边缘设备）和系统级指标（延迟、吞吐量、内存）的多维分析，从而揭示了模型架构与硬件约束之间的复杂交互关系。</p>
<p><img src="https://arxiv.org/html/2509.11480v2/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：在NVIDIA Jetson AGX Orin上进行推理时，每个被评估VLA模型的峰值VRAM使用情况。结果显示，内存使用主要受骨干网络大小和视觉编码器选择驱动，动作头设计（如令牌数量或MLP深度）影响可忽略。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>基准与数据集</strong>：使用LIBERO基准测试评估模型精度，该测试包含四个任务套件，每个套件10个任务，每个任务重复20次。</p>
<p><strong>对比方法</strong>：对比了五个VLA模型：OpenVLA、SpatialVLA、OpenVLA-OFT、QwenVLA以及VOTE的三种配置（VOTE-1T, VOTE-2T, VOTE-MLP4）。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>模型精度对比</strong>：如表V所示，VOTE变体在所有套件中取得了最高的平均成功率（SR）。VOTE-1T以96.9%的总体性能位居榜首，超过了最强的基线OpenVLA-OFT（95.3%）。尽管QwenVLA的骨干网络小得多（1.5B），但其平均成功率（78.8%）仍超过了更大的OpenVLA基线（76.5%），表明在减小模型规模的同时仍能保持有竞争力的任务性能。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.11480v2/x5.png" alt="实验结果表"></p>
<blockquote>
<p><strong>表V</strong>：各模型在LIBERO基准测试四个任务套件上的成功率（SR）。VOTE-1T取得了最高的平均成功率。</p>
</blockquote>
<ol start="2">
<li><p><strong>内存使用分析</strong>：如图1所示，基线模型中，OpenVLA和OpenVLA-OFT内存占用最高（分别为14.35 GB和19.20 GB），而SpatialVLA需求显著更低（7.82 GB）。QwenVLA整体内存使用最低（7.39 GB）。所有VOTE配置的内存占用相似（14.40–14.45 GB），与OpenVLA相当。</p>
</li>
<li><p><strong>延迟对比</strong>：如图2所示，在最高性能的数据中心GPU（H100）上，所有模型的延迟（0.03 ms 到 0.34 ms）比在MAX功耗模式下的Jetson AGX Orin（0.29 ms 到 1.95 ms）低大约一个数量级。VOTE配置在两个平台上都保持了有竞争力的延迟，其中VOTE-MLP4在Orin上实现了最低延迟。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2509.11480v2/x2.png" alt="延迟对比图"></p>
<blockquote>
<p><strong>图2</strong>：在H100数据中心GPU和Jetson AGX Orin（MAX功耗模式）上评估的每个VLA模型的每块延迟。H100的延迟比Orin低约一个数量级。</p>
</blockquote>
<ol start="4">
<li><strong>吞吐量扩展趋势</strong>：<ul>
<li><strong>跨数据中心GPU</strong>：如图3(a)所示，H100始终提供最高性能，VOTE-MLP4达到474.78 Hz，比同一硬件上的OpenVLA快64倍以上。A100遵循类似的扩展模式，但绝对值较低。A6000对于SpatialVLA、QwenVLA等较小模型保持了强劲性能，但对于更大、计算更密集的模型，其优势减弱。V100受限于较旧的架构和较低的内存带宽，整体吞吐量最低。</li>
<li><strong>跨边缘功耗预算</strong>：如图3(b)所示，AGX Orin的吞吐量强烈依赖于功耗约束。在MAX模式下，VOTE-MLP4达到55.57 Hz，比相同条件下的OpenVLA（1.20 Hz）快46倍以上。即使功耗降低，模型的相对排序保持一致。吞吐量的减少与功耗缩放呈非线性关系，从50W降至30W会导致更急剧的性能损失，特别是对于计算量大的模型。</li>
<li><strong>边缘与数据中心对比</strong>：比较MAX模式下的Orin与最快的H100，突显了性能差距：VOTE-MLP4在H100上快8.5倍。然而，一个关键发现是：MAX模式下的Orin搭配VOTE-MLP4（55.57 Hz）的吞吐量超过了数据中心GPU V100（32.28 Hz），这表明现代高端边缘设备可以超越旧的数据中心硬件。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2509.11480v2/x3.png" alt="吞吐量对比图"></p>
<blockquote>
<p><strong>图3</strong>：每个被评估VLA模型在（a）四种数据中心GPU和（b）不同功耗模式下的Jetson AGX Orin上的吞吐量（Hz）。结果突显了硬件类别、功耗预算和模型架构的扩展趋势。</p>
</blockquote>
<p><strong>消融实验总结</strong>：本文通过VOTE的三种配置（VOTE-1T, VOTE-2T, VOTE-MLP4）和QwenVLA，对模型架构的关键变量进行了“消融”式对比。结果表明：（1）优化分块解码的架构（如VOTE-2T和VOTE-MLP4）能在牺牲少量精度（相对于VOTE-1T）的情况下，显著提高所有硬件类别上的吞吐量。（2）模型内存使用主要由骨干网络大小和视觉编码器选择决定，小型骨干设计（如QwenVLA）能以最低的内存占用保持有竞争力的精度。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：</p>
<ol>
<li><strong>首次系统性跨平台评估</strong>：首次对VLA模型在从功耗受限边缘设备到高性能数据中心GPU的多种硬件平台上的性能扩展趋势进行了系统性的实证研究，提供了精度、内存、延迟和吞吐量的多维度分析。</li>
<li><strong>揭示关键权衡与挑战假设</strong>：研究发现，为分块解码优化的架构能实现最高吞吐量；模型内存占用主要由骨干大小决定；现代高端边缘设备在特定配置下可以超越旧的数据中心GPU，挑战了云端硬件必然优于边缘的固有假设。</li>
<li><strong>提供可操作的部署指南</strong>：研究结果为根据部署约束（功耗、延迟要求、硬件预算）和性能优先级（最高精度 vs. 最高吞吐量）选择和配置VLA模型提供了具体、可操作的指导。</li>
</ol>
<p><strong>论文提到的局限性</strong>：本文主要集中于特定的一组模型和硬件平台进行评估，未来工作可以扩展到更多样的模型架构、量化策略以及真实世界的机器人部署场景，以进一步优化实际约束下的VLA推理。</p>
<p><strong>对后续研究的启示</strong>：这项工作强调了在机器人AI模型设计中考虑<strong>算法-硬件协同优化</strong>的重要性。未来的VLA架构设计不应仅追求基准测试上的最高精度，还需将推理效率、内存 footprint 以及对不同功耗预算的适应性作为核心设计目标。同时，在部署机器人系统时，应根据具体的硬件约束和性能需求，在模型架构、硬件选型和功耗配置之间进行精细的权衡。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文研究了视觉-语言-动作（VLA）模型在不同硬件平台（从边缘设备到云端GPU）上的性能扩展问题，旨在评估其准确性、延迟、吞吐量和内存占用的权衡。研究评估了五种代表性VLA模型，包括现有基准和新提出的架构，使用LIBERO基准测试，并在不同边缘功耗约束与高性能数据中心GPU配置下进行测量。核心发现包括：架构选择（如动作标记化和主干大小）显著影响吞吐量和内存占用；功耗受限的边缘设备性能呈非线性下降，部分配置可匹配或超越旧款数据中心GPU；并且可以实现高吞吐量变体而不显著损失准确性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.11480" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>