<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.05985" target="_blank" rel="noreferrer">2506.05985</a></span>
        <span>作者: Ping Luo Team</span>
        <span>日期: 2025-06-06</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前机器人学习的主流范式是“预训练-微调”，即在大规模数据集上预训练一个视觉-语言-动作模型，然后为下游任务进行微调。参数高效微调方法，如低秩适应，因其只需优化少量参数即可有效引导冻结的预训练模型，在单任务适应中被广泛采用。然而，在终身学习场景中，现有方法存在两个关键局限：首先，它们通常依赖不切实际的假设，即测试时已知任务标识符，以便检索对应的任务特定适配器；其次，这些方法将知识隔离在独立的适配器中，阻碍了任务间的知识共享，导致前向迁移能力不佳。</p>
<p>本文针对终身机器人学习中“如何在不依赖任务标识符的情况下，实现高效的前向迁移并最小化灾难性遗忘”这一具体痛点，提出构建一个渐进增长的参数高效专家库，并利用轻量级路由器动态组合专家的新视角。核心思路是：通过动态混合历史专家库中的知识来适应新任务以提升前向迁移，并通过回放专家组合系数来正则化路由器以缓解遗忘。</p>
<h2 id="方法详解">方法详解</h2>
<p>DMPEL的整体框架基于一个冻结的预训练策略模型，在其线性层上渐进地附加一个低秩专家库，并引入一个轻量级路由器来动态整合这些专家。输入是当前上下文（历史观测和语言指令），输出是机器人动作。其工作流程分为两个核心部分：在适应新任务时，路由器根据当前上下文动态计算各专家的组合系数，生成一个混合策略；在任务完成后，冻结该任务对应的新专家，并利用专家系数回放机制来稳定路由器对已学任务的记忆。</p>
<p><img src="https://arxiv.org/html/2506.05985v2/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：DMPEL方法概述。左侧：在终身学习过程中，策略的每个选定子模块（如视觉编码器、时序Transformer等）都配备了一个渐进增长的低秩专家库。一个轻量级路由器根据当前上下文（聚合的视觉、语言和本体感知特征）动态生成各专家的组合系数。右侧：专家系数回放机制。在任务完成后，将路由器输入输出对存入缓冲区；在学习新任务时，除了最小化行为克隆损失，还通过回放缓冲区的数据来正则化路由器，使其对旧任务保持一致的专家组合。</p>
</blockquote>
<p>核心模块一：<strong>渐进低秩专家库</strong>。该方法为策略中的每个选定子模块（共M=6个，包括视觉编码器、文本编码器等）维护一个专家库。对于任务k，每个专家包含可训练的低秩矩阵A_k、B_k和偏置b_k。前向传播时，动态权重由预训练权重与专家库的混合构成：y = xW_0 + b_0 + x(Σ c_j A_j)(Σ c_j B_j) + Σ c_j b_j。创新点在于：1) <strong>动态组合</strong>：不同于为每个任务固定分配一个适配器，DMPEL允许根据上下文灵活混合所有历史专家；2) <strong>模块化系数</strong>：路由器为每个子模块输出独立的系数向量，允许不同模块采用不同的知识组合策略；3) <strong>正交初始化</strong>：为新任务初始化专家A矩阵时，采用Gram-Schmidt正交化，以减少与已有专家间的干扰。</p>
<p>核心模块二：<strong>轻量级路由器与专家系数回放</strong>。路由器是一个多层感知机，输入是过去T步内视觉嵌入、语言嵌入和本体感知状态的均值聚合，输出是M个k维系数向量。采用top-k操作保留最重要的专家以提升效率。为缓解因路由器持续更新导致的遗忘，提出了专家系数回放机制：在完成每个任务后，存档一部分路由器的输入（上下文嵌入r）和输出（系数向量c）到缓冲区；在学习新任务时，除了行为克隆损失，还引入一个均方误差损失来强制路由器在面对旧上下文时产生与存档一致的系数。相比传统的经验回放需要存储完整轨迹并用整个策略处理，该方法仅需存储低维嵌入和系数，计算和存储开销显著降低。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在终身机器人学习基准LIBERO上进行，包含Goal、Spatial、Object和Long四个任务序列（各10个任务）。使用预训练的CLIP作为视觉和文本编码器，策略其余部分在LIBERO-90数据集上预训练。</p>
<p>对比的基线方法包括：顺序全微调、顺序冻结特征微调；经典终身学习方法（经验回放ER、弹性权重巩固EWC、PackNet）；分层方法LOTUS；以及基于LoRA的方法（TAIL、L2M、IsCiL）。评估指标为前向迁移、负向后向迁移和成功率曲线下面积。</p>
<p><img src="https://arxiv.org/html/2506.05985v2/x3.png" alt="主要结果"></p>
<blockquote>
<p><strong>图3</strong>：不同终身学习方法在LIBERO基准上的性能对比。DMPEL在FWT（前向迁移）、NBT（负向后向迁移，值越低越好）和AUC（曲线下面积）三个指标上均表现优异，尤其在FWT上显著优于其他LoRA基方法。</p>
</blockquote>
<p>关键实验结果：DMPEL在大多数任务序列上取得了最佳或接近最佳的AUC分数，表明其整体性能更优。具体而言，其FWT指标显著高于其他LoRA基方法（如TAIL、L2M），证明动态组合专家能更有效地利用先前知识进行快速适应。同时，其NBT与表现最好的回放方法ER相当，表明专家系数回放能有效控制遗忘。如图1所示，DMPEL仅需回放5%的系数数据，即可在实现更好前向迁移的同时达到接近零的遗忘。</p>
<p><img src="https://arxiv.org/html/2506.05985v2/x5.png" alt="消融实验1"></p>
<blockquote>
<p><strong>图5</strong>：动态组合与系数回放的消融研究。移除动态组合（“w/o DC”）严重损害前向迁移；移除系数回放（“w/o CR”）导致严重的灾难性遗忘（NBT激增）。两者结合对性能至关重要。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.05985v2/x6.png" alt="消融实验2"></p>
<blockquote>
<p><strong>图6</strong>：专家选择策略（top-k）的消融。top-3策略在性能和效率间取得了良好平衡。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.05985v2/x7.png" alt="消融实验3"></p>
<blockquote>
<p><strong>图7</strong>：路由器输入组件的消融。同时包含视觉、语言和本体感知信息能获得最佳性能，移除任一组件都会导致性能下降。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.05985v2/x8.png" alt="消融实验4"></p>
<blockquote>
<p><strong>图8</strong>：专家库增长方式的消融。与“仅训练新专家”相比，允许在新任务训练期间微调整个专家库（“微调所有专家”）会带来严重的灾难性遗忘，验证了冻结历史专家并仅训练新专家的必要性。</p>
</blockquote>
<p>消融实验总结：动态组合机制对提升前向迁移贡献最大；专家系数回放对防止遗忘至关重要；top-3的专家选择策略是有效的；路由器需要融合多模态上下文信息；冻结历史专家是维持稳定性的关键。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出了DMPEL框架，通过渐进构建低秩专家库和上下文感知的动态路由，实现了终身机器人学习中灵活、高效的前向知识迁移；2) 设计了专家系数回放机制，利用参数的高效模块化特性，以极低的存储和计算成本有效缓解了灾难性遗忘。</p>
<p>论文自身提到的局限性包括：专家库随任务数量线性增长，虽然每个专家参数量小，但长远看仍需管理；路由器容量固定，可能限制其处理大量任务时的表达能力。</p>
<p>这项工作对后续研究的启示在于：将参数高效微调与动态模型融合相结合，是解决终身学习中知识迁移与保留矛盾的有效途径；利用模块化设计的优势，可以设计出比传统经验回放更高效的防遗忘机制；未来的工作可以探索更智能的专家库压缩或修剪策略，以及更具表达力的路由器架构，以支持更长时间的终身学习。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对终身机器人学习中前向迁移与灾难性遗忘的平衡问题，提出动态混合渐进参数高效专家库（DMPEL）。方法核心是渐进构建低秩专家库，通过轻量级路由器动态组合专家形成策略，并引入专家系数重放以准确检索旧任务专家，从而高效抑制遗忘。在LIBERO基准上的实验表明，DMPEL在持续适应中取得了更高的成功率，同时使用的可训练参数和存储开销极小。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.05985" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>