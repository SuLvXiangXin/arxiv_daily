<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>LIBERO-X: Robustness Litmus for Vision-Language-Action Models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Computer Vision and Pattern Recognition (cs.CV)</span>
      <h1>LIBERO-X: Robustness Litmus for Vision-Language-Action Models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.06556" target="_blank" rel="noreferrer">2602.06556</a></span>
        <span>作者: Wang, Guodong, Zhang, Chenkai, Liu, Qingjie, Zhang, Jinjin, Cai, Jiancheng, Liu, Junjie, Liu, Xinmin</span>
        <span>日期: 2026/02/06</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作（VLA）模型已成为机器人操作的关键范式。为了系统评估其能力，研究社区引入了如LIBERO、SimpleEnv等一系列标准化基准。然而，现有基准存在两大关键局限性：首先，在评估协议上，现有基准通常只关注独立的扰动类型（如空间位置），未能捕捉真实部署中多源分布偏移的耦合效应，且缺乏从易到难的系统性难度递进，难以刻画性能随环境与任务复杂度增加的退化情况。其次，在数据层面，训练数据多样性不足，且训练与测试场景、任务差异有限，导致模型容易过拟合到有限的、模板化的行为模式，在接近训练分布的测试中取得近乎饱和的成功率，从而产生过于乐观甚至误导性的能力评估。</p>
<p>本文针对现有VLA基准在评估协议和数据多样性上的不足，提出了一个系统性的新视角：通过联合解决评估层次性和训练数据多样性问题，构建一个更全面、更可靠的基准。本文的核心思路是提出LIBERO-X基准，它包含一个通过人类遥操作收集的高多样性训练数据集，以及一个结合了渐进式多级评估和细粒度多标签系统的评估框架，旨在更真实地反映VLA模型在复杂、动态环境中的鲁棒性和泛化能力。</p>
<h2 id="方法详解">方法详解</h2>
<p>LIBERO-X基准的核心由两部分构成：一个高多样性的训练数据集，以及一个多维度的评估框架。</p>
<p><img src="https://arxiv.org/html/2602.06556v1/x2.png" alt="LIBERO-X概览"></p>
<blockquote>
<p><strong>图2</strong>：LIBERO-X概览。LIBERO-X提供了一个通过人类遥操作构建的高多样性训练数据集，以及多级、多标签的评估数据。</p>
</blockquote>
<p><strong>1. 高多样性训练数据集</strong><br>为缓解原始LIBERO中场景单一、轨迹相似导致的过拟合风险，LIBERO-X构建了一个更具现实变异性的训练数据集。该数据集包含2520条演示轨迹、600个任务和100个场景。其设计特点包括：</p>
<ul>
<li><strong>多任务场景设计</strong>：与原始LIBERO平均每个场景仅2.6个任务不同，LIBERO-X将任务密度显著提升至平均每个场景6个任务。这迫使模型在相同的视觉和物理条件下，适应不同的操作策略。</li>
<li><strong>属性条件化操作</strong>：任务指令明确依赖于细粒度的物体属性（如尺寸、颜色、纹理），而非宽泛的类别。场景中包含具有相似属性的干扰物，以严格测试模型的感知对齐能力。</li>
<li><strong>空间关系推理</strong>：任务要求模型理解和推理物体间的空间关系（如左/右、前/后、近/远）。</li>
</ul>
<p>这些设计鼓励模型学习目标物体与其语言描述之间可组合的语义对应关系，而非依赖模板化指令或固定场景结构做出“记忆性”决策。数据收集通过VR遥操作（Meta Quest 3）在MuJoCo仿真环境中完成，记录了末端执行器的6D位姿和夹爪状态，并渲染多视角图像。</p>
<p><img src="https://arxiv.org/html/2602.06556v1/x3.png" alt="训练轨迹分布对比"></p>
<blockquote>
<p><strong>图3</strong>：训练轨迹分布可视化对比。(a) LIBERO的轨迹分布相对集中。(b) LIBERO-X的轨迹分布更广、密度更高，展示了其更大的多样性。</p>
</blockquote>
<p><strong>2. 多维评估框架</strong><br>评估框架采用“二维”设计：纵向是多级评估协议，横向是细粒度多标签系统。</p>
<ul>
<li><p><strong>多级评估（纵向）</strong>：采用“重用-调整-重构”策略，构建了一个难度逐级递增的五级测试体系，高级别在低级别基础上叠加新的扰动维度：</p>
<ul>
<li><strong>Level 1 - 局部空间扰动</strong>：物体位置微小变化。</li>
<li><strong>Level 2 - 扩展空间扰动</strong>：在Level 1基础上，扩大空间变化范围。</li>
<li><strong>Level 3 - 场景拓扑重构</strong>：改变物体的相对位置（如交换目标物与干扰物的位置），打破训练中学到的固定空间关联。</li>
<li><strong>Level 4 - 视觉属性变化</strong>：改变物体的纹理、颜色、尺寸；引入未见过的物体类别和视觉相似的混淆物。</li>
<li><strong>Level 5 - 语义等价重述</strong>：对任务指令进行同义改写，包括同义词替换、词语压缩、词序调整、语态转换和冗余描述五种方式。</li>
</ul>
</li>
<li><p><strong>多标签评估（横向）</strong>：每个任务被标注上细粒度的属性标签，用于深入诊断模型在不同维度的具体表现：</p>
<ul>
<li><strong>交互类型</strong>：评估操作策略多样性（抓放、开关类、组合类）。</li>
<li><strong>子任务数量</strong>：评估规划与序列推理能力（单步到三步）。</li>
<li><strong>空间关系</strong>：评估空间推理与环境感知能力。</li>
<li><strong>物体属性</strong>：评估细粒度视觉感知与利用能力。</li>
</ul>
</li>
</ul>
<p>与现有基准相比，LIBERO-X的创新点在于<strong>系统性</strong>：它不仅像一些后续工作那样引入了更多扰动，更重要的是通过层次化的设计使扰动<strong>累积</strong>和<strong>递进</strong>，从而能够精确分析性能退化；同时，它从根本上<strong>提升了训练数据的多样性</strong>，打破了场景-任务-轨迹的模板化映射，为模型学习泛化策略提供了更好的数据基础。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在LIBERO-X基准上进行。选择了五个代表性的VLA模型进行评估：OpenVLA-OFT、X-VLA、GR00T-N1.5、π0和π0.5。所有模型均在LIBERO-X自收集的训练数据集上进行监督微调（SFT）。每个任务进行10轮试验，并设置动态时间限制（人类平均完成时间的1.1倍）。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>多级评估性能</strong>：如表II所示，即使在仅包含微小空间扰动的Level 1，五个模型的平均成功率也仅为39.4%，表现最好的π0.5为65.2%。这与原有基准上接近90%的成功率形成鲜明对比，证明了LIBERO-X的挑战性。随着难度从Level 1增加到Level 5，模型性能平均下降了31.2%，所有模型均表现出显著的性能下降趋势。</li>
</ol>
<p><img src="https://arxiv.org/html/2602.06556v1/x5.png" alt="多级评估成功率下降"></p>
<blockquote>
<p><strong>图5</strong>：各模型在多级评估中的成功率下降趋势。横轴为评估级别（L1-L5），纵轴为成功率。所有模型均随难度增加性能显著下降，其中从L2到L3的下降最为剧烈。</p>
</blockquote>
<ol start="2">
<li><p><strong>核心发现</strong>：</p>
<ul>
<li><strong>发现1：VLA模型难以进行超出训练分布的空间外推</strong>。从Level 1到Level 2（空间扰动增大），平均成功率下降了9.8%，表明模型倾向于过拟合到训练数据中的特定空间配置。</li>
<li><strong>发现2：面对拓扑扰动时缺乏结构不变性</strong>。Level 3（场景拓扑重构）导致了最剧烈的性能下降（平均12.7%），表明模型缺乏对物体间相对空间关系的鲁棒推理能力。</li>
<li><strong>发现3：数据多样性促成了新兴泛化，但对新物体的语义对齐仍是瓶颈</strong>。在Level 4中，模型对未见物体（UO）的成功率远低于对混淆物体（CO）的成功率（例如π0.5：UO为7.2%，CO为28.9%），表明模型难以将新物体的视觉外观与语言描述对齐。</li>
<li><strong>发现4：指令的措辞变化显著影响任务执行</strong>。Level 5的语义改写导致所有模型性能进一步下降，其中同义词替换和词序调整的影响尤为突出。</li>
</ul>
</li>
<li><p><strong>多标签评估分析</strong>：<br><img src="https://arxiv.org/html/2602.06556v1/x6.png" alt="多标签评估结果"></p>
<blockquote>
<p><strong>图6</strong>：多标签评估结果。展示了不同模型在交互类型、子任务数量、空间关系、物体属性四个维度上的性能。π0.5在多数维度上领先，但所有模型在处理多步任务和复杂空间关系时都面临困难。</p>
</blockquote>
</li>
<li><p><strong>消融实验</strong>：论文通过控制训练数据多样性进行了消融实验。使用原始LIBERO数据训练的模型在LIBERO-X测试集上性能极差（接近0%），而使用LIBERO-X多样化数据训练的模型性能显著提升，这证明了<strong>训练数据多样性对于模型泛化能力至关重要</strong>，是本文所提方法有效的关键。</p>
</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了LIBERO-X基准，它引入了一个结合渐进式多级评估和细粒度多标签注释的评估框架，能够系统地表征模型在多维分布偏移下的性能。</li>
<li>构建了一个通过人类遥操作收集的高多样性训练数据集（2520条轨迹，600个任务，100个场景），显著提升了场景多样性和任务粒度，为模型学习泛化策略提供了更好的数据基础。</li>
<li>对代表性VLA模型的大量实验揭示了其在空间外推、拓扑不变性、新物体语义对齐及语言鲁棒性方面的显著局限，为未来模型设计提供了实证依据。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，目前的工作局限于仿真环境。虽然仿真提供了可重复性和可控性，但最终需要在真实机器人上进行验证以确认其发现。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>数据多样性优先</strong>：构建具有丰富场景、任务和轨迹变体的高质量数据集是提升VLA模型泛化能力的基础。</li>
<li><strong>模型架构与训练</strong>：需要设计更具空间推理、结构不变性和细粒度语义对齐能力的VLA架构及训练策略（如π0.5的联合训练策略显示出优势）。</li>
<li><strong>评估设计</strong>：未来的基准设计应采纳层次化、多维度的评估理念，以更系统、更真实地衡量模型鲁棒性，避免因测试集与训练集过于相似而产生的能力高估。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对现有视觉-语言-动作模型基准测试评估不全面、难以反映真实分布变化的问题，提出了LIBERO-X基准。其核心技术包括：1）分层评估协议，针对空间泛化、物体识别和任务理解三大能力设计渐进难度；2）通过人类遥操作收集的高多样性训练数据集，以缩小训练与评估分布差距。实验结果表明，代表性VLA模型在累积扰动下性能显著下降，暴露出其在场景理解与指令基础方面存在持续局限性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.06556" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>