<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.13324" target="_blank" rel="noreferrer">2510.13324</a></span>
        <span>作者: Jan Peters Team</span>
        <span>日期: 2025-10-15</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在接触丰富的机器人操作任务中，尤其是在处理易碎或可变形物体时，施加正确的抓握力至关重要。目前大多数模仿学习方法通常仅将视觉触觉反馈视为额外的观察模态，而施加的力则成为夹爪命令的不可控结果。这导致策略无法主动、精确地调控接触力。本文针对这一痛点，提出了一个名为FARM（Force-Aware Robotic Manipulation）的模仿学习框架，其核心思路是<strong>将高维触觉数据不仅作为观察，更直接整合到动作空间中，使策略能够联合预测机器人位姿、夹持宽度和目标抓握力，从而实现力感知的闭环控制</strong>。</p>
<h2 id="方法详解">方法详解</h2>
<p>FARM框架的整体流程包括：使用集成了GelSight Mini视觉触觉传感器的改装手持UMI夹爪收集人类演示数据；利用FEATS模型从触觉图像中提取物理接地的力分布估计；训练一个扩散策略，该策略以视觉、本体感知和触觉力观察为条件，预测包含目标末端执行器位姿、目标夹持宽度和目标抓握力的动作序列；最后，在配备驱动式UMI夹爪的机器人上，通过一个双模式控制器（根据接触状态在宽度控制和力控制间切换）部署策略。</p>
<p><img src="https://arxiv.org/html/2510.13324v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图3</strong>：FARM扩散策略架构示意图。视觉、本体感知和触觉观察被编码后，输入到带有FiLM条件调节的1D时序CNN中。模型预测的动作轨迹包括绝对末端执行器位姿、夹持宽度和抓握力。此结构支持操作过程中的夹爪闭环力控制。</p>
</blockquote>
<p>核心模块与技术细节如下：</p>
<ol>
<li><strong>硬件平台</strong>：包含两个几何匹配的夹爪。一个是用于数据收集的<strong>改装手持UMI夹爪</strong>，集成了Intel RealSense D405相机（提供手内RGB图像）、GelSight Mini触觉传感器（安装在一个指尖）、用于运动捕捉的OptiTrack标记和用于测量夹持宽度的ArUco标记。另一个是用于机器人部署的<strong>驱动式UMI夹爪</strong>，采用单个DYNAMIXEL电机驱动，传感器布局与手持版本完全相同，实现了策略的直接迁移。</li>
<li><strong>数据收集与处理</strong>：使用手持夹爪收集演示，同步记录RGB图像、夹持宽度、夹爪位姿、原始GelSight触觉图像。关键步骤是使用预训练的<strong>FEATS模型</strong>处理每一帧触觉图像，推断出剪切力（x, y方向）和法向力（z方向）的空间分布图，并积分得到总法向力标量值。所有数据流以触觉图像（25 Hz）为参考时钟进行同步。</li>
<li><strong>扩散策略设计</strong>：<ul>
<li><strong>观察空间</strong>：包括下采样后的手内RGB图像（96x96x3）、夹持宽度、由FEATS生成的三通道力分布图像（96x96x3）及总法向力标量、夹爪位姿（3D位置+6D旋转表示）。</li>
<li><strong>动作空间</strong>：预测未来32步的动作轨迹，包括绝对目标位姿、目标夹持宽度 (w^d) 和目标抓握力 (F_z^d)。执行时采用重规划（replanning）策略，每次执行16步。</li>
<li><strong>网络结构</strong>：使用基于1D时序CNN的扩散策略变体，并采用FiLM进行条件调节。视觉RGB图像和触觉力图像分别使用独立的ResNet-18编码器提取特征。</li>
<li><strong>训练</strong>：使用去噪扩散概率模型（DDPM），损失函数为去噪过程中添加噪声的均方误差。</li>
</ul>
</li>
<li><strong>策略部署与双模式控制</strong>：这是实现力感知操作的关键创新。策略同时输出目标宽度 (w^d) 和目标力 (F_z^d)。控制器根据当前估计的接触力 (\hat{F}_z)（来自FEATS）进行决策：<ul>
<li><strong>位置控制模式</strong>：当估计力 (\hat{F}_z) 和目标力 (F_z^d) 均低于-0.5N（无接触或接触很轻）时，直接将目标宽度 (w^d) 发送给电机的内部PD控制器。</li>
<li><strong>力控制模式</strong>：当估计力 (\hat{F}_z) 和目标力 (F_z^d) 均高于-0.5N（检测到可靠接触）时，切换为闭环力控制。计算力误差 (e = \hat{F}_z - F_z^d)，通过一个抗饱和的PID控制器处理该误差，输出值被加到当前夹持宽度上，再作为位置命令发送给电机。力控制环以25Hz运行，与触觉图像采集同步。</li>
</ul>
</li>
</ol>
<p>与现有方法相比，FARM的主要创新在于：<strong>将物理接地的力信号同时作为策略的观察和输出动作</strong>，并通过<strong>双模式控制器</strong>实现了对夹持宽度和抓握力的连续、自适应控制，避免了类似工作中需要等待力收敛或只能进行二值化夹爪控制的限制。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在真实Franka Research 3机器人上进行，使用了三个具有不同力需求的任务进行评估：需要高抓握力的<strong>植物插入</strong>、需要低抓握力的<strong>葡萄采摘</strong>以及需要动态力适应的<strong>螺丝拧紧</strong>。</p>
<p><img src="https://arxiv.org/html/2510.13324v1/figures/4_experiments_results/plant_insertion.png" alt="实验设置"></p>
<blockquote>
<p><strong>图4</strong>：三个任务的实验设置：(a) 植物插入，(b) 葡萄采摘，(c) 螺丝拧紧。</p>
</blockquote>
<p>为了评估FARM中触觉表示和力控制的作用，论文设置了三个基线方法进行对比：<strong>Force-Aware</strong>（仅使用总法向力标量作为触觉输入，保留力控制）、<strong>Tactile-Aware</strong>（使用原始GelSight触觉图像作为输入，但动作空间无目标力，即无力控制）和<strong>Vision-Only</strong>（仅使用视觉，无任何触觉输入，动作空间为二值化开/合命令）。</p>
<p><img src="https://arxiv.org/html/2510.13324v1/figures/4_experiments_results/grape_extraction.png" alt="成功率对比"></p>
<blockquote>
<p><strong>图5</strong>：植物插入、葡萄采摘和螺丝拧紧三个任务的成功率对比，每个任务评估20次 rollout。FARM框架在全部三个任务上均取得了最高或并列最高的成功率。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ul>
<li><strong>植物插入（高力任务）</strong>：Force-Aware基线达到95%成功率，Tactile-Aware为65%，Vision-Only为0%。这表明<strong>显式的力控制对于需要高抓握力的任务至关重要</strong>。FARM取得了与Force-Aware相同的95%成功率，表明在此任务中高维力分布信息未提供额外优势。</li>
<li><strong>葡萄采摘（低力任务）</strong>：FARM获得最高成功率（80%），Force-Aware为55%，Tactile-Aware为45%，Vision-Only为0%。这证明了<strong>结合高维力分布观察和显式力控制对于精细的低力操作最为有效</strong>。仅有力控制（Force-Aware）或仅有触觉图像（Tactile-Aware）但无力控制，效果均显著下降。</li>
<li><strong>螺丝拧紧（动态力任务）</strong>：FARM再次获得最高成功率（85%），Force-Aware为70%，Tactile-Aware为20%，Vision-Only为0%。该任务需要根据拧紧状态动态调整力。</li>
</ul>
<p><img src="https://arxiv.org/html/2510.13324v1/figures/4_experiments_results/screw_tightening.png" alt="螺丝拧紧力曲线"></p>
<blockquote>
<p><strong>图6</strong>：螺丝拧紧任务中，FARM与Force-Aware基线在典型成功试验中的估计抓握力随时间变化曲线。FARM展现出更平滑、更一致的力曲线，并且在拧紧后能更稳定地维持力。</p>
</blockquote>
<p><strong>消融实验总结</strong>：实验通过对比三个基线，实质上对FARM的两个关键组件进行了消融研究。结果表明：1) <strong>显式力控制组件</strong>（对比Tactile-Aware和Vision-Only）在所有任务中都带来了巨大性能提升；2) <strong>高维力分布观察组件</strong>（对比Force-Aware和FARM）在需要精细力调节（葡萄采摘）和动态力适应（螺丝拧紧）的任务中贡献了额外的性能增益。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：</p>
<ol>
<li>提出了<strong>FARM扩散策略</strong>，首次在模仿学习中<strong>将物理接地的力信号同时作为观察模态和显式动作输出</strong>，实现了对抓握力的直接预测与闭环控制。</li>
<li>设计并开源了<strong>几何匹配的驱动式UMI夹爪平台</strong>，实现了从手持演示装置到机器人执行器的无缝策略迁移，避免了复杂的重定向问题。</li>
<li>通过系统的实验验证了<strong>高维触觉力表示与显式力控制相结合</strong>在多种力敏感操作任务中的优越性。</li>
</ol>
<p>论文自身提到的局限性包括：依赖的FEATS模型可能存在预测偏差；硬件上目前仅在一个指尖安装了触觉传感器；双模式控制器的切换阈值需要根据传感器噪声特性进行设定。</p>
<p>这项工作为后续研究提供了重要启示：在接触丰富的操作中，将触觉感知<strong>从被动的观察角色转变为主动的控制目标</strong>是提升性能的关键方向。未来的工作可以探索更先进的触觉表征学习、在多指灵巧手上的应用，以及将力控制与更复杂的操作技能（如滑动、滚动等）相结合。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出FARM框架，解决接触式机器人操作中抓取力难以精确控制的核心问题。方法核心是触觉条件化扩散策略：通过高维触觉数据推断力信号，并构建基于力的动作空间，使策略能联合预测位姿、夹爪宽度与抓取力。实验表明，FARM在需高力、低力及动态力适应的三类任务上均优于基线，验证了力感知触觉观测与力控空间的有效性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.13324" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>