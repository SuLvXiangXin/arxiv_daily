<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.17111" target="_blank" rel="noreferrer">2510.17111</a></span>
        <span>作者: Guan, Weifan, Hu, Qinghao, Li, Aosheng, Cheng, Jian</span>
        <span>日期: 2025/10/20</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>传统机器人系统依赖特定任务算法和人工设计规则，在结构化环境中表现良好，但在非结构化、真实世界场景中泛化能力差。深度学习，特别是视觉语言模型（VLMs）的发展，为机器人控制提供了新范式，由此衍生的视觉-语言-动作（VLA）模型通过端到端映射语言指令和视觉观测到机器人动作，展现出卓越的语义理解和泛化能力。然而，当前主流VLA系统通常复用大型语言模型和重型视觉骨干网络，导致参数量巨大、内存占用高、推理速度慢，这与移动机械臂等边缘平台有限的板载计算能力、能量预算和严格的实时延迟要求形成尖锐冲突，阻碍了实际部署。尽管效率优化在VLM领域已被广泛研究，但直接将其应用于VLA系统并不直接，因为VLA还需生成时序一致的动作序列、满足实时约束并确保执行时的物理可靠性，激进的压缩或剪枝容易导致性能下降。现有VLA综述多关注概念、架构或特定应用，缺乏从效率视角的系统性梳理。本文旨在填补这一空白，首次系统性地从模型架构、感知特征、动作生成、训练/推理策略四个维度，综述提升VLA效率的方法。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文对高效VLA方法的讨论围绕其处理流程组织，整体框架涵盖四个核心效率优化维度。</p>
<p><img src="https://arxiv.org/html/2510.17111v3/images/1-1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：本综述的结构概览。围绕VLA系统的处理流程，将效率提升技术分为四个核心维度：高效模型架构、高效感知特征、高效动作生成以及高效训练-推理策略。</p>
</blockquote>
<p><strong>1. 高效模型架构</strong><br>这是决定系统效率的首要因素，主要分为三类策略：</p>
<ul>
<li><strong>静态主干选择</strong>：早期VLA为追求泛化能力常采用参数量巨大的VLMs（如RT-2达550亿参数），导致推理延迟高。近期研究转向采用更紧凑的骨干网络来直接提升效率，例如：RoboMamba引入状态空间模型Mamba（约27亿参数）以更高效地进行时序建模；TinyVLA使用Pythia-1.3B等更小的语言模型；SmolVLA采用参数量仅0.24B至2.25B的SmolVLM-2并剪枝最后几层Transformer。</li>
<li><strong>动态计算路径</strong>：此策略旨在保留大型骨干网络表达能力的同时，在推理时动态跳过冗余计算。例如：FLOWER基于可解释性发现，静态剪枝语言模型中过度专注于下一词预测的冗余上层；DEER-VLA在语言模型不同中间层插入轻量级策略头，并基于输出相似性度量实现早期退出；MoLE-VLA采用混合专家框架，由门控机制动态选择参与计算的层；Efficient-VLA则通过计算层输入输出特征向量的余弦相似度，动态决定是否跳过该层。</li>
<li><strong>双系统设计</strong>：受认知科学双系统理论启发，将模型划分为处理复杂推理和长期规划的“慢系统”（通常为大模型），以及负责快速、直觉响应的“快系统”（轻量级模型）。两者通过潜在令牌或嵌入进行信息交换以协同完成任务。</li>
</ul>
<p><img src="https://arxiv.org/html/2510.17111v3/images/3-1.png" alt="双系统框架"></p>
<blockquote>
<p><strong>图4</strong>：双系统VLA框架示意图。多模态LLM（系统2）处理更新频率较低的视觉和文本令牌，生成推理和潜在令牌。这些潜在令牌随后被轻量级动作模型（系统1）使用，结合更新频率较高的视觉令牌，生成原始动作。两个系统异步运行：系统2的一轮推理提供的潜在向量可支持系统1的多步推理。</p>
</blockquote>
<p><strong>2. 高效感知特征</strong><br>视觉输入通常贡献了大部分令牌序列长度，是计算负担的主要来源。优化方向包括：</p>
<ul>
<li><strong>选择性特征处理</strong>：旨在压缩输入下游策略网络的视觉令牌序列。核心方法是基于重要性评分对令牌进行剪枝。例如，FastV根据视觉令牌在LLM中间层获得的平均注意力进行Top-K剪枝；EfficientVLA进一步量化视觉令牌与任务指令的交互来选择关键令牌；SP-VLA同时考虑语义重要性（通过注意力）和空间相关性（通过边缘检测）来保留令牌；LightVLA采用查询驱动的、可微分的令牌选择机制；ADP引入了任务驱动静态剪枝和动作感知动态切换的两阶段机制。</li>
<li><strong>时序共享与重用</strong>：利用帧间相似性，避免对静态或缓慢变化特征的重复计算。例如，FlashVLA对注意力输出矩阵进行奇异值分解，推导信息贡献分数来指导剪枝；SpecPrune-VLA则是一种无需训练的两级令牌缩减方法。</li>
</ul>
<p><img src="https://arxiv.org/html/2510.17111v3/images/4-1.png" alt="令牌剪枝"></p>
<blockquote>
<p><strong>图5</strong>：VLA系统中的令牌剪枝。在前向推理过程中，根据重要性度量对视觉令牌进行评分，信息量较少的令牌被剪枝以减少计算。这种剪枝可以在进入LLM主干之前或其内部层中进行。</p>
</blockquote>
<p><strong>3. 高效动作生成</strong><br>动作表示和生成方式显著影响效率，主要分为两类：</p>
<ul>
<li><strong>原始动作表示</strong>：直接输出低维连续动作值（如关节角度、末端执行器位姿）。其优点是维度低、解码快，但需要模型具备强大的从抽象语义到精确运动控制的映射能力。代表性方法如Diffusion Policy使用扩散模型生成动作序列。</li>
<li><strong>基于推理的动作表示</strong>：将动作编码为离散令牌，与语言令牌共享词汇表，利用LLM的推理能力进行预测（如RT-2）。这种方式能利用LLM的规划能力，但自回归解码可能带来延迟。为了加速，可采用非自回归解码、引入中间紧凑表示（如VLA-Adapter将视觉和语言特征适配到紧凑的潜在空间）或知识蒸馏（用大教师模型训练小学生模型）。</li>
</ul>
<p><strong>4. 高效训练与推理</strong><br>涵盖模型全生命周期的优化：</p>
<ul>
<li><strong>高效训练范式</strong>：包括<strong>高效微调</strong>（如LoRA、QLoRA仅更新少量参数）、<strong>高效预训练</strong>（设计针对机器人任务的预训练目标，如在大量机器人轨迹数据上训练）、以及<strong>数据高效学习</strong>（利用模拟数据、数据增强、课程学习、主动学习、模仿学习与离线强化学习结合）。</li>
<li><strong>高效推理优化</strong>：涉及<strong>模型压缩</strong>（量化、权重共享/低秩分解）、<strong>硬件感知优化</strong>（算子融合、内核优化、利用硬件特性）以及<strong>系统级优化</strong>（批处理、缓存、异步执行、云边协同）。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p>本文作为系统性综述，并未进行传统意义上的对比实验，但通过梳理文献，总结了高效VLA方法的发展轨迹、代表性工作及其特点。</p>
<p><img src="https://arxiv.org/html/2510.17111v3/images/2-2.png" alt="发展轨迹"></p>
<blockquote>
<p><strong>图3</strong>：高效VLA算法的发展轨迹图。该图突出了过去几年中专注于提升VLA模型效率的代表性工作，展示了该领域从早期探索到架构收敛，再到近期效率优化研究激增的演进过程。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.17111v3/images/5-1.png" alt="双系统模型总结"></p>
<blockquote>
<p><strong>表1</strong>：代表性双系统VLA模型总结。该表对比了不同双系统架构中“快系统”（直觉系统）和“慢系统”（深思系统）的具体组成以及两者间的通信方式。</p>
</blockquote>
<p>图3直观展示了高效VLA研究随着VLA模型本身发展而兴起的脉络。表1则系统对比了多种双系统VLA的设计，例如LCB使用LLaVA作为慢系统生成描述和提示，引导3D Diffuser Actor快系统生成动作；HiRT用InstructBLIP作为慢系统，EfficientNet-B3作为快系统；RoboDual组合OpenVLA和DiT等。这些设计在通信机制（特殊令牌、潜在向量、网络参数等）上各有不同，反映了实现层次化协作的多种思路。</p>
<p>在性能方面，综述引用了一些具体数据以说明效率问题的严峻性和优化效果：例如，OpenVLA拥有70亿参数，在强大GPU上运行频率仅为5 Hz；π0模型包含30亿参数，频率约为10 Hz。而采用效率优化手段后，如使用Mamba架构的RoboMamba参数量约为27亿，在保持任务性能的同时降低了延迟；TinyVLA、SmolVLA等通过采用更小主干，将参数量降至十亿甚至数亿级别，提升了边缘部署可行性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>首次系统性综述</strong>：填补了VLA领域效率优化视角的空白，首次对高效VLA模型进行了系统性的梳理和分类。</li>
<li><strong>提出四维分类法</strong>：创新性地将效率提升技术归纳为模型架构、感知特征、动作生成、训练/推理策略四个核心维度，为研究者提供了清晰的分析框架。</li>
<li><strong>总结现状与展望未来</strong>：系统总结了每个维度下的主流方法及其优缺点，并基于当前发展趋势，指出了未来需要优先关注的研究方向以进一步提升效率。</li>
</ol>
<p><strong>论文提及的局限性</strong>：文中分析的各效率优化方法本身存在局限。静态主干过度压缩会降低模型容量上限和泛化能力；动态计算路径通常需要额外的分支模块、大量的训练开销以及手动设计选择标准和阈值；双系统架构的异步实现可能引入子系统间的输出延迟，损害实时决策。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>探索VLA缩放定律</strong>：需要在多样化任务和实验条件下评估，以厘清模型规模、泛化能力和效率之间的权衡，找到最适合当前数据可用性的骨干网络规模。</li>
<li><strong>开发自适应动态路径</strong>：动态计算路径可受益于自适应和自动化机制，例如使用强化学习进行层跳过，使执行的层数由在线决策而非手动设计的启发式方法固定。</li>
<li><strong>考虑云边协同架构</strong>：鉴于许多VLA用例需要边缘部署，架构设计应明确考虑云边划分：轻量级快系统本地部署以确保低延迟控制，重型推理模块在云端运行。此类框架必须考虑通信延迟、带宽限制和隐私要求以确保鲁棒运行。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本论文是一篇系统性综述，旨在解决具身操控中视觉-语言-动作模型面临的高计算、内存开销与机器人边缘平台实时性需求之间的矛盾。论文将现有效率优化方法归纳为四个维度：模型架构、感知特征、动作生成和训练/推理策略，并对每类代表性技术进行了总结。其核心贡献在于系统梳理了提升VLA模型效率的路径，并讨论了未来趋势与开放挑战，为推进高效具身智能的发展指明了方向。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.17111" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>