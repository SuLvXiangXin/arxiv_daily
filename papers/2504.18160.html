<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Offline Learning of Controllable Diverse Behaviors - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Machine Learning (cs.LG)</span>
      <h1>Offline Learning of Controllable Diverse Behaviors</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2504.18160" target="_blank" rel="noreferrer">2504.18160</a></span>
        <span>作者: Petitbois, Mathieu, Portelas, Rémy, Lamprier, Sylvain, Denoyer, Ludovic</span>
        <span>日期: 2025/04/25</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>模仿学习（IL）旨在复制人类在特定任务中的行为。传统方法通常使用专家数据集来训练单一高效策略，但无法处理包含多种行为（如不同技能水平、目标或犹豫）的多模态数据集。近期工作尝试解决多模态问题，主要分为两类：一类在状态转移层面捕获多样性，但缺乏整个轨迹的时间一致性；另一类在轨迹层面处理多样性，但大多需要在与环境的在线交互中进行强化学习优化或熵最大化，并非旨在精确再现离线数据集中真实的轨迹分布。本文针对现有方法难以在完全离线设置下捕获真实轨迹多样性并实现可控生成的具体痛点，提出了一种新视角：通过引入“风格”作为轨迹层面的条件隐变量，来确保时间一致性并实现可控性。本文核心思路是：为数据集中的每个轨迹学习一个风格嵌入，训练一个以状态和风格为条件的策略，并通过相似性加权回归框架来平衡可控性与对随机环境的鲁棒性。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文方法的目标是从离线轨迹数据集中学习一个策略，使其生成的轨迹分布 $p_{\mathcal{M},\pi}(\tau)$ 尽可能接近专家轨迹的混合分布 $p_{\mathcal{M},\mu}(\tau)$，并允许通过隐空间（风格）控制生成的行为。</p>
<p><strong>整体框架</strong>：方法基于风格条件策略 $\pi(a|s, z)$，其中 $z$ 是代表轨迹“风格”的隐编码。训练过程涉及两个核心模块：一个为每个轨迹分配风格嵌入 $z_i$ 的编码器（实为嵌入矩阵），以及一个以状态和风格为输入的动作预测策略网络。生成时，通过采样不同的风格 $z$，即可诱导策略产生不同的行为轨迹。</p>
<p><strong>核心模块与细节</strong>：</p>
<ol>
<li><p><strong>基于风格的行为克隆（ZBC）</strong>：这是方法的基础。对于一个包含 $N$ 条轨迹的数据集 $\mathcal{D} = {\tau_i}$，为每条轨迹 $\tau_i$ 分配一个可训练的风格嵌入向量 $z_i$（即 $e_\phi(z|\tau_i) = \delta_{z_i}(z)$）。策略 $\pi_\theta(a|s, z)$ 的训练目标是最大化给定对应风格时，轨迹中状态-动作对的似然。其损失函数为：<br>$$\mathcal{L}<em>{ZBC}(\phi,\theta) = -\mathbb{E}</em>{\tau_i \sim \mathcal{D}} \left[ \mathbb{E}_{(s_t^i, a_t^i) \sim \tau_i} \left[ \log \pi_\theta(a_t^i | s_t^i, z_i) \right] \right]$$<br>训练完成后，通过均匀采样风格向量集 ${z_i}$ 中的嵌入，可以近似再生原始轨迹分布。ZBC 提供了精确的可控性，但可能因过拟合而对环境随机性（如初始状态分布、状态转移噪声）敏感，导致任务失败或风格控制失灵。</p>
</li>
<li><p><strong>相似性加权回归（SWR）</strong>：为解决 ZBC 的鲁棒性问题，本文提出了 SWR 框架，其核心算法是加权 ZBC（WZBC）。WZBC 在训练时，不再严格使用轨迹 $\tau_i$ 的动作和它自身的风格 $z_i$ 配对，而是引入一个轨迹间相异性函数 $\nu(\tau_i, \tau_j) \in [0,1]$。算法会采样一对轨迹 $(\tau_i, \tau_j)$，然后使用轨迹 $\tau_j$ 的风格 $z_j$ 来预测轨迹 $\tau_i$ 在状态 $s_t^i$ 下的动作 $a_t^i$，但损失权重由两轨迹间的相异性决定：$W_{\beta,\nu}(\tau_i, \tau_j) = \exp(-\beta \cdot \nu(\tau_i, \tau_j))$。超参数 $\beta \ge 0$ 控制着相似轨迹的影响带宽。$\beta=0$ 时退化为标准 BC（所有风格权重相同），$\beta$ 很大且 $\nu$ 为指示函数时逼近 ZBC。通过这种方式，策略在学习特定风格行为时，也能从相似轨迹中获取信息，增强了在面对环境随机性导致状态偏移时的泛化能力。为保持风格嵌入的语义，算法会阻止来自其他轨迹样本的梯度更新风格嵌入 $z_j$。</p>
</li>
</ol>
<p><strong>创新点</strong>：与现有方法相比，本文的创新点主要体现在：1) 明确强调并实现了轨迹层面的<strong>时间一致性</strong>，而非仅关注瞬时状态下的多模态动作。2) 通过构建行为隐空间实现了<strong>可控性</strong>，用户可通过选择风格来激活特定行为。3) 提出了 <strong>SWR 框架</strong>，创造性地通过轨迹相异性加权来调和 BC 的鲁棒性与 ZBC 的可控性，这是方法的核心贡献。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：本文在多个环境和人类生成的数据集上评估方法。使用了一个新的 Maze2D 环境以及修改版的 D3IL 库提供的数据集。评估涵盖三个关键维度：多样性重建、可控性和对随机性的鲁棒性。</p>
<p><strong>对比方法</strong>：Baseline 包括标准行为克隆（BC）、隐式行为克隆（IBC）、行为 Transformer（BeT）、DDPM-GPT，以及本文的 ZBC 和 SWR（WZBC）。</p>
<p><strong>关键结果与图表分析</strong>：</p>
<ul>
<li><p><strong>多样性重建评估</strong>：本文提出使用生成行为直方图与演示行为直方图之间的距离作为评估指标。在迷宫导航任务中，演示数据包含“只走一侧”和“只向前走”两种模式。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/medium_maze_one_side.png" alt="迷宫环境与行为直方图"></p>
<blockquote>
<p><strong>图1</strong>：“只走一侧”行为在迷宫环境中的示例轨迹。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/medium_maze_one_side_hist.png" alt="迷宫环境与行为直方图"><br><strong>图2</strong>：“只走一侧”行为的直方图评估。SWR（$\beta=3$）和 ZBC 能够很好地重建原始数据（Demo）的双峰分布，而 BC 和 IBC 则失败，产生了平均化的单峰分布。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/medium_maze_only_forward.png" alt="迷宫环境与行为直方图"><br><strong>图3</strong>：“只向前走”行为在迷宫环境中的示例轨迹。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/medium_maze_only_forward_hist.png" alt="迷宫环境与行为直方图"><br><strong>图4</strong>：“只向前走”行为的直方图评估。同样，SWR 和 ZBC 成功重建了多峰分布，而 BC 和 IBC 未能捕获多样性。</p>
</blockquote>
</li>
<li><p><strong>可控性测试</strong>：在 D3IL 的“对齐”和“躲避”任务中，通过指定特定风格嵌入，可以可靠地生成对应的行为模式。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/avoiding.png.png" alt="躲避行为"></p>
<blockquote>
<p><strong>图5</strong>：通过风格控制生成的“躲避”行为轨迹。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/avoiding_hist.png" alt="躲避行为直方图"><br><strong>图6</strong>：“躲避”行为的可控生成直方图。不同风格（颜色）对应不同的行为模式，表明良好的可控性。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/aligning.png" alt="对齐行为"><br><strong>图7</strong>：通过风格控制生成的“对齐”行为轨迹。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/aligning_hist.png" alt="对齐行为直方图"><br><strong>图8</strong>：“对齐”行为的可控生成直方图。不同风格成功诱导出不同的对齐策略。</p>
</blockquote>
</li>
<li><p><strong>消融实验（β 与相似性度量）</strong>：实验分析了 SWR 中 $\beta$ 参数和不同相异性函数 $\nu$ 的影响。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/similarity_0.png" alt="相似性度量影响"></p>
<blockquote>
<p><strong>图9</strong>：使用 $L_0$（基于状态的）相异性度量时，不同 $\beta$ 下的成功率。$\beta=3$ 时取得最佳平衡。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/similiarity_4.png" alt="相似性度量影响"><br><strong>图10</strong>：使用 $L_4$（基于动作的）相异性度量时，不同 $\beta$ 下的成功率。趋势类似，但整体成功率更高。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/similarity_2.png" alt="相似性度量影响"><br><strong>图11</strong>：使用 $L_2$（基于状态的）相异性度量时，不同 $\beta$ 下的成功率。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/beta_0.png" alt="β参数影响"><br><strong>图12</strong>：$\beta=0$（即 BC）生成的行为直方图。缺乏多样性，所有风格产生相同行为。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/beta_3.png" alt="β参数影响"><br><strong>图13</strong>：$\beta=3$（SWR）生成的行为直方图。成功分离出不同的行为模式。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/beta_100.png" alt="β参数影响"><br><strong>图14</strong>：$\beta=100$（近似 ZBC）生成的行为直方图。虽然有多样性，但某些模式因过拟合而失败（柱状图高度为0）。</p>
</blockquote>
</li>
<li><p><strong>鲁棒性测试</strong>：在存在环境随机性的迷宫中，SWR（$\beta=3$）相比 ZBC 实现了更高的任务成功率（例如，在某个设置下 SWR 成功率 ~85%，ZBC ~65%），证明了其更好的鲁棒性。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/control_behaior_l1.png" alt="可控性定量评估"></p>
<blockquote>
<p><strong>图15</strong>：不同方法在可控性指标（生成轨迹与目标风格轨迹的 $L_1$ 距离）上的表现。ZBC 和 SWR 显著优于基线。<br><img src="https://arxiv.org/html/2504.18160v1/extracted/6388466/figures/control_histograms_length_metric.png" alt="可控性直方图评估"><br><strong>图16</strong>：使用轨迹长度作为度量评估可控性。ZBC 和 SWR 生成的轨迹长度分布与目标风格分布匹配良好。</p>
</blockquote>
</li>
</ul>
<p><strong>消融实验总结</strong>：$\beta$ 参数在平衡多样性与鲁棒性上起关键作用，适中的值（如3）效果最佳。相异性度量 $\nu$ 的选择影响性能，基于动作的度量可能比基于状态的度量更有效。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1) 提出了<strong>相似性加权回归（SWR）框架</strong>，能够在完全离线设置下学习具有时间一致性和可控性的多样化行为，并显著提升对环境随机性的鲁棒性。2) 引入了基于<strong>生成行为直方图距离</strong>的评估指标，用于量化方法对演示多样性的重建能力。3) 在多个环境和数据集上进行了综合实验，验证了方法在多样性捕获、可控性和鲁棒性上优于现有基线。</p>
<p><strong>局限性</strong>：论文自身提到，当前方法中的风格嵌入是数据集中每条轨迹对应的，没有泛化到新的、未见过的轨迹。此外，SWR 框架依赖于预定义的轨迹相异性度量 $\nu$，其选择会影响性能。</p>
<p><strong>后续研究启示</strong>：未来的工作可以探索如何学习一个能够泛化的轨迹编码器，从而将风格语义推广到新轨迹。另一个方向是研究如何自动学习或优化相异性度量 $\nu$，使其更适合特定的任务或数据模态。此外，将 SWR 框架与更强大的序列生成模型（如扩散模型）结合，以处理更复杂的高维行为数据，也是一个有潜力的方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对模仿学习在处理多样化行为数据集时的局限性，提出了一种新的离线学习方法。传统方法难以再现演示的真实多样性或实现可控生成。为此，论文引入了两个关键技术：1）**时间一致性**，确保行为在整个情节内保持一致，而非仅在单步转移层面；2）**可控性**，通过构建行为潜在空间，允许用户根据需要选择性地激活特定行为。该方法在多种任务和环境上与先进方法进行了比较（具体性能数据请参见论文完整实验部分）。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2504.18160" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>