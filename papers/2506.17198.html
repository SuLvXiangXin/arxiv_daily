<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.17198" target="_blank" rel="noreferrer">2506.17198</a></span>
        <span>作者: Ye, Jianglong, Wang, Keyi, Yuan, Chengjing, Yang, Ruihan, Li, Yiquan, Zhu, Jiyue, Qin, Yuzhe, Zou, Xueyan, Wang, Xiaolong</span>
        <span>日期: 2025/06/20</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>灵巧手操作是机器人学中长期存在的挑战。其高自由度（DoF）虽然带来了灵活性，但也使其控制极具挑战性。当前主流的数据生成方法存在显著局限性：人类演示成本高昂且不精确；基于优化的方法（如DexGraspNet）计算缓慢且对初始化敏感；基于强化学习（RL）的方法则缺乏数据多样性。这导致可用于训练的大规模、高质量灵巧操作演示数据严重稀缺。</p>
<p>本文针对两个具体痛点提出新视角：1) <strong>可行性</strong>：生成模型的成功率通常低于确定性模型；2) <strong>多样性</strong>：生成模型倾向于在已有演示之间插值，而非扩展数据集的整体多样性。为解决这些问题，本文提出结合优化与生成模型优势的迭代数据生成流水线。核心思路是：首先使用高效的优化方法构建一个小规模、高质量的“种子”数据集；然后训练一个条件生成模型来学习其分布并进行大规模扩展；最后通过引入基于几何条件的去偏机制，主动生成多样化样本，迭代地提升数据规模与质量。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架是一个迭代的数据生成流水线，旨在高效生成大规模、高质量、多样化的灵巧操作演示。输入是物体资产和手部姿态初始化，输出是完整的抓取或关节操作轨迹序列。</p>
<p><img src="https://arxiv.org/html/2506.17198v1/extracted/6557444/figures/overview_v3.jpg" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：Dex1B演示生成流水线。引擎以物体资产和手部姿态初始化为输入，使用基于控制的优化算法生成种子数据集。种子数据集用于训练DexSimple生成模型。训练好的模型以比例π生成大规模的提案数据集。随后，利用模拟器批评器和去偏算法对提案数据集进行处理，生成去偏数据集，最后进行优化精炼。此过程可迭代进行。</p>
</blockquote>
<p><strong>核心模块与技术细节：</strong></p>
<ol>
<li><p><strong>优化生成种子数据集</strong>：采用基于球体近似的手部表示（每个连杆约10个球体）替代网格，显著加速优化过程。抓取任务的能量函数为：<code>E_grasp = E_fc + w_dis*E_dis + w_sdf*E_sdf + w_j*E_j + w_s*E_s</code>，其中<code>E_fc</code>为力闭合项，<code>E_dis</code>最小化接触距离，<code>E_sdf</code>防止穿透（基于球体SDF查询），<code>E_j</code>强制关节限位，<code>E_s</code>避免自碰撞。对于关节操作任务，将力闭合项<code>E_fc</code>替换为任务扳手空间项<code>E_tws</code>，以产生旋转或平移所需的力量/扭矩。</p>
</li>
<li><p><strong>生成模型（DexSimple）用于扩展</strong>：这是一个经过增强的条件变分自编码器（CVAE），其创新在于结合了几何约束和支持条件生成以提升多样性。</p>
<ul>
<li><strong>网络结构</strong>：使用PointNet编码物体点云，得到全局特征<code>f_obj</code>和每个点的局部特征<code>f_p</code>。CVAE的编码器和解码器均为多层感知机（MLP）。手部姿态<code>g</code>（包含平移T、旋转R、关节角θ）与条件特征（如<code>f_obj</code>）拼接后输入编码器，得到潜在分布参数(μ, σ)，采样得到潜变量<code>z</code>，再与条件特征拼接输入解码器重建姿态<code>g^</code>。</li>
<li><strong>损失函数</strong>：除了标准的重建损失<code>L_R</code>和KL散度损失<code>L_KL</code>，<strong>关键创新</strong>是引入了基于符号距离函数（SDF）的几何损失<code>L_sdf</code>。该损失惩罚生成的手部姿态与物体之间的穿透，并鼓励手指靠近物体表面，从而显著提升生成样本的物理可行性。</li>
<li><strong>条件生成与去偏</strong>：为提升多样性，模型可额外以物体表面的一个3D点的特征向量为条件。在数据生成阶段，统计每个点与已有动作的关联频率，然后<strong>逆概率采样</strong>，优先为关联动作较少的点生成新动作，以此主动探索数据分布中未被充分覆盖的区域。</li>
</ul>
</li>
<li><p><strong>后优化与运动规划</strong>：生成模型输出的姿态会经过一个轻量级的后优化步骤（能量函数仅包含<code>E_dis</code>， <code>E_sdf</code>， <code>E_j</code>， <code>E_s</code>），以微调手指位置，确保无穿透且紧密接触物体。随后，通过运动规划生成从起始点到关键帧姿态的平滑、无碰撞的 reaching 轨迹，并完成抓取后的提起或关节操作动作。</p>
</li>
</ol>
<p><strong>与现有方法的创新点</strong>：</p>
<ul>
<li><strong>迭代生成流水线</strong>：将优化（保证质量）与生成模型（保证效率）结合，并引入主动去偏机制迭代提升数据规模和多样性，突破了单一方法的瓶颈。</li>
<li><strong>简单而有效的生成模型</strong>：DexSimple模型结构虽简单（CVAE），但通过集成SDF几何损失，在可行性上大幅超越了更复杂的生成模型。</li>
<li><strong>统一的多任务处理</strong>：框架同时支持抓取和关节操作两种基础任务，并使用条件生成统一处理。</li>
</ul>
<p><img src="https://arxiv.org/html/2506.17198v1/extracted/6557444/figures/pipeline_v3.jpg" alt="生成模型框架"></p>
<blockquote>
<p><strong>图3</strong>：DexSimple模型框架。模型以手部参数和物体点云作为CVAE的固定输入，根旋转、平移和关节值作为可选条件。这些信息被组合为输入嵌入，同时点云嵌入在潜在空间中被重新强调。CVAE的输出通过前向运动学定义手部姿态轨迹，并由有效的损失函数进行优化。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>数据集/基准</strong>：使用了GraspNet-1B（抓取）、ArtiNet-B（关节操作）以及ManiSkill仿真基准进行评估。</li>
<li><strong>对比方法</strong>：包括基于优化的（DexGraspNet）、基于RL的（SynH2R）、基于生成模型的（DDG）以及先前SOTA方法。</li>
<li><strong>评估指标</strong>：抓取成功率（模拟器验证）、关节操作成功率、数据多样性指标（如接触点分布）、以及真实世界转移性能。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>数据规模与多样性优势</strong>：Dex1B包含10亿（1B）条演示，覆盖6000多个物体，在相似物体规模下，演示数量是DexGraspNet（132万）的约700倍。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.17198v1/extracted/6557444/figures/div_2.0.png" alt="数据对比"></p>
<blockquote>
<p><strong>图4</strong>：与DexGraspNet的多样性对比。左图显示Dex1B（蓝色）的接触点分布比DexGraspNet（红色）更广泛、更均匀，覆盖了物体表面更多区域。右图量化了不同物体上的演示数量分布，Dex1B的分布更广。</p>
</blockquote>
<ol start="2">
<li><strong>抓取合成性能提升</strong>：在GraspNet-1B基准上，使用Dex1B数据训练的DexSimple模型达到了<strong>86.2%</strong> 的成功率，比之前最好的方法（DexGraspNet）的<strong>64.2%</strong> 提升了**22%**。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.17198v1/extracted/6557444/figures/lifting-removebg.png" alt="抓取成功率"></p>
<blockquote>
<p><strong>图5</strong>：在GraspNet-1B基准上的抓取成功率对比。DexSimple（Ours）显著优于所有基线方法。</p>
</blockquote>
<ol start="3">
<li><strong>关节操作任务性能</strong>：在ArtiNet-B基准上，DexSimple也达到了SOTA性能，成功率为**69.9%**，大幅优于其他对比方法。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.17198v1/extracted/6557444/figures/arti_comb.png" alt="关节操作成功率"></p>
<blockquote>
<p><strong>图11</strong>：在ArtiNet-B基准上的关节操作成功率对比。DexSimple（Ours）表现最佳。</p>
</blockquote>
<ol start="4">
<li><strong>消融实验</strong>：<ul>
<li><strong>SDF损失的重要性</strong>：移除SDF损失会导致抓取成功率下降约10%。</li>
<li><strong>去偏机制的作用</strong>：使用去偏策略生成的数据，其接触点分布的熵值更高，表明多样性更好。</li>
<li><strong>迭代生成的效果</strong>：随着迭代次数增加，模型性能和生成数据的质量持续提升。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2506.17198v1/extracted/6557444/figures/scaling.png" alt="消融实验"></p>
<blockquote>
<p><strong>图8</strong>：迭代生成的效果。随着迭代进行（使用更多、更多样化的数据重新训练生成模型），生成样本的质量（成功率）和多样性（覆盖范围）持续提升。</p>
</blockquote>
<ol start="5">
<li><strong>仿真到真实转移</strong>：在真实机器人实验中（使用Shadow Hand），基于Dex1B训练的模型能够成功抓取和操作一系列未见过的日常物体，展示了良好的泛化能力。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.17198v1/extracted/6557444/figures/real.png" alt="真实实验"></p>
<blockquote>
<p><strong>图9</strong>：真实世界实验结果。展示了在真实Shadow Hand上对未见物体的成功抓取和关节操作。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>数据集贡献</strong>：提出了Dex1B，这是迄今为止规模最大、最多样化的灵巧操作演示数据集，包含10亿条高质量的抓取和关节操作轨迹。</li>
<li><strong>方法贡献</strong>：设计了一种新颖的迭代数据生成流水线，巧妙结合了优化方法的可靠性与生成模型的高效性，并通过条件生成和去偏机制主动提升数据多样性。</li>
<li><strong>性能贡献</strong>：提出了一个简单而强大的基准模型DexSimple，通过引入SDF几何约束，在多项任务上实现了显著的性能提升（抓取任务提升22%），为利用大规模数据的学习方法设立了新标杆。</li>
</ol>
<p><strong>局限性</strong>：论文提到，该方法依赖于模拟器进行演示评估和策略训练，因此模拟与现实的差距（Sim2Real Gap）仍然存在。生成数据的质量上限受限于优化种子数据集的质量和模拟器的物理真实性。</p>
<p><strong>后续研究启示</strong>：</p>
<ul>
<li><strong>数据规模与质量的价值</strong>：本工作强有力地证明，大规模、高质量的数据是解锁复杂灵巧操作能力的关键，能够显著提升学习模型的性能上限。</li>
<li><strong>简单模型的有效性</strong>：DexSimple的成功表明，与其一味追求复杂的模型架构，不如专注于将正确的归纳偏置（如几何约束）整合到简单模型中，这在拥有海量数据时尤为有效。</li>
<li><strong>生成与优化的协同</strong>：为大规模机器人数据生成提供了一个可扩展的范式，即用优化保证“质量锚点”，用生成模型进行“高效扩展”，并通过主动策略提升多样性，这对其他需要大量演示数据的机器人学习任务具有借鉴意义。</li>
</ul>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对灵巧操作数据稀缺的核心问题，提出了大规模演示数据集Dex1B。关键技术是结合几何约束的生成模型，通过整合优化技术确保物理可行性，并引入额外条件增强数据多样性。该方法在模拟基准测试中显著超越现有最优方法，并通过实物机器人实验验证了其有效性和鲁棒性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.17198" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>