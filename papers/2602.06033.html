<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Can vision language models learn intuitive physics from interaction? - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Machine Learning (cs.LG)</span>
      <h1>Can vision language models learn intuitive physics from interaction?</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.06033" target="_blank" rel="noreferrer">2602.06033</a></span>
        <span>作者: Buschoff, Luca M. Schulze, Voudouris, Konstantinos, Demircan, Can, Schulz, Eric</span>
        <span>日期: 2026/02/05</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，预训练的视觉语言模型在理解物理世界方面存在明显不足，在直观物理任务上表现不佳，且与人类行为数据拟合度差。主流的改进方法是监督微调，它能让模型在特定微调任务上达到良好性能，但模型似乎并未学到能够泛化到新情境的、鲁棒的物理规则。基于认知科学的研究，本文假设模型需要通过与环境互动来正确学习其物理动力学。因此，本文针对“如何让VLM学到可泛化的物理直觉”这一具体痛点，提出了通过强化学习实现“交互学习”的新视角。核心思路是：比较通过试错（交互式条件）学习搭建积木塔的模型与通过观察最优动作序列（非交互式条件）学习的模型，检验交互学习是否能带来更好的任务内性能及跨任务、跨数据分布的泛化能力。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文旨在探究交互学习（使用强化学习）与被动学习（使用监督微调）对VLM学习直观物理的影响。实验围绕积木塔的稳定性判断与搭建任务展开。</p>
<p><img src="https://arxiv.org/html/2602.06033v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：数据集与任务类型概览。<strong>数据集</strong>：<code>top block</code>（塔顶方块错位）和<code>side block</code>（地面方块错位）。<strong>任务类型</strong>：<code>binary stability</code>（二值稳定性判断）、<code>x-only</code>（输出单个整数移动方块以稳定/增大塔）、<code>x-y</code>（输出两个整数移动方块至塔顶稳定位置）。实验在四种数据集与任务组合上进行。</p>
</blockquote>
<p><strong>整体流程与核心模块</strong>：</p>
<ol>
<li><strong>环境与数据</strong>：使用ThreeDWorld物理引擎生成包含2-4个彩色立方体积木塔的256x256 RGB图像。构建两个核心数据集：<code>top block</code>（塔顶方块水平错位）和<code>side block</code>（地面方块水平错位）。此外，使用来自Lerer等人的真实木积木塔图像作为外部评估集。</li>
<li><strong>任务定义</strong>：基于数据集构建四种任务：<ul>
<li><code>binary stability</code>：判断给定塔是否稳定。</li>
<li><code>x-only</code>：输出一个整数，将错位方块沿x轴移动到最稳定（居中）位置。</li>
<li><code>x-y</code>：输出两个整数，将地面方块移动到塔顶最稳定位置（涉及x和y轴）。</li>
</ul>
</li>
<li><strong>模型与微调方法</strong>：基础模型为8B参数的4比特量化版Qwen3-VL。采用参数高效微调，仅更新注入各层的低秩适配器权重。<ul>
<li><strong>交互式条件</strong>：使用<strong>组相对策略优化</strong>进行强化学习训练。将模型及其适配器权重视为策略π_θ，输入提示和图像，输出token序列作为动作。对一批M个提示-图像对，模型生成M x N个补全序列，通过奖励函数计算奖励。损失函数基于近端策略优化风格，计算新旧策略概率比与标准化优势函数的裁剪最小值，并通过梯度上升更新适配器权重。</li>
<li><strong>非交互式条件</strong>：使用<strong>监督微调</strong>作为基线。在标注数据集上，通过token级交叉熵损失的梯度下降来更新适配器权重。</li>
</ul>
</li>
<li><strong>奖励函数</strong>：为每个任务设计了具体的奖励函数。<ul>
<li>对于<code>binary stability</code>：不可解析答案奖励-1，合法但错误答案奖励0，合法且正确答案奖励1。</li>
<li>对于<code>x-only</code>和<code>x-y</code>任务：不可解析答案奖励-5。对于可解析答案，根据最终位置与最优位置的欧氏距离，使用高斯函数计算奖励，使更接近最优位置的答案获得更高奖励，并且成功构建稳定高塔的答案奖励幅度最大（如<code>20 * e^(-d^2)</code>）。</li>
</ul>
</li>
</ol>
<p><strong>创新点</strong>：本文的核心创新在于首次在VLM的直观物理学习背景下，系统地比较了基于交互的强化学习（GRPO）与传统的非交互监督微调（SFT），并严格评估了二者在任务内性能与跨任务泛化能力上的差异，从而检验“交互对学习可泛化物理直觉至关重要”这一认知科学假说在现有VLM范式下的有效性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准/数据集</strong>：合成的<code>top block</code>和<code>side block</code>数据集，以及真实的Lerer木积木塔图像数据集。</li>
<li><strong>实验平台</strong>：单张80GB A100 GPU。</li>
<li><strong>对比方法</strong>：监督微调作为非交互基线，与基于GRPO的交互学习进行对比。后续还补充了使用GSPO算法和其他模型（Qwen2.5-VL-7B, Qwen3-VL-32B）的实验。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>任务内性能</strong>：GRPO和SFT都能显著提升模型在各自训练任务上的性能，达到接近天花板水平。例如，在<code>binary stability top block</code>任务上，GRPO和SFT模型测试准确率均达到0.969；在<code>x-only top block</code>任务上，平均测试奖励均达到19.999。交互学习在提升任务内性能方面并未显示出直接优势。</li>
</ol>
<p><img src="https://arxiv.org/html/2602.06033v1/x2.png" alt="实验结果总览"></p>
<blockquote>
<p><strong>图2</strong>：Qwen3-VL-8B在不同训练和测试任务上的性能热图。对角线子图显示任务内性能（GRPO和SFT均接近天花板）。非对角线子图显示泛化性能：模型普遍无法可靠地泛化到其他任务，无论是否经过交互训练。仅在同一数据分布的不同任务间（如图中左上和右下象限）观察到有限的泛化。</p>
</blockquote>
<ol start="2">
<li><strong>跨任务泛化</strong>：无论是GRPO还是SFT模型，都无法可靠地泛化到所有其他任务。仅观察到有限模式的泛化：例如，在相同<code>top block</code>数据上，从<code>x-only</code>任务到<code>binary stability</code>任务有少量泛化（GRPO模型准确率0.624）；在相同<code>side block</code>数据上，从<code>x-y</code>任务到<code>x-only</code>任务有泛化（GRPO模型奖励5.396）。但从一种数据分布泛化到另一种（如从<code>top block</code>任务到<code>side block</code>任务）则非常有限。</li>
<li><strong>泛化到真实图像</strong>：在Lerer的真实木积木塔图像上评估二值稳定性判断任务。</li>
</ol>
<p><img src="https://arxiv.org/html/2602.06033v1/x3.png" alt="真实图像泛化结果"></p>
<blockquote>
<p><strong>图3</strong>：在真实木积木塔图像上的性能。虽然从合成的<code>binary stability</code>任务到真实图像有一定迁移（准确率约0.6），但所有模型性能均低于人类平均水平（红线）。同样，交互训练并未显示出优于监督训练的优势。</p>
</blockquote>
<ol start="4">
<li><strong>解码能力分析</strong>：线性探测表明，塔的稳定性和顶部方块的x偏移量在基础模型的激活中就已经高度可解码，且微调后变化不大。这表明模型具备解决任务所需信息的“能力”，但未能将其转化为良好的“表现”，暗示了捷径学习。</li>
<li><strong>消融实验总结</strong>：<ul>
<li><strong>其他模型</strong>：在Qwen2.5-VL-7B上重复实验，发现泛化能力更差。</li>
<li><strong>特征可迁移性测试</strong>：将在<code>x-only</code>任务上微调的模型，用少量步骤继续微调<code>binary stability</code>任务，发现其比基础模型学习更快，表明学到了一些可迁移特征。</li>
<li><strong>更长时间训练</strong>：延长GRPO训练至48,000步会导致对训练任务奖励函数过拟合，损害泛化能力。</li>
<li><strong>多任务训练</strong>：先后或交替训练多个任务，并未显著改善模型在未同时训练过的组合任务（如<code>x-only top block</code>）上的泛化性能。</li>
<li><strong>其他RL算法</strong>：使用GSPO算法得到与GRPO类似的结论。</li>
</ul>
</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>首次在VLM的直观物理学习背景下系统评估了交互学习的作用，发现尽管交互学习能提升任务内性能，但<strong>并未比监督微调带来更好的跨任务或跨数据分布泛化能力</strong>，挑战了“交互对学习可泛化物理直觉必不可少”这一假说在现有VLM范式下的直接适用性。</li>
<li>揭示了当前VLM在物理推理中的一个关键问题：模型可能在其内部表示中编码了解决任务所需的信息（能力），但<strong>无法可靠地将这种能力转化为正确的输出（表现）</strong>，凸显了能力与表现之间的差距。</li>
<li>提供了一套在合成物理环境中对VLM进行交互式训练和系统性泛化评估的实验框架。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到的局限性包括：交互形式相对简单（单步RL），任务和环境较为受限（积木塔），以及可能受到模型架构和微调方法（如PEFT）的影响。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li>需要探索更复杂、更长期的交互范式（如多步RL、具身交互），以更好地模拟人类学习物理的过程。</li>
<li>应深入探究为何模型内部已编码的物理信息无法有效转化为输出，以及如何弥合能力与表现之间的鸿沟。</li>
<li>考虑设计更有效的多任务或元学习训练方案，以鼓励模型学习任务不变的本质物理规律，而非任务特定的捷径。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文探讨视觉语言模型能否通过交互学习直观物理学。核心问题是预训练模型缺乏物理世界直觉，监督微调虽能提升任务性能，但无法学习可泛化的物理规则。基于认知科学假设，作者采用强化学习方法，让模型与环境交互学习物理动态。实验发现，交互学习虽能提高模型在训练任务内的表现，但未能使其获得可泛化的物理直觉；模型在视觉统计和物理原理相关的任务上泛化能力差，无论是否通过交互训练。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.06033" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>