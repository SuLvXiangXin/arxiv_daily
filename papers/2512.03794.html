<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Computer Vision and Pattern Recognition (cs.CV)</span>
      <h1>AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.03794" target="_blank" rel="noreferrer">2512.03794</a></span>
        <span>作者: Lin, Zichuan, Liu, Yicheng, Yang, Yang, Tao, Lvfang, Ye, Deheng</span>
        <span>日期: 2025/12/03</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="概述">概述</h2>
<p>本文题为 &quot;AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition&quot;，聚焦于机器人领域的关键挑战。</p>
<h2 id="方法">方法</h2>
<p>文章提出了一种新颖的技术方案。</p>
<h2 id="实验与结论">实验与结论</h2>
<p>实验表明该方法在基准测试中取得了有竞争力的结果。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出AdaptVision，以解决视觉语言模型因依赖大量视觉令牌导致计算开销过大的问题。该方法通过从粗到细的自适应视觉获取机制，先处理低分辨率图像的压缩令牌，再根据需要调用边界框工具裁剪关键区域。核心训练框架采用解耦轮次策略优化（DTPO），将学习目标分解为工具学习和准确性提升两部分进行强化学习优化。实验表明，AdaptVision在多个VQA基准上取得了优越性能，同时视觉令牌消耗量显著低于现有高效VLM方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.03794" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>