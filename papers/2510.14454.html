<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Towards Adaptable Humanoid Control via Adaptive Motion Tracking - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Towards Adaptable Humanoid Control via Adaptive Motion Tracking</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.14454" target="_blank" rel="noreferrer">2510.14454</a></span>
        <span>作者: Huang, Tao, Wang, Huayi, Ren, Junli, Yin, Kangning, Wang, Zirui, Chen, Xiao, Jia, Feiyu, Zhang, Wentao, Long, Junfeng, Wang, Jingbo, Pang, Jiangmiao</span>
        <span>日期: 2025/10/16</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人需要能够将演示的运动适应到多样化的现实世界条件中，同时精确地保持运动模式。现有的方法主要分为两类：一类是将参考运动作为先验融入强化学习（RL）的方法，它们能够实现超越数据本身的适应，但通常以牺牲模仿精度为代价，或需要大量的奖励函数调优；另一类是运动跟踪方法，它们能以较低的奖励工程负担精确复现参考运动，但其适应性受到限制，因为它们依赖于大规模的训练运动来覆盖多样条件，并且在每次测试部署时可能需要一个可能无法获取的参考运动。如何结合这两种范式的优势——精确模仿和广泛适应——仍然是一个开放的挑战。本文针对这一痛点，提出了一种名为AdaMimic的新型运动跟踪算法，其核心思路是：通过关键帧编辑从单一参考运动创建增强数据集，并引入可学习的适配器进行灵活的时间扭曲，从而在保证高模仿精度的同时，实现从单一参考运动出发的广泛适应。</p>
<h2 id="方法详解">方法详解</h2>
<p>AdaMimic的整体框架是一个两阶段流程，旨在从单一参考运动学习可适应的跟踪策略。其输入是单条参考运动轨迹，输出是可直接部署在真实机器人上的自适应控制策略。</p>
<p><img src="https://arxiv.org/html/2510.14454v1/x1.png" alt="方法概述"></p>
<blockquote>
<p><strong>图2</strong>：方法概述。(a) 人体运动通过GVHMR重建为SMPL运动并重定向到人形机器人。随后选择并编辑稀疏关键帧，形成用于自适应跟踪的增强数据集。(b) 基于此数据集，AdaMimic首先使用固定的相位间隔和双评论家（用于稀疏全局跟踪和稠密局部跟踪奖励）训练跟踪策略，随后训练相位和跟踪适配器，以实现有效的时间扭曲，从而提升跟踪性能。(c) 最终策略可直接部署在真实的Unitree G1机器人上。</p>
</blockquote>
<p><strong>第一阶段：基于固定相位间隔的运动跟踪</strong>。此阶段使用现有运动跟踪算法训练一个基础跟踪策略 <code>π_track</code>。其创新之处在于奖励函数设计：</p>
<ol>
<li><strong>稀疏全局奖励</strong>：仅在运动的关键帧相位（如起跳、落地时刻）被激活，鼓励机器人在这些关键时间点与编辑后的参考运动在全局空间（如身体位置、朝向）对齐，避免了在全局空间上的过度约束。</li>
<li><strong>稠密局部奖励</strong>：在每个时间步都计算，鼓励机器人精确模仿参考运动的局部关节运动模式。<br>为了稳定处理稀疏奖励信号，该方法引入了双评论家架构：一个稀疏值函数 <code>V_track_sparse</code> 用于估计稀疏全局奖励的回报，一个稠密值函数 <code>V_track_local</code> 用于估计稠密局部奖励的回报。</li>
</ol>
<p><strong>第二阶段：适配器学习与自适应相位间隔</strong>。第一阶段策略的适应能力受限于固定的相位推进速度。第二阶段联合学习两个适配器来突破此限制：</p>
<ol>
<li>**相位适配器 <code>π_phase^Δ</code>**：以观测为输入，输出一个相位间隔增量 <code>Δφ_k^Δ</code>。该增量与基础间隔 <code>Δφ_k</code> 相加，得到自适应的相位间隔 <code>Δφ_k^ada</code>，从而实现对运动速度的灵活调节（时间扭曲）。</li>
<li>**跟踪适配器 <code>π_track^Δ</code>**：根据自适应相位间隔，对基础跟踪策略输出的动作进行补偿，生成最终的自适应动作 <code>a_k^ada</code>。其输出被 <code>Δφ_k^Δ</code> 缩放，确保当相位增量为零时，动作退化为原始跟踪动作，便于优化。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.14454v1/x5.png" alt="适配器有效性"></p>
<blockquote>
<p><strong>图6</strong>：适配器的有效性。(上) 相位间隔和跟踪动作适应不同的远跳距离，更长的距离对应更长的空中时间和更大的动作补偿，而更短的距离则导致调整减少。(下) 使用适配器后，策略执行有效的时间扭曲，通过调整运动速度来改善适应。</p>
</blockquote>
<p><strong>核心创新点</strong>：</p>
<ol>
<li><strong>数据增强策略</strong>：不同于依赖大规模数据或复杂物理假设的编辑方法，本文通过对单一运动进行<strong>关键帧提取和极简物理假设下的轻量编辑</strong>（例如，仅平移落地关键帧的位置）来构建增强数据集 <code>D_ref_edit</code>，在保留局部运动模式的前提下引入全局变化。</li>
<li><strong>自适应时间扭曲机制</strong>：通过<strong>可学习的相位适配器和跟踪适配器</strong>，使策略能够动态调整运动执行的时序，这是提升对编辑后运动（尤其是大幅编辑）的物理合理性和跟踪精度的关键。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.14454v1/x3.png" alt="关键帧与编辑"></p>
<blockquote>
<p><strong>图4</strong>：(上) 任务可视化：用作人形重定向输入的五种代表性运动。(下) 关键帧提取与编辑：从每个运动中提取稀疏关键帧，并进一步编辑其中选定的少数几个以实现适应。颜色表示相对于原始关键帧（灰色）的适应难度：蓝色表示简单适应情况，红色表示困难适应情况。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在Isaac Gym模拟器中训练，并在真实的29自由度Unitree G1人形机器人上部署验证。涵盖了七项任务：远跳、高跳、三级跳、台阶跳、网球击球、羽毛球击球等。测试时设定了“简单适应”和“困难适应”两种范围（具体数值见表1）。</p>
<p><strong>对比基线</strong>：包括AMP-Style（运动先验RL）、AMP-Mimic、DeepMimic-NoAdapt（仅跟踪原始运动）、DeepMimic-Adapt（使用基于规则的编辑数据）、DeepMimic-Adapt-Δφ^ada（在DeepMimic-Adapt上增加自适应相位），以及使用大规模数据训练的UniTracker。</p>
<p><img src="https://arxiv.org/html/2510.14454v1/x6.png" alt="主要仿真结果"></p>
<blockquote>
<p><strong>图7</strong>：主要仿真结果。该表对比了AdaMimic与多个基线及消融版本在成功率和多种跟踪误差指标上的表现。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>综合性能</strong>：如表3(a)所示，AdaMimic在整体成功率（86.8%）、局部稠密误差（30.3）和全局稀疏误差（94.8）上均优于所有基线。特别是在困难适应条件下，其成功率（74.2%）显著高于DeepMimic-Adapt（74.8%接近，但误差更低）和AMP-Mimic（62.3%）。</li>
<li><strong>消融实验</strong>：表3(b)验证了各组件贡献。<ul>
<li><code>AdaMimic-Stage1</code>（仅第一阶段）：性能显著下降，尤其在困难适应下全局误差增大，说明固定相位间隔限制适应能力。</li>
<li><code>AdaMimic-Stage1-Δφ^ada</code>（第一阶段策略+自适应相位但无跟踪适配器）：性能甚至更差，说明仅调整速度而不补偿动作会导致不稳定。</li>
<li><code>AdaMimic-NoFreeze</code>（联合训练适配器而不冻结第一阶段策略）：性能崩溃，验证了分阶段训练策略的必要性。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2510.14454v1/x4.png" alt="基线对比"></p>
<blockquote>
<p><strong>图5</strong>：使用大规模运动数据训练的基线。在五项任务中，AdaMimic的性能优于UniTracker及其使用DeepMimic-Adapt规则运动的变体。此外，结果表明额外的运动数据并未给UniTracker带来相对于DeepMimic-Adapt的明显专业化增益。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.14454v1/x2.png" alt="适配器动机"></p>
<blockquote>
<p><strong>图3</strong>：关键帧提取与适配器的动机。(上) 远跳落地时刻的全局跟踪误差表明，AdaMimic通过结合稀疏关键帧和自适应时间扭曲，在物理合理性上优于基线。(下) 局部跟踪误差进一步验证了改进。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.14454v1/x7.png" alt="硬件结果"></p>
<blockquote>
<p><strong>图8</strong>：主要硬件结果。在缺乏精确里程计的情况下，我们报告成功率、局部关节跟踪误差和平滑度，以定量比较AdaMimic与基线。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.14454v1/figures/real_main_snapshot.png" alt="真实世界部署"></p>
<blockquote>
<p><strong>图9</strong>：真实世界部署快照。展示了AdaMimic在Unitree G1机器人上执行多种适应任务的场景。</p>
</blockquote>
<p><strong>实物部署结果</strong>：如图9和表4所示，训练好的策略无需调整即可直接在G1机器人上运行。在五项任务中，AdaMimic在成功率、局部跟踪误差和平滑度方面均优于DeepMimic-Adapt基线，证明了其仿真到实物的有效迁移和在实际条件下的鲁棒性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>AdaMimic框架</strong>，一种新颖的运动跟踪算法，首次实现了人形机器人<strong>仅从单一参考运动</strong>出发，既能高精度保持关键运动模式，又能广泛适应不同任务条件。</li>
<li>设计了<strong>关键帧编辑与两阶段适配器学习</strong>机制，通过极简物理假设的数据增强和灵活的时间扭曲，有效解决了数据依赖与适应性的矛盾。</li>
<li>在仿真和真实的Unitree G1机器人上进行了广泛验证，证明了该方法在多项敏捷全身任务中优于现有方法，并实现了成功的零次仿真到实物迁移。</li>
</ol>
<p><strong>局限性</strong>：论文指出，当前方法中关键帧的选择 <code>Φ_key</code> 和编辑函数 <code>f_edit</code> 的定义相对直接且依赖于具体任务。将其扩展到更广泛的任务，需要开发更通用的机制来自动化或半自动化这些步骤。</p>
<p><strong>启示</strong>：本文为运动基元的学习与控制提供了一个新思路，即<strong>不追求覆盖所有可能运动的大规模数据集，而是通过“小数据编辑”与“智能适配”相结合</strong>，实现数据效率与泛化能力的平衡。这为未来开发更通用、更高效的人形机器人技能学习方法指明了方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人控制中如何从单一参考运动实现准确模仿和广泛适应的核心问题，提出AdaMimic自适应运动跟踪算法。该方法通过稀疏化参考运动为关键帧并进行轻量编辑以创建增强数据集，初始化策略跟踪关键帧生成密集中间运动，并训练适配器调整跟踪速度和细化动作，实现灵活时间扭曲。在模拟和真实Unitree G1机器人上的多种任务验证中，该方法在广泛适应条件下取得了显著性能提升。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.14454" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>