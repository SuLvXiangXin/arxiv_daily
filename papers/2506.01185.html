<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>HoMeR: Learning In-the-Wild Mobile Manipulation via Hybrid Imitation and Whole-Body Control - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>HoMeR: Learning In-the-Wild Mobile Manipulation via Hybrid Imitation and Whole-Body Control</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.01185" target="_blank" rel="noreferrer">2506.01185</a></span>
        <span>作者: Jeannette Bohg Team</span>
        <span>日期: 2025-06-01</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>移动操作机器人具有在人类日常非结构化环境中工作的潜力，但面临两大核心挑战：控制复杂性与泛化能力。一方面，现代移动操作平台（如轮式、人形、四足）需要协调多个自由度（如基座与手臂），控制维度高且复杂。现有方法中，全身控制器（WBC）常被用于管理此复杂性，但先前工作主要集中于四足机器人，依赖于大量奖励工程和仿真到真实的迁移技术。另一方面，现实世界的任务通常是多阶段的，结合了长距离移动（如接近目标）和精细操作（如抓取、对齐）。在策略学习方面，近期模仿学习方法展示了混合动作空间（结合绝对关键姿态动作和相对密集动作）在桌面操作中的优势，但这些方法尚未应用于工作空间更大、任务时域更长、具身更复杂的移动操作领域。</p>
<p>本文针对移动操作中“协调高维控制”与“处理多阶段任务”的具体痛点，提出将高效的全身控制与混合模仿学习策略相结合的新视角。其核心思路是：利用一个基于运动学的快速全身控制器，将策略学习简化为末端执行器的动作空间；在此空间内，学习一个混合策略，动态切换用于长距离运动的绝对姿态预测和用于精细操作的相对姿态预测，从而将低层协调卸载给控制器，使学习专注于任务级决策。</p>
<h2 id="方法详解">方法详解</h2>
<p>HOMER框架包含一个全身控制器和一个混合模仿学习代理，其整体流程为：代理根据观测（点云和RGB图像）预测下一个末端执行器目标姿态和下一个控制模式，该目标姿态被输入全身控制器，控制器将其解算为基座和手臂的关节位置指令并执行。</p>
<p><img src="https://..." alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：HOMER概览。左侧：演示者使用基于iPhone的全身遥操作在真实家庭中收集数据。右侧：从这些演示中，HOMER学习一个混合模仿学习策略，在用于接近的绝对动作和用于精细操作的相对动作之间切换。全身控制器将这些末端执行器命令映射为手臂和基座的关节命令以执行。</p>
</blockquote>
<p><img src="https://..." alt="策略架构"></p>
<blockquote>
<p><strong>图2</strong>：HOMER策略架构。HOMER由一个使用RGB图像预测精细操作相对动作的密集策略，和一个使用点云预测长距离运动绝对末端执行器姿态的关键姿态策略组成。每个策略还预测下一个控制模式，实现学习到的模式切换。关键姿态策略可选地以从视觉语言模型（VLM）导出的显著点作为条件（HOMER-COND）。最后，全身控制器将预测的末端执行器动作转换为移动基座和手臂的关节命令。</p>
</blockquote>
<p><strong>核心模块1：全身控制器（WBC）</strong><br>该控制器是一个基于运动学的逆运动学求解器，其作用是将期望的末端执行器姿态 <code>x_ee</code> 映射为整个机器人（3自由度基座 + N自由度手臂）的关节位置指令 <code>q</code>。其优化目标函数为：<br><code>min_˙q ∥J_ee(q_t) ˙q - e_ee∥^2_W_ee + ∥q_t + ˙q·∆t - q_retract∥^2_W_posture + ∥ ˙q_base ∥^2_W_damping</code><br>其中第一项促使末端执行器向目标姿态运动，第二项鼓励关节配置接近一个预设的中立收缩姿势（见图3），第三项对基座运动进行阻尼。优化过程受到关节速度限、关节位置限以及基于速度的自我碰撞避免约束（针对手臂-基座、手臂-相机支架等部件对）的限制。该控制器是任务无关的，所有超参数在所有任务中保持不变，无需针对每个任务重新调整。</p>
<p><strong>核心模块2：混合模仿学习代理</strong><br>代理由两个子策略组成，并预测控制模式 <code>m_t+1 ∈ {关键姿态， 密集， 终止}</code>。</p>
<ol>
<li><strong>关键姿态子策略</strong>：用于长距离移动。输入为第三人称点云 <code>P_t</code>。其创新在于不直接回归目标姿态，而是预测点云中每个点的显著性概率以及指向真实末端执行器位置的3D偏移。取显著性最高的点作为任务相关显著点（如柜门把手上的关键点），并将预测的偏移应用于该点以获得目标位置，再结合预测的方向和夹爪状态构成完整的末端执行器动作。训练时，仅对高显著性点的偏移预测进行监督。该策略可扩展为<strong>条件化版本（HOMER-COND）</strong>，允许接收外部提供的3D关键点（例如来自VLM的检测结果）作为额外输入通道，通过距离加权的显著性图进行融合，并在训练时采用掩码监督策略（50%样本掩码条件，50%样本使用条件）以兼顾有/无条件的情况。</li>
<li><strong>密集子策略</strong>：用于精细操作。输入为第三人称和腕部RGB图像以及当前末端执行器状态。它预测一个相对于当前姿态的6自由度增量动作 <code>∆x_ee_t</code>。该策略实例化为扩散策略，预测未来16步动作并执行8步后重新规划。<br><strong>执行流程</strong>：初始模式为关键姿态。每个时间步，根据当前模式调用相应子策略，得到目标姿态 <code>x_ee_t+1</code> 和下一个模式 <code>m_t+1</code>。<code>x_ee_t+1</code> 被送入WBC执行，而 <code>m_t+1</code> 决定了下一个时间步使用的子策略，从而实现基于学习的动态模式切换。</li>
</ol>
<p><strong>创新点</strong>：1) 将先前仅限于桌面操作的混合动作策略成功扩展至移动操作领域，并配备了全身控制器。2) 引入了可条件化的关键姿态策略，能够利用VLM的互联网规模先验知识来指定动态目标。3) 设计了一个实用、任务无关的WBC，不仅用于策略执行，还极大地简化了演示收集过程。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验平台与任务</strong>：在TidyBot++机器人（全向移动基座+7自由度Kinova手臂）上进行评估。任务包括3个模拟任务（抓取立方体、打开洗碗机、打开橱柜）和3个真实家庭任务（移动枕头、取电视遥控器、清扫垃圾），这些任务覆盖了机器人位姿随机化、物体位姿随机化、需要精确操作和长时域推理等挑战。</p>
<p><strong>对比基线</strong>：沿两个维度设计基线：动作空间（混合 vs. 仅密集）和控制方式（全身 vs. 基座手臂解耦）。</p>
<ul>
<li>Diffusion Policy (B+A): 仅密集，预测10-DoF相对位姿（基座3+末端6+夹爪1），代表解耦控制。</li>
<li>HOMER (B+A): 混合，但预测解耦的基座关键姿态、手臂关键姿态或10-DoF相对位姿。</li>
<li>Diffusion Policy (WBC): 仅密集，但预测7-DoF相对末端位姿（末端6+夹爪1），并通过WBC执行。</li>
<li>HOMER (OURS): 本文方法，混合，预测6-DoF末端关键姿态或相对位姿+夹爪1，通过WBC执行。</li>
</ul>
<p><img src="https://..." alt="基准测试结果"></p>
<blockquote>
<p><strong>图4</strong>：基准测试结果。柱状图展示了各方法在六个任务上的成功率（成功次数/20次试验）。HOMER在几乎所有任务上都取得了最高的成功率，显著优于缺乏混合动作或全身控制的基线。例如，在真实任务“取电视遥控器”和“清扫垃圾”中，HOMER的成功次数分别达到16和15，而最强的基线HOMER (B+A)分别为13和10。</p>
</blockquote>
<p><strong>关键实验结果</strong>：使用每任务仅20次演示进行训练和评估。HOMER取得了79.17%的整体平均成功率，平均优于次佳基线29.17%。具体而言，缺乏混合动作和全身控制的DP (B+A)基线在需要长距离接近的任务中失败最多。仅使用WBC但无混合动作的DP (WBC)略有改善但仍受限。使用了混合动作但为解耦控制的HOMER (B+A)是强基线，但在需要平滑协调（如开橱柜、清扫）或基座未对齐影响手臂可达性时遇到困难。HOMER结合了二者优势，在所有任务中成功率最高，尤其是在操作比机器人自身还大的家电、执行平滑长时域动作（清扫）和精确操作方面表现突出。</p>
<p><strong>泛化实验</strong>：评估了条件化版本HOMER-COND在模拟抓取立方体任务变体上的表现，包括随机化立方体尺寸、添加干扰物、抓取不同颜色立方体。</p>
<p><img src="https://..." alt="泛化结果"></p>
<blockquote>
<p><strong>图5</strong>：泛化结果。HOMER-COND在存在干扰物或物体外观新颖的情况下仍能保持高性能。而无条件版本(HOMER)或有关键点条件但无数据增强的版本(HOMER-COND-NoAugs)在这些挑战性场景下性能下降。</p>
</blockquote>
<p><strong>消融实验总结</strong>：图5的结果实质上是对条件化和数据增强的消融。结果表明，<strong>关键点条件化</strong>使策略能专注于VLM指定的新目标，<strong>点云数据增强</strong>（去除颜色、添加随机干扰点）则提升了模型对视觉干扰和外观变化的鲁棒性，二者结合对于在陌生、杂乱环境中泛化至关重要。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1) 提出了一个样本高效的移动操作模仿学习框架，通过结合全身控制器和混合动作表征，仅用每任务20次演示即超越强基线。2) 设计了模块化的策略架构，可条件化于VLM提供的关键点，从而泛化到新的物体几何、外观和杂乱环境。3) 实现了一个支持直观遥操作的实用全身控制器，促进了在真实家庭场景中高效收集演示。</p>
<p><strong>局限性</strong>：1) WBC考虑了自我碰撞，但未包含与外部环境的碰撞避免。2) 使用了固定的、手动选择的相机视角，未探索主动感知。3) 专注于操作，未解决大范围导航问题。4) 当前策略为单任务策略。</p>
<p><strong>后续研究启示</strong>：HOMER展示了一条通往现实世界、样本高效、可泛化移动操作的可行路径。其将动作空间简化为末端执行器命令的设计，为未来与（移动或非移动）多任务数据集的协同训练打开了可能性。集成环境碰撞避免、主动感知以及与导航模块的结合，是未来令人兴奋的研究方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出HOMER框架，旨在解决移动机器人在真实非结构化家庭环境中执行复杂操作任务的问题。核心方法结合了基于运动学的全身控制器与混合模仿学习策略：控制器将末端执行器位姿映射为底座与机械臂的协调运动；策略则在学习中切换绝对位姿（用于长距离移动）与相对位姿（用于精细操作）。在3项真实家庭任务实验中，HOMER仅用每任务20次演示即达到79.17%的整体成功率，平均优于次优基线29.17%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.01185" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>