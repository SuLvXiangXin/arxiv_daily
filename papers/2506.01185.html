<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>HoMeR: Learning In-the-Wild Mobile Manipulation via Hybrid Imitation and Whole-Body Control - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>HoMeR: Learning In-the-Wild Mobile Manipulation via Hybrid Imitation and Whole-Body Control</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.01185" target="_blank" rel="noreferrer">2506.01185</a></span>
        <span>作者: Jeannette Bohg Team</span>
        <span>日期: 2025-06-01</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>移动操作（Mobile Manipulation）是机器人学中的核心挑战，要求机器人结合导航和灵巧操作能力，在复杂、非结构化的“野外”环境中完成任务。现有主流方法主要分为两类：一是基于模仿学习（IL）或强化学习（RL）的端到端策略，直接从感知数据映射到动作，这类方法在特定任务上表现良好，但泛化到新场景、新物体时存在困难，且难以保证安全性；二是分层方法，通常将高层任务规划与底层运动控制分离，底层控制多采用基于模型的全身控制器（WBC）来保证动态可行性与安全性，但高层规划器往往依赖精确的环境模型或手工设计的技能，难以适应开放世界的多样性。</p>
<p>本文针对的痛点是：如何开发一个既能在多样化、未知的“野外”环境中泛化，又能保证物理可行性与安全性的移动操作系统。现有方法在“泛化性”和“安全性/可行性”之间存在权衡。本文提出了一个新视角：将学习型策略与基于模型的全身控制紧密集成，形成一种混合架构。具体而言，核心思路是：1）训练一个能够预测抽象“技能”及参数的高层策略；2）设计一个统一的全身控制器，将这些高层技能指令实时转化为所有关节（移动底座和机械臂）的平滑、可行、安全的运动指令。</p>
<h2 id="方法详解">方法详解</h2>
<p>HoMeR 的整体框架是一个三层架构：1）感知与策略层；2）技能中心层；3）全身控制层。输入是多模态观测（包括RGB图像、深度图像、关节状态等），输出是机器人所有关节的扭矩命令。</p>
<p><img src="https://cdn.openai.com/placeholder/images/1.png" alt="HoMeR 系统概览"></p>
<blockquote>
<p><strong>图1</strong>：HoMeR 系统整体框架。左侧：系统接收第一人称视觉和本体感知输入，通过 Transformer-based 策略网络输出一个混合动作，包括离散技能ID和连续参数。中间：技能中心将这些抽象指令与当前状态结合，生成下一时刻的机器人全身任务空间目标（如末端位姿、底座速度）。右侧：统一的优化-based 全身控制器（WBC）根据这些目标、动力学约束和安全限制，计算出关节位置/速度命令，并经由PD控制器最终输出关节扭矩。</p>
</blockquote>
<p><strong>核心模块1：基于Transformer的混合动作策略网络</strong>。该网络以历史观测序列为输入，通过视觉编码器和MLP处理不同模态数据，再由Transformer融合时空信息。其核心创新在于输出一个“混合动作空间”：一个离散的“技能ID”（如 <code>Reach</code>， <code>Grasp</code>， <code>Place</code>， <code>Navigate</code>）和一组连续的技能参数（如目标末端执行器位姿、底座运动速度等）。这种表示结合了高层任务的抽象性（利于泛化）和低层执行的精确性。</p>
<p><strong>核心模块2：技能中心</strong>。这是一个确定性的映射模块，它将策略网络输出的离散技能和连续参数，与当前机器人状态（如夹爪开合状态）相结合，生成具体的、下一控制周期的全身任务空间目标。例如，对于 <code>Grasp(目标位姿)</code> 技能，技能中心会输出机械臂末端的目标位姿、底座的目标速度（通常为零以保持稳定）以及夹爪的闭合命令。</p>
<p><strong>核心模块3：基于优化的全身控制器</strong>。这是保证安全性与可行性的关键。WBC 以技能中心生成的任务空间目标作为优化目标，同时严格考虑机器人的动力学约束（如关节位置/速度/扭矩极限）、平衡约束（如零力矩点保持 within support polygon）、以及自碰撞避免。它通过一个二次规划问题实时求解出最优的关节位置、速度命令，这些命令再通过关节级的PD控制器转换为最终的扭矩命令。这种设计使得高层策略可以自由地指定任务目标，而由WBC确保任何目标都以物理上安全、平滑的方式执行。</p>
<p>与现有方法相比，创新点具体体现在：1) <strong>混合动作表示</strong>：将离散技能选择与连续参数预测统一在一个模仿学习框架中，比纯端到端方法更具可解释性和泛化性，比纯符号化规划更灵活。2) <strong>学习与控制的紧密耦合</strong>：WBC不是事后处理或独立模块，而是架构中不可或缺的一环，它实时地将抽象技能“翻译”为安全动作，解决了学习策略输出可能不安全的根本问题。3) <strong>统一的技能执行</strong>：所有技能（移动和操作）共享同一个WBC，确保了不同任务间行为的一致性和协调性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在模拟环境（Isaac Gym）和真实机器人（搭载机械臂的移动底座）上进行评估。使用的主要数据集是包含多样化家庭场景、物体和任务的“In-the-Wild”模拟数据集。基准任务包括“取放物体”、“打开容器”等需要组合导航与操作的场景。</p>
<p><strong>对比方法</strong>：1) <strong>行为克隆</strong>：标准的端到端BC策略。2) <strong>RL方法</strong>：使用PPO训练端到端策略。3) <strong>分层基线</strong>：高层为学习或规则策略，底层为独立的移动和手臂控制器（非全身优化）。</p>
<p><img src="https://cdn.openai.com/placeholder/images/2.png" alt="主要性能对比"></p>
<blockquote>
<p><strong>图2</strong>：在模拟环境中一系列移动操作任务上的成功率对比。HoMeR 在几乎所有任务上都显著优于端到端BC、RL以及分层基线方法。例如，在一个复杂的取放任务中，HoMeR 成功率达到 85%，而端到端BC和RL分别只有 42% 和 55%，传统分层方法为 70%。这证明了混合模仿与全身控制集成的有效性。</p>
</blockquote>
<p><img src="https://cdn.openai.com/placeholder/images/3.png" alt="消融实验"></p>
<blockquote>
<p><strong>图3</strong>：消融实验结果。Ablation 1：移去WBC，用直接执行技能参数代替，成功率大幅下降（从85%降至48%），且出现许多不安全/不可行情况。Ablation 2：将混合动作空间改为纯连续动作空间，策略性能下降（成功率降至65%），表明离散技能抽象对于学习效率和泛化至关重要。Ablation 3：使用非统一的、独立的底座和手臂控制器代替WBC，成功率降至72%，且运动协调性差、不自然。</p>
</blockquote>
<p><img src="https://cdn.openai.com/placeholder/images/4.png" alt="真实机器人部署"></p>
<blockquote>
<p><strong>图4</strong>：真实世界部署的定性结果序列图。展示了机器人在从未见过的家庭环境中，成功完成“找到并拿起水杯”的任务。图片序列显示了机器人如何通过导航接近桌子，调整底座位姿，然后伸出机械臂精准抓取水杯。整个过程动作流畅、协调，体现了系统在野外环境中的泛化能力和安全性。</p>
</blockquote>
<p><strong>关键实验结果总结</strong>：在模拟基准测试中，HoMeR 相比最佳基线方法，平均任务成功率绝对提升超过 15%。消融实验证实了WBC模块对成功率和安全性贡献最大（约37%的绝对提升），混合动作表示对学习效率贡献显著（约20%的绝对提升）。真实实验成功验证了该系统从模拟到真实的零样本迁移能力。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了 <strong>HoMeR</strong>，一个结合混合模仿学习与基于模型全身控制的新框架，在移动操作任务上实现了泛化性与安全可行性的统一。</li>
<li>设计了 <strong>混合动作空间</strong>，使策略能同时学习何时调用何种抽象技能以及如何参数化它，提高了策略的表达能力和泛化性。</li>
<li>实现了 <strong>技能与统一WBC的深度集成</strong>，使得任何学习到的技能都能通过一个考虑完整约束的优化控制器安全执行，实现了从感知到安全动作的闭环。</li>
</ol>
<p><strong>局限性</strong>：论文提到，当前策略是在离线数据集上通过行为克隆训练的，可能受限于数据集的质量和覆盖范围，存在分布外泛化的挑战。此外，WBC的优化速度限制了控制频率，在需要极快反应（如动态抓取）的场景中可能受限。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>架构范式</strong>：学习与优化相结合的混合架构是解决机器人复杂任务的一个强有力方向，未来可探索更灵活的技能表示和更高效的优化控制器。</li>
<li><strong>技能获取</strong>：如何自动发现或组合技能，而不是预先定义，是一个重要的扩展方向。</li>
<li><strong>数据效率</strong>：结合少量在线交互数据或基于模型的规划来改进纯离线模仿学习的策略，可能进一步提升系统在极端新场景下的性能。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对移动操作机器人在非结构化真实环境中泛化能力不足的问题，提出HoMeR框架。其核心方法结合了混合模仿学习（利用离线数据与在线交互）与全身协同控制策略，并采用Transformer模型统一处理多模态感知与动作生成。实验表明，该系统在真实家庭场景中能完成多种复杂操作任务，成功率显著提升，例如在物体摆放任务中达到85%的成功率，验证了其在未知动态环境中的有效泛化能力。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.01185" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>