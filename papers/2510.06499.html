<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.06499" target="_blank" rel="noreferrer">2510.06499</a></span>
        <span>作者: Weiran Yao Team</span>
        <span>日期: 2025-10-07</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前大语言模型（LLMs）的成功主要建立在基于海量文本语料的模仿学习之上，包括下一个词预测的预训练和监督微调（SFT）。这种范式使模型依赖于“教师强迫”，容易受到分布偏移的影响，并导致训练与生成动态之间存在显著差距。因此，模型在复杂问题解决中缺乏鲁棒的推理能力。强化学习（RL）通过在线奖励反馈进行学习，能够探索更广的解空间并弥合训练-推理差距，是一种数据效率更高的训练范式。然而，RL的应用面临一个关键的数据瓶颈：现有的RL数据集在规模（例如&lt;100亿令牌）和多样性上比网络规模的预训练语料（&gt;1万亿令牌）小几个数量级，这主要源于生成高质量、可验证的问答（QA）对成本高昂。这种数据规模和多样性的巨大差异限制了RL在提升LLMs通用推理能力方面的潜力。</p>
<p>本文针对RL数据稀缺且多样性不足的痛点，提出了一个新的视角：系统地将大规模预训练文档转化为适合RL训练的数据。其核心思路是设计一个自动化的、可扩展的数据管道（Webscale-RL），将网络规模的预训练语料转换为数百万个多样化、可验证的QA对，从而将RL数据的规模提升到与预训练相当的水平。</p>
<h2 id="方法详解">方法详解</h2>
<p>Webscale-RL管道的目标是将叙事性的预训练文档大规模地转化为适用于RL训练的可验证QA对。其整体框架包含四个主要阶段，旨在确保输出数据的高质量和多样性。</p>
<p><img src="https://arxiv.org/html/2510.06499v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：Webscale-RL数据管道概览。该管道系统地将大规模预训练数据转化为RL数据，同时保持了网络数据的规模和多样性。管道维护了一个领域特定的演示库用于高质量生成的少样本示例，并为每个文档分配多个角色以鼓励反映不同观点。</p>
</blockquote>
<ol>
<li><strong>数据过滤</strong>：此阶段旨在剔除不太可能产生高质量可验证问题的输入。首先使用启发式方法过滤掉明显低质量的文档，然后采用LLM进行更细粒度的过滤，识别并移除（i）大部分内容为模板（如网站HTML中的导航、页眉、页脚）的非信息性页面，以及（ii）缺乏足够上下文来验证答案的非自包含片段。</li>
<li><strong>领域分类和角色分配</strong>：过滤后，使用基于LLM的分类器将每个文档分类到特定领域（如商业、医疗保健、社会科学等）。领域标签将用于在后续的QA生成步骤中收集相关的少样本示例。此外，为了进一步增强生成QA对的多样性，为每个文档分配多个对该内容感兴趣的角色，这定义了生成问题的风格和视角（例如，“医疗专家”、“患者”、“健康记者”）。</li>
<li><strong>可验证QA生成</strong>：以源文档、领域标签和选定角色为条件，基于LLM的QA生成器产生可验证的QA对。具体而言，首先从领域特定的演示库（一个涵盖各领域内多种问题类型和复杂度的精选池）中采样少样本示例。然后通过提示模板整合所有上下文，指导生成器从指定角色的视角提取多样化的QA对。为确保问题在RL期间（模型无法访问源文档）是自包含的，指示生成器提供必要的上下文。并且，只要求一个简短、可验证的答案（如数字、日期、名称、短语），而非长篇解释，这降低了生成复杂度。</li>
<li><strong>质量检查与泄漏控制</strong>：为确保RL数据集的可靠性，采用基于LLM的验证器进行多阶段检查：（1）<strong>正确性验证</strong>：评估答案的正确性，确保提取的QA数据基于源文档，有效减少RL训练期间奖励信号的无效性；（2）<strong>泄漏预防</strong>：确保问题不会明确透露答案。验证器过滤掉不符合这些标准的任何QA对。最后，进一步应用数据去污处理，移除与评估集的重叠部分。</li>
</ol>
<p>该管道的主要创新点在于其数据生成范式。与许多现有SFT/RL数据集通过蒸馏教师模型的答案不同，Webscale-RL直接从源文档中提取答案并加以验证。这降低了对强大教师模型的依赖，并使数据集能够随着可用语料库（即预训练规模）的大小自然扩展，同时保持多样性，突破了人工标注或完全蒸馏数据集在扩展上的瓶颈。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验使用Qwen2.5-3B模型作为基座，在由Webscale-RL管道生成的数据集上进行训练和评估。</p>
<p><strong>基准与基线</strong>：评估涵盖了一系列基准，包括通用任务（MMLU-pro、Big-Bench）、数学与STEM任务（GSM8K、MATH500、GPQA-diamond）和编码任务（MBPP、EvalPlus）。对比的基线包括：在对应原始预训练数据上的<strong>持续预训练</strong>，以及几种先进的数据精炼技术（<strong>QuRating、ProX、Generative Data Refinement</strong>）后接持续预训练。为进行公平比较，所有基线在持续预训练后都使用同一个10K高质量示例的SFT数据集进行了微调，以缓解因指令跟随能力差异带来的评估偏差。RL训练则先进行相同的SFT预热，然后在Webscale-RL数据集采样数据上运行GRPO训练。</p>
<p><img src="https://arxiv.org/html/2510.06499v1/figs/avg.png" alt="缩放效率比较"></p>
<blockquote>
<p><strong>图4</strong>：Webscale-RL训练与使用原始预训练语料进行持续预训练之间的缩放比较。报告了所有基准的平均性能。RL训练的令牌数基于用于生成Webscale-RL数据集的原始预训练语料计算。Webscale-RL训练在不同训练规模下始终优于持续预训练，并表现出更好的缩放效率。</p>
</blockquote>
<p><strong>关键结果</strong>：</p>
<ol>
<li><strong>性能对比</strong>：如表2所示，在大多数基准测试中，Webscale-RL方法优于所有基线（持续预训练及数据精炼方法），平均比最强的基线（GDR）高出3.4分。在通用知识和推理任务（MMLU-pro、Big-Bench、GPQA-diamond）上改进最为显著。在数学任务MATH500上，分数从47.6大幅提升至58.0。经过Webscale-RL微调的3B模型，在宏观平均分上与7B基座模型的差距从10.6分缩小到6.1分。</li>
<li><strong>数据效率</strong>：如图4所示，RL训练相比持续预训练展现出显著更高的数据效率。具体而言，RL训练仅使用相当于持续预训练 <strong>1/100</strong> 的令牌数，就能达到与之相当的性能水平。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.06499v1/figs/teaser2.png" alt="领域分布与多样性"></p>
<blockquote>
<p><strong>图3</strong>：左：Webscale-RL数据集的领域分布。右：Webscale-RL与Nemotron数据的问题嵌入对比。随机从每个数据集中采样5K个问题，使用Qwen3-Embedding编码后通过UMAP降维至2D可视化。Webscale-RL的数据点分布更均匀和分散，表明其主题覆盖更广。</p>
</blockquote>
<p><strong>数据集分析</strong>：构建的Webscale-RL数据集包含约120万个QA对，覆盖9个以上领域。如图3所示，其领域分布继承了预训练源的多样性，涵盖了现有RL数据集中代表性不足的领域（如生活方式、商业）。与主要覆盖数学、代码和科学的Nemotron数据集相比，Webscale-RL的问题嵌入分布更均匀、更分散，表明其主题和知识领域覆盖更广。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>Webscale-RL管道</strong>，一个自动化、可扩展的数据引擎，能够将网络规模的预训练文档转化为适用于RL的可验证QA对。</li>
<li>构建了<strong>Webscale-RL数据集</strong>，一个大规模、多样化的RL数据集，包含120万个跨越9个以上领域的可验证QA对。</li>
<li>提供了<strong>实证证据</strong>，表明使用该数据集的RL训练在多种基准测试中显著优于持续预训练和先进的数据精炼基线，并且数据效率高出<strong>100倍</strong>，为实现RL到预训练规模的扩展提供了可行路径。</li>
</ol>
<p><strong>局限性</strong>：论文提到，管道中生成和验证步骤的质量可能依赖于所使用的生成模型（如GPT-4.1）的能力。此外，专注于生成简短、可验证答案的QA对格式，可能不直接适用于需要长篇幅推理或创造性生成的复杂任务。</p>
<p><strong>启示</strong>：这项工作表明，通过将海量预训练语料转化为适合RL的格式，可以释放显著的性能和效率增益。它为解决RL数据瓶颈问题提供了一种系统化方案，为未来训练更强大、更高效、更鲁棒的语言模型指明了一个新的方向，即大规模RL预训练或早期训练。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文旨在解决强化学习（RL）应用于大语言模型时面临的核心数据瓶颈：现有RL数据集规模小、多样性不足，远未达到预训练数据级别。为此，论文提出了 **Webscale-RL自动化数据管道**，其关键技术是将海量预训练文档系统地转化为**数百万个多样且可验证的问答对**，从而构建了覆盖9个以上领域、包含120万个样本的大规模RL数据集。核心实验表明，基于此数据集的RL训练**效率极高**，仅使用**少至100倍的token**即可达到持续预训练（continual pretraining）的同等性能，在多项基准测试上显著超越基线模型。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.06499" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>