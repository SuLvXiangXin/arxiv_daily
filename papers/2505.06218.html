<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Let Humanoids Hike! Integrative Skill Development on Complex Trails - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Let Humanoids Hike! Integrative Skill Development on Complex Trails</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.06218" target="_blank" rel="noreferrer">2505.06218</a></span>
        <span>作者: Lin, Kwan-Yee, Yu, Stella X.</span>
        <span>日期: 2025/05/09</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前人形机器人研究在应对复杂徒步任务时存在碎片化和不足。运动控制方法专注于特定运动技能（如行走、跑酷），但缺乏长期目标或情境感知，将地形视为固定、同质的被动背景。语义导航方法则依赖于场景地图、刚性世界几何或大模型规划，往往忽略了真实世界的具身性和局部地形的可变性，难以实现实时感知与细粒度运动控制的结合。这两者之间存在固有的响应速度差异（快速反应控制 vs. 较慢的深思熟虑规划），导致在复杂环境中实现上下文敏感执行的紧密协调具有挑战性。</p>
<p>本文针对人形机器人缺乏一个能够整合低级运动技能与高级导航的统一框架这一具体痛点，提出了将“徒步”作为推动视觉感知、决策制定和运动执行综合技能发展的测试平台。本文的核心思路是提出一个名为LEGO-H的端到端具身学习框架，通过两项技术创新——为分层强化学习定制的时序视觉变换器变体（TC-ViT）来预测局部目标以引导运动，以及结合分层度量学习的关节运动模式潜在表征来增强特权学习方案——从而使人形机器人能够自主地在复杂步道上徒步。</p>
<h2 id="方法详解">方法详解</h2>
<p>LEGO-H框架旨在满足人形机器人成功徒步的两个核心要求：1）学习既能目标驱动又能局部自适应的具身路径探索；2）实现能根据情境涌现、且安全的运动执行。为此，LEGO-H采用了一个统一的策略学习流程，并增强了特权学习方案。</p>
<p><img src="https://arxiv.org/html/2505.06218v1/x3.png" alt="方法框架总览"></p>
<blockquote>
<p><strong>图3</strong>：LEGO-H框架概述。LEGO-H通过在一个统一的端到端学习框架（b）中整合导航模块ℋ和运动模块ℰ，为人形机器人配备自适应徒步技能。为了培养运动技能的多样性，我们通过特权学习从预言机策略（a）中训练统一策略。</p>
</blockquote>
<p>整体流程分为两个阶段（图3）。首先，在特权学习阶段（图3a），利用特权信息（如地形类型、地面摩擦力）和专家导航目标作为输入，训练一个预言机运动技能策略π_tea，以高效、安全地获取高质量技能。其次，在统一策略学习阶段（图3b），通过一个高层导航模块ℋ和一个低层运动技能模块ℰ组成的管道，训练最终策略π_uni。</p>
<p>导航模块ℋ（由TC-ViT实现）充当“步道侦察兵”，接收真实状态s_real（深度图像、本体感知、终点PB和一个中间路标），生成统一的步道潜在表征z_uni，并预测一系列未来局部导航目标G={g_n}（每个g_n是相对于机器人根部的偏航角）以及一个捕获上一步执行不匹配的目标残差δg_0。运动模块ℰ充当“敏捷的步道奔跑者”，接收z_uni、本体感知𝒳_pro、残差δg_0和下一个预期目标g_1，实时预测可执行动作a_t。它并不严格跟踪ℋ的目标序列，而是适应局部地形和机器人状态，安全地向终点推进。</p>
<p>核心创新点一：用于自主局部目标预测的TC-ViT。TC-ViT是一个时序信息条件视觉变换器变体，其架构（图4）包含三个关键组件，以解决导航模块的四个关键方面：1）认知环境并平衡短期反应与最终目标对齐；2）以空间精度预测近期目标；3）具备具身意识的目标适应；4）产生感知与动作同步的表征。</p>
<p><img src="https://arxiv.org/html/2505.06218v1/x4.png" alt="TC-ViT架构"></p>
<blockquote>
<p><strong>图4</strong>：TC-ViT架构。三个关键组件：a) 一个面向目标的时序变换器编码器，用于机器人结合最终目标认知环境；b) 对当前深度帧的并行处理，用于整合空间精确信息以反映当前状态；c) 一个循环目标适应机制，整合视觉感知、目标信息和本体感知。</p>
</blockquote>
<p>具体而言：a) 目标导向的时序变换器编码器（图4a）处理16帧深度序列（下采样为4帧），并将最终目标PB作为额外通道在标记化时早期融合，输出长程目标感知的特征向量α。b) 并行空间路径（图4b）通过一个浅层CNN处理当前深度图像C_k=t，产生高分辨率空间特征β，捕获近场地形细节。α和β通过MLP连接融合为γ。c) 循环目标适应机制（图4c）将视觉特征γ、终点PB、中间线索𝒟_rm和本体感知𝒳_pro通过MLP和GRU处理，输出潜在表征z_uni、目标残差δg_0和未来目标序列G。这使机器人能够根据过去的行动结果调整其局部目标（如图5所示）。此外，TC-ViT采用“最近目标转发”（仅将g_1传递给运动模块）和“潜在表征平铺”策略，以同步感知与控制之间不匹配的时间尺度。</p>
<p><img src="https://arxiv.org/html/2505.06218v1/x5.png" alt="动态目标调整"></p>
<blockquote>
<p><strong>图5</strong>：近期目标预测的动态调整。从左到右的快照显示机器人沿步道穿越混合地形。TC-ViT不提供固定的、运动模块必须 rigidly 遵循的轨迹，而是预测几个近期目标（g1, g2, g3），这些目标根据机器人当前状态动态调整，反映了其导航决策的实时调整。</p>
</blockquote>
<p>核心创新点二：通过分层潜在匹配（HLM）增强特权学习。为了在将预言机策略蒸馏到运动模块ℰ时，既能保持行为多样性又能确保动作合理性，LEGO-H引入了HLM度量。与监督全局行为或单关节精度的方法不同，HLM利用变分自编码器（VAE）的结构化潜在表征和掩码重建，来强制关节间的关联一致性。这个与任务无关的HLM损失项提升了跨运动任务的策略学习。关键在于，潜在先验来源于预言机策略，而非人类演示，这使得机器人能够学习适合其自身形态的自立行为。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在专为徒步任务开发的模拟环境中进行，使用了不同难度（简单、中等、困难）和地形（泥土、岩石、楼梯、溪流等）的步道。评估的机器人形态包括Unitree H1（全尺寸）和G1（较小尺寸）。实验平台基于Isaac Gym。</p>
<p>对比的基线方法包括：1) <strong>No Vision</strong>：无视觉输入，仅依赖本体感知和GPS向量。2) <strong>Flat Policy</strong>：非分层（扁平）策略，将视觉、本体感知和目标直接输入单一网络。3) **TC-ViT (w/o Recur.)**：TC-ViT的无循环版本（即无GRU）。4) **TC-ViT (w/o Paral.)**：TC-ViT的无并行空间路径版本。5) **TC-ViT (w/o HLM)**：在特权学习阶段不使用HLM损失的TC-ViT完整版。6) <strong>Oracle Policy</strong>：使用特权信息的预言机策略（性能上界）。</p>
<p><img src="https://arxiv.org/html/2505.06218v1/x6.png" alt="主要结果对比"></p>
<blockquote>
<p><strong>图6</strong>：在三种不同难度（简单、中等、困难）的步道上，LEGO-H（TC-ViT）与基线方法的成功率对比。LEGO-H在所有难度上均达到最高成功率（简单<del>99%，中等</del>92%，困难~85%），显著优于无视觉、扁平策略等基线。</p>
</blockquote>
<p>关键实验结果：LEGO-H（即完整的TC-ViT）在所有难度步道上均取得了最高的成功率（简单<del>99%，中等</del>92%，困难~85%），显著优于其他基线（图6）。扁平策略在中等和困难步道上性能大幅下降，证明了分层结构的必要性。无视觉基线在困难步道上完全失败，凸显了视觉感知的重要性。</p>
<p><img src="https://arxiv.org/html/2505.06218v1/x7.png" alt="消融研究结果"></p>
<blockquote>
<p><strong>图7</strong>：TC-ViT各组件（循环机制、并行路径、HLM）的消融研究结果（成功率）。移除任一组件都会导致性能下降，尤其是在困难步道上，证明了每个组件对整体鲁棒性的贡献。</p>
</blockquote>
<p>消融实验（图7）总结了每个组件的贡献：1) <strong>循环机制</strong>：其缺失导致在困难地形上成功率下降约10%，说明其对适应动态变化至关重要。2) <strong>并行空间路径</strong>：其缺失导致在所有地形上性能下降，在困难步道上尤为明显（下降~12%），证明了精细空间信息对精确脚部放置的重要性。3) <strong>HLM度量</strong>：其缺失导致成功率和步态多样性下降，表明其在保持动作合理性和技能多样性方面的关键作用。</p>
<p><img src="https://arxiv.org/html/2505.06218v1/x8.png" alt="运动技能涌现"></p>
<blockquote>
<p><strong>图8</strong>：LEGO-H（H1机器人）在遇到不同障碍时涌现出的多样化、自适应运动技能示例，包括侧步、跳跃、大跨步等，而无需预先定义的运动模式。</p>
</blockquote>
<p>LEGO-H能够根据环境上下文，涌现出多样化的运动技能，如侧步、跳跃、大跨步等（图8），而无需预先定义的运动模式。此外，实验还表明LEGO-H框架能够迁移到不同形态的机器人（如G1）上，并发展出适合其自身身体尺寸的具身路径探索策略（例如，G1更倾向于绕行而非跨越某些障碍）。</p>
<p><img src="https://arxiv.org/html/2505.06218v1/x9.png" alt="效率与步态分析"></p>
<blockquote>
<p><strong>图9</strong>：在不同难度步道上的效率指标（平均速度）和步态多样性（不同步态类型的比例）分析。LEGO-H在保持较高成功率的同时，也展现出良好的效率和丰富的步态。</p>
</blockquote>
<p>在效率和步态多样性方面（图9），LEGO-H在保持高成功率的同时，也展现出良好的平均速度和丰富的步态类型组合。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：1) 提出了“徒步”作为推动人形机器人综合技能发展的新颖且具有挑战性的测试平台。2) 引入了LEGO-H，一个端到端的具身学习框架，它通过TC-ViT和增强的特权学习（HLM），首次将导航所需的感知意识、路径探索与运动所需的多样性、适应性在统一框架中整合。3) 通过在不同模拟步道和机器人形态上的广泛实验，证明了LEGO-H的鲁棒性、通用性和有效性，确立了其作为未来人形机器人研究的基线。</p>
<p>论文自身提到的局限性包括：目前冻结了机器人的上半身姿势，专注于下半身功能；训练和评估主要在模拟环境中进行；虽然框架设计考虑了感知-控制延迟，但真实世界的完全同步仍有待进一步处理。</p>
<p>这项工作对后续研究具有重要启示：首先，它展示了通过精心设计的分层学习和表征学习，可以有效地整合高层规划与低层控制，为解决更复杂的具身AI任务提供了框架参考。其次，徒步任务本身包含了丰富的物理和认知挑战，可以作为衡量和推动具身智能发展的综合性基准。最后，所提出的HLM等与任务无关的改进，有可能迁移到其他需要复杂运动技能和感知-运动协调的机器人学习领域。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人在复杂小径上徒步能力不足、现有研究分散的问题，提出整合视觉感知、决策与运动执行的LEGO-H框架。关键技术包括：时间视觉Transformer变体预测局部目标以指导运动，实现导航与运动的无缝结合；关节运动模式的潜在表示结合分层度量学习，增强特权学习以实现平滑策略转移。实验在多样化模拟小径和机器人形态上验证了LEGO-H的通用性与鲁棒性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.06218" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>