<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.03912" target="_blank" rel="noreferrer">2505.03912</a></span>
        <span>作者: Cui, Can, Ding, Pengxiang, Song, Wenxuan, Bai, Shuanghao, Tong, Xinyang, Ge, Zirui, Suo, Runze, Zhou, Wanqi, Liu, Yang, Jia, Bofang, Zhao, Han, Huang, Siteng, Wang, Donglin</span>
        <span>日期: 2025/05/06</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人策略学习传统上依赖于从头开始训练的轻量级模型，这些模型对环境扰动敏感且泛化能力有限。随着大语言模型（LLMs）和视觉语言模型（MLLMs）的发展，视觉-语言-动作模型（VLAs）应运而生，通过在大规模机器人轨迹数据和互联网视觉-语言任务上共同微调，显著提升了对新对象和多样化语义指令的泛化能力。然而，直接将VLAs应用于特定领域或现实场景仍面临挑战：庞大的模型尺寸导致实时推理效率低下（例如，55B模型运行频率为1-3 Hz）；端到端微调存在领域偏移和灾难性遗忘问题。</p>
<p>为解决上述挑战，双系统VLA架构被提出。该架构借鉴心理学中的“双过程理论”，将系统划分为两个部分：类似系统2的慢速、深思熟虑但泛化能力强的大型模型（如MLLMs/VLAs），负责高级理解和决策；类似系统1的快速、自动但任务特定的轻量级策略网络，负责实时低层动作生成。两者以不同频率并行更新，旨在兼顾大模型的多模态推理能力和轻量模型的高效实时控制。</p>
<p>本文的核心思路是：首先对现有双系统VLA架构的设计进行综述与比较，然后通过系统的实证评估剖析其核心设计要素的有效性，最终提供一个低成本的开源模型（OpenHelix）及代码库，以促进该领域的进一步探索与优化。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文并未提出一个全新的、统一的模型架构，而是对构成双系统VLA的<strong>关键设计要素</strong>进行了系统性梳理与实证分析。研究的目标是厘清这些设计选择如何影响最终性能，并为社区提供一个可复现、可评估的基线。</p>
<p><img src="https://arxiv.org/html/2505.03912v1/x1.png" alt="关键设计要素"></p>
<blockquote>
<p><strong>图1</strong>：双系统VLA的关键设计要素。主要包括七大方面：MLLM选择、策略选择、潜在特征表示选择、MLLM训练策略、策略训练策略、双系统集成策略以及双系统异步策略。</p>
</blockquote>
<p>根据图1所示的框架，一个双系统VLA模型的设计需解决以下核心问题：</p>
<ol>
<li><strong>MLLM选择</strong>：为机器人场景选择合适的视觉语言模型。需权衡模型能力与轻量化，例如是选择在空间感知/低层视觉能力强的模型（如Flower），还是选择极小参数量的模型（如MiniVLA使用的Qwen-VL 0.25B）以降低开销。同时，是否需要在机器人数据上预训练的MLLM（如OpenVLA）也是一个开放问题。</li>
<li><strong>策略选择</strong>：下游轻量策略模型的选择。当前共识是基于DiT或流匹配（Flow Matching）结构的模型能满足需求，但新架构（如CARP、Dense Policy）不断涌现。此外，策略是否需要以及需要哪些模态的输入（RGB、深度、触觉、本体感知等）也值得探讨。</li>
<li><strong>潜在特征表示选择</strong>：如何从系统2（MLLM）提取信息来指导系统1（策略）。这是最复杂且亟待研究的方向。现有方法差异巨大：DP-VLA直接使用MLLM最后一层的隐藏嵌入；GR00T-N1选用中间层特征以可能包含更多视觉信息；HiRT和Roboflamnigo对最后一层的语言和视觉特征进行最大池化；LCB引入了可微调的<code>&lt;ACT&gt;</code>特殊令牌；Robodual则结合了多个<code>&lt;ACT&gt;</code>令牌和最后一层语言特征。</li>
<li><strong>MLLM训练策略</strong>：如何训练MLLM以保持其泛化能力并与下游任务良好集成。主要方法有关闭参数（Frozen）和微调（Fine-tuning），探索更好的微调技术是有价值的方向。</li>
<li><strong>策略训练策略</strong>：如何训练下游策略以降低训练成本。主要范式是从头训练（Scratch）或基于预训练模型进行微调（Fine-tuning）。</li>
<li><strong>双系统集成策略</strong>：如何将潜在信息作为条件嵌入下游模型。常见做法是在上下游之间添加一个投影器（Projector），但如何训练这个投影器至关重要。例如，当下游策略是预训练模型时，必须在不解冻MLLM的情况下预先对齐（Pre-align）投影器，否则联合训练会导致模型崩溃。</li>
<li><strong>双系统异步策略</strong>：系统2与系统1在训练和推理时的更新频率协调。不同方法（如LCB、HiRT、Robodual）采用了不同的异步处理方式。</li>
</ol>
<p>为了进行公平的实证分析，本文在实验中<strong>标准化了部分设计选择</strong>以控制变量：采用LLaVA1.0作为统一的MLLM（系统2），采用3D Diffusion Actor (3DDA) 作为统一的下游策略（系统1），潜在特征表示采用LCB引入的<code>&lt;ACT&gt;</code>令牌方式，异步策略采用LCB的“同步训练、异步测试”模式。研究焦点集中在上述第4、5、6点，即MLLM训练策略、策略训练策略和双系统集成策略。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准与环境</strong>：核心实验在CALVIN模拟环境中进行。除了标准ABC-D场景评估外，还引入了两个更具挑战性的测试场景（如图2所示）：<ol>
<li><strong>CALVIN-E</strong>：使用更丰富（Enriched）的语言指令，测试语言泛化能力。</li>
<li><strong>CALVIN-D</strong>：在抓取任务中让物体以四种不同模式（向左、向前、对角线、圆周）运动，测试动态场景鲁棒性。</li>
</ol>
</li>
<li><strong>对比基线</strong>：与单系统模型RF（Roboflamnigo）和不同的双系统训练策略进行对比。</li>
</ul>
<p><img src="https://arxiv.org/html/2505.03912v1/x2.png" alt="三种评估环境"></p>
<blockquote>
<p><strong>图2</strong>：三种不同的评估环境。从左至右分别为：标准静态CALVIN环境、使用丰富指令的CALVIN-E环境、物体动态移动的CALVIN-D环境。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><p><strong>双系统必要性的验证</strong>：在CALVIN-D动态场景下测试单系统模型RF，其成功率在四种运动模式下均为0%（表2）。分析指出，RF依赖过去多帧图像生成潜在表示，在动态场景下训练与测试的表示差异导致性能急剧下降。这凸显了在动态场景下，依赖高频更新的轻量策略（系统1）的必要性，而RF模型在静态简单任务上极高的成功率（100%）也说明了MLLM作为“大脑”的重要性。</p>
</li>
<li><p><strong>策略训练策略对比</strong>：如表3所示，下游策略采用<strong>基于预训练模型的微调</strong>（Fine-tuning）相比<strong>从头训练</strong>（From-scratch）在连续任务完成率和平均任务长度上均有显著优势（例如，连续完成5个任务的成功率：48% vs 34%），且能减少总体训练时间。因此后续实验均采用微调策略。</p>
</li>
<li><p><strong>MLLM训练策略对比</strong>：</p>
<ul>
<li><strong>初步发现</strong>：如表4所示，在标准CALVIN环境中，对MLLM进行<strong>微调</strong>（Fine-tuning）并配合CLIP损失（用于对齐<code>&lt;ACT&gt;</code>令牌与下游指令）能取得最佳性能（连续5任务成功率48%）。若冻结（Frozen）MLLM，是否使用CLIP损失对性能影响不大。</li>
<li><strong>深入探索与语言泛化</strong>：作者假设CLIP损失可能损害大模型固有泛化能力，因此引入<strong>提示调优</strong>（Prompt-tuning），即仅训练新增的<code>&lt;ACT&gt;</code>令牌对应的嵌入和lm-head层，保持MLLM主干参数冻结。如表5所示，在CALVIN-E（语言泛化）测试中，<strong>提示调优</strong>（无论有无CLIP损失）的性能显著优于<strong>微调</strong>和<strong>冻结</strong>方法。例如，在无CLIP损失时，提示调优的连续5任务成功率为20%，而微调仅为4%，冻结仅为5%。这表明提示调优能以最小化改变大模型的方式，更好地保持其语言泛化能力。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2505.03912v1/extracted/6416779/figtex/figures/Comparasion_VLM.png" alt="三种MLLM训练策略"></p>
<blockquote>
<p><strong>图3</strong>：三种不同的MLLM训练策略示意图：冻结（Frozen）、微调（Fine-tuning）和提示调优（Prompt-tuning）。</p>
</blockquote>
<ol start="4">
<li><p><strong>双系统集成策略的关键</strong>：如表6所示，在连接MLLM和策略的投影器（Projector）训练中，<strong>投影器预对齐</strong>（Pre-alignment）至关重要。若没有预先对齐阶段（即直接联合训练所有部件），无论采用冻结、微调还是提示调优策略，模型性能都会完全崩溃（连续任务成功率全部为0%）。这证实了在集成双系统时，分阶段训练以确保投影器初始化的有效性是必要的。</p>
</li>
<li><p><strong>异步策略的意外发现</strong>：如图4所示，在CALVIN和CALVIN-D环境中，改变系统2（MLLM）的推理频率（即系统1在单次MLLM推理期间执行的步数从1到60）对模型性能影响微乎其微。这一反直觉的结果暗示，当前MLLM提供的潜在表征可能对环境变化不敏感。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2505.03912v1/x3.png" alt="层级推理评估"></p>
<blockquote>
<p><strong>图4</strong>：在CALVIN基准上对层级推理的评估。横轴为连续任务长度，纵轴为成功率。评估了MLLM推理步长分别为1和60（代表最典型的异步场景）时的性能，两者曲线高度重合。</p>
</blockquote>
<ol start="6">
<li><strong>对潜在表征的深入分析</strong>：为了探究上述异步实验现象的原因，作者对MLLM生成的潜在表征进行了可视化分析。如图5所示，在一个动态干扰场景中（第三步时蓝色积木被手动左移），MLLM的潜在嵌入对应的最接近语义词和空间词概率分布在干扰前后<strong>几乎没有变化</strong>。这表明当前基于<code>&lt;ACT&gt;</code>令牌的潜在表征主要编码了高级任务意图（如“拾取蓝色积木”），但缺乏对场景细节（如物体精确位置）的实时感知，因此无法为高频控制提供有效的动态指导。</li>
</ol>
<p><img src="https://arxiv.org/html/2505.03912v1/x4.png" alt="现有双系统短板的评估"></p>
<blockquote>
<p><strong>图5</strong>：对现有双系统短板的评估。第一行是输入MLLM的图像序列（第三步发生干扰）。第二行是环境状态可视化。第三、四行显示，在干扰发生前后，潜在嵌入对应的最接近语义词和空间词概率分布基本不变，说明其未捕捉到环境细节变化。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>系统性实证分析</strong>：首次对双系统VLA架构的多个核心设计要素（尤其是MLLM训练策略、策略训练策略和集成策略）进行了控制变量的、系统的实证研究与对比，得出了多项具有指导意义的结论（如提示调优利于泛化、投影器预对齐至关重要）。</li>
<li><strong>开源模型与代码库</strong>：提供了OpenHelix开源项目，包含一个基于实证分析最佳实践（LLaVA + 3DDA，提示调优，投影器预对齐）实现的双系统VLA模型，以及用于复现和进一步实验的完整代码框架，旨在降低该领域的研究门槛。</li>
<li><strong>揭示当前局限</strong>：通过实验发现了当前双系统架构的一个重要局限性：MLLM生成的潜在表征可能无法充分编码实时环境细节（如图5所示），导致其对动态场景不敏感，这解释了为何异步推理频率变化对性能影响不大（如图4所示）。这指向了未来改进的关键方向。</li>
</ol>
<p><strong>局限性（论文提及）</strong>：</p>
<ul>
<li>实证分析尚未覆盖所有设计要素（如不同的潜在特征表示选择、更复杂的异步策略）。</li>
<li>对单系统模型的对比未能涵盖所有相关方法（如π₀, GR00TN1），这些将在未来工作中补充。</li>
<li>当前实验主要基于模拟环境（CALVIN），真实世界实验将后续补充。</li>
</ul>
<p><strong>对后续研究的启示</strong>：</p>
<ul>
<li><strong>潜在表征设计是核心瓶颈</strong>：未来的研究应致力于设计能够同时编码高级任务语义和低级空间/动态细节的、更丰富的潜在表征，以真正发挥双系统架构在动态环境中的优势。</li>
<li><strong>训练策略的权衡</strong>：提示调优在保持MLLM泛化能力方面展现出潜力，是连接系统2与系统1的一种有前景且高效的训练范式。</li>
<li><strong>集成策略的稳定性</strong>：投影器或类似连接模块的初始化与训练策略需要谨慎设计，多阶段预对齐是保证训练稳定性的有效手段。</li>
<li><strong>开源基准的价值</strong>：OpenHelix项目为社区提供了一个可扩展的测试平台，鼓励后续研究在其基础上进行更深入的探索、比较与优化。</li>
</ul>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人操作中双系统视觉-语言-动作（VLA）架构缺乏开源模型、难以深入分析与优化的问题，首先综述并比较了现有架构设计，并对其核心设计要素进行了系统实证评估。论文提出了OpenHelix开源项目，旨在提供一个低成本的双系统VLA模型供社区使用。研究指出VLA模型在泛化能力上优势显著，但直接部署面临模型庞大、推理速度慢（如RT-2 55B模型仅1-3 Hz）以及微调困难等挑战。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.03912" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>