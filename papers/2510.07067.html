<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.07067" target="_blank" rel="noreferrer">2510.07067</a></span>
        <span>作者: Pugacheva, Daria, Moskalenko, Andrey, Shepelev, Denis, Kuznetsov, Andrey, Shakhuro, Vlad, Tutubalina, Elena</span>
        <span>日期: 2025/10/08</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>视觉-语言-动作模型在具身AI中扮演核心角色，使机器人能够理解和执行基于视觉感知的自然语言指令。然而，这些模型在现实场景中对自然语言多样性的鲁棒性尚未得到充分研究。现有工作对模型鲁棒性的评估通常局限于有限的、基于模板的指令扰动，例如特定格式的改写或单一类型的无关上下文，未能充分考虑真实用户如何自然地复述任务指令或添加无关信息。本文旨在系统性地评估先进VLA模型在语言扰动下的鲁棒性，具体针对两个痛点：人类自然产生的指令复述（同义改写）以及指令中存在的无关上下文。本文的核心思路是，通过引入更贴近真实场景的、系统化的指令扰动来全面评估VLA模型的脆弱性，并利用大型语言模型构建过滤框架来提取核心指令，从而提升模型在噪声输入下的性能。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文的研究框架分为两大阶段：首先是对VLA模型在多种语言扰动下的性能进行系统性评估，其次是提出并评估一个基于LLM的过滤框架来缓解性能下降问题。</p>
<p><strong>扰动类型设计</strong>：评估阶段的核心是精心设计了两大类指令噪声。</p>
<ol>
<li><strong>无关上下文</strong>：在目标指令前后添加无关文本。这又细分为两个组别：<ul>
<li><strong>长度变化</strong>：旨在评估无关文本长度的影响。包括：“Single”（单个引导词，如“However”）；“Short”（3-5个词的随机短句）；“Long”（7-10个词的随机长句）。这些上下文在词法和语义上都与训练集指令不同。</li>
<li><strong>语义与词法相似性</strong>：旨在评估与训练指令相似的无关内容的影响。包括：“Description”（描述场景中随机物体的短语，如“Cup is a container for liquids.”）；“Infeasible”（机器人无法执行的不可行命令，如“Bake a pie with peach slices.”）；“Location”（包含场景中物体位置信息的短语，如“There’s an apple on the TV stand, but...”）。这些上下文在语义和/或词法上与训练指令接近。</li>
</ul>
</li>
<li><strong>指令复述</strong>：通过众包平台收集真实用户对原始任务指令的自然语言复述，以评估模型对自然语言变化的适应性。</li>
</ol>
<p>所有扰动指令在格式上（如标点、大小写）都经过调整，以匹配模型训练集的模板风格，排除格式差异的影响。</p>
<p><img src="https://arxiv.org/html/2510.07067v1/all-twemojis.pdf" alt="扰动指令示例表"></p>
<blockquote>
<p><strong>表1</strong>：为Habitat 2.0模拟器和LIBERO基准生成的无关上下文示例。展示了原始指令、人类复述以及按长度和语义分类的各种无关上下文如何嵌入到指令中。</p>
</blockquote>
<p><strong>LLM过滤框架</strong>：为应对无关上下文导致的性能下降，本文提出一个预处理框架。该框架利用LLM从含噪声的输入中提取核心命令。研究探索了不同规模的LLM（从数亿到80亿参数）在少样本提示设置下的过滤能力。提示中包含“Short”、“Location”和“Infeasible”三种无关上下文的过滤示例。该方法的核心创新在于利用LLM强大的文本理解与选择能力，以轻量级、无需重新训练VLA模型的方式，处理复杂（语义相似）的无关上下文，从而恢复模型性能。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>仿真环境</strong>：使用LIBERO（包含Spatial, Object, Goal, Long四个任务套件）和Habitat 2.0两个主流仿真基准。</li>
<li><strong>评估模型</strong>：在LIBERO上评估OpenVLA、UniAct、π0和MoDE；在Habitat 2.0上评估LLARP。</li>
<li><strong>评估指标</strong>：任务成功率。每个统计结果均基于多次试验和随机种子的平均值。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>人类复述的影响</strong>：自然的人类指令复述导致VLA模型性能普遍下降，平均降幅约为20%。例如，在LIBERO-Goal任务上，OpenVLA的成功率从77.5%降至58.2%。这表明模型对训练数据之外的自然语言变体适应能力不足。</li>
<li><strong>无关上下文的影响</strong>：<ul>
<li><strong>语义相似性至关重要</strong>：与训练指令在语义和词法上相似的无关上下文（如“Location”类型）造成的性能下降最为严重，可达50%以上。例如，LLARP模型在Habitat 2.0上，面对“Location”型上下文，成功率从98.3%骤降至46.2%。</li>
<li><strong>长度效应</strong>：无关上下文长度增加会导致性能持续下降。当上下文长度与目标指令相当时，即使是随机无关文本（“Long”）造成的性能下降也可能与某些语义相似类型上下文造成的下降相当。</li>
<li><strong>随机上下文相对鲁棒</strong>：对于词义和语义均与训练集不同的随机无关上下文（“Short”），模型的性能下降通常在10%以内，表现出相对较强的鲁棒性。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2510.07067v1/all-twemojis.pdf" alt="无关上下文导致异常行为"></p>
<blockquote>
<p><strong>图3</strong>：在Habitat 2.0模拟器中，无关上下文“On the sofa there’s an apple”导致机器人对目标指令“find a lid and move it the black table”产生异常行为。机器人被误导去沙发上寻找目标物体，失败后开始执行拾取非目标物体、随机移动等混乱动作。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.07067v1/x1.png" alt="不同LLM过滤器的性能恢复情况"></p>
<blockquote>
<p><strong>图4</strong>：不同规模LLM对LLARP模型在Habitat 2.0中受各类无关上下文影响的指令进行过滤后的成功率。即使小规模LLM（如0.5B参数）也能较好处理随机上下文，但对于语义相似的上下文（如“Location”），需要更大模型（如3B）才能显著恢复性能。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.07067v1/all-twemojis.pdf" alt="LIBERO指令恢复比例"></p>
<blockquote>
<p><strong>图5</strong>：不同规模LLM过滤器从LIBERO基准的含噪声指令中成功恢复原始命令的平均比例。参数规模达3B的Llama 3.2模型能够恢复大部分原始命令。</p>
</blockquote>
<ol start="3">
<li><strong>过滤框架效果</strong>：采用Meta-Llama-3-8B-Instruct作为过滤器后，模型性能得到显著恢复。<ul>
<li>对于LIBERO基准，过滤后几乎所有类型的无关上下文都被成功去除，目标指令得以完整保留，模型成功率恢复至与原始指令相当的水平。</li>
<li>对于LLARP模型，过滤框架能将因无关上下文而下降的性能恢复90%以上。例如，针对“Location”型上下文，LLARP的成功率从46.2%恢复至94.9%。</li>
<li><strong>局限性</strong>：过滤框架在处理人类复述指令时，可能偶尔（约5%的情况）误删有用信息或对指令进行标准化改写，导致成功率有小幅波动（有升有降）。在极少数情况下（约0.6%的测试数据），过滤可能错误地将原始指令中的有效细节（如物体位置信息）当作噪声移除。</li>
</ul>
</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>首次对多种先进VLA模型进行了系统性的语言扰动鲁棒性评估，揭示了模型对真实场景中自然语言变化（特别是语义相似的无关上下文）的显著脆弱性。</li>
<li>通过人类众包研究量化了自然指令复述导致的性能下降（约20%），凸显了基于LLM的VLA模型与实际部署需求间的适应差距。</li>
<li>提出并验证了一个轻量级的、基于LLM的过滤框架，该框架能有效从含噪声指令中提取核心命令，使模型在噪声条件下的性能恢复最高可达98.5%，为提升部署鲁棒性提供了实用方案。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ol>
<li>本文考虑的无关上下文类型未涵盖带有条件或推理任务的复杂指令。</li>
<li>所提过滤方法在极少数情况下可能误滤除指令中的重要细节。</li>
</ol>
<p><strong>研究启示</strong>：<br>本研究强调了解决语言可变性对开发实用具身AI系统的关键性。未来工作可集中于开发更自适应的过滤机制、提升模型对复杂指令的理解鲁棒性，以及将此类鲁棒性评估和增强方法整合到VLA模型的训练流程中，以构建更可靠、适用于真实人机交互的机器人系统。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文研究了具身AI中VLA模型对指令中无关上下文和转述的鲁棒性问题。通过引入人类生成的转述指令和按长度、语义/词汇相似度分类的无关上下文进行系统评估。核心实验发现：无关上下文越长，性能下降越明显；语义/词汇相似的上下文可导致性能骤降约50%，而随机上下文仅下降10%以内；人类转述导致性能下降近20%。为缓解此问题，论文提出一种基于LLM的过滤框架，能从含噪指令中提取核心命令，使模型性能在噪声条件下恢复至原性能的98.5%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.07067" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>