<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Few-Shot Neuro-Symbolic Imitation Learning for Long-Horizon Planning and Acting - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Few-Shot Neuro-Symbolic Imitation Learning for Long-Horizon Planning and Acting</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.21501" target="_blank" rel="noreferrer">2508.21501</a></span>
        <span>作者: Matthias Scheutz Team</span>
        <span>日期: 2025-08-29</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>模仿学习使智能系统能够以最少的监督学习复杂行为。然而，现有方法通常侧重于短视界技能，需要大型数据集，并且难以解决长视界任务或泛化到任务变体和分布偏移。人类通过将问题抽象为符号表示来获得优势，这促进了推理和泛化。分层方法，如任务与运动规划，利用了类似的划分，但传统上依赖于手动构建的符号模型，使其脆弱且难以适应。先前的工作要么从符号轨迹中学习动作模型，要么用符号领域指导底层强化学习，但都假设可以访问先验的符号表示：要么通过手动设计的符号状态表示、已知谓词和对象类型，要么通过从连续状态到符号事实的预定义映射函数。据本文所知，没有先前的工作能够在不依赖预定义符号状态、谓词或词典的情况下，仅从少量演示中联合学习底层控制策略和高级规划模型。</p>
<p>本文针对从少量原始演示中联合学习连续控制策略和符号领域抽象这一具体痛点，提出了一种新的神经符号视角。其核心思路是：从技能演示中构建一个捕捉高级状态转换的图，使用答案集编程求解器自动发现符号规则以形成PDDL规划模型，并利用扩散策略模仿学习来训练由符号算子引导的、关注最小化观察空间的底层控制器。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的神经符号模仿学习框架旨在从原始演示轨迹集合𝒟中学习，以解决长视界任务与运动规划问题。整体流程如算法1所示，可分为学习阶段和执行阶段。</p>
<p><img src="https://arxiv.org/html/2508.21501v1/figures/IVA_Fig1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：神经符号框架整体流程图。从少量技能演示（左侧）开始，构建一个捕捉状态转换（边）的图，其中节点是高级状态（黑盒）。该图通过ASP求解器实现PDDL模型的自动提取，进而支持高级规划。Oracle将复杂任务分解为由学习到的扩散控制器执行的原始动作步骤策略，从而在需要最少训练数据的同时泛化到新的长视界任务。</p>
</blockquote>
<p><strong>整体流程</strong>：首先，每个演示轨迹被映射为一个节点转换τ^node = (n_start, l, n_end)，其中n_start和n_end是演示开始和结束时的抽象高级状态（仅由视觉快照表示的黑盒节点），l是人为分配的描述转换的标签。这些转换构成一个图G。接着，计算图G的最小互模拟G_bar以消除冗余结构。然后，使用基于答案集编程的求解器从G_bar中抽象出符号谓词ℱ和算子𝒪，形成PDDL领域。对于每个符号算子o_i，将其关联的演示数据通过聚类分解为一系列更简单的动作步骤（例如，MOVE算子分解为reach_pick, pick, reach_drop, drop）。Oracle函数ϕ为每个步骤过滤掉无关的观察信息，并转换坐标。最后，使用扩散策略在过滤后的数据上训练每个动作步骤的连续控制策略π_i,j。执行时，给定初始和目标节点，使用经典规划器生成符号计划𝒫 = [o_1, ..., o_|𝒫|]，然后顺序调用对应的神经技能π_i（内部按步骤π_i,j执行）来完成计划。</p>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>从稀疏演示中学习符号结构</strong>：该方法的核心创新之一是能够从无序的演示中构建符号图，且只需最少的人工输入（仅需为状态转换分配标签并通过视觉比对链接相同状态）。通过计算<strong>最小互模拟</strong>来压缩图，减少领域学习的搜索空间和标注工作量。符号抽象采用<strong>ASP求解器</strong>，其目标是找到一个最简单的规划实例P = ⟨σ, I⟩，使得该实例定义的图G(P)与输入图G同构。学习到的领域σ以PDDL表示，可供经典规划器使用。</li>
<li><strong>Oracle - 过滤技能相关数据</strong>：Oracle函数ϕ是关键的信息瓶颈，它根据符号算子的逻辑自动确定每个技能执行时需要关注哪些对象。具体而言，对于算子o_i，首先通过函数γ过滤出受该算子影响的对象子集ℰ_o_i的观察信息：γ(s<del>, o_i) = s</del>(ℰ_o_i)。然后通过函数α将绝对坐标转换为相对于智能体末端执行器的坐标：α(s<del>, ℰ_o_i) = {s</del>(ε_k) - s<del>(EE) | ε_k ∈ ℰ_o_i}。因此，ϕ(s</del>_t) = α ∘ γ(s~_t, o_i)。这大幅降低了观察空间的维度，使策略学习更高效，并提高了对不同空间配置的泛化能力。</li>
<li><strong>动作步骤分解</strong>：受分层强化学习中选项框架的启发，每个技能被进一步分解为顺序执行的动作步骤。分解是基于演示数据中一致性的顺序动作空间模式自动完成的。</li>
</ol>
<p><img src="https://arxiv.org/html/2508.21501v1/figures/cluster.png" alt="技能分解与Oracle过滤"></p>
<blockquote>
<p><strong>图2</strong>：以汉诺塔领域中的MOVE算子为例，展示了技能分解与Oracle过滤过程。演示被收集后，首先使用γ过滤出算子相关对象（块1和平台3），然后使用α将坐标转换为相对于末端执行器。随后，轨迹被分解为一系列更简单的动作步骤（如到达、抓取等），以便高效训练底层控制器。</p>
</blockquote>
<ol start="4">
<li><strong>学习连续控制策略</strong>：使用<strong>扩散策略</strong>从演示数据中学习控制策略。扩散模型p_θ(a_t | ϕ(s<del>_t))通过学习去噪被扰动的专家动作来生成动作，其损失函数为ℒ_diff = E[‖ϵ - ϵ_θ(a_t + σϵ, ϕ(s</del>_t))‖²]。这种方法能捕捉多模态动作分布，避免直接回归中常见的模式坍塌。框架也兼容其他模仿学习算法。</li>
</ol>
<p><strong>创新点</strong>：与现有方法相比，本文的主要创新体现在：1) <strong>首次提出</strong>从少量原始演示中<strong>联合学习</strong>底层神经控制策略和高级符号抽象，无需任何预定义的符号状态、谓词、词典或领域知识。2) 通过基于图的表示和ASP求解，能够捕捉包括非空间关系和时间依赖转换在内的复杂状态转换，这是数据驱动学习或聚类技术在有限演示数据中难以发现的。3) 引入了自动化的Oracle机制，动态地为每个技能过滤和转换观察空间，极大地提高了学习效率和泛化能力。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：本文在六个模拟环境中评估方法：四个基于Robosuite（Stacking堆叠、Kitchen厨房、Nut Assembly螺母装配、以及自定义的Towers of Hanoi汉诺塔），以及两个基于ROS 2 &amp; Gazebo的叉车任务领域（Forklift Loading/Unloading叉车装卸和Multiple Pallets Storage多托盘存储）。观测信息包括场景中物体和末端执行器的6D位姿。任务在评估时随机化。提供给框架的演示是短视界技能，每个演示最大长度为300步，并添加了观测噪声。每个智能体评估30回合，结果在5个随机种子上取平均。每个策略训练8000轮次。</p>
<p><strong>基线方法</strong>：与三个端到端神经基线对比：1) <strong>IL</strong>：对整个轨迹进行模仿学习。2) <strong>H-IL</strong>：分层模仿学习，具有类似Oracle的高级策略来调用底层策略。3) <strong>H-IL Dense</strong>：类似H-IL，但高级策略接收完整轨迹而非每个操作开始时的单点。为确保公平，IL基线和H-IL基线的高级策略接收绝对观测，其底层策略接收相对观测。</p>
<p><strong>关键实验结果</strong>：</p>
<p><img src="https://arxiv.org/html/2508.21501v1/figures/main_results.png" alt="主要实验结果对比"></p>
<blockquote>
<p><strong>图6</strong>：神经符号框架与基线方法在短视界和长视界任务上的性能对比。在仅需规划的叉车装卸和堆叠任务中，所有方法表现相近或本文方法略优；而在需要复杂推理的汉诺塔、多托盘存储等长视界任务中，基线方法即使有500次演示也完全失败，本文方法仅用5次演示即能可靠解决，证明了其强大的符号抽象和规划能力。</p>
</blockquote>
<p><strong>神经技能学习</strong>：在主要强调控制而非规划的叉车装卸和堆叠任务中（图6左上及中部），所有智能体在叉车任务上表现相似。而在堆叠任务中，本文方法开始优于基线，这得益于Oracle结合了相对观测和符号抽象进行策略精炼，以及动作空间聚类的优化，仅用5次演示就实现了接近100%的成功率。叉车任务成功率较低源于其铰接式运动学带来的控制挑战。</p>
<p><strong>推理能力</strong>：在汉诺塔、多托盘存储、螺母装配和厨房等长视界环境中评估（图6右侧）。基线方法即使有500次完整演示也无法解决汉诺塔任务，而本文方法能从部分演示中可靠地抽象出问题约束，构建正确的符号领域并解决任务。在其他领域的成功进一步证实了该方法的领域无关推理能力。失败仅发生在底层技能未能达到预期效果时，而非由于推理错误。</p>
<p><strong>泛化与微调</strong>：</p>
<p><img src="https://arxiv.org/html/2508.21501v1/figures/gen_results.png" alt="泛化结果"></p>
<blockquote>
<p><strong>图7</strong>：在汉诺塔不同配置上的零样本和少样本泛化结果。本文方法能够从基础配置（3×3）泛化到更复杂配置（如7×5）和空间偏移，并通过添加少量专家修正（5+Experts）进行课程学习，性能显著提升，甚至优于使用更多数据从头训练的智能体。</p>
</blockquote>
<p>零样本评估将方法扩展到更难的汉诺塔配置（从3立方体×3桩到7立方体×5桩）和空间偏移（桩位移达10cm），仅使用基础配置的演示。少样本微调从5次完整MOVE技能演示开始，然后通过课程学习逐步添加5次针对更难配置的专家动作步骤演示。结果显示，添加少量专家修正后性能获得显著提升，在更复杂配置中偶尔能表现出鲁棒行为。</p>
<p><strong>消融实验</strong>：论文虽未明确设置独立消融实验，但通过在不同任务中分析组件的作用间接体现了消融思想。例如，在Stacking任务中，通过Oracle进行的策略精炼（结合γ和α）以及动作空间聚类被证明是优于纯神经基线的关键。这说明了符号引导的观察过滤和技能分解对提升数据效率和性能的贡献。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了第一个能从少量原始演示中<strong>联合学习</strong>底层连续控制策略和高级符号领域抽象的神经符号模仿学习框架，无需任何预定义的符号状态、谓词、词典或领域知识。</li>
<li>展示了<strong>卓越的数据效率</strong>（仅需5次技能演示）和<strong>强大的零样本/少样本泛化能力</strong>，能够解决基线方法无法处理的长视界规划任务。</li>
<li>框架具有<strong>领域无关性</strong>和<strong>可解释性</strong>，在多种截然不同的机器人领域（机械臂、叉车）中均验证有效，并产生可解释的符号计划。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，失败主要发生在底层神经技能未能实现其符号算子的预期效果时，而非高层推理错误。这表明控制精度和鲁棒性仍是实际部署中的挑战。此外，方法假设演示图是完整且无噪声的。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>神经与符号的深度融合</strong>：本文展示了在数据稀缺场景下，符号推理能为神经学习提供强有力的引导和归纳偏置，反之神经控制能实现符号规划的物理实例化。这种结合是解决复杂长视界任务的有力途径。</li>
<li><strong>课程学习与持续学习</strong>：框架支持通过逐步添加新演示进行课程学习，这为智能体在开放环境中持续扩展技能库提供了可能。</li>
<li><strong>可解释性与人机交互</strong>：生成的符号计划易于人类理解，且所需的人工输入（匹配视觉状态、标注技能）直观，降低了专业知识门槛，有利于构建更透明、更易教授的人机协作系统。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对模仿学习在长期任务中数据需求大、泛化能力差的核心问题，提出一种少样本神经符号框架。该方法通过图构建抽象高级任务结构，利用答案集编程（ASP）求解器自动发现符号规则，并采用扩散策略模仿学习训练低级控制器，辅以高级预言机过滤任务信息以聚焦观测空间。在多个机器人领域实验表明，仅需五个技能演示即可实现高数据效率，具备强大的零样本和少样本泛化能力，且决策过程可解释。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.21501" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>