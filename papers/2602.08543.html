<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>GISA: A Benchmark for General Information-Seeking Assistant - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>GISA: A Benchmark for General Information-Seeking Assistant</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.08543" target="_blank" rel="noreferrer">2602.08543</a></span>
        <span>作者: Zhicheng Dou Team</span>
        <span>日期: 2026-02-09</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>随着大语言模型（LLMs）的发展，能够通过多轮网络交互自主收集信息的搜索智能体得到了快速发展。为了评估此类智能体，研究社区提出了多种基准测试。然而，现有基准测试存在几个关键局限性：首先，许多基准（如BrowseComp）采用从预选答案反向构建查询的逆向工程方法，导致任务不自然，与真实世界的信息需求脱节。其次，现有基准主要侧重于评估智能体在网络上进行深度搜索（即定位特定信息）的能力，或像WideSearch那样侧重于从多源进行广度信息聚合，缺乏对深度推理和广度信息聚合能力的统一评估。最后，为了方便评估和复现，大多数基准依赖于答案长期稳定的静态问题集，这使得模型可能通过预训练记忆答案，而无法真正测试其搜索能力。</p>
<p>本文针对上述痛点，提出了一个名为GISA（General Information-Seeking Assistant）的基准测试。其核心思路是：通过一个以人为中心、多阶段标注的流程，构建一个包含真实信息需求查询、结构化答案格式、动态实时子集以及完整人类搜索轨迹的基准，以全面、真实地评估通用信息寻求助手的能力。</p>
<h2 id="方法详解">方法详解</h2>
<p>GISA基准的构建是一个严谨的、以人为中心的过程，旨在确保每个查询都具有挑战性、真实性，并严格符合评估真实世界信息寻求能力的目标。整个工作流程受严格的准则和多阶段验证控制。</p>
<p><img src="https://arxiv.org/html/2602.08543v1/fig/github-mark.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：基准构建流程及不同答案类型的查询示例。构建流程包含四个阶段：(1)头脑风暴，(2)查询精炼，(3)人工标注，(4)质量检查。</p>
</blockquote>
<p>整体构建流程（Pipeline）包含四个阶段：</p>
<ol>
<li><strong>头脑风暴</strong>：为确保基准覆盖反映人类兴趣的多样化主题，采用了BrowseComp的十领域分类法（电视电影、科技、艺术、历史、体育、音乐、电子游戏、地理、政治、其他）。标注者被指示访问特定领域的网站进行开放式浏览，并记录在消费信息过程中自发产生的问题，模拟“遇到信息并寻求更多知识”的自然认知过程。</li>
<li><strong>查询精炼</strong>：将原始问题转化为正式、结构化的查询。此阶段是实现GISA两个核心设计目标的关键：通过结构化答案格式实现确定性评估，以及在现实任务中统一深度和广度搜索能力。标注者需要确定目标答案的最佳格式，并据此完善查询。</li>
<li><strong>人工标注</strong>：为每个精炼后的查询收集标准答案和完整的人类搜索轨迹。答案被格式化为四种结构化类型之一：<strong>项目</strong>（单一、精确的事实）、<strong>集合</strong>（无序的、去重的项目集合）、<strong>列表</strong>（有序的项目序列）、<strong>表格</strong>（具有行和列的结构化数据）。搜索轨迹记录了人类解决者从初始查询到最终答案的完整步骤序列，包括发出的搜索查询、点击的链接、浏览的页面以及提取的信息。</li>
<li><strong>质量检查</strong>：每个查询及其答案和轨迹都经过多轮验证，包括自我检查、同行评审和负责人审核，以确保高质量。</li>
</ol>
<p>GISA的核心创新模块和设计体现在其整体特性上：</p>
<ul>
<li><strong>多样化的答案格式与确定性评估</strong>：四种结构化答案类型（项目、集合、列表、表格）使得可以使用严格的匹配指标（如精确匹配、F1分数）进行确定性和可复现的评估，避免了基于LLM评判的主观性和不稳定性。</li>
<li><strong>深度与广度搜索能力的统一</strong>：GISA的查询设计天然地融合了深度推理（如多跳问答）和广度信息聚合（如从多个来源收集和总结信息）的需求，在一个复杂的、长视野的任务中评估智能体的垂直调查和横向概括能力。</li>
<li><strong>动态与抗静态评估</strong>：GISA将查询分为<strong>稳定子集</strong>（答案长期不变）和<strong>实时子集</strong>（答案需要访问实时信息并会定期更新）。实时子集的设计旨在防止预训练记忆造成的数据污染，确保基准随时间推移仍具有挑战性。</li>
<li><strong>通过人类轨迹进行过程级监督</strong>：除了问答对，GISA为每个查询提供了完整的人类搜索轨迹。这些轨迹可作为过程奖励建模和模仿学习的黄金标准，同时也验证了所有任务都可以通过现实的搜索行为解决。</li>
</ul>
<p>与现有方法相比，GISA的创新点具体体现在：1) 查询由人类根据真实信息需求正向构建，而非从答案反向工程；2) 在一个基准内统一评估深度和广度搜索；3) 引入动态更新的实时子集以对抗记忆；4) 提供可支持过程级训练和评估的完整人类轨迹。</p>
<p><img src="https://arxiv.org/html/2602.08543v1/x1.png" alt="主题分布"></p>
<blockquote>
<p><strong>图2</strong>：GISA中查询的主题分布。涵盖了十个不同的领域，其中“其他”类别占比最高，确保了主题的多样性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.08543v1/x2.png" alt="标注时间统计"></p>
<blockquote>
<p><strong>图3</strong>：GISA上人工标注时间的统计。从问题设计到最终验证，每个查询平均需要超过一小时的人力投入，体现了数据构建的高质量和高成本。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>评估设置</strong>：实验在GISA基准的373个查询上进行。评估了多种主流的大语言模型（包括GPT-4o、Claude-3.5-Sonnet、Gemini-1.5-Pro、DeepSeek-V2等）以及商业搜索产品（如OpenAI Deep Research、Gemini Deep Research）。评估时，为智能体提供了网络搜索和页面浏览的工具。</p>
<p><strong>基线方法</strong>：由于GISA是一个新基准，论文主要将当前最先进的LLMs和商业系统作为基线进行性能对比。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>整体性能低下</strong>：即使表现最好的模型（GPT-4o），在GISA上的整体精确匹配（Exact Match）得分也仅为19.30%。商业深度研究系统（OpenAI Deep Research, Gemini Deep Research）的表现并未超越基于LLM的智能体，甚至更差（Gemini Deep Research得分仅5.90%）。这突显了GISA的挑战性。</li>
<li><strong>不同答案格式的难度差异</strong>：模型在“项目”类型任务上表现相对最好（GPT-4o得分为27.78%），而在需要组织和呈现多个信息的“列表”和“表格”类型任务上表现最差（GPT-4o得分分别为10.00%和9.52%）。这表明当前智能体在信息综合与结构化输出方面存在明显短板。</li>
<li><strong>深度与广度任务表现</strong>：在需要深度推理的任务上，最佳模型（GPT-4o）的F1得分为20.37%；在需要广度聚合的任务上，最佳模型（Claude-3.5-Sonnet）的F1得分为22.86%。两者表现均不理想，且广度任务略优于深度任务。</li>
<li><strong>实时子集的有效性</strong>：在实时子集上，所有模型的性能相比稳定子集都有显著下降（例如GPT-4o从20.43%降至15.38%），验证了实时子集能有效降低模型通过记忆作弊的可能，更能反映真实的搜索能力。</li>
</ol>
<p><img src="https://arxiv.org/html/2602.08543v1/x3.png" alt="主要结果"></p>
<blockquote>
<p><strong>图4</strong>：不同模型在GISA整体、不同答案类型以及深度/广度任务上的性能（Exact Match %）。GPT-4o整体最佳，但所有模型得分均很低。在列表和表格任务上表现尤其薄弱。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.08543v1/x4.png" alt="实时子集结果"></p>
<blockquote>
<p><strong>图5</strong>：模型在稳定子集 vs. 实时子集上的性能对比。所有模型在实时子集上的表现均出现下降，证明了引入动态数据的必要性。</p>
</blockquote>
<p><strong>消融实验分析</strong>：论文通过分析失败案例，总结了当前智能体在GISA任务上失败的主要原因，这可以视为对“所需能力组件”的消融分析：</p>
<ol>
<li><strong>复杂规划能力不足</strong>（占失败案例的31.2%）：智能体无法制定有效的多步搜索策略。</li>
<li><strong>综合信息收集能力不足</strong>（28.0%）：智能体难以从多个页面或来源全面收集所需信息。</li>
<li><strong>信息过滤与验证能力不足</strong>（19.4%）：智能体容易被无关或错误信息干扰。</li>
<li><strong>精确指令遵循能力不足</strong>（12.9%）：智能体未能严格按照答案格式要求输出。</li>
<li><strong>其他原因</strong>（8.5%）：如工具使用错误、上下文长度限制等。</li>
</ol>
<p><img src="https://arxiv.org/html/2602.08543v1/x5.png" alt="失败原因分析"></p>
<blockquote>
<p><strong>图6</strong>：当前智能体在GISA任务上失败的原因分布。复杂规划和综合信息收集是两大主要瓶颈。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了GISA，一个旨在全面评估通用信息寻求助手的新基准。其核心特征包括：人类正向构建的真实查询、四种结构化答案格式以实现确定性评估、深度与广度搜索能力的统一评估、包含动态更新的实时子集以抵抗记忆、以及为每个查询提供的完整人类搜索轨迹。</li>
<li>通过严谨的多阶段人工标注流程，构建了一个包含373个高质量查询的数据集，并公开了完整的评估工具和排行榜。</li>
<li>对现有先进LLMs和商业系统进行了广泛评估，结果表明当前技术的性能（最佳精确匹配19.30%）远未达到实用水平，特别是在需要复杂规划、综合信息收集和结构化输出的任务上存在显著不足，为未来研究指明了方向。</li>
</ol>
<p><strong>局限性</strong>：论文提到，由于GISA完全由人工构建，其规模（373个查询）相对于一些自动构建的基准较小。此外，实时子集的维护需要持续的人工投入以更新答案。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li>GISA为训练和评估搜索智能体提供了高质量的、过程可解释的数据。人类搜索轨迹可用于模仿学习或作为强化学习中的密集奖励信号，以提升智能体的规划能力。</li>
<li>实验结果揭示了当前智能体在复杂、开放域信息寻求任务上的关键弱点，未来的研究应着重提升智能体的多步规划、多源信息综合与验证、以及精确遵循复杂输出指令的能力。</li>
<li>GISA的动态评估设计强调了开发能够处理实时、演化信息的搜索智能体的重要性，这是通向实用化信息助手的关键一步。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对现有信息检索智能体评测基准存在的查询构造不自然、任务单一且易受数据污染等问题，提出了GISA基准。该基准包含373个人工构建的真实场景查询，支持条目、集合、列表和表格四种结构化答案格式，并整合了深度推理与广泛信息聚合任务，部分子集答案动态更新以抵抗模型记忆。实验表明，当前主流大模型在GISA上的精确匹配得分最高仅为19.30%，尤其在需要复杂规划和综合信息收集的任务上表现显著下降。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.08543" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>