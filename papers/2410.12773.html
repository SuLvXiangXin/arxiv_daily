<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2410.12773" target="_blank" rel="noreferrer">2410.12773</a></span>
        <span>作者: Jiang, Zhenyu, Xie, Yuqi, Li, Jinhan, Yuan, Ye, Zhu, Yifeng, Zhu, Yuke</span>
        <span>日期: 2024/10/16</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人因其类人的形态，有潜力无缝融入人类环境。实现其与人类共存和协作的关键在于理解自然语言指令并展现出类人的行为。目前，直接从语言描述生成人形机器人动作面临缺乏大规模语言-动作配对数据集的挑战。现有方法主要分为两类：一类是基于强化学习模仿人类动作的方法，这些方法通常在仿真中生成物理上逼真的动作，但因其使用理想化的机器人模型（如无扭矩限制的SMPL机器人），难以部署到真实机器人；另一类是直接利用大语言模型生成动作，但生成的动作往往显得不自然和僵硬。本文针对“如何生成自然、富有表现力且与语言描述对齐的全身人形机器人动作”这一具体痛点，提出了结合人类运动先验与视觉语言模型常识推理能力的新视角。核心思路是：首先利用在大规模人类动作数据上训练的扩散模型，根据文本生成人类动作作为先验，并通过逆运动学重定向到人形机器人；随后，利用视觉语言模型对重定向后的动作进行编辑和细化，补充头部和手指运动，并调整动作以更好地对齐语言描述。</p>
<h2 id="方法详解">方法详解</h2>
<p>Harmon的整体流程分为三个阶段：1）基于文本的人类动作生成与重定向；2）基于VLM的人形机器人动作编辑；3）真实机器人上的动作执行。输入是自由形式的语言描述X，输出是人形机器人的关节配置序列Q。</p>
<p><img src="https://arxiv.org/html/2410.12773v1/x2.png" alt="方法总览"></p>
<blockquote>
<p><strong>图2</strong>：Harmon方法概览。给定动作的语言描述，首先生成对应的人类动作并重定向到人形机器人；接着利用VLM细化人形机器人动作，包括生成手指和头部运动，并迭代调整身体动作；最终生成与语言描述精确对齐的全身人形机器人动作。</p>
</blockquote>
<p><strong>核心模块一：文本条件人类动作重定向</strong>。由于缺乏配对数据，直接训练从语言生成机器人动作的模型是困难的。因此，本文利用预训练的物理引导运动扩散模型PhysDiff，根据文本描述X生成对应的SMPL参数序列P（包含关节旋转和根节点平移）。为了缩小人体模型与人形机器人之间的形态差异，首先优化SMPL的身体形状参数β，使选定17个对应关节的位置差异最小。然后，使用逆运动学求解器，以优化后的SMPL关节位置作为目标，逐时间步优化机器人关节配置q，使其关键关节（手腕、肘部、肩膀、膝盖、脚踝）与人体模型对齐，从而得到重定向后的机器人关节序列Q_r。</p>
<p><strong>核心模块二：基于VLM的人形机器人动作编辑</strong>。重定向得到的动作Q_r缺乏头部和手指运动，且可能因运动学结构差异导致语义偏差。因此，本模块利用GPT-4对动作进行编辑。</p>
<p><img src="https://arxiv.org/html/2410.12773v1/x2.png" alt="VLM编辑流程"></p>
<blockquote>
<p><strong>图3</strong>：基于VLM的动作编辑流程。<strong>左上</strong>：GPT-4根据渲染的人形机器人动作视频和手指动作描述，在关键帧生成手指关节配置。<strong>右上</strong>：GPT-4根据头部动作描述，确定关键帧并生成头部关节配置。<strong>下方</strong>：GPT-4通过评估和细化渲染的帧，迭代调整手臂动作以对齐运动描述。</p>
</blockquote>
<ol>
<li><strong>手指与头部运动生成</strong>：首先，GPT-4从原始描述中提取专门的手指和头部动作描述。对于手指运动，从重定向动作视频中等间隔采样4帧，连同手指描述输入GPT-4V，让其生成每个间隔内12个手指关节的配置，拼接得到序列Q_f。对于头部运动，则直接向GPT-4（文本）输入头部描述、总帧数和帧率，由其自主决定关键帧并生成3个颈部关节的配置，插值后得到平滑序列Q_h。</li>
<li><strong>迭代动作调整</strong>：为纠正重定向或人类动作生成本身导致的语义偏差，设计了包含“判断智能体”和“调整智能体”的迭代调整流程。判断智能体（GPT-4V）根据采样的4帧视频和语言描述，生成描述、评估对齐程度并提供改进建议。调整智能体（GPT-4V）则根据相同帧和建议，预测所需的动作调整。调整通过一组预定义的控制基元（例如，使用逆运动学使左/右手腕向特定方向移动）实现。调整后渲染新视频，重新判断，直至对齐或超过两轮。最终得到调整后的身体关节序列Q_b。若无需调整，则直接使用Q_r作为Q_b。</li>
</ol>
<p>最后，将身体序列Q_b、手指序列Q_f和头部序列Q_h组合，形成完整的机器人关节配置序列Q*。</p>
<p><strong>核心模块三：真实机器人动作执行</strong>。由于动力学和平衡问题，无法直接在真实机器人上执行Q<em>。因此，遵循现有方法，将运动解耦为上、下半身。下半身简化为从骨盆轨迹提取的移动命令，由基于零力矩点的控制器执行；上半身则使用关节位置控制执行Q</em>中的对应部分。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>评估设置</strong>：由于缺乏配对数据，通过人类研究进行评估。测试集包含约50条语言描述，一部分来自HumanML3D测试集（主要涉及身体动作），另一部分由GPT-4生成（包含头手动作）。在仿真中渲染动作视频供参与者评估。</p>
<p><strong>对比基线</strong>：</p>
<ol>
<li><strong>VLM-based Motion Generation</strong>：不使用人类运动先验，直接从静态T姿势开始VLM编辑，仅用于评估人类先验的重要性。</li>
<li><strong>Human Motion Retargeting</strong>：直接使用重定向的人类动作作为身体动作，并加上Harmon生成的头手动作，用于评估迭代调整的有效性。</li>
<li><strong>Harmon w/o Head or Finger</strong>：Harmon的消融版本，头手关节保持零位，用于评估头手运动生成的重要性。</li>
</ol>
<p><strong>关键实验结果</strong>：参与者从手指/头部运动、手臂运动、整体身体协调性三方面评估动作与文本的对齐程度。</p>
<p><img src="https://arxiv.org/html/2410.12773v1/x3.png" alt="定量结果"></p>
<blockquote>
<p><strong>图4</strong>：人类研究的定量结果。左侧为整体归一化分数，右侧为不同身体部位的分数。Harmon在整体和各项上均表现最佳。</p>
</blockquote>
<p>Harmon获得了<strong>81.2%</strong> 的整体归一化分数，显著优于所有基线。VLM直接生成基线的分数最低（31.6%），凸显了人类运动先验的重要性。仅重定向基线的<strong>手臂运动</strong>分数较低，证明了VLM迭代调整对改善手臂动作对齐的有效性。消融版本（无头手）在头手运动分数上自然较低。</p>
<p><img src="https://arxiv.org/html/2410.12773v1/x4.png" alt="定性结果"></p>
<blockquote>
<p><strong>图5</strong>：Harmon的定性结果示例。红圈标出了生成的头手运动，红箭头标出了运动调整。展示了重定向提供良好初始化、VLM增强表达力、以及迭代调整纠正语义偏差等多种情况。</p>
</blockquote>
<p><strong>真实机器人部署</strong>：方法在真实的Fourier GR1人形机器人上成功执行了生成的站立和需要移动的动作，验证了其可行性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1）提出了Harmon框架，首次将人类运动先验与VLM的常识推理相结合，从语言描述生成自然、富有表现力且对齐的全身人形机器人动作。2）设计了基于VLM的迭代动作编辑流程，能够生成缺失的头手运动并细化身体动作以改善语义对齐。3）在仿真和真实人形机器人上验证了方法的有效性。</p>
<p><strong>局限性</strong>：1）迭代调整依赖一组固定的控制基元，当生成的人类动作与描述偏差很大（尤其是高频动作）时难以处理。2）真实机器人执行时上下半身解耦，可能导致失去平衡或自碰撞。</p>
<p><strong>后续启示</strong>：1）未来可探索让VLM生成自由形式的控制基元，以处理更复杂的偏差。2）可研究结合强化学习的全身控制策略，以实现更鲁棒的真实机器人执行。3）该方法展示了利用丰富人类数据与强大基础模型解决机器人具体任务的有效范式。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出Harmon方法，解决人形机器人根据自由形式语言描述生成多样化、自然全身运动的核心问题。关键技术是利用大规模人类运动数据先验，通过基于扩散的生成模型PhysDiff生成初始人类运动，并借助视觉语言模型（VLMs）的常识推理能力对运动进行编辑和优化。实验验证表明，该方法能生成与文本对齐、富有表现力的人形机器人全身运动，并在仿真和真实机器人上成功执行。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2410.12773" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>