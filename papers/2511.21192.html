<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2511.21192" target="_blank" rel="noreferrer">2511.21192</a></span>
        <span>作者: Xudong Jiang Team</span>
        <span>日期: 2025-11-26</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作模型在开放世界操作、语言条件规划等方面取得了显著进展。然而，这类多模态流程容易受到结构化视觉扰动的攻击，导致感知误导、跨模态对齐破坏，并最终引发不安全动作。在机器人领域，这一问题尤为严重。尽管VLA模型的脆弱性已受到关注，但<strong>通用且可迁移的对抗攻击</strong>仍未被充分探索。现有的大多数补丁攻击方法通常与特定模型、数据集或提示模板过度适配，在未知架构或微调变体（即实际安全评估中重要的黑盒场景）上性能会急剧下降。这导致现有评估可能高估了攻击者在缺乏白盒访问时的安全性，同时低估了利用跨模态瓶颈的补丁攻击风险。</p>
<p>本文旨在弥补这一差距，系统性地研究针对VLA驱动机器人的<strong>通用、可迁移对抗补丁</strong>，以应对未知架构、微调变体以及从仿真到现实的域偏移等实际部署中的挑战。本文的核心思路是：提出一个统一的框架UPA-RFAS，通过在共享特征空间中学习单个物理补丁，并结合特征偏差、注意力劫持和语义错配来促进跨模型迁移。</p>
<h2 id="方法详解">方法详解</h2>
<p>UPA-RFAS框架是一个两阶段协调的优化过程，旨在学习一个能跨模型、任务和视点迁移的通用物理补丁。</p>
<p><img src="https://arxiv.org/html/2511.21192v2/x1.png" alt="方法整体框架"></p>
<blockquote>
<p><strong>图1</strong>：针对VLA机器人的整体可迁移补丁攻击框架。框架在共享特征空间目标内分两个协调阶段运行。<strong>阶段1 – 内层最小化</strong>：通过PGD学习一个小的、不可见的样本级扰动σ，以最小化特征目标𝒥_in（§3.3），同时冻结补丁（§3.4）。<strong>阶段2 – 外层最大化</strong>：冻结σ，并优化单个物理补丁δ以最大化𝒥_out（§3.7），该目标结合了ℓ_1偏差、排斥对比项以及两个VLA特定目标：补丁注意力主导和补丁语义错配。红色虚线箭头表示反向传播。</p>
</blockquote>
<p><strong>整体流程与问题定义</strong>：攻击者仅能访问一个代理模型π̂，目标是学习一个通用补丁δ，使其能迁移到一系列未知的目标策略Π_tgt。攻击在代理特征空间中使用可微目标𝒥_tr进行优化，并在目标策略上使用评估目标𝒥_eval评估其成功与否。补丁通过粘贴函数𝒫以随机几何变换T_t渲染到输入图像上。</p>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><p><strong>基于特征空间的ℓ_1偏差与对比错配</strong>：这是实现可迁移性的基础。作者假设代理与目标模型的特征空间存在线性对齐关系（假设1）。基于此，命题1表明，增大代理侧的特征偏差（ℓ_1范数）必然会在目标侧引发非平凡的响应。因此，特征空间目标𝒥_tr包含ℓ_1偏差损失ℒ_1。同时，引入排斥对比损失ℒ_con（基于InfoNCE），将补丁特征推离其干净锚点，并沿批次一致的方向集中变化。总特征目标为：𝒥_tr = ℒ_1 + λ_con ℒ_con。</p>
</li>
<li><p><strong>鲁棒性增强的通用补丁攻击</strong>：为了模拟鲁棒代理模型而不实际重新训练VLA，框架采用了一个双层优化过程。<strong>内层最小化</strong>：针对当前补丁δ，为每个输入样本学习一个小的、样本级的不可见扰动σ，以最小化攻击损失𝒥_tr，这相当于在局部“硬化”代理模型。<strong>外层最大化</strong>：在冻结σ的情况下，优化通用补丁δ以最大化同一损失𝒥_tr，同时施加随机的补丁放置和变换。这使得补丁能够利用内层循环揭示的稳定、跨输入的方向。</p>
</li>
<li><p><strong>VLA特定损失</strong>：</p>
<ul>
<li><strong>补丁注意力主导损失</strong>：旨在使补丁成为位置无关的注意力吸引器，将动作相关文本查询的注意力从真实语义区域重定向到补丁区域。它计算补丁运行与干净运行之间，来自动作相关文本查询的视觉注意力份额增量。损失ℒ_PAD鼓励补丁令牌的注意力增量，同时通过ReLU项和边距项抑制非补丁令牌的增量。</li>
<li><strong>补丁语义错配损失</strong>：旨在诱导持久的图像-文本错配，从而干扰指令条件策略。它将补丁区域的池化表示拉向一组预定义的“探测短语”锚点（如“错误”、“失败”），同时推离当前指令的嵌入，从而在不依赖标签的情况下破坏跨模态对齐。</li>
</ul>
</li>
</ol>
<p><strong>最终优化目标</strong>：外层最大化阶段的总目标𝒥_out是上述所有损失的综合：𝒥_out = 𝒥_tr + λ_PAD ℒ_PAD + λ_PSM ℒ_PSM。</p>
<p><strong>创新点</strong>：与现有方法相比，UPA-RFAS的创新性体现在：1) 首次针对VLA机器人提出了通用可迁移补丁攻击框架；2) 提出了无需重新训练VLA的鲁棒性增强双层优化策略；3) 设计了两个专门针对VLA跨模态特性的损失函数，分别用于劫持注意力与制造语义错配。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在多个基准和环境中进行，包括模拟环境（使用RLBench和ManiSkill2）和物理世界（使用Franka Emika机械臂）。评估了多种VLA模型作为目标，包括OpenVLA、其轻量级OFT变体、以及扩散模型π_0。对比的基线方法包括：不攻击（Clean）、随机补丁（Random Patch）、白盒补丁攻击（White-box）、基于梯度的可迁移攻击（DIM、TIM、SIM、Admix）以及特征空间攻击（FDA、RPA）。</p>
<p><strong>关键实验结果</strong>：<br><img src="https://arxiv.org/html/2511.21192v2/patch_sim_bs.png" alt="模拟环境中的攻击成功率对比"></p>
<blockquote>
<p><strong>图2</strong>：在模拟环境中，不同攻击方法在多个VLA目标模型上的攻击成功率（ASR）对比。UPA-RFAS在所有目标模型上均取得了最高的平均攻击成功率（75.5%），显著优于其他可迁移攻击基线。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2511.21192v2/patch_dof7_sim.png" alt="7自由度操作任务中的动作误差"></p>
<blockquote>
<p><strong>图3</strong>：在模拟7自由度操作任务中，UPA-RFAS导致的目标模型动作输出（位置、旋转）与干净运行动作之间的平均误差。误差越大表明攻击越有效，UPA-RFAS在两种动作类型上均产生了最大的扰动。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2511.21192v2/our_sim_patch.png" alt="学习到的模拟补丁可视化"></p>
<blockquote>
<p><strong>图4</strong>：UPA-RFAS在模拟环境中学习到的通用对抗补丁的可视化。补丁呈现出高频、非语义的纹理模式。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2511.21192v2/patch_phy_bs.png" alt="物理实验中的攻击成功率对比"></p>
<blockquote>
<p><strong>图5</strong>：在物理机器人实验中，不同攻击方法在多个任务和视角下的攻击成功率。UPA-RFAS同样取得了最佳的整体攻击性能。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2511.21192v2/patch_dof7_phy.png" alt="物理实验中的动作误差"></p>
<blockquote>
<p><strong>图6</strong>：物理实验中，UPA-RFAS导致的目标模型末端执行器位置与期望轨迹之间的误差。攻击显著增大了跟踪误差。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2511.21192v2/our_phy_patch.png" alt="学习到的物理补丁可视化"></p>
<blockquote>
<p><strong>图7</strong>：UPA-RFAS为物理部署学习到的对抗补丁的可视化。其模式与模拟补丁相似，但可能考虑了物理打印的约束。</p>
</blockquote>
<p><strong>消融实验总结</strong>：论文对UPA-RFAS的各个组件进行了消融研究。结果表明：1) <strong>特征空间组件（ℒ_1 + ℒ_con）</strong> 是跨模型可迁移性的基础，移除后性能下降最显著；2) <strong>鲁棒性增强（RAUP）</strong> 进一步提升了在黑盒目标上的成功率；3) <strong>VLA特定损失（ℒ_PAD + ℒ_PSM）</strong> 对提升攻击效果有明确贡献，特别是在需要复杂指令理解的任务中。所有组件共同作用时达到最佳性能。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了首个针对VLA驱动机器人的<strong>通用、可迁移对抗补丁攻击框架</strong>（UPA-RFAS），该框架在共享特征空间中优化单个物理补丁。</li>
<li>设计了<strong>鲁棒性增强的双层优化策略</strong>，通过模拟局部对抗训练来硬化代理模型，从而提升补丁的迁移能力，而无需实际重新训练昂贵的VLA模型。</li>
<li>引入了两个<strong>新颖的VLA特定攻击损失</strong>——补丁注意力主导和补丁语义错配，专门用于劫持跨模态注意力流和破坏指令 grounding，从而更有效地误导策略。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，UPA-RFAS的计算成本仍然较高，因为涉及双层优化和多个损失项。此外，尽管对视角变化有一定鲁棒性，但在极端视角或严重遮挡下，补丁的有效性可能会下降。攻击的成功也依赖于代理与目标模型之间存在合理的特征空间对齐这一假设。</p>
<p><strong>对后续研究的启示</strong>：这项工作暴露了VLA模型在现实黑盒场景下一个切实可行的补丁攻击面，为评估此类系统的安全性建立了重要的基准。它启示后续研究需要关注：1) 开发针对此类可迁移补丁攻击的防御机制；2) 探索更高效的可迁移攻击方法；3) 深入研究VLA模型跨模型特征一致性的本质，以更好地理解其脆弱性和鲁棒性。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对视觉-语言-动作模型在未知架构、微调变体及仿真到现实迁移等黑盒场景下，现有对抗补丁攻击过拟合单一模型、缺乏通用性与迁移性的问题，提出了一种通用可迁移补丁攻击框架UPA-RFAS。该框架通过在共享特征空间中学习单一物理补丁，融合特征空间目标、鲁棒性增强的两阶段最小最大优化，以及针对VLA的补丁注意力主导与补丁语义失配损失，以提升跨模型迁移能力。实验表明，UPA-RFAS生成的补丁能够持续在不同模型、任务及视角间有效迁移，为VLA模型的安全性评估建立了强基线。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2511.21192" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>