<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Self-Adapting Improvement Loops for Robotic Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Self-Adapting Improvement Loops for Robotic Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.06658" target="_blank" rel="noreferrer">2506.06658</a></span>
        <span>作者: Chen Sun Team</span>
        <span>日期: 2025-06-07</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，利用在专家演示数据上训练的视频生成模型作为文本条件视觉规划器，已成为解决机器人任务的一种高性能方法。然而，此类方法在面对训练时未见过的任务时，泛化能力仍然有限。虽然利用从额外离线数据源（如网络规模视频数据集）中学到的先验知识可能有助于提升泛化，但在“经验时代”，研究者更希望设计能够通过自收集行为在线持续改进的智能体。因此，本文提出了自我适应改进循环，旨在让一个领域内视频模型在通过与大网络预训练视频模型自适应收集的自产生轨迹上迭代更新，从而持续提升其在指定感兴趣任务上的性能。</p>
<h2 id="方法详解">方法详解</h2>
<p>SAIL的整体框架是一个迭代的自我改进循环。其核心是利用两个预训练的视频生成模型：一个是在网络规模数据上通用预训练的大模型，另一个是在一组通用的领域内演示数据上预训练的小模型。通过逆概率适应技术将两者结合，形成一个具有强先验的视觉规划器，用于与环境交互并收集轨迹。这些自收集的轨迹随后被用于微调领域内模型，从而通过在线经验整体提升自适应视觉规划器的质量。</p>
<p><img src="https://arxiv.org/html/2506.06658v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：SAIL框架。左侧为两个预训练的视频生成模型：一个在互联网规模数据上通用预训练，另一个在一组通用的领域内演示数据上预训练。组合这两个组件产生了一个具有强先验的视觉规划器，当用于与环境交互时，即使对于初始未见过的任务，也能产生成功率更高的轨迹。在自我适应改进循环中，这些轨迹随后被迭代反馈以微调领域内模型，从而通过自收集的在线经验提高整个自适应视觉规划器的整体质量。</p>
</blockquote>
<p>该方法的详细流程如算法1所示。输入包括初始的领域内视频模型、逆动力学模型、冻结的网络预训练视频模型、迭代次数K、每次迭代的轨迹数N、环境、任务提示g以及领域内初始训练数据。输出是自我改进后的领域内模型。算法初始化改进后的模型和微调数据集。在每一次迭代中，首先通过逆概率适应结合当前领域内模型和通用大模型，生成一个自适应视觉规划器。然后，使用该规划器在环境中执行N次轨迹收集。收集到的轨迹（可选择性地进行过滤）被添加到微调数据集中。最后，使用累积的数据对领域内模型进行微调。循环结束后返回改进后的模型。</p>
<p>核心模块是<strong>逆概率适应</strong>。这是一种无需训练的方法，用于使通用预训练的文本到视频模型适应特定领域的视频生成。在采样过程中，将在一个小规模演示样本上训练的领域内视频模型预测的分数，与网络规模预训练模型预测的分数进行组合。具体公式如下：</p>
<blockquote>
<p><code>ϵ~inv = ϵgeneral(τt, t) + α(ϵgeneral(τt, t | text) + γϵθ(τt, t | text) - ϵgeneral(τt, t))</code><br>其中，γ是先验强度，α是文本条件的引导尺度。直观上，小的领域内文本到视频模型作为一个概率知识先验，在采样过程中引导小领域内模型的生成过程。IPA利用大规模预训练模型（其本身具有更强的文本条件泛化能力）作为主去噪器，因此构建的视觉规划器既具备强大的泛化能力，又理解领域特定特征。</p>
</blockquote>
<p>与现有方法相比，SAIL的创新点在于首次将这种基于分数组合的自适应机制与在线自我收集经验相结合，形成了一个闭环的自我改进系统。它不仅利用了离线大规模数据作为强泛化先验，还通过在线交互数据不断针对特定任务优化模型，突破了纯离线数据的性能上限。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在两个平台上进行：<strong>MetaWorld-v2</strong>模拟环境和真实的<strong>Franka Emika Panda</strong>机械臂。</p>
<ul>
<li><strong>MetaWorld</strong>：收集了来自7个不同任务的25条演示，用于初始训练领域内视频模型和逆动力学模型。随后评估了6个任务（其中5个是新颖任务）的视觉规划性能。</li>
<li><strong>真实机器人</strong>：<ol>
<li><strong>推杯子任务</strong>：场景中有3个不同颜色的杯子，任务是根据文本提示定位并推动指定颜色的杯子。使用4种已见颜色（红、绿、蓝、粉）进行训练，评估对2种未见颜色（橙、紫）的泛化。</li>
<li><strong>开抽屉任务</strong>：场景中有两个不同颜色的关闭抽屉，任务是根据提示打开对应颜色的抽屉。使用3种已见颜色（红、绿、蓝）训练，评估对1种未见颜色（黄）的泛化。</li>
</ol>
</li>
</ul>
<p>对比的基线方法主要是<strong>仅使用领域内模型</strong>（不使用IPA适应，仅用自收集数据微调）与<strong>SAIL</strong>方法。</p>
<p><img src="https://arxiv.org/html/2506.06658v1/x2.png" alt="实验结果汇总"></p>
<blockquote>
<p><strong>图2</strong>：SAIL在MetaWorld和Panda机械臂上的结果。我们报告了MetaWorld上6个任务的平均性能，以及Panda机械臂实验的两个新颖推动任务和一个新颖抽屉打开任务。与仅使用领域内模型相比，SAIL展示了更稳健的改进行为，没有性能下降，并在两个真实机器人任务上实现了持续改进。</p>
</blockquote>
<p>关键实验结果如下：</p>
<ol>
<li><strong>MetaWorld</strong>：通过IPA自适应，初始成功率更高，突出了使用大规模离线数据作为新颖任务泛化强先验的好处。SAIL有效促进了利用自收集经验的进一步性能提升，成功率随迭代次数增加而持续提高。仅使用领域内模型虽有一些初始改进，但无法在多轮迭代中保持一致，且整体性能不如SAIL。</li>
<li><strong>真实机器人推杯子任务</strong>：对于初始未见的橙色和紫色杯子，SAIL性能随迭代持续改进。而仅使用领域内模型并未带来实质性改进，在推紫色杯子的任务中性能甚至单调下降。</li>
<li><strong>真实机器人开抽屉任务</strong>：SAIL实现了稳定的迭代改进，而仅使用领域内模型则导致性能持续衰减。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.06658v1/x3.png" alt="定性结果"></p>
<blockquote>
<p><strong>图3</strong>：视觉计划细化的定性结果。我们展示了在随机初始物体位置下，迭代0（顶部）和迭代2（底部）的各种任务和设置的视觉计划。尽管迭代0的视觉计划渲染出模糊的物体并未能完成指定任务，但我们的方法在经过两次SAIL迭代后合成了正确的视觉计划（略有颜色漂移）。</p>
</blockquote>
<p>定性结果显示，初始迭代（Iteration 0）的视觉计划常常物体模糊且任务执行不正确。经过两次SAIL迭代后，视觉计划不仅清晰度提高，而且展示了成功的任务完成行为。</p>
<p><img src="https://arxiv.org/html/2506.06658v1/x4.png" alt="数据过滤消融"></p>
<blockquote>
<p><strong>图4</strong>：数据过滤的消融研究。我们评估了使用成功信号过滤自收集数据对SAIL在MetaWorld和Panda机械臂设置上性能的影响。我们还为真实机器人实验提供了重新标记策略的额外结果。我们观察到，在两个基准测试中，不过滤收集的数据，SAIL仍能持续提高任务性能，这证实了我们的方法在缺乏过滤信号情况下的鲁棒性。</p>
</blockquote>
<p><strong>消融实验</strong>主要研究了<strong>数据过滤策略</strong>和<strong>初始数据质量</strong>的影响。</p>
<ol>
<li><strong>数据过滤</strong>：实验比较了使用真实/人工评估的成功信号过滤轨迹、不使用任何过滤（使用所有轨迹）、以及一种“重新标记”策略（为不成功的轨迹添加“not”前缀）。结果发现，对于MetaWorld和Panda任务，<strong>不使用过滤</strong>仍然能通过SAIL实现持续的迭代改进，甚至有时略优于过滤。这表明即使是失败的演示也可能包含有意义的行为信息，有助于整体任务改进。这一发现非常重要，因为它降低了在线自我改进中对人工干预（轨迹筛选）的依赖。</li>
<li><strong>初始数据质量</strong>：论文还测试了使用次优演示（如包含错误或低质量数据）初始化领域内模型的情况。结果表明，SAIL仍然能够引导模型性能提升，展现出对初始数据质量的鲁棒性。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：</p>
<ol>
<li><strong>提出了自我适应改进循环框架</strong>：首次将基于逆概率适应的视觉规划与在线自收集经验微调相结合，形成了一个可迭代提升任务性能的闭环系统。</li>
<li><strong>实证了在线自我改进的有效性</strong>：在模拟和真实机器人环境中，针对训练时未见的新任务，SAIL能够实现成功率的持续、稳定提升，而仅微调领域内模型则效果有限或不稳定。</li>
<li><strong>揭示了方法对设计选择的鲁棒性</strong>：通过消融实验发现，SAIL对自收集经验是否过滤以及如何过滤相对不敏感，且对初始演示数据的质量也具有鲁棒性，这增强了其在实际场景中的实用性。</li>
</ol>
<p>论文提到的局限性主要在于需要依赖一个大规模预训练的视频模型（如AnimateDiff）来提供泛化先验，这可能限制了方法的可访问性。</p>
<p>这项工作对后续研究的启示在于：它展示了一条结合大规模离线先验与在线交互数据来持续改进机器人技能的可行路径。其核心思想——利用强基础模型引导在线探索并从中学习——可扩展至其他基于生成模型的机器人学习范式。此外，对数据过滤鲁棒性的发现，鼓励研究者探索更宽松、更自动化的在线数据利用策略。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对视频生成模型作为机器人视觉规划器时，对未见任务泛化能力不足的核心问题，提出自适应改进循环（SAIL）方法。该方法通过域内视频模型与互联网规模预训练视频模型进行自适应，迭代收集自我产生的轨迹并更新模型，从而持续提升特定任务性能。实验在MetaWorld任务套件和真实机器人手臂操作任务上验证，发现SAIL能对训练时未见的新任务实现性能持续改进，且对自收集经验的过滤方式和初始演示质量表现出强鲁棒性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.06658" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>