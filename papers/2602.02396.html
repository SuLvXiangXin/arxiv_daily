<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.02396" target="_blank" rel="noreferrer">2602.02396</a></span>
        <span>作者: Alexander Schperberg Team</span>
        <span>日期: 2026-02-02</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人模仿学习（IL）旨在直接从示教数据中学习复杂的视觉运动策略。理想的模仿策略应满足三个关键标准：实时推理速率以进行闭环物理控制；表征专家行为的多模态分布；以及在部分感官输入下通过有效融合多传感流实现鲁棒性能。当前主流生成方法往往只能满足部分要求：扩散模型能捕获复杂的多模态动作分布，但其依赖迭代去噪（通常每推理10-100步）严重限制了实时部署；基于流的方法通过连续时间积分减少了采样步骤，但可能在多模态保真度上存在不足。这些方法在推理时由于迭代采样而计算昂贵。隐式最大似然估计（IMLE）方法通过最小化每个专家数据点到其最近生成样本的距离来确保专家分布的完全覆盖，并支持单次推理，但其在扩展到条件策略时面临挑战。先前方法通常对每个样本进行拒绝采样，这违反了IMLE的批全局覆盖原则，可能导致策略回归到平均行为而无法表示多模态设置中的不同模式。此外，闭环机器人任务要求动作序列具有强时序平滑性，现有的局部平滑启发式方法在避免模式切换方面较为脆弱。</p>
<p>本文针对现有生成方法在实时性、多模态覆盖和时序平滑性之间难以兼得的痛点，提出了PRISM（Performer RS-IMLE for Single-pass Multisensory Imitation）。其核心思路是：通过一个基于Performer架构的、单次前向传递的线性注意力生成器，配合一个批全局的RS-IMLE训练目标，在无需迭代采样的前提下，生成覆盖多模态且时序平滑的动作序列，从而实现高效、准确的实时多感官模仿学习。</p>
<h2 id="方法详解">方法详解</h2>
<p>PRISM的整体框架将问题解耦为三个阶段：a) 时间多感官编码器，融合异构输入并保留时间维度；b) 单次传递生成器，使用双向线性注意力（FAVOR+）并行产生完整动作序列；c) 批全局RS-IMLE训练目标，为模式覆盖提供理论依据且无迭代扩散的推理成本。</p>
<p><img src="https://arxiv.org/html/2602.02396v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：PRISM方法整体概览。可用的传感器特征按时间步融合为时间上下文令牌。使用双向FAVOR+（Performer）生成器与可学习的查询令牌，单次输出完整的动作序列。训练使用批全局RS-IMLE目标（鲁棒的Charbonnier距离、带EMA校准的ε-拒绝、可选的小覆盖项），以在不进行迭代采样的情况下保持动作多模态性。</p>
</blockquote>
<p><strong>时间多感官编码器</strong>：对于上下文时间范围 (T_o) 内的每个时间步 (t)，将每种模态（手腕RGB、静态RGB、深度、触觉、本体感觉、音频、文本）的嵌入向量拼接，并通过一个MLP融合为固定维度 (d) 的上下文令牌 (\mathbf{c}_t)。然后将所有时间步的 (\mathbf{c}_t) 堆叠，并添加绝对位置嵌入，得到上下文令牌 (\mathbf{C} \in \mathbb{R}^{T_o \times d})。这种按时间步融合的方式避免了时间统计量的纠缠，将长程一致性任务委托给生成器。</p>
<p><strong>单次传递线性注意力生成器（双向）</strong>：给定上下文 (\mathbf{C})，生成器通过一次前向传递产生长度为 (T_p) 的动作序列。它初始化 (T_p) 个可学习的查询令牌 (\mathbf{Q} \in \mathbb{R}^{T_p \times d})，并加入一个投影的潜变量 (z \sim \mathcal{N}(\mathbf{0}, \mathbf{I}))（作为产生不同轨迹候选的随机种子）以及位置编码。随后，应用 (L) 个Transformer块，每个块包含：i) 对 (\mathbf{Q}) 的双向自注意力（无因果掩码），以及 ii) 对完整上下文 (\mathbf{C}) 的交叉注意力（也无因果掩码）。两种注意力均使用FAVOR+（线性化softmax），将计算成本从 (\mathcal{O}(T^2)) 降低到 (\mathcal{O}(T m))（(m) 为随机特征数）。一个线性头将最终的令牌映射为动作 (\hat{\mathbf{A}} \in \mathbb{R}^{T_p \times D_a})。这种非自回归、双向的设计允许联合选择整个序列。</p>
<p><strong>鲁棒序列距离</strong>：使用带Charbonnier惩罚 (\varepsilon_c) 和按维度权重 (w_d) 的度量来比较预测序列和目标序列：(D_{\rho}(\hat{\mathbf{A}},\mathbf{A}) = \frac{1}{T_p} \sum_{t=1}^{T_p} \sum_{d=1}^{D_a} w_d \sqrt{(\hat{a}<em>{t,d} - a</em>{t,d})^2 + \varepsilon_c^2})。该度量对异常值鲁棒且可微，用于训练和评估时的候选选择。</p>
<p><strong>批全局RS-IMLE目标</strong>：对于批次 (B) 中的每个样本 (i)，抽取 (K) 个潜变量得到候选序列 ({\hat{\mathbf{A}}^{(k)}<em>i}</em>{k=1}^K)。计算每个候选与自身目标之间的距离 (D_{i,k})，以及与批次内所有目标 (j) 之间的批全局距离 (D_{i,k \rightarrow j})。通过一个由指数移动平均（EMA）校准的阈值 (\varepsilon_{\text{RS}}) 进行拒绝采样：拒绝那些与任何目标过于接近（即 (\min_j D_{i,k \rightarrow j} &lt; \varepsilon_{\text{RS}})）的候选。训练损失由硬IMLE损失和可选的软覆盖项组成：</p>
<ul>
<li>硬IMLE损失：(\mathcal{L}<em>{\text{hard}} = \frac{1}{B} \sum</em>{i=1}^{B} \min_{k \in \mathcal{K}<em>i} D</em>{i,k})，其中 (\mathcal{K}_i) 是未被拒绝的候选索引集（若全部被拒绝则使用所有候选）。</li>
<li>软覆盖项：(\mathcal{L}<em>{\text{soft}} = -\frac{1}{B} \sum</em>{i=1}^{B} \log \sum_{k \in \text{Top}K&#39;(D_{i,\cdot})} \exp(-D_{i,k}/\tau))，对前 (K&#39;) 个候选施加一个温和的熵正则化，防止模式坍塌。<br>总损失为 (\mathcal{L} = \mathcal{L}<em>{\text{hard}} + \lambda</em>{\text{soft}} \mathcal{L}<em>{\text{soft}})，其中 (\lambda</em>{\text{soft}} \ll 1)。批全局拒绝防止单个候选“覆盖”批次中多个相近的目标，从而保留了替代模式的梯度信号。</li>
</ul>
<p><strong>滑动窗口推理（单次传递）</strong>：在测试时，模型观察当前上下文，编码后抽取 (K) 个潜变量，单次前向传递生成 (K) 条动作序列。然后根据仅使用观测的规则选择一条轨迹：1) <strong>代理评分</strong>（当本体感觉或手腕姿态可观测时）：选择其第一动作诱导的预测末端执行器姿态最接近观测姿态的候选。2) <strong>确定性平局打破</strong>（当代理评分不可用时）：选择其第一动作最接近最后执行动作（L2距离）的候选。执行选中轨迹的前 (T_a) 个动作，然后滑动观测窗口并重新规划。这种连续重规划机制在不增加推理延迟的前提下保证了时序平滑性。</p>
<p>与现有方法相比，PRISM的创新点具体体现在：1) <strong>批全局拒绝采样</strong>：将RS-IMLE从样本级扩展到批全局，有效避免了模式平均并保持了多模态覆盖。2) <strong>单次非自回归生成</strong>：基于双向线性注意力的生成器一次性输出完整动作序列，完全避免了迭代采样步骤，实现了实时推理。3) <strong>时序感知的多感官融合与平滑性保证</strong>：通过按时间步融合编码器和滑动窗口推理中的轨迹选择策略，共同确保了生成动作的时序连贯性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：PRISM在多样化的真实机器人套件和大型仿真基准上进行了验证。</p>
<ul>
<li><strong>真实硬件</strong>：包括用于移动操作（loco-manipulation）的Unitree Go2（配备7自由度机械臂D1）和用于桌面精确操作的UR5机械臂。任务包括操作前泊车、高精度插入和多物体取放。</li>
<li><strong>仿真基准</strong>：包括CALVIN（10%数据划分）、MetaWorld和Robomimic。</li>
<li><strong>对比基线</strong>：包括扩散策略（Diffusion Policy）、流匹配（Flow Matching）以及IMLE策略等最先进的方法。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ul>
<li><strong>真实机器人性能</strong>：在挑战性物理任务上，PRISM比最先进的扩散策略的成功率高出10–25%，同时保持高频（30–50 Hz）闭环控制。</li>
<li><strong>仿真基准性能</strong>：在CALVIN（10%数据）上，PRISM比扩散策略的成功率提高约25%，比流匹配提高约20%，同时将轨迹加加速度（jerk）降低了20–50倍，这对硬件寿命和安全至关重要。在MetaWorld和Robomimic上，PRISM也达到或超过了SOTA策略的性能。</li>
</ul>
<p><img src="https://arxiv.org/html/2602.02396v1/x2.png" alt="基准数据集与模态"></p>
<blockquote>
<p><strong>图2</strong>：各基准数据集使用的传感器模态。R代表RGB相机，D代表深度相机，Tact代表触觉，P代表本体感觉，Text代表文本令牌，A代表音频。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/x3.png" alt="真实硬件任务成功率"></p>
<blockquote>
<p><strong>图3</strong>：真实硬件任务的成功率。PRISM在UR5的插入和取放任务，以及Unitree Go2的泊车和取放任务上，均显著优于扩散策略（Diffusion Policy）和流匹配（Flow Matching）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/x4.png" alt="CALVIN基准成功率和加加速度"></p>
<blockquote>
<p><strong>图4</strong>：在CALVIN基准（10%数据）上的成功率和轨迹加加速度。左图显示PRISM的成功率显著高于扩散和流匹配；右图显示PRISM产生的轨迹加加速度（衡量运动平滑性的指标）比扩散策略低20-50倍。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/x5.png" alt="MetaWorld成功率"></p>
<blockquote>
<p><strong>图5</strong>：在MetaWorld基准上的成功率。PRISM在多个任务上表现与扩散策略相当或更优。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/x6.png" alt="消融实验：组件贡献"></p>
<blockquote>
<p><strong>图6</strong>：消融实验研究各组件贡献。(a) 移除软覆盖项（<code>w/o soft</code>）、使用标准注意力（<code>w/o linear</code>）或使用因果注意力（<code>w/o bidir</code>）都会导致性能下降。(b) 候选数 (K) 的影响，性能在 (K \approx 16) 时饱和。(c) 批全局拒绝采样（<code>Global RS</code>）相比每样本拒绝采样（<code>Per-sample RS</code>）能带来显著性能提升。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/x7.png" alt="消融实验：模态重要性"></p>
<blockquote>
<p><strong>图7</strong>：传感器模态重要性分析。手腕RGB和本体感觉是关键模态，而深度信息在某些任务中可能是冗余的。模态丢弃研究表明PRISM在传感器缺失时具有优雅的性能降级能力。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/x8.png" alt="Robomimic上的成功率"></p>
<blockquote>
<p><strong>图8</strong>：在Robomimic基准上的成功率。PRISM在多个任务上优于或与扩散策略相当。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/x9.png" alt="推理延迟比较"></p>
<blockquote>
<p><strong>图9</strong>：不同策略的推理延迟（毫秒）。PRISM的单次传递推理速度显著快于需要多步采样的扩散策略和流匹配。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/fig/pushT.png" alt="真实机器人轨迹可视化"></p>
<blockquote>
<p><strong>图10</strong>：真实机器人任务（UR5插入）的轨迹可视化。展示了预测的多个候选轨迹（彩色线）和最终执行的平滑轨迹。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/x10.png" alt="ε_RS阈值校准过程"></p>
<blockquote>
<p><strong>图11</strong>：批全局拒绝采样阈值 (\varepsilon_{\text{RS}}) 的EMA校准过程。该估计器方差低（(O(1/N))），确保了训练稳定性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/x11.png" alt="不同距离度量的影响"></p>
<blockquote>
<p><strong>图12</strong>：不同序列距离度量对性能的影响。鲁棒的Charbonnier距离优于标准的L2或L1距离。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/x12.png" alt="注意力机制消融"></p>
<blockquote>
<p><strong>图13</strong>：注意力机制消融。双向线性注意力（FAVOR+）在性能和效率上取得最佳平衡。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/x13.png" alt="预测视野的影响"></p>
<blockquote>
<p><strong>图14</strong>：预测视野 (T_p) 对成功率的影响。存在一个最佳范围，视野过长或过短都会损害性能。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/fig/language_guided.png" alt="语言引导任务示例"></p>
<blockquote>
<p><strong>图15</strong>：语言引导任务示例。展示了PRISM在处理多模态输入（包括语言指令）时的能力。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.02396v1/fig/batch_calibration.png" alt="批全局校准有效性"></p>
<blockquote>
<p><strong>图16</strong>：批全局校准有效性可视化。说明了批全局拒绝如何防止候选聚集在单个模式周围，从而促进多模态覆盖。</p>
</blockquote>
<p><strong>消融实验总结</strong>：消融实验明确了各核心组件的贡献：1) <strong>批全局RS-IMLE目标</strong>是提升多模态覆盖和性能的关键。2) <strong>软覆盖项</strong>对稳定训练和防止优化偏差有积极作用。3) <strong>双向线性注意力（FAVOR+）</strong> 在保证效率的同时实现了有效的时序建模。4) <strong>手腕RGB和本体感觉</strong>是最关键的传感器模态。5) 候选数 (K) 在约16时达到性能饱和。6) 鲁棒的Charbonnier距离度量优于传统L2距离。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>PRISM框架</strong>，一个基于Performer RS-IMLE的单次传递多感官模仿策略，首次在单次前向传递中同时实现了实时推理、多模态动作覆盖和时序平滑性。</li>
<li>引入了<strong>批全局RS-IMLE训练目标</strong>，通过EMA校准的拒绝采样和软覆盖项，理论严谨且实践有效地解决了条件IMLE中的模式平均问题，无需增加测试时采样成本。</li>
<li>设计了一个<strong>时间感知的多感官融合编码器</strong>和一种<strong>滑动窗口推理策略</strong>，能够优雅地处理异构、可能缺失的传感器输入，并生成硬件安全所需的平滑轨迹。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到的局限性包括：1) 方法依赖于高质量、时间对齐的多感官演示数据。2) 尽管单次传递效率高，但训练时生成多个候选并进行批全局距离计算可能带来额外的计算开销。3) 滑动窗口推理中的轨迹选择规则（代理评分）依赖于特定的可观测状态（如末端执行器姿态）。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>单次生成方法的潜力</strong>：PRISM证明了无需迭代采样也能实现高质量的多模态策略生成，为实时机器人控制开辟了新路径，未来可探索更高效的生成器架构。</li>
<li><strong>多传感器融合与鲁棒性</strong>：对传感器模态重要性的分析强调了选择关键传感器和设计稳健融合方案的重要性，特别是在真实世界部分可观测的场景下。</li>
<li><strong>运动平滑性与硬件安全</strong>：显著降低轨迹加加速度不仅关乎性能，更是硬件安全和寿命的关键，未来的模仿学习工作应更加重视动作序列的物理可行性和平滑性。</li>
<li><strong>理论指导的实践</strong>：将IMLE理论与高效的注意力机制、精心设计的损失函数相结合，展示了理论洞察对解决实际机器人学习问题的重要价值。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>论文PRISM解决了机器人模仿学习中现有方法难以同时满足实时控制速率、多模态传感输入（如RGB、深度、触觉）和动作多模态分布的挑战。它提出基于Performer RS-IMLE的单次通过策略，结合多传感器时序编码器与线性注意力生成器，采用批全局拒绝采样IMLE目标进行训练。实验表明，在真实硬件任务中PRISM比扩散策略成功率提高10-25%，在CALVIN基准上成功率提升约25%，轨迹急动度减少20-50倍，同时保持30-50Hz闭环控制。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.02396" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>