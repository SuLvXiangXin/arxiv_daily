<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>HumanoidExo: Scalable Whole-Body Humanoid Manipulation via Wearable Exoskeleton - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>HumanoidExo: Scalable Whole-Body Humanoid Manipulation via Wearable Exoskeleton</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.03022" target="_blank" rel="noreferrer">2510.03022</a></span>
        <span>作者: Zhong, Rui, Sun, Yizhe, Wen, Junjie, Li, Jinming, Cheng, Chuang, Dai, Wei, Zeng, Zhiwen, Lu, Huimin, Zhu, Yichen, Xu, Yi</span>
        <span>日期: 2025/10/03</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人策略学习领域在快速发展，但获取大规模、多样化的真实世界数据仍然是一个主要瓶颈。目前主流方法包括仿真到真实迁移、从网络规模的人类视频中学习（如EgoMimic、Vid2Robot）以及各种遥操作系统。这些方法存在关键局限性：仿真数据与真实机器人动力学不匹配，人类视频数据则存在严重的形态学和运动学差异（即“形态差异”），使得直接迁移策略非常困难。而直接遥操作难以规模化，需要一对一的人机设置，成本高昂、对操作员要求高，且存在损坏昂贵硬件的风险。</p>
<p>本文针对人形机器人全身操控数据稀缺这一具体痛点，提出了一个通过可穿戴外骨骼将人类运动转化为全身人形机器人数据的新视角。其核心思路是设计一套集成的硬件（外骨骼）和软件（策略学习模型）系统，以低成本、高效率的方式收集野外人类演示数据，并通过运动重定向和混合学习策略，将其转化为可直接部署在物理人形机器人上的可执行策略。</p>
<h2 id="方法详解">方法详解</h2>
<p>HumanoidExo系统包含硬件数据采集、运动重定向和策略学习三个主要阶段。输入是穿戴外骨骼的人类操作员的自然运动，输出是可直接控制人形机器人关节角度的策略。</p>
<p><strong>1. 硬件数据采集系统：</strong><br>系统采用定制设计的轻量、柔性可穿戴外骨骼来捕捉人体上半身（7自由度手臂）的运动。为捕捉全身运动，在操作员背部安装了Mid-360 LiDAR，通过基于FAST-LIO的激光雷达里程计模块实时估计系统在空间中的位移、朝向和高度变化，从而记录行走、下蹲、弯腰等基座运动。视觉信息通过安装在头部的Realsense D455摄像头和两个安装在手腕（Dexmo力反馈手套上）的鱼眼摄像头获取，其型号和视野与目标机器人（Unitree G1）的摄像头进行了校准匹配。</p>
<p><img src="https://arxiv.org/html/2510.03022v1/x1.png" alt="硬件概述"></p>
<blockquote>
<p><strong>图1</strong>：HumanoidExo硬件系统概览。集成了Mid-360 LiDAR用于获取外骨骼运动里程计，并添加了两个腕部摄像头以捕获新的操作视角并丰富环境感知。</p>
</blockquote>
<p><strong>2. 运动重定向：</strong> 为解决人与机器人之间的形态差异，系统采用关节空间控制方法，直接将人类关节运动映射到机器人。这避免了笛卡尔空间（末端执行器）控制中因逆运动学多解和零空间问题带来的实时计算挑战。</p>
<ul>
<li><strong>上臂姿态对齐</strong>：以外骨骼基座为参考坐标系，通过正向运动学计算上臂附着点的相对位姿，并使用迭代逆运动学方法将其映射到机器人手臂的前三个关节。</li>
<li><strong>前臂姿态对齐</strong>：外骨骼肘部电机直接捕获人类肘部弯曲角度，并映射到机器人的前臂。</li>
<li><strong>腕部姿态对齐</strong>：利用前臂和手套上的IMU计算腕部相对于前臂的旋转四元数，作为腕部目标姿态，再次使用迭代逆运动学映射到机器人手臂的最后三个关节。</li>
</ul>
<p><strong>3. 策略学习模型 (HE-VLA)：</strong> 这是从收集的外骨骼数据中学习全身人形策略的方法，包含两个关键组件。</p>
<p><img src="https://arxiv.org/html/2510.03022v1/x2.png" alt="HE-VLA概览"></p>
<blockquote>
<p><strong>图2</strong>：HE-VLA方法整体框架。左侧展示了数据收集过程和数据集构成，训练数据主要来源于独立于被控机器人、由HumanoidExo收集的野外数据。右侧展示了模型部署和推理流程，采用VLA模型和RL模型两级系统控制机器人。</p>
</blockquote>
<ul>
<li><strong>视觉-语言-动作模型</strong>：利用预训练的DexVLA模型作为基础，通过外骨骼和真实机器人演示数据进行微调，学习将视觉观察映射为高层控制指令（基座平移速度、偏航角速度、目标躯干高度）。</li>
<li><strong>强化学习平衡控制</strong>：仅靠模仿学习直接输出关节位置进行全身控制存在稳定性风险。因此，引入一个基于强化学习的鲁棒全身运动操控控制器，负责在执行VLA模型指令的同时维持动态平衡。</li>
</ul>
<p><img src="https://arxiv.org/html/2510.03022v1/x3.png" alt="演员-评论家强化学习"></p>
<blockquote>
<p><strong>图3</strong>：HE-VLA中的演员-评论家强化学习模块。该模块与主VLA模型协同工作，确保人形机器人在策略推理过程中能够可靠地站立、下蹲和行走。</p>
</blockquote>
<p>RL策略的观察空间包括VLA指令、基座角速度、躯干坐标系下的重力向量、关节状态和上一时刻动作。其动作指定了下半身关节的目标位置，通过PD控制器计算关节扭矩驱动运动，而上半身关节则直接跟随操作员（VLA输出）。训练采用了课程学习（逐步扩大关节运动范围）、专门针对下蹲动作设计的奖励函数，以及通过状态-动作镜像和对称性损失来提高样本效率并减少左右偏置。</p>
<p><strong>创新点</strong>：与现有主要针对传统机械臂或上半身操作的系统不同，HumanoidExo是首个为<strong>全身人形机器人</strong>的<strong>野外</strong>策略学习设计的系统。其创新具体体现在：1) 通过关节空间映射和LiDAR里程计，系统性桥接人与机器人的形态差异，实现全身运动数据采集；2) 提出HE-VLA混合架构，结合模仿学习（VLA）的技能泛化能力和强化学习（RL）的稳定性保证。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验平台为Unitree G1人形机器人（29身体自由度 + 2个12自由度灵巧手）。在三个具有挑战性的真实世界任务上进行评估（如图4所示）：</p>
<ol>
<li><strong>PlaceToy</strong>：桌面操作任务，测试灵巧性。</li>
<li><strong>Walk &amp; PlaceToy</strong>：移动操作复合任务，结合行走与放置。</li>
<li><strong>PlaceLaundry</strong>：全身灵巧操作任务，涉及下蹲、抓取衣物和放入洗衣机。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.03022v1/x4.png" alt="任务示例"></p>
<blockquote>
<p><strong>图4</strong>：PlaceToy（任务1）、Walk &amp; PlaceToy（任务2）和PlaceLaundry（任务3）的任务示例。</p>
</blockquote>
<p><strong>基线对比与数据高效性</strong>：在PlaceToy任务中，比较了三种数据配置的训练结果：1) 200条真实遥操作演示；2) 5条真实演示 + 195条HumanoidExo演示（混合）；3) 仅5条真实演示。关键结果如图5(a)所示：仅用5条真实数据成功率仅5%，而加入195条HumanoidExo数据后，成功率大幅提升至约80%，与使用200条纯真实数据的性能相当。这证明了HumanoidExo数据在极端数据稀缺场景下能提供显著的性能提升，且其效用与真实机器人数据可比。</p>
<p><strong>泛化能力</strong>：在物体和环境泛化测试中，混合训练方法（遥操作+HumanoidExo数据）在所有设置下的平均成功率均高于仅使用遥操作数据。例如，在面对训练中未出现的物体和全新环境（新玩具和托盘）时，混合策略展现出了更好的泛化性能（见图5(a)中标签F及子图d,e）。</p>
<p><strong>新技能获取与鲁棒性</strong>：在Walk &amp; PlaceToy任务中，仅使用5条无行走的真实演示和195条包含行走的HumanoidExo演示进行训练，策略在行走部分达到了100%的成功率，且整体任务成功率与静态操作实验持平。这表明机器人<strong>仅从HumanoidExo数据中就学会了行走这一新技能</strong>。此外，该策略表现出对物理干扰的强鲁棒性（图5(f)）：当机器人被强行拖离工作区时，它能自主走回桌子前并恢复任务。</p>
<p><img src="https://arxiv.org/html/2510.03022v1/x5.png" alt="实验结果汇总"></p>
<blockquote>
<p><strong>图5</strong>：模型泛化与鲁棒性实验结果。(a) 模型在不同数据配置和测试条件下的成功率。(b) 物品放置测试位置。(c) 训练数据集构成。(d)(e) 新环境中的任务。(f) 对干扰的鲁棒性：机器人被移开后能自主走回并恢复任务。</p>
</blockquote>
<p><strong>全身灵巧操作</strong>：在PlaceLaundry任务中（结果见表1，表中数据未在提供正文中完整显示，但根据描述可知），使用5条真实演示加195条HumanoidExo数据训练的模型，其性能显著优于仅用5条真实数据训练的模型，并接近使用200条真实数据训练的性能，再次验证了HumanoidExo数据在复杂全身操控任务中的有效性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出了HumanoidExo，一种通过可穿戴外骨骼为全身人形机器人进行规模化数据收集的新范式，有效解决了数据稀缺和形态差异问题；2) 设计了HE-VLA混合策略学习架构，结合了VLA模型的泛化能力和RL控制的稳定性，实现了从外骨骼数据到可部署策略的可靠学习；3) 通过大量实验实证了该系统的数据高效性（仅需少量真实数据）、强大的泛化能力以及能够赋予机器人全新技能（如行走）的潜力。</p>
<p>论文自身提到的局限性包括：目标机器人（Unitree G1）的头部不可驱动，因此无法将人类操作员的头部运动转化为机器人摄像机运动；且外骨骼与机器人的头部摄像机位置无法完美对应。然而实验表明，这些差异并未阻碍策略学习。</p>
<p>这项工作对人形机器人研究的重要启示是：通过精心设计的硬件接口和算法桥接，利用低成本、易获取的人类野外演示数据来规模化增强机器人学习是可行且高效的路径。它为实现更通用、更强大的人形机器人提供了一种可扩展的数据解决方案，未来可探索结合更多传感器模态、更复杂的任务场景以及与其他基础模型的集成。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人策略学习中大规模、多样化数据获取困难的问题，提出HumanoidExo系统。其核心方法是利用轻量可穿戴外骨骼捕捉人体动作，并结合背载LiDAR传感器追踪躯干位姿，融合数据以生成全身运动轨迹，从而显著缩小人机实体差距。实验表明，该方法能使人形策略泛化至新环境，仅需五次真实机器人演示即可学习复杂全身控制，并仅从HumanoidExo数据中习得行走等新技能。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.03022" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>