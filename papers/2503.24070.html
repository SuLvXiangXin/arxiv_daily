<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>HACTS: a Human-As-Copilot Teleoperation System for Robot Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>HACTS: a Human-As-Copilot Teleoperation System for Robot Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2503.24070" target="_blank" rel="noreferrer">2503.24070</a></span>
        <span>作者: Xu, Zhiyuan, Zhao, Yinuo, Wu, Kun, Liu, Ning, Ji, Junjie, Che, Zhengping, Liu, Chi Harold, Tang, Jian</span>
        <span>日期: 2025/03/31</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人学习，特别是需要人类演示或修正的操作任务，严重依赖于遥操作技术。目前主流的遥操作硬件系统，如VR、外骨骼和动作捕捉设备，通常设计为单向控制。人类操作员可以向机器人发送指令，但无法实时接收机器人状态的反馈。当机器人在执行自主任务需要人工干预时，缺乏反馈会导致机器人可能做出意外、突然的动作，破坏任务的连续性和性能，类似于自动驾驶汽车驾驶员在没有方向盘同步机制的情况下试图干预车辆。</p>
<p>近期的一些工作提出了集成触觉和力反馈的双边控制系统，但这些系统要求机器人端能生成精确的力或触觉传感信息，而这在大多数机器人平台上并不普遍具备。因此，需要一个能在遥操作系统与机器人之间提供双边关节同步、确保平滑过渡和更可靠干预，且兼容广泛机器人平台的解决方案。</p>
<p>本文针对现有遥操作缺乏实时双向状态同步的关键痛点，提出了“人作为副驾驶”的新视角，旨在构建一个低成本、可扩展的双边同步遥操作系统。其核心思路是：通过建立机器人手臂与遥操作硬件之间的实时、双边关节位置同步，使人类操作员能够像使用汽车方向盘一样，在机器人自主运行时进行无缝干预，同时收集用于后续学习的“动作-修正”数据。</p>
<h2 id="方法详解">方法详解</h2>
<p>HACTS是一个采用双边位置控制的领导者-跟随者系统，支持领导者到跟随者以及跟随者到领导者的双向同步。</p>
<p><img src="https://arxiv.org/html/2503.24070v2/etc-figs/overview.png" alt="方法总览"></p>
<blockquote>
<p><strong>图1</strong>：HACTS系统总览。在离线数据收集中，HACTS作为运动学等效控制器收集精确的人类演示数据。在在线收集中，其反向同步功能支持无缝的人工干预，为策略模型学习提供在线动作修正数据。</p>
</blockquote>
<p>整体上，系统有两种工作模式：1）<strong>领导者到跟随者同步（离线演示）</strong>：人类操作HACTS硬件（领导者）来控制机器人（跟随者），用于收集高质量的演示数据，功能类似于ALOHA、Gello等单向系统。2）<strong>跟随者到领导者同步（在线干预）</strong>：当机器人根据模型推理自主运行时，其实时关节位置会同步反馈到HACTS硬件上，使其物理状态与机器人保持一致。当人类需要干预时，可以直接“接管”已经与机器人同步的操纵杆，进行无缝修正，此过程同时记录修正数据。</p>
<p>系统的核心创新在于实现了简单有效的<strong>双边关节位置同步</strong>。这仅需交换位置信息，无需复杂的力或触觉反馈，因此与绝大多数机器人平台兼容。</p>
<p>硬件设计遵循三个原则：<strong>低成本</strong>、<strong>轻量化</strong>和<strong>易用性</strong>。具体而言：</p>
<ul>
<li><strong>低成本</strong>：使用现成的伺服电机（DYNAMIXEL XL430和XL330系列）而非昂贵的机器人模块，结合3D打印（PLA材料）的结构件，整套硬件成本低于300美元。</li>
<li><strong>轻量化</strong>：针对受力较大的前三个关节使用扭矩更高的XL430电机，末端执行器等部分使用更轻便的XL330电机，并采用3D打印框架以减轻整体重量。</li>
<li><strong>易用性</strong>：硬件设计为与目标机器人（如UR5）运动学等效的缩小版，其连杆参数根据Denavit–Hartenberg参数按比例缩放，使操作直观。这种设计易于扩展到其他机械臂，因为只需同步位置信息。</li>
</ul>
<p><img src="https://arxiv.org/html/2503.24070v2/etc-figs/system.png" alt="系统概览"></p>
<blockquote>
<p><strong>图2</strong>：HACTS使用概览图。展示了系统在离线数据收集和在线人类干预两种模式下的双边同步数据流。</p>
</blockquote>
<p>软件设计采用流线型架构。以DYNAMIXEL API作为电机位置监控与调整的主要接口。经过初始偏移校准后，处理后的控制关节值通过该接口发送给机器人控制器。对于反向同步，机器人位置数据经过反向偏移补偿后传回电机单元，以维持全系统同步。一个外置脚踏板作为手动切换接口，用于在自主运行和人工干预模式之间进行切换。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在真实世界的UR5机械臂（配备Robotiq 2f-85夹爪）工作站上进行，使用Realsense D435和D435i相机从不同角度捕捉视觉输入。策略模型运行在单台RTX 4090工作站上。</p>
<p><img src="https://arxiv.org/html/2503.24070v2/etc-figs/ws.png" alt="实验设置"></p>
<blockquote>
<p><strong>图3</strong>：实验设置：（左）模仿学习设置，（右）强化学习设置。</p>
</blockquote>
<p><strong>模仿学习实验</strong>：设计了三个任务：OpenBox（开盒）、SteamBun（夹馒头）、UprightMug（扶正杯子）。使用两种先进的模仿学习方法：动作分块Transformer（ACT）和扩散策略（DP）。基线模型包括：使用50条专家轨迹训练的“pre-模型”，使用100条专家轨迹训练的“full-模型”，以及使用50条专家轨迹混合50条HACTS干预轨迹训练的“HACTS-模型”。在四种设置下评估：</p>
<ol>
<li><strong>等量数据对比（EADC）</strong>：验证HACTS数据能否替代等量的专家数据。</li>
<li><strong>分布内故障修正（FCID）</strong>：评估修正数据对训练分布内失败案例的纠正能力。</li>
<li><strong>分布外静态泛化（ODSS）</strong>：评估修正数据对物体位置完全不同的静态新场景的泛化能力。</li>
<li><strong>分布外动态泛化（ODDS）</strong>：评估修正数据对执行过程中物体被移动的动态干扰的鲁棒性。</li>
</ol>
<p>关键实验结果如下表所示：</p>
<p><img src="https://arxiv.org/html/2503.24070v2/x1.png" alt="模仿学习任务"></p>
<blockquote>
<p><strong>图4</strong>：模仿学习实验的三个任务图示。</p>
</blockquote>
<p><strong>表II</strong>（ACT在前三个设置下的成功率）显示：</p>
<ul>
<li><strong>EADC</strong>：HACTS-ACT在所有任务上的成功率均<strong>高于</strong>使用等量（100条）专家数据的full-ACT。例如，OpenBox任务中，HACTS-ACT为80%，full-ACT为60%。这表明HACTS收集的干预数据可以有效替代专家数据。</li>
<li><strong>FCID</strong>：HACTS-ACT显著提升了pre-ACT的性能，并<strong>持续超越</strong>full-ACT。例如在UprightMug任务中，HACTS-ACT成功率达70%，而pre-ACT仅10%，full-ACT为40%。说明针对失败的修正数据比单纯增加数据量更有效。</li>
<li><strong>ODSS</strong>：pre-ACT和full-ACT在所有任务上的成功率均为0%，而HACTS-ACT取得了显著的成功率（OpenBox:30%, SteamBun:50%, UprightMug:40%）。证明HACTS数据能有效提升模型对分布外静态场景的泛化能力。</li>
</ul>
<p><strong>表III</strong>（DP在ODDS设置下的成功率）显示：</p>
<ul>
<li><strong>ODDS</strong>：pre-DP和full-DP的成功率为0%，而HACTS-DP达到了40%的成功率。证明HACTS数据也能提升模型对动态干扰的鲁棒性。</li>
</ul>
<p><strong>强化学习实验</strong>：设计了CloseBin（关垃圾桶盖）任务，机器人需关闭随机位置和朝向的垃圾桶。方法RLPD-HACTS结合了HACTS与RLPD算法，包含三个阶段：1) 使用HACTS收集正负样本训练奖励分类器；2) 收集专家数据训练行为克隆（BC）策略；3) 加载BC策略，使用RLPD在线微调，期间通过HACTS进行频繁、短时的人工修正。</p>
<p><img src="https://arxiv.org/html/2503.24070v2/etc-figs/drl-env.png" alt="强化学习任务"></p>
<blockquote>
<p><strong>图5</strong>：CloseBin任务。机器人需要关闭一个随机放置和朝向的垃圾桶。</p>
</blockquote>
<p><strong>表IV</strong>结果显示，RLPD-HACTS经过10分钟离线预训练和45分钟在线训练后，成功率从50%提升至80%，平均回合长度从32步缩短至19步，证明了其在复杂HITL RL中的有效性。</p>
<p><img src="https://arxiv.org/html/2503.24070v2/x2.png" alt="干预长度变化"></p>
<blockquote>
<p><strong>图6</strong>：CloseBin任务中RLPD-HACTS训练期间的平均干预长度。随着训练进行，策略越来越依赖自身的Q值估计，所需的人工干预步骤数减少，且干预变得更精细。</p>
</blockquote>
<p>图6进一步显示，在线训练初期，由于Q网络学习和探索导致性能下降，需要较长的人工干预。随着训练推进，策略能力增强，干预长度下降至6步以下，允许进行更精细的修正。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献有三点：</p>
<ol>
<li><strong>提出了一种新颖的双边同步遥操作系统HACTS</strong>：通过低成本、运动学等效的硬件和简单的双向位置同步机制，实现了机器人自主运行时人类“副驾驶”的无缝、精准干预。</li>
<li><strong>证明了HACTS能显著提升模仿学习性能</strong>：其收集的“动作-修正”数据不仅能等效替代专家数据，更能针对性地提升模型在分布内故障恢复、分布外泛化（静态与动态）方面的能力。</li>
<li><strong>展示了HACTS支持复杂的人机交互强化学习</strong>：通过RLPD-HACTS框架验证了系统可有效集成于在线RL流程，提升样本效率和最终策略性能。</li>
</ol>
<p>论文自身提到的局限性在于，实验仅选取了部分代表性的IL和RL方法进行验证。作者相信，通过进一步的模型优化和人类反馈集成设计，HACTS将发挥更大作用。</p>
<p>本文的启示在于：为机器人学习提供高质量、多样化的数据（特别是修正和失败数据）至关重要。一种低成本、易用且能实现自然双向交互的硬件接口，可以极大地促进模仿学习、人机交互强化学习等范式的发展，推动更有效的人机协作。HACTS的设计理念——利用简单的位置同步实现直观的“副驾驶”干预——为未来遥操作系统的设计提供了新思路。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对现有遥操作系统仅支持单边控制、缺乏机器人状态与硬件实时同步、导致人为干预困难的核心问题，提出了HACTS（人类副驾驶遥操作）系统。该系统通过建立机器人手臂与遥操作硬件的双边实时关节同步，采用类似方向盘的反馈机制，实现人类无缝干预并在线收集动作纠正数据；技术要点包括使用3D打印组件和低成本现成电机，确保易用性和可扩展性。实验表明，HACTS显著提升了模仿学习（IL）和强化学习（RL）任务的性能，增强了IL的恢复能力和数据效率，并促进了人在环RL。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2503.24070" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>