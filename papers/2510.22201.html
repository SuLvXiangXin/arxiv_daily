<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>ACG: Action Coherence Guidance for Flow-based VLA models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>ACG: Action Coherence Guidance for Flow-based VLA models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.22201" target="_blank" rel="noreferrer">2510.22201</a></span>
        <span>作者: Jaegul Choo Team</span>
        <span>日期: 2025-10-25</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，基于扩散（Diffusion）和流匹配（Flow Matching）的生成模型已成为强大的机器人策略，它们作为视觉-语言-动作（VLA）模型的动作头，能够从人类演示中学习并泛化到多样的场景和指令。然而，当通过模仿学习进行训练时，其强大的生成能力使得它们对人类演示中的噪声（如抖动、停顿、颤动）非常敏感，这些噪声会降低动作的连贯性（Action Coherence）。动作连贯性下降会导致部署时的不稳定和轨迹漂移，在需要高精度的精细操作任务中，这种失败是灾难性的。现有提升连贯性的方法（如动作分块、时序集成）要么无法消除分块内的不连贯，要么会带来巨大的推理开销。本文针对基于流匹配的VLA模型在模仿学习后动作不连贯的痛点，提出了一种无需额外训练、在测试时（test-time）使用的引导算法。其核心思路是：通过破坏模型自注意力层的时序通信来构造一个“不连贯”的动作生成向量场，并在推理时引导采样过程远离该不连贯方向，从而生成更连贯的动作序列。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的动作连贯性引导（Action Coherence Guidance, ACG）是一个即插即用（plug-and-play）的测试时算法。其整体流程基于流匹配策略的标准推理过程，但修改了去噪向量场的计算方式。</p>
<p>流匹配策略以当前观测 <code>o_t</code>、语言指令 <code>ℓ_t</code> 和一个噪声动作块 <code>A_t^τ</code> 为输入，输出一个去噪向量场 <code>v_θ</code>。在推理时，从高斯噪声 <code>A_t^0</code> 开始，通过前向欧拉积分（公式4）迭代地应用该向量场，最终生成干净的动作块 <code>A_t^1</code>。ACG 的核心在于修改了每次迭代中使用的向量场。</p>
<p><img src="https://i.imgur.com/4aZ0rDv.png" alt="方法概念图"></p>
<blockquote>
<p><strong>图1</strong>：ACG概念示意图。通过构造一个不连贯的向量场 <code>v_θ^IC</code>，并将其与原始向量场 <code>v_θ</code> 结合，引导采样过程朝向连贯的动作序列分布。</p>
</blockquote>
<p>具体而言，ACG 定义了新的引导向量场 <code>v_θ^ACG</code>（公式8）：<br><code>v_θ^ACG = (1 + λ) * v_θ - λ * v_θ^IC</code><br>其中，<code>λ</code> 是引导尺度，<code>v_θ^IC</code> 是专门构造的“不连贯”向量场。该公式引导模型远离 <code>v_θ^IC</code> 所指向的不连贯动作分布。</p>
<p>**核心模块是构造不连贯向量场 <code>v_θ^IC</code>**。其技术细节基于流匹配VLA模型普遍采用的Transformer架构。在自注意力（Self-Attention）层中，注意力图（Attention Map） <code>softmax(QK^⊤/√d)</code> 负责建立不同时间步动作令牌（Token）之间的通信，这是实现时序连贯性的关键。为了破坏这种连贯性，ACG 将特定自注意力层中的注意力图替换为单位矩阵 <code>I</code>（公式11）。这使得每个动作令牌只关注自身，切断了跨时间步的通信，从而生成时序上不连贯的动作序列。这个修改后的网络前向传播结果即为 <code>v_θ^IC</code>。</p>
<p><img src="https://i.imgur.com/vu0tFqU.png" alt="方法实现细节"></p>
<blockquote>
<p><strong>图3</strong>：ACG实现示意图。左侧为原始推理过程，右侧为构造不连贯向量场 <code>v_θ^IC</code> 的过程：将自注意力层的注意力图替换为单位矩阵（Identity Attn.）。最终，引导向量场由原始向量场减去不连贯向量场得到。</p>
</blockquote>
<p>与现有方法相比，ACG的创新点具体体现在：1) <strong>首次将“扰动引导”（Perturbation Guidance）的思想引入机器人控制领域</strong>，通过主动构造一个性能退化的模型变体（而非像CFG那样使用无条件模型）作为引导参考。2) <strong>明确针对并有效提升了每个动作分块内部（intra-chunk）的连贯性</strong>，而现有方法多关注分块之间（inter-chunk）的连贯性或平滑整个序列。3) 是一种<strong>无需训练</strong>的测试时方法，计算开销低。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在模拟和真实世界三个基准上评估：模拟厨房任务基准 <strong>RoboCasa</strong>（24个任务，7种技能）、灵巧操作基准 <strong>DexMimicGen</strong>（9个任务，3种 embodiment）、以及真实世界基准 <strong>SO-101</strong>（“三颗草莓”和“井字棋”抓放任务）。主要使用的VLA模型是 <strong>GR00T-N1</strong>。</p>
<p><strong>对比基线</strong>：</p>
<ol>
<li><strong>Vanilla GR00T-N1</strong>：基础流匹配策略，无任何后处理。</li>
<li><strong>动作平滑方法</strong>：包括多推理集成（Ensemble, n=2,5）、对最终动作进行高斯平滑（Action Smoothing）、对中间特征进行平滑（Feature Smoothing）。</li>
<li><strong>基于引导的方法</strong>：分类器无关引导（CFG）、白噪声引导（WNG，通过向特征注入白噪声构造不连贯向量场）。</li>
</ol>
<p><strong>关键实验结果</strong>：</p>
<p><img src="https://i.imgur.com/1i7lY2q.png" alt="性能对比总览"></p>
<blockquote>
<p><strong>图2</strong>：ACG在模拟（RoboCasa， DexMG）和真实世界（SO-101）任务上相对于Vanilla GR00T-N1、朴素集成和CFG的性能提升（成功率百分比）。ACG在所有设置下均带来显著提升。</p>
</blockquote>
<p>如表I所示，ACG在所有基准上均超越了所有基线方法。在RoboCasa上平均成功率提升6.7个百分点（pp），在DexMG上提升3.4 pp。在真实世界的“三颗草莓”任务上提升高达30.8 pp，平均提升9.6 pp。</p>
<p><img src="https://i.imgur.com/9m6cJQe.png" alt="分技能性能"></p>
<blockquote>
<p><strong>图5</strong>：在RoboCasa七种操作技能上的性能。ACG在需要高精度的精细操作任务（如按钮按压+23.1 pp，插入+11.8 pp）上提升尤为显著。</p>
</blockquote>
<p><strong>动作连贯性定量分析</strong>：通过动作总变差（ATV，越低越好）和加加速度均方根（JerkRMS，越低越好）衡量。如表II所示，ACG生成的序列具有最低的JerkRMS和较低的ATV，表明其动作最平滑、最连贯。作为对比，故意构造的“不连贯”变体（<code>v_θ^IC</code>）的ATV极高。</p>
<p><img src="https://i.imgur.com/1pLg8lY.png" alt="定性轨迹对比"></p>
<blockquote>
<p><strong>图6</strong>：在“抓草莓”任务上的末端执行器轨迹定性对比。颜色表示时间进程。基线方法轨迹抖动、不准确；ACG（Ours）的轨迹则连贯、稳定且精准。</p>
</blockquote>
<p><strong>消融实验总结</strong>：</p>
<ol>
<li><strong>超参数影响</strong>（图7左）：引导尺度 <code>λ</code> 存在最佳值（文中为3.0），过大或过小均会降低性能；将中间层（第4-6层）的自注意力替换为单位矩阵效果最好。</li>
<li><strong>与Self-GAD对比</strong>（图7右）：Self-GAD是一种提升分块间连贯性的方法。ACG在相同设置下性能更优，说明<strong>分块内连贯性比分块间连贯性对操作性能影响更大</strong>。两者结合能获得进一步增益。</li>
<li><strong>模型通用性</strong>（表III）：ACG同样能提升其他流匹配VLA模型（如 <code>π_0</code>, SmolVLA）的性能，证明了其通用性。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>本文核心贡献</strong>：</p>
<ol>
<li>提出了<strong>动作连贯性引导（ACG）</strong>，一种首次将扰动引导思想应用于机器人控制、无需训练即可提升基于流匹配的VLA模型动作连贯性的测试时算法。</li>
<li>通过系统性的实验，在模拟和真实世界多个基准上验证了ACG能显著提升操作任务的成功率，尤其是在精细操作任务上。</li>
<li>揭示了<strong>动作分块内连贯性</strong>对机器人操作性能的关键作用，并证明其重要性高于分块间连贯性。</li>
</ol>
<p><strong>局限性</strong>：论文提到，ACG的性能依赖于超参数（如引导尺度、被扰动层的选择）的调整。此外，虽然无需训练，但在推理时计算两个向量场会带来约一倍的额外前向传播计算开销。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>动作质量的重要性</strong>：除了追求更高的任务成功率，生成动作的平滑性、稳定性等“质量”指标对实际机器人部署至关重要。</li>
<li><strong>测试时优化的潜力</strong>：无需修改或重新训练庞大模型，仅通过设计精巧的推理时算法即可显著提升模型表现，这是一个高效且有前景的方向。</li>
<li><strong>模块化改进</strong>：ACG专注于分块内连贯性，且被证明可与改善分块间连贯性的方法（如Self-GAD）互补。这启发未来工作可以模块化地解决机器人策略生成中的不同问题。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对基于流匹配的视觉-语言-动作模型在模仿学习时，因学习人类演示中的噪声而导致生成动作序列不连贯、影响操作稳定性的问题，提出了一种免训练的测试时引导算法——动作连贯性引导。该方法通过构建一个不连贯的动作向量场，并与原始模型向量场结合，引导采样过程生成更平滑、一致的动作序列。在RoboCasa、DexMimicGen等多个模拟与真实机器人操作任务上的实验表明，ACG能有效提升动作的连贯性，并显著提高任务的成功率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.22201" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>