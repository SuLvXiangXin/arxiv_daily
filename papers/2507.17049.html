<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Evaluating Uncertainty and Quality of Visual Language Action-enabled Robots - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Evaluating Uncertainty and Quality of Visual Language Action-enabled Robots</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.17049" target="_blank" rel="noreferrer">2507.17049</a></span>
        <span>作者: Aitor Arrieta Team</span>
        <span>日期: 2025-07-22</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>目前，视觉语言动作（VLA）模型是使机器人能够理解视觉场景、自然语言指令并执行具体任务的主流生成式AI方法。然而，对这些模型的评估缺乏标准化，通常依赖于二元任务成功率（即成功或失败）。这种评估方式存在关键局限性：它无法捕捉任务执行的质量（例如，是否发生碰撞、轨迹是否最优），也无法衡量模型对其决策的置信度。现有评估（如VLATest框架）仅通过符号化预言机检查最终目标状态来判断成功，导致许多低质量的执行（如掉落物体、碰撞、非最优轨迹）也被计为成功，且无法区分任务完成是源于模型能力还是运气。</p>
<p>本文针对当前VLA模型评估中“重结果、轻过程”的痛点，提出了一个从执行质量和模型不确定性两个维度进行精细化评估的新视角。其核心思路是：设计并验证一系列专门针对VLA模型的不确定性指标和质量指标，通过大规模实证研究，分析这些指标与人类专家判断之间的相关性，从而为超越二元成功率的、更全面的VLA模型评估奠定基础。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文的核心工作是提出并验证一套用于评估VLA模型的指标，而非提出新的VLA模型架构。其方法论框架是：首先，从VLA模型的内在输出（令牌概率、动作序列）和外在表现（多次推理的方差、执行过程数据）中，提取出八项不确定性指标和五项质量指标。然后，通过人类专家对大量VLA任务执行录像进行质量标注，最后统计分析各项指标与专家标注之间的相关性，以验证指标的有效性。</p>
<p><img src="https://arxiv.org/html/2507.17049v2/Figures/VLA_arch.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：VLA模型架构概述。输入包括多张RGB图像（(I^t_n)）、语言指令（(\ell_t)）和机器人本体感知状态（(q_t)）。经过视觉、语言和状态编码器后，特征被投影到共享潜在空间。动作解码器输出一个包含未来H个时间步的动作块（(A_t)），每个动作是一个D维控制信号（通常为7维：位置x, y, z，方向roll, pitch, yaw，夹爪开合度）。</p>
</blockquote>
<p><strong>不确定性指标</strong>（共8项）旨在量化VLA模型在决策时的置信度，分为两类：</p>
<ol>
<li><p><strong>基于动作序列的指标</strong>：通过分析模型输出的连续动作之间的变化来衡量决策的稳定性。</p>
<ul>
<li><strong>动作位置不稳定性（A-PI）</strong>：计算连续动作的一阶差分绝对值均值（公式2），捕捉动作的突变。</li>
<li><strong>动作速度不稳定性（A-VI）</strong>：计算动作的二阶差分绝对值均值（公式4），捕捉速度的突变，以克服A-PI在匀速运动场景下的局限。</li>
<li><strong>动作加速度不稳定性（A-AI）</strong>：计算动作的三阶差分绝对值均值（公式6），捕捉加速度的突变，用于识别振荡行为。</li>
<li><strong>执行变异性（EV）</strong>：对同一输入进行多次推理，计算输出动作的标准差（公式15），衡量模型决策的内部一致性。置信度高的模型应输出一致的动作。</li>
</ul>
</li>
<li><p><strong>基于令牌概率的指标</strong>：利用VLA模型中视觉语言模型（VLM）骨干网络输出的离散令牌的概率分布来衡量不确定性。这些指标是经典分类不确定性度量在VLA多令牌输出场景下的适配。</p>
<ul>
<li><strong>令牌概率（TB-TP）</strong>：基于最大概率（MaxP），计算1减去所有令牌平均MaxP的值（公式8）。概率越低，不确定性越高。</li>
<li><strong>预测置信度得分（TB-PCS）</strong>：基于最高概率与次高概率之差（PCS），计算1减去所有令牌平均PCS的值（公式10）。差值越小，不确定性越高。</li>
<li><strong>DeepGini（TB-D）</strong>：基于概率分布的Gini不纯度，计算所有令牌DeepGini值的平均值（公式12）。分布越均匀，不确定性越高。</li>
<li><strong>熵（TB-E）</strong>：基于信息熵，计算所有令牌熵值的平均值（公式14）。分布越分散，不确定性越高。</li>
</ul>
</li>
</ol>
<p><strong>质量指标</strong>（共5项）旨在客观量化任务执行过程的优劣，无需人类干预：</p>
<ol>
<li><strong>执行时间（QT）</strong>：完成任务所需的总时间。</li>
<li><strong>碰撞检测（QC）</strong>：执行过程中机器人是否与环境或其他物体发生碰撞。</li>
<li><strong>轨迹长度（QTL）</strong>：机器人末端执行器在任务期间移动的总路径长度。</li>
<li><strong>夹爪方向变化（QGO）</strong>：机器人夹爪方向角（roll, pitch, yaw）在整个轨迹中的总变化量。</li>
<li><strong>首次尝试抓取成功（QFG）</strong>：机器人是否在第一次尝试时就成功抓取目标物体。</li>
</ol>
<p>与现有方法相比，本文的创新点具体体现在：<strong>首次系统性地为机器人操作任务的VLA模型提出了超越二元成功率的、多维度的不确定性和质量评估指标体系</strong>，并将基于模型内部信号的指标（如令牌概率）与基于外部可观测行为的指标（如动作序列平滑度）相结合，进行了大规模的实证相关性验证。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：研究使用了VLATest基准测试框架生成的测试用例。实验涉及<strong>三个先进的VLA模型</strong>：GR00T-N1, π₀, 和 OpenVLA，在<strong>四个代表性的机器人操作任务</strong>上：抓取可乐罐、将书放入盒子、将木块堆叠起来、将工具放入工具箱。研究分析了来自这三个模型的<strong>共计908个被标记为“成功”的任务执行</strong>（由符号预言机判定）。</p>
<p><strong>评估方法</strong>：三位领域专家通过观看任务执行录像，手动为每个成功执行标注质量等级（高、中、低）。标注依据一份详细的问卷，问卷内容基于五项质量指标制定。</p>
<p><img src="https://arxiv.org/html/2507.17049v2/Figures/questionnaire.png" alt="专家标注问卷"></p>
<blockquote>
<p><strong>图2</strong>：用于指导人类专家进行质量标注的问卷示例。问题围绕执行时间、碰撞、轨迹效率、动作流畅性（方向变化）和首次尝试抓取成功率等维度设计。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><p><strong>质量指标与人类评估的相关性</strong>：计算了五项自动质量指标（QT, QC, QTL, QGO, QFG）与专家质量标签之间的斯皮尔曼秩相关系数。结果显示，<strong>QGO（夹爪方向变化）和QTL（轨迹长度）与人类评估具有中等至强的正相关</strong>（相关系数较高），表明动作更流畅、路径更短的执行被专家评为更高质量。QT（执行时间）也显示出中等相关性。</p>
</li>
<li><p><strong>不确定性指标与人类评估的相关性</strong>：分析了八项不确定性指标与专家质量标签的相关性。<strong>EV（执行变异性）和A-AI（动作加速度不稳定性）表现出最强的负相关</strong>，即较高的不确定性指标值对应于较低的专家质量评分。基于令牌的指标（如TB-D, TB-E）也显示出一定的负相关性，但弱于基于动作的指标。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2507.17049v2/x1.png" alt="指标相关性热力图"></p>
<blockquote>
<p><strong>图3</strong>：所有提出的指标（不确定性指标和质量指标）与人类专家质量标签之间的斯皮尔曼秩相关系数热力图。颜色越深（红）表示正相关性越强，颜色越浅（蓝）表示负相关性越强。可以直观看出QGO、QTL、EV、A-AI等指标与人类判断有显著关联。</p>
</blockquote>
<ol start="3">
<li><strong>区分不同质量等级的能力</strong>：研究进一步检验了所提指标能否区分高、中、低质量的成功执行与失败执行。结果表明，<strong>EV（执行变异性）和A-AI（动作加速度不稳定性）等指标能够有效区分不同质量等级</strong>。例如，高质量成功执行的不确定性值显著低于低质量成功和失败执行。</li>
</ol>
<p><img src="https://arxiv.org/html/2507.17049v2/x4.png" alt="指标区分能力箱线图"></p>
<blockquote>
<p><strong>图4</strong>：EV（执行变异性）指标在不同执行结果（失败、低质量成功、中质量成功、高质量成功）上的分布箱线图。清晰显示高质量成功执行的EV值最低，而失败执行的EV值最高，表明该指标具有良好的区分能力。</p>
</blockquote>
<ol start="4">
<li><strong>模型间性能对比</strong>：通过对指标的分析，揭示了仅凭成功率无法发现的模型差异。例如，尽管π₀模型在任务成功率上表现尚可，但其<strong>执行质量普遍较低</strong>，且其自我评估（如果存在）往往过于乐观，这与基于动作序列的客观不确定性指标（如A-AI）揭示出的不稳定行为形成对比。</li>
</ol>
<p><strong>消融实验分析</strong>：虽然论文未以典型“消融实验”命名，但其对不同指标相关性强弱和区分能力的分析，实质上评估了每个指标组件的贡献。核心结论是：<strong>基于动作序列的指标（尤其是EV和A-AI）和部分质量指标（QGO, QTL）在反映人类质量判断方面最为有效</strong>；而基于令牌概率的指标虽然有用，但相关性相对较弱。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>提出了首个针对VLA机器人操作模型的综合不确定性与质量评估指标体系</strong>，包含8个不确定性指标和5个质量指标，突破了当前依赖二元成功率的评估范式。</li>
<li><strong>通过大规模实证研究（908个成功执行，3个模型，4个任务，人类专家标注）验证了指标的有效性</strong>，发现多项指标（如EV, A-AI, QGO, QTL）与人类评估存在中到强相关性。</li>
<li><strong>揭示了当前VLA模型评估的不足</strong>，并证明所提指标能有效区分执行质量等级，甚至在测试预言机不可用时，为识别低质量或侥幸的成功提供了可能。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，部分指标（如基于令牌的指标TB-TP, TB-PCS等）的计算需要访问模型内部概率分布，这在某些黑盒或部署场景中可能无法获取。此外，并非所有指标都与人类评估高度相关，需要根据实际应用场景选择最有效的子集。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>评估标准</strong>：为VLA模型社区建立更细致、更可靠的评估标准提供了基础，未来研究应同时报告成功率和关键质量/不确定性指标。</li>
<li><strong>实时监控与安全</strong>：这些指标可用于机器人系统的运行时监控，当检测到高不确定性或低质量行为时触发安全干预或请求人类协助。</li>
<li><strong>模型改进</strong>：不确定性指标可以作为训练信号或用于主动学习，帮助提升模型在边缘案例上的鲁棒性和决策置信度。</li>
<li><strong>测试生成</strong>：高不确定性区域可以引导基于证伪的测试生成，更高效地发现模型缺陷。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对视觉语言动作（VLA）模型在机器人操作任务中现有评估方法（仅依赖二元成功率）的不足，提出了一套包含8个不确定性指标和5个质量指标的新评估体系。通过对3个先进VLA模型在4项任务上的908次成功执行进行大规模实证研究，并结合领域专家的人工质量标注，分析指标与人工评估的相关性。结果表明，多个指标与专家评判呈现中等到强相关性，能有效评估执行质量与模型置信度，部分指标还可区分高、中、低质量执行，为VLA模型的实时监控与自适应增强提供了新途径。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.17049" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>