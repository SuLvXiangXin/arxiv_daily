<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>HuBE: Cross-Embodiment Human-like Behavior Execution for Humanoid Robots - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>HuBE: Cross-Embodiment Human-like Behavior Execution for Humanoid Robots</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.19002" target="_blank" rel="noreferrer">2508.19002</a></span>
        <span>作者: Lyu, Shipeng, Wang, Fangyuan, Lin, Weiwei, Zhu, Luhao, Navarro-Alarcon, David, Guo, Guodong</span>
        <span>日期: 2025/08/26</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人在人机交互中扮演着关键角色，其行为的拟人化程度显著影响用户的感知和接受度。当前，确保机器人行为拟人化的主流方法主要聚焦于<strong>行为相似性</strong>，即通过运动重定向或模仿学习等技术，使机器人的运动学模式与人类相似。然而，根据“恐怖谷”理论，仅有关似性而缺乏<strong>行为适当性</strong>——即行为符合情境需求和人类认知期望——可能引发不适。现有方法存在几个关键局限：1) 现有数据集缺乏连接情境语义与行为适当性的细粒度标注；2) 姿态生成与重定向过程通常采用开环机制，导致两阶段间的身体结构失配，损害动作的拟人化程度和语义；3) 缺乏跨形态适应性，难以部署到形态各异的人形机器人上。</p>
<p>本文针对上述痛点，提出了一个兼顾<strong>行为相似性</strong>与<strong>行为适当性</strong>的新视角，并致力于解决跨形态部署的难题。核心思路是构建一个双层闭环框架（HuBE），通过融合机器人状态、目标姿态和情境语义，实现端到端的运动生成与控制，并引入基于骨骼缩放的数据增强策略以实现毫米级的跨形态兼容性。</p>
<h2 id="方法详解">方法详解</h2>
<p>HuBE框架旨在驱动人形机器人在行为相似性与适当性的要求下执行富有表现力的人类姿态。整体流程包含三个模块：数据处理、行为生成和行为执行。</p>
<p><img src="https://arxiv.org/html/2508.19002v1/Figure/Overview-v2.png" alt="方法框架总览"></p>
<blockquote>
<p><strong>图2</strong>：HuBE算法整体概览。包含三部分：1) 数据集构建：从开源数据集中提取并增强，创建HPose数据集。2) 模型训练：行为生成模块接收情境<code>l</code>、当前状态<code>s</code>和目标<code>g</code>，通过策略网络生成动作<code>a</code>。3) 算法实现：行为执行模块通过多约束逆运动学求解器将生成的动作映射到具体机器人关节空间。</p>
</blockquote>
<p><strong>1. 数据准备（构建HPose数据集）</strong><br>为支持框架训练，论文从KIT、AMASS、Motion-X等开源数据集构建了HPose数据集，包含约6.2万帧数据。关键处理包括：</p>
<ul>
<li><strong>数据定义</strong>：简化人体骨骼为11个关键关节（见图3），并为每个关节引入四元数表示的旋转数据。使用GPT-4o为运动序列生成细粒度的情境描述<code>l</code>（如“一个人用右手试图拿起左侧桌上的杯子”），以丰富行为语义。</li>
<li><strong>数据结构</strong>：将每帧数据格式化为<code>(s_i, g_i, l_i, a_i)</code>元组。其中<code>s_i</code>为当前帧11个关节姿态，<code>g_i</code>为下一帧三个末端执行器（双手和头）的目标姿态，<code>a_i</code>为下一帧11个关节姿态（即要执行的动作）。</li>
<li><strong>数据增强（核心创新）</strong>：为适应不同人形机器人的形态差异，提出基于<strong>骨骼缩放</strong>的数据增强策略。该策略将骨骼分为固定骨骼（长度稳定）和浮动骨骼（长度随姿态变化，如脊柱），并利用从9款商用机器人（如Unitree H1）收集的身体参数<code>R</code>，通过算法1将原始人体骨骼链<code>H</code>缩放为伪真实值<code>H&#39;</code>（Pseudo GT），从而模拟目标机器人的形态分布，实现跨形态兼容性。</li>
</ul>
<p><img src="https://arxiv.org/html/2508.19002v1/Figure/floating_bone-v4.png" alt="人体骨骼系统"></p>
<blockquote>
<p><strong>图3</strong>：人体骨骼系统示意。a) 人体骨骼组成。b) 用于HPose数据集的简化人体上半身骨骼链<code>H</code>定义。c) 浮动骨骼影响示例：脊柱（浮动骨）长度随姿态变化，而手臂（固定骨）长度稳定。</p>
</blockquote>
<p><strong>2. 行为生成模块</strong><br>该模块被建模为一个马尔可夫决策过程，目标是学习一个策略<code>π_θ: (s, g, l) → a</code>，以最大化专家演示数据的似然。采用MLP或Transformer作为策略网络。为解决“相似末端位置对应不同情境行为”以及“生成数据集中未见目标行为”的挑战，引入了两项关键技术：</p>
<ul>
<li><strong>输入对齐</strong>：使用BERT对情境描述<code>l_i</code>进行编码，同时使用MLP将机器人本体感知<code>(s_i, g_i)</code>映射到相同维度，然后将两者拼接，确保情境语义与运动目标在特征空间中对齐（公式3）。</li>
<li><strong>事后训练</strong>：受事后经验回放启发，在训练时不仅使用下一帧作为目标，而是从当前帧起的一个未来时间窗口<code>H</code>内随机采样一帧的姿态作为目标<code>g_{t+k}</code>，并对应地使用该帧的动作<code>a_{t+k}</code>（公式4）。这极大地丰富了目标-动作对的多样性，提升了策略的泛化能力。</li>
</ul>
<p><strong>3. 行为执行模块</strong><br>此模块负责将生成的动作（笛卡尔空间关节姿态）映射到机器人关节空间，同时保持拟人化。挑战在于如何处理浮动骨骼的运动。论文提出一个<strong>多约束逆运动学求解器</strong>（基于Pinocchio工具箱的闭环逆运动学算法）。该求解器分为两步（公式5）：</p>
<ol>
<li>优先计算躯干（包含颈、头等浮动骨骼关节）的关节角度<code>J_torso*</code>，强调目标关节的旋转姿态。</li>
<li>锁定已计算的躯干关节，在简化模型上计算双臂（固定骨骼关节）的关节角度<code>J_arms*</code>。<br>所有关节姿态均通过SE(3)群滤波器处理以增强稳定性。这种分层求解方式有效保持了生成姿态的拟人化特征。</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在HPose数据集（特别是KIT_ML子集）上训练模型。对比的基线方法包括传统的逆运动学方法、以及使用MLP/Transformer但不包含情境输入或事后训练的变体。评估在多个商用机器人平台（如GR1, G1, TALOS）上进行。</p>
<p><strong>评估指标</strong>：</p>
<ul>
<li><strong>行为相似性</strong>：末端执行器精度（E-A）和人类相似度（H-S），分别用平均每关节位置误差（MPJPE）和方向误差（MPJOE）衡量。</li>
<li><strong>行为适当性</strong>：弗雷歇运动距离（FMD，衡量与真实人类动作分布的距离）、多模态距离（MM-Dist，情境与生成动作间的距离）、R-Precision（文本-动作检索精度）。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><p><strong>跨形态兼容性验证</strong>：</p>
<ul>
<li><strong>骨骼尺寸稳定性</strong>：如表II所示，在原始数据（GT）上训练的模型，为不同机器人生成姿态的骨骼长度误差较大（固定骨达0.14-0.23米，浮动骨达0.26-0.31米）。而使用增强后伪真实值（Pseudo GT）训练的模型，误差降至毫米级（~1e-4到6.8e-3米），证明了数据增强策略的有效性。</li>
</ul>
<p><img src="https://arxiv.org/html/2508.19002v1/Figure/Generated_bone_example-v5.png" alt="骨骼尺寸生成结果"></p>
<blockquote>
<p><strong>图4</strong>：基于GT和Pseudo GT训练模型生成的姿态对比。输入为GR1机器人姿态，情境为“双手将重箱举过头顶”。第二行（Pseudo GT）生成的姿态骨骼长度更符合输入机器人的形态。</p>
</blockquote>
<ul>
<li><strong>重定向精度</strong>：如图5所示，在不同机器人上执行生成的运动，其末端执行器精度（E-A）和整体相似度（H-S）的MPJPE和MPJOE值均保持在较低水平，表明执行模块能准确地将生成姿态映射到机器人，同时保持拟人化。</li>
</ul>
<p><img src="https://arxiv.org/html/2508.19002v1/Figure/Different_platform-v4.png" alt="重定向精度"></p>
<blockquote>
<p><strong>图5</strong>：三种人形机器人在不同帧下的重定向精度（MPJPE和MPJOE）。误差值较小，表明框架具有良好的跨平台适应性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.19002v1/Figure/Multi_platform_testing-v2.png" alt="多平台演示"></p>
<blockquote>
<p><strong>图6</strong>：HuBE框架在GR1、G1、TALOS三种人形机器人上的定性演示。浅色为初始姿态，深色为根据给定目标和情境规划的目标姿态。</p>
</blockquote>
</li>
<li><p><strong>消融实验</strong>：</p>
<ul>
<li><strong>数据频率与事后训练</strong>：如表III所示，采用随机频率的事后训练策略在所有指标上均优于固定频率（240Hz, 60Hz, 15Hz）训练，显著提升了行为相似性（E-A MPJPE: 0.015 vs. 0.056）和适当性（R-Precision: 0.492 vs. 0.384）。</li>
<li><strong>情境语义的作用</strong>：对比有/无情境<code>l</code>输入的模型（MLP(w) vs. MLP(w/o), Transformer(w) vs. Transformer(w/o)），包含情境输入的模型在所有相似性和适当性指标上均表现更优，证明了情境信息对于生成适当行为的关键作用。</li>
<li><strong>观测完整性的影响</strong>：如图7所示，缺失骨盆、颈、肩、肘等关键关节的观测会严重损害整体人类相似度（H-S）和行为适当性，而缺失手/腕部观测的影响相对较小，因为末端执行器姿态本身是训练目标的一部分。</li>
</ul>
<p><img src="https://arxiv.org/html/2508.19002v1/Figure/ablation_of_observation-v4.png" alt="观测消融"></p>
<blockquote>
<p><strong>图7</strong>：观测输入消融实验结果。缺失躯干核心关节的观测会显著降低H-S和适当性指标，而缺失末端执行器观测影响较小。</p>
</blockquote>
</li>
<li><p><strong>对比实验</strong>：如表III所示，HuBE框架（MLP(w) with Random frequency）在行为相似性（E-A和H-S的MPJPE/MPJOE）和行为适当性（FMD, MM-Dist, R-Precision）上均优于所列出的其他方法变体，证明了其整体有效性。</p>
</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个衡量人形机器人行为拟人化的新视角，明确划分为<strong>行为相似性</strong>和<strong>行为适当性</strong>，并构建了包含细粒度情境标注的HPose数据集来支持该视角。</li>
<li>提出了<strong>HuBE双层闭环框架</strong>，通过融合机器人状态、目标姿态和情境语义，实现了端到端的拟人化行为生成与执行，解决了运动生成与执行间的结构失配问题。</li>
<li>提出了<strong>基于骨骼缩放的数据增强策略</strong>，实现了毫米级的跨形态兼容性，使方法能够直接、鲁棒地部署到多种异构人形机器人上，无需额外的形态适应。</li>
</ol>
<p><strong>局限性</strong>：论文提到，当前工作主要关注上半身的表达性行为，未来的工作需要将框架扩展到全身运动，并集成动态平衡控制。</p>
<p><strong>研究启示</strong>：</p>
<ol>
<li>将高层语义（情境）与底层运动控制紧密结合，是提升机器人行为可接受度和智能水平的重要方向。</li>
<li>通过数据驱动的方式显式地建模机器人形态差异，是实现算法跨平台泛化的有效途径。</li>
<li>闭环的、考虑当前机器人状态的生成方式，比开环的重定向 pipeline 更能保证最终执行动作的保真度和物理可行性。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人类人行为生成中难以同时保证**行为相似性与适当性**，且缺乏**跨具身适应性**的核心问题，提出了**HuBE框架**。该框架通过整合机器人状态、目标姿态与上下文情境，结合**HPose情境标注数据集**与**骨骼缩放数据增强策略**，实现了毫米级跨机器人兼容。在多平台实验验证中，HuBE在运动相似性、行为适当性与计算效率上均显著优于现有先进基线。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.19002" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>