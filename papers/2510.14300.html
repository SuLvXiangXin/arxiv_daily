<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.14300" target="_blank" rel="noreferrer">2510.14300</a></span>
        <span>作者: Yao Mu Team</span>
        <span>日期: 2025-10-16</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作模型在机器人操作任务中发展迅速。主流方法如OpenVLA、π₀等基于流匹配的密集模型，通过端到端框架整合多模态输入以生成动作序列。然而，扩展VLA模型面临两大关键挑战：一是从头训练新模型需要海量计算资源和数据集，而机器人数据稀缺，使得在扩展过程中充分利用预训练好的VLA模型权重变得尤为重要；二是实时控制需要在模型容量与计算效率之间仔细权衡。混合专家架构虽已被证明是扩展模型容量同时保持计算效率的有效范式，但其在VLA领域的应用存在一个根本性局限：传统的MoE路由机制将专家选择与贡献权重耦合在一起，这导致负载平衡损失（要求专家使用均匀）与主任务目标（倾向于专家专业化、非均匀激活）之间存在直接的优化冲突，迫使模型收敛到一个次优解。本文针对这一痛点，提出了一个新颖的视角：<strong>“专长无需垄断”</strong>，即专家的选择权不应决定其在最终输出中的相对重要性。本文核心思路是：通过引入一个独立的尺度适配器，将MoE中的专家选择与专家加权解耦，从而缓解优化冲突，实现负载平衡与任务性能的同时提升。</p>
<h2 id="方法详解">方法详解</h2>
<p>AdaMoE的整体框架建立在预训练的π₀ VLA模型之上。π₀是一个基于流匹配的模型，输入为包含多视角RGB图像、语言指令和机器人本体状态的多模态观测，输出为用于高频控制的一个动作块。AdaMoE的扩展策略是：<strong>继承π₀的预训练权重，并将其动作专家中的前馈网络层替换为稀疏激活的MoE层</strong>，而模型的输入输出形式保持不变。</p>
<p><img src="https://arxiv.org/html/2510.14300v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：AdaMoE架构总览。(a) 整体流程：多模态输入通过VLM主干和集成了MoE层的Transformer块处理。(b) 专家初始化：共享专家继承原始FFN权重，路由专家则被创建为副本以实现高效扩展。(c) 传统MoE：单一路由器通过top-k选择和softmax输出耦合了专家选择与加权。(d) AdaMoE：解耦架构，包含独立的路由器（蓝色）负责选择，以及尺度适配器（绿色）负责额外的加权，包含共享专家和路由专家以实现灵活利用。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>MoE动作专家构成</strong>：包含两类专家。<ul>
<li><strong>共享专家</strong>：处理所有任务的通用动作模式，捕获普适的操作知识，始终被激活以确保基线性能。</li>
<li><strong>路由专家</strong>：通过门控机制专注于特定类型的动作或任务类别。</li>
</ul>
</li>
<li><strong>前向计算（传统耦合形式）</strong>：对于每个动作token (x_a)，传统MoE输出为 (F_{MoE}(x_a) = F_{shared}(x_a) + \sum_{i \in top-k} \text{softmax}(r_i(x)) \cdot F_i(x_a))。其中，同一组路由器logits (r_i(x)) 经过softmax后既用于top-k选择，又作为选中专家的组合权重。</li>
<li><strong>关键创新：解耦选择与加权</strong>：本文指出上述耦合设计是性能受限的根源。为此，AdaMoE引入了一个与原始路由器 (R(\cdot)) 结构相同但功能独立的<strong>尺度适配器 (S(\cdot))</strong>。改进后的计算公式为：<br>(F_{MoE}(x) = F_{shared}(x_a) + \sum_{i \in top-k} [S_i(x) + \text{softmax}(R_i(x))] \cdot F_i(x))<br>在此设计中，路由器 (R(\cdot)) 专注于通过多样化的专家选择来满足负载平衡需求；而尺度适配器 (S(\cdot)) 则专注于任务性能，可以自由地调整专家的贡献权重，不受负载平衡要求的约束。这种解耦使得模型能够同时更好地满足这两个目标。</li>
<li><strong>训练目标</strong>：总损失函数为流匹配损失 (\mathcal{L}<em>{\tau}) 与负载平衡损失 (\mathcal{L}</em>{balance}) 的加权和：(\mathcal{L}<em>{total} = \mathcal{L}</em>{\tau} + \lambda_{balance} \mathcal{L}_{balance})。负载平衡损失鼓励所有路由专家被均匀使用，防止专家崩溃。</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：使用了两个仿真基准进行评估：1) LIBERO数据集的四个任务套件；2) RoboTwin 2.0的19个任务。Baseline包括Diffusion Policy、OpenVLA、SpatialVLA、CoT-VLA以及作为主要对比的π₀模型。此外，还在真实世界的双灵巧手操作平台上进行了四项任务的验证。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><p><strong>MoE相对于密集模型的提升</strong>：<br><img src="https://arxiv.org/html/2510.14300v1/x4.png" alt="仿真结果表1"></p>
<blockquote>
<p><strong>表1</strong>：在LIBERO基准上，AdaMoE平均成功率达到96.0%，比π₀基线（94.2%）提升了1.8%，尤其在长时程任务上提升显著（85.2% → 92.0%）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.14300v1/x5.png" alt="仿真结果表2"></p>
<blockquote>
<p><strong>表2</strong>：在更大规模的RoboTwin数据集上，AdaMoE平均成功率为49.7%，比π₀基线（40.4%）提升了9.3%，证明了其在复杂、多样化任务上的优势。</p>
</blockquote>
</li>
<li><p><strong>专家专业化分析</strong>：<br><img src="https://arxiv.org/html/2510.14300v1/x2.png" alt="专家使用强度可视化"></p>
<blockquote>
<p><strong>图2</strong>：专家激活模式可视化。不同专家在不同操作阶段（如目标定位、夹爪释放）显示出清晰的、与任务阶段相关的激活模式，表明专家学习到了有意义的操作原语。</p>
</blockquote>
</li>
<li><p><strong>解耦架构的有效性验证</strong>：<br><img src="https://arxiv.org/html/2510.14300v1/x3.png" alt="架构变体对比"></p>
<blockquote>
<p><strong>图3</strong>：三种架构变体示意图。(a) 传统耦合MoE，(b) 拼接式尺度适配器MoE，(c) 本文提出的加法式尺度适配器MoE。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.14300v1/x6.png" alt="消融实验结果表3"></p>
<blockquote>
<p><strong>表3</strong>：路由设计的消融研究结果。AdaMoE（96.0%）优于传统MoE（94.4%）和拼接式变体CSMoE（95.5%），验证了解耦设计的有效性，带来了1.6%的平均提升。一个有趣的发现是，即使发生专家崩溃（仅使用单个专家），MoE架构仍优于原始密集模型，表明路由机制本身引入了有益的归纳偏置。</p>
</blockquote>
</li>
<li><p><strong>超参数消融研究</strong>：<br><img src="https://arxiv.org/html/2510.14300v1/x7.png" alt="超参数消融表4"></p>
<blockquote>
<p><strong>表4</strong>：关键超参数的影响。最优配置为：top-k=1，专家数量=4，负载平衡损失权重 (\lambda_{balance}=0.01)。这表明解耦架构下，少量专家且每个token仅激活一个专家即可实现高效专业化。</p>
</blockquote>
</li>
<li><p><strong>真实世界实验结果</strong>：<br><img src="https://arxiv.org/html/2510.14300v1/x8.png" alt="真实世界结果表5"></p>
<blockquote>
<p><strong>表5</strong>：真实世界操作任务的成功率。AdaMoE平均成功率达到71.5%，相比π₀基线（50.0%）实现了21.5%的显著提升，验证了其从仿真到现实的有效迁移和实际应用价值。</p>
</blockquote>
</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一种高效的VLA模型扩展方法，通过继承预训练密集模型的权重并将其转换为MoE架构，以较低成本实现了模型容量的提升。</li>
<li>提出了一种新颖的、专为VLA模型设计的解耦MoE架构，通过独立的尺度适配器将专家选择与贡献加权分离，有效解决了负载平衡与任务性能之间的优化冲突。</li>
<li>在仿真和真实世界实验中均证明了方法的有效性，在LIBERO、RoboTwin基准上分别获得1.8%和9.3%的性能提升，在真实任务上更实现了21.5%的平均提升。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，当前研究采用的专家数量较少（4个），这可能限制了模型捕获更细粒度专业化的能力。</p>
<p><strong>后续研究启示</strong>：</p>
<ol>
<li><strong>解耦思想</strong>：将MoE中耦合的功能进行解耦，为解决多目标优化冲突提供了一种通用思路，可应用于其他存在类似权衡的领域。</li>
<li><strong>高效专业化</strong>：研究表明，在解耦设计下，少量专家（甚至top-1选择）即可实现有效提升，这挑战了“更多专家总是更好”的直觉，启发研究者更深入地探索专家数量、容量与专业化质量之间的关系。</li>
<li><strong>路由即调制</strong>：即使专家崩溃，路由机制仍能带来性能增益，这提示路由网络本身可能作为一个自适应的特征调制器，其设计值得独立研究。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对扩展Vision-Language-Action模型时面临的计算资源需求大、机器人数据稀缺以及模型容量与效率平衡的核心挑战，提出AdaMoE架构。该方法基于混合专家模型，继承预训练权重，通过将前馈层替换为稀疏激活的MoE层来扩展动作专家，并采用解耦技术使专家选择与权重分配独立，实现协作利用而非赢家通吃。实验结果表明，AdaMoE在LIBERO和RoboTwin基准上性能分别提升1.8%和9.3%，真实世界实验更提升21.5%，验证了其有效性和实用性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.14300" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>