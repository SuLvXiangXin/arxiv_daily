<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Realizing Text-Driven Motion Generation on NAO Robot: A Reinforcement Learning-Optimized Control Pipeline - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Realizing Text-Driven Motion Generation on NAO Robot: A Reinforcement Learning-Optimized Control Pipeline</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.05117" target="_blank" rel="noreferrer">2506.05117</a></span>
        <span>作者: Xu, Zihan, Hu, Mengxian, Xiao, Kaiyan, Fang, Qin, Liu, Chengju, Chen, Qijun</span>
        <span>日期: 2025/06/05</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人的运动模仿，传统上依赖于通过姿态估计或动作捕捉系统捕获的人类演示数据。这些方法存在显著局限性：动作捕捉设备成本高昂，限制了数据多样性；同时，人类与机器人在结构和运动学上存在差异，直接映射关节角度或依赖参数化人体模型进行关键点跟踪，往往难以保证机器人执行的稳定性和动作保真度。</p>
<p>本文旨在探索一种更灵活、直观的文本驱动方法，将人类动作映射到人形机器人。核心痛点是生成的基于文本的人类动作表征与机器人运动学约束之间存在固有差异。为此，本文提出了一种结合文本到动作扩散模型与强化学习优化控制的全新流程。其核心思路是：首先利用扩散模型根据文本生成人类动作序列，然后通过一个基于标准化位置与旋转损失（NPR Loss）的关节角度信号网络将其映射为机器人关节角度参考指令，最后使用强化学习训练一个全身关节运动控制策略来跟踪这些指令，同时确保机器人的执行稳定性。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的方法流程包含两个核心阶段：姿态映射和全身控制。</p>
<p><img src="https://arxiv.org/html/2506.05117v1/x2.png" alt="方法总览"></p>
<blockquote>
<p><strong>图2</strong>：文本驱动人类动作到人形机器人映射的总体框架：(a) 姿态映射（第III节）：通过角度信号网络将文本驱动生成的人类动作映射为机器人关节角度。(b) 全身控制（第IV节）：训练基于强化学习的控制器，并使用ONNX Runtime部署策略，在ROS2框架中运行系统。</p>
</blockquote>
<p><strong>1. 姿态映射</strong><br>输入是文本描述，输出是机器人关节角度序列。该阶段分为两步：</p>
<ul>
<li><strong>文本驱动人类动作合成</strong>：采用运动一致性训练（MLCT）框架的扩散模型。给定文本指令，使用CLIP模型提取文本特征。从标准正态分布采样噪声，并参考文本特征沿预计算的反向扩散轨迹求解，得到运动潜在表示，再经解码器生成符合语义的人类动作序列（格式同HumanML3D数据集），包含f帧22个关节的3D坐标。</li>
<li><strong>人类到机器人的标准化映射</strong>：为解决结构差异，将生成的人类动作序列简化为四个基本关节链（双臂和双腿）。首先将世界坐标系下的人体骨架点转换到机器人坐标系。对于每个肢体（以左臂为例），其位置由从左肩到左腕的向量经臂长归一化后得到“标准化位置”；其旋转由从左肘到左腕的向量与机器人默认水平臂方向向量之间的旋转矩阵（转换为四元数）描述。腿部计算方式类似。</li>
</ul>
<p><img src="https://arxiv.org/html/2506.05117v1/x5.png" alt="角度信号网络架构"></p>
<blockquote>
<p><strong>图5</strong>：角度信号网络架构。该网络将末端执行器的四元数Q和位移D拼接成的特征向量映射到关节空间配置，同时尊重机器人的物理关节限位。</p>
</blockquote>
<p>映射的核心是一个角度信号网络，其输入是拼接的末端执行器四元数（Q∈R^4）和位移（D∈R^3），输出是预测的关节角度（D_out=21）。网络包含两个128单元的隐藏层，使用批归一化和ReLU激活。为确保输出在关节限位内，原始输出通过Sigmoid函数并按限位缩放（公式4）。</p>
<p>本方法的关键创新是提出了NPR损失函数，用于训练该网络。它联合优化平移和旋转精度：</p>
<ul>
<li><strong>旋转损失</strong>：使用基于四元数的角误差（公式5）。</li>
<li><strong>平移损失</strong>：使用预测与目标位置的均方误差（MSE），并根据机器人实际臂长和腿长进行加权（公式6,7）。</li>
<li><strong>总损失</strong>：为加权平移损失和旋转损失之和（公式8）。</li>
</ul>
<p><strong>2. 全身控制策略训练</strong><br>此阶段在IsaacLab强化学习框架中进行。输入是上一阶段生成的关节角度参考指令以及机器人的本体状态，输出是实际发送给关节的执行指令。</p>
<ul>
<li><strong>状态空间</strong>：包括关节角度、关节速度、机器人基座的全局朝向和位置。</li>
<li><strong>动作空间</strong>：为关节的位置控制命令。</li>
<li><strong>奖励函数</strong>：设计用于鼓励策略跟踪参考运动并保持稳定。主要包括：1) <strong>跟踪奖励</strong>：鼓励末端执行器位置和方向与参考值对齐；2) <strong>关节命令奖励</strong>：鼓励输出关节命令接近参考关节角度；3) <strong>正则化项</strong>：惩罚过大的关节加速度、关节速度，并为双脚接触地面提供奖励以保持平衡。</li>
<li><strong>训练与部署</strong>：在精细调整碰撞模型的NAO仿真模型中进行大规模并行训练。训练好的策略被导出为ONNX格式，并通过ROS2框架部署到真实的NAO机器人上执行。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>平台</strong>：使用IsaacSim 4.5进行仿真训练，在真实NAO机器人上部署验证。</li>
<li><strong>数据</strong>：文本-动作生成基于HumanML3D数据集格式。</li>
<li><strong>对比基线</strong>：由于是新颖的文本驱动流程，论文主要与<strong>无强化学习优化</strong>的纯映射方法进行对比，即仅使用角度信号网络映射关节指令后直接执行。</li>
</ul>
<p><strong>关键结果</strong>：</p>
<ol>
<li><p><strong>映射精度验证</strong>：<br><img src="https://arxiv.org/html/2506.05117v1/x4.png" alt="轨迹对比与误差热图"></p>
<blockquote>
<p><strong>图4</strong>：挥手动作的参考空间轨迹与测量空间轨迹对比，附有误差分布的热图可视化及均值和标准差。该图表明，基于NPR损失的角度信号网络能准确捕捉映射动作的空间特征，生成精确的关节序列指令。</p>
</blockquote>
</li>
<li><p><strong>仿真训练性能</strong>：<br><img src="https://arxiv.org/html/2506.05117v1/x6.png" alt="训练曲线"></p>
<blockquote>
<p><strong>图6</strong>：仿真训练期间的平均奖励和 episode 长度。奖励曲线上升并最终稳定，episode长度达到最大值，表明策略成功学习到跟踪参考动作并保持稳定。</p>
</blockquote>
</li>
<li><p><strong>真实世界结果</strong>：<br><img src="https://arxiv.org/html/2506.05117v1/extracted/6514789/fig_real_world_results.png" alt="真实世界结果"></p>
<blockquote>
<p><strong>图7</strong>：真实NAO机器人执行文本生成动作的定性结果。从左至右动作依次为：“一个人张开双臂”、“一个人向左挥手”、“一个人抬起左腿”。实验证明，整个流程成功地将多种文本描述的动作转移到了真实的NAO机器人上。</p>
</blockquote>
</li>
</ol>
<p><strong>消融实验</strong>：论文通过对比“仅映射”与“映射+RL优化”的策略，凸显了RL控制器的必要性。仅使用映射关节指令直接控制机器人，由于动力学和稳定性问题，往往导致动作扭曲或机器人跌倒。而加入RL优化的全身控制策略能够补偿这些因素，生成稳定、可执行的运动。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出并实现了一个完整的、端到端的文本驱动人形机器人运动生成流程，首次将文本-动作扩散模型与强化学习优化控制相结合，并在真实机器人上成功验证。</li>
<li>设计了基于标准化位置与旋转描述（NPR）的损失函数及对应的角度信号网络，有效解决了人类动作表征到机器人运动学约束的映射问题。</li>
<li>开源了为IsaacSim精细调整的NAO机器人仿真模型、控制接口及训练代码，为后续研究提供了便利的工具。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，当前方法生成的动作复杂度可能受限于底层扩散模型和机器人本身的自由度；此外，实时性方面，文本生成动作和策略推理需要一定时间。</p>
<p><strong>启示</strong>：本工作展示了生成式AI与机器人控制结合的潜力。后续研究可探索更复杂的动态动作、结合环境交互的指令，以及进一步优化从文本到机器人动作的端到端效率与性能。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文旨在解决将文本驱动的人类动作生成应用于NAO人形机器人时，生成的动作表示与机器人运动学约束之间存在差异的核心问题。提出基于规范位置和旋转损失（NPR Loss）的角度信号网络，生成关节角度作为输入；并采用强化学习优化的全身关节运动控制策略，确保动作跟踪同时维持机器人稳定性。实验证明该方法有效，成功在真实NAO机器人上实现了文本驱动人类动作的转移。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.05117" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>