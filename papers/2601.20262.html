<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Shallow-{\pi}: Knowledge Distillation for Flow-based VLAs - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Shallow-{\pi}: Knowledge Distillation for Flow-based VLAs</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.20262" target="_blank" rel="noreferrer">2601.20262</a></span>
        <span>作者: Jeon, Boseong, Choi, Yunho, Kim, Taehan</span>
        <span>日期: 2026/01/28</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，基于流的视觉-语言-动作（VLA）模型，如π、GR00T和CogACT，因其强大的生成能力和支持扩散引导技术而备受关注。然而，这些模型通常结合了大型视觉语言模型（VLM）主干和由数十个Transformer层构成的扩散动作头，并在推理时需要迭代的扩散步骤，导致在边缘设备上实现实时部署极具挑战性。为提升VLA效率，现有研究主要沿两个方向：1）视觉令牌剪枝，但在现代GPU高度并行化令牌计算的背景下，其延迟收益有限；2）Transformer层减少，具体包括动态层跳过（如DeeR-VLA、EfficientVLA）和使用更小的VLM主干（如SmolVLA）。但这些方法存在关键局限性：动态层跳过需要完整模型驻留内存，且现有评估多集中于仅减少VLM主干的深度；而训练小主干方法通常需要从头训练，限制了与大型预训练模型的兼容性，且未减少动作头深度，而动作头计算在基于流的模型中占据了主要成本。</p>
<p>本文针对π类架构（其动作头镜像VLM主干深度，以便从所有中间层接收条件信息）的模型压缩问题，提出了一个新的视角：通过知识蒸馏（KD）联合、系统地压缩VLM主干和动作头的Transformer深度。核心思路是：设计一个原则性的知识蒸馏框架，将深层教师模型（如18层）压缩为浅层学生模型（如6层），通过精心设计的蒸馏目标（包括任务监督、教师轨迹模仿和中间注意力转移）来保持性能，从而实现显著的推理加速。</p>
<h2 id="方法详解">方法详解</h2>
<p>Shallow-π的整体目标是将一个预训练的、基于流的VLA教师策略 (v_{\phi}) 蒸馏为一个Transformer层数大幅减少的学生模型 (v_{\theta})，同时保持动作生成性能。学生模型通过结合任务监督和知识蒸馏损失进行训练，以近似教师的去噪行为。</p>
<p><img src="https://arxiv.org/html/2601.20262v1/img/diagram.png" alt="方法框架"></p>
<blockquote>
<p><strong>图5</strong>：Shallow-π 知识蒸馏框架。通过知识蒸馏减少VLM主干和动作头的Transformer深度，使用三个损失项来匹配真实动作、教师输出以及主干与动作头之间的中间层交叉注意力。</p>
</blockquote>
<p><strong>整体流程与初始化</strong>：给定一个预训练的教师模型，学生模型通过均匀子采样策略（遵循TinyBERT风格）初始化，减少VLM主干和动作头中的Transformer层数。论文指出，只要训练步数足够，基于层敏感性分析选择初始化层并未带来额外收益。</p>
<p><strong>核心蒸馏目标</strong>：学生模型 (v_{\theta}) 使用三个互补的损失进行训练：</p>
<ol>
<li>**任务损失 ((L_{\text{task}}))**：标准的流匹配损失，监督学生预测真实速度 (u = a - \epsilon)。<br>[ L_{\text{task}} = \mathbb{E}[|v_{\theta}(\cdot) - u|_2^2] ]</li>
<li>**知识蒸馏损失 ((L_{\text{kd}}))**：鼓励学生匹配教师预测的速度，提供教师生成的指导性信息。<br>[ L_{\text{kd}} = \mathbb{E}[|v_{\theta}(\cdot) - v_{\phi}(\cdot)|_2^2] ]</li>
<li>**注意力蒸馏损失 ((L_{\text{attn}}))**：本文提出的新颖损失，专为多模态VLA架构设计。它在一个中间Transformer层对齐动作查询与视觉语言键值对之间的交叉注意力分布。<br>[ L_{\text{attn}} = \mathbb{E}\left[\operatorname{KL}\left(\operatorname{Attn}<em>{\phi}^{a \rightarrow vl} | \operatorname{Attn}</em>{\theta}^{a \rightarrow vl}\right)\right] ]<br>其中，(\operatorname{Attn}^{a \rightarrow vl} = \mathrm{softmax}(Q^a K^{vl\top}))，KL散度针对每个动作令牌在视觉语言令牌上的对应注意力分布进行计算。</li>
</ol>
<p><strong>注意力蒸馏的设计考量</strong>：与LLM/VLM中常见的注意力蒸馏不同，本文<strong>不</strong>强制匹配所有令牌的注意力（如 (\operatorname{Attn}^{vl \rightarrow vl})）。这是因为在基于流的VLA中，只有动作令牌定义生成策略，而视觉和语言令牌仅作为条件上下文。蒸馏非生成的主干令牌注意力会过度约束学生，并与预训练表示产生干扰，且无助于提升控制保真度。实验表明，匹配所有令牌的注意力会导致训练不稳定和最终策略成功率接近零（见表1-(c)）。此外，受Align-KD启发，注意力蒸馏仅应用于一个特定的中间层，而非所有层。因为学生通过直接复制教师的底层层进行初始化，早期层表示已基本对齐；而在最后一层，输出匹配已通过 (L_{\text{task}}) 和 (L_{\text{kd}}) 强制执行。</p>
<p><strong>创新点</strong>：与现有方法相比，Shallow-π的核心创新在于：1）<strong>联合压缩</strong>：首次系统性地同时压缩VLM主干和动作头的深度，适用于需要逐层特征注入的π类架构。2）<strong>针对性蒸馏目标</strong>：设计了专门针对基于流VLA的复合损失函数，特别是只针对动作到视觉语言交叉注意力的注意力蒸馏，避免了蒸馏过程中的干扰。3）<strong>原则性压缩</strong>：通过蒸馏进行端到端训练，而非依赖复杂的手动阈值或路由机制，实现了更彻底的结构性层减少，而非动态跳过。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准/数据集</strong>：LIBERO仿真基准（评估泛化能力）；真实世界复杂动态操作任务（包括移动目标插入、倾倒、人形机器人双手躯干协调任务等）。</li>
<li><strong>实验平台</strong>：仿真使用H100 GPU测量计算；真实部署在边缘设备Jetson Orin（用于ALOHA机器人）和Jetson Thor（用于RB-Y1人形机器人）。</li>
<li><strong>对比方法</strong>：<ul>
<li><strong>基线</strong>：原始π₀和π₀.₅模型。</li>
<li><strong>令牌压缩（正交方向）</strong>：CogVLA、LightVLA。</li>
<li><strong>小主干方法</strong>：SmolVLA。</li>
<li><strong>层蒸馏（本文）</strong>：Shallow-π (L9, L6, L4)，数字表示层数。</li>
</ul>
</li>
</ul>
<p><img src="https://arxiv.org/html/2601.20262v1/img/computation.png" alt="延迟分析"></p>
<blockquote>
<p><strong>图2</strong>：Transformer深度与视觉令牌数量对CUDA推理时间的影响（H100与Jetson Orin）。减少Transformer层数比减少视觉令牌能带来更显著的延迟降低，突显了层减少在提升推理延迟方面的独特有效性。</p>
</blockquote>
<p><strong>关键仿真结果</strong>：如表2所示，在LIBERO基准上，蒸馏得到的浅层模型（如π₀.₅-L6）在平均成功率上仅比教师（96%）下降约1%（至95%），同时FLOPs和CUDA推理时间减少了超过一半（FLOPs从3.39T降至1.30T，时间从25.5ms降至11.3ms）。与SmolVLA相比，Shallow-π在成功率和延迟方面均表现更优。这表明蒸馏大容量模型比从头训练小主干更有效，且联合减少VLM和动作头深度能带来更优的效率。</p>
<p><img src="https://arxiv.org/html/2601.20262v1/img/pi05_similarity_and_success_drop_edited.png" alt="层跳过分析"></p>
<blockquote>
<p><strong>图3</strong>：（上）特征相似性随噪声水平τ的变化趋势。（下）π₀.₅在LIBERO上的层敏感性分析（跳过单层导致的平均成功率下降）。结果表明，基于相似性的跳过规则在τ上不稳定，且相似性不能预测功能重要性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.20262v1/img/sr-along-layer.png" alt="成功率随跳过层数变化"></p>
<blockquote>
<p><strong>图4</strong>：LIBERO成功率随跳过的Transformer层数增加而下降。即使按照敏感性顺序移除层，跳过超过三层后成功率也会急剧下降，证明了测试时层跳过方法的根本局限性。</p>
</blockquote>
<p><strong>消融实验</strong>：表1展示了损失设计和注意力蒸馏放置位置的消融结果。(a) 表明结合 (L_{\text{task}})、(L_{\text{kd}}) 和 (L_{\text{attn}}) 的复合损失在所有深度（L9, L6, L4）上都能取得最佳性能。(b) 显示在中间层应用注意力蒸馏效果最好。(c) 证实了仅蒸馏动作令牌注意力的必要性，蒸馏所有令牌注意力会导致灾难性失败。</p>
<p><strong>真实世界实验结果</strong>：如表3所示，在动态、复杂和未见过的任务中，部署在边缘设备上的6层Shallow-π模型 consistently 优于其教师模型和SmolVLA。例如，在“Peg in hole”动态任务中，Shallow-π₀取得了10/10的成功率，而教师π₀为7/10，SmolVLA为0/10。关键原因在于Shallow-π大幅降低了端到端推理延迟（例如，在Jetson Orin上从教师的364ms降至110ms），从而减少了开环执行时间，使机器人能够更频繁地根据最新观察做出反应，提高了在动态场景中的鲁棒性和精度。</p>
<p><img src="https://arxiv.org/html/2601.20262v1/img/jerkness_comparison.png" alt="训练曲线与动作质量"></p>
<blockquote>
<p><strong>图9</strong>：（上）流匹配损失随训练步数的变化。SmolVLA的损失约为Shallow-π的两倍。（下）真实世界训练集中动作块样本对比。Shallow-π产生的动作更平滑精确，而SmolVLA的动作更嘈杂。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.20262v1/img/open-loop-histogram.png" alt="开环执行影响"></p>
<blockquote>
<p><strong>图10</strong>：训练数据集中右臂末端执行器每帧平均平移直方图。减少的推理延迟意味着更短的开环平移距离，这对于精确操作至关重要。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.20262v1/img/openloop-failure.png" alt="开环失败示例"></p>
<blockquote>
<p><strong>图11</strong>：教师模型开环失败的实验快照示例。由于推理延迟高，教师模型无法根据更新的观察及时纠正抓取或释放姿势，而学生模型因响应更快取得了更好性能。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了Shallow-π，一个原则性的知识蒸馏框架，首次实现了对π类基于流VLA模型中VLM主干和动作头Transformer深度的联合压缩，将模型从18层压缩至6层。</li>
<li>精心设计并系统验证了一套针对此类模型的蒸馏目标，包括真实监督、教师轨迹模仿以及专门针对动作到视觉语言交叉注意力的中间层注意力转移。</li>
<li>在复杂动态操作任务和多个机器人平台（包括人形系统）上，通过工业规模的边缘设备（Jetson Orin/Thor）部署验证了方法的强现实世界性能和计算效率，实现了近10 Hz的端到端推理。</li>
</ol>
<p><strong>局限性</strong>：论文自身未明确阐述局限性，但从内容可推断，其工作聚焦于层深度压缩，并未探索与视觉令牌剪枝、减少扩散步数等其他正交效率提升方法的结合，这可能是未来进一步提升性能的方向。</p>
<p><strong>启示</strong>：</p>
<ol>
<li>对于需要逐层特征注入的VLA架构，联合压缩主干和动作头是比单独压缩更有效的效率提升路径。</li>
<li>知识蒸馏提供了一种比动态层跳过或从头训练小模型更原则、更彻底（结构性移除而非跳过）的模型压缩方法，尤其适合边缘部署。</li>
<li>在机器人VLA模型中，降低推理延迟不仅提升速度，更能通过减少开环执行误差来直接提高任务成功率，特别是在动态和复杂场景中。未来的高效VLA设计应高度重视端到端延迟指标。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本论文针对基于流的视觉-语言-动作（VLA）模型计算成本高、难以在边缘设备实时部署的问题，提出了一种名为Shallow-π的知识蒸馏框架。其核心方法是系统性地联合压缩VLM主干和扩散动作头的Transformer深度（从18层减至6层），而传统方法仅压缩主干或动态跳层。实验表明，该方法在标准操作基准上实现了超过2倍的推理加速，同时成功率下降小于1%，并在Jetson平台的多机器人复杂场景中验证了有效性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.20262" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>