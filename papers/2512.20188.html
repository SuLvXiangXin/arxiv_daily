<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.20188" target="_blank" rel="noreferrer">2512.20188</a></span>
        <span>作者: Lianyang Ma Team</span>
        <span>日期: 2025-12-23</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前主流的视觉-语言-动作（VLA）模型通常将用于语义推理的大规模视觉语言模型（VLM）与生成连续动作信号的动作专家集成在一个系统中，并以单一的统一频率运行。因此，策略性能受限于大型VLM的低推理速度。这种强制性的同步执行严重限制了在全身机器人操控（涉及更多关节、更大运动空间和动态变化的视角）中的控制稳定性和实时性能。本文针对VLA模型中语义推理（慢）与实时控制（快）因同步执行而产生的速度瓶颈，提出了一种真正异步的快-慢VLA框架新视角。其核心思路是：将系统组织为高频动作生成的快通路和丰富VLM推理的慢通路，通过一个潜表征缓冲器连接两者，并采用端到端联合训练，从而在利用大型VLM推理能力的同时实现高频全身动作生成。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的DuoCore-FS框架包含两个异步运行的子系统：一个用于语义推理和意图提取的低频慢系统，以及一个用于实时全身控制的高频快系统。</p>
<p><img src="https://arxiv.org/html/2512.20188v1/framework.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：提出的快-慢异步VLA策略框架概览。慢系统（底部）以1-3 Hz的低频运行，大型VLM解析任务指令、视觉观察和本体感知状态，产生高级语义隐藏状态（包括文本嵌入、推理特征和可学习的融合查询），并定期写入桥接缓冲器。快系统（顶部）以25-30 Hz的高控制频率从缓冲器中获取最新的潜在语义表征，将其与当前视觉特征和本体感知状态融合，并使用基于Transformer的扩散策略解码器生成平滑、连续、完全协调的全身动作。</p>
</blockquote>
<p><strong>整体流程</strong>：慢系统以1-3 Hz的频率，利用大型VLM处理当前的多模态观察（多视角图像和本体状态）和任务指令，生成结构化的语义输出（如思维链、粗略离散动作令牌）和可学习的融合查询。这些表征被周期性刷新至一个<strong>桥接缓冲器</strong>中。快系统以25-30 Hz的控制频率，从缓冲器中获取最新的潜表征，将其与当前时刻的感知输入融合，并通过一个扩散策略解码器生成连续的全身动作块。缓冲器实现了信息生成与消费的解耦，是异步执行的关键。</p>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>慢系统（语义推理）</strong>：使用如PaliGemma-3B等VLM，接收多模态观察和任务指令，生成语义输出。训练目标为负对数似然损失 ℒ_slow，鼓励模型产生与多模态上下文对齐的语义和推理表征。</li>
<li><strong>桥接缓冲器</strong>：存储由VLM产生的任务相关语义和推理表征，特别是<strong>可学习的融合查询</strong>。这些查询通过跨模态注意力聚合任务相关的语义线索，其参数ψ通过快系统的动作生成目标进行训练，从而学习最能支持全身动作生成的语义特征。缓冲器作为慢、快系统之间的可微分接口，支持端到端训练。</li>
<li><strong>快系统（动作生成）</strong>：作为一个类似Pi0-small的扩散策略网络，以约25-30 Hz运行。它将所有条件模态（当前观察、缓冲器中的融合查询、原始指令嵌入）投影到共享嵌入空间并拼接，由Transformer编码器处理，为扩散过程生成条件信号。其优化目标是预测去噪向量场，损失函数ℒ_fast为预测噪声与真实噪声之间的L2距离。</li>
<li><strong>全身动作分词器</strong>：为25自由度的全身动作空间提供紧凑的离散表示。动作被分解为位置、旋转和夹爪三个语义分明的流。每个流由独立的轻量级1D卷积编码器-解码器和残差向量量化（RVQ）模块处理，使用包括L2重建损失和SO(3)测地损失在内的目标进行训练。训练后，编码器将连续动作块转换为离散令牌序列。</li>
</ol>
<p><strong>创新点</strong>：</p>
<ul>
<li><strong>真正的并行异步执行</strong>：快慢通路完全并行，动作生成频率最终由快通路决定，突破了同步架构中快系统必须等待慢系统的限制。</li>
<li><strong>跨V-L-A对齐的桥接缓冲器</strong>：不仅存储指令嵌入，还通过可训练的融合查询提供与场景-指令上下文对齐的高级动作推理表征，为快系统提供语义指导。</li>
<li><strong>端到端的跨时间尺度协同训练</strong>：采用两阶段训练策略，并在联合训练阶段引入<strong>跨时间尺度采样</strong>，模拟部署时的异步时序，以消除训练-推理失配。</li>
</ul>
<p><img src="https://arxiv.org/html/2512.20188v1/co_training.jpg" alt="协同训练策略"></p>
<blockquote>
<p><strong>图2</strong>：跨时间尺度协同训练示意图。慢系统处理观察o_t0，而快系统接收一个时间偏移的观察o_{t0+Δ}，其中Δ服从均匀分布。这种策略模拟了真实部署中的异步时序，实现一致的端到端优化。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>平台与数据</strong>：在Astribot S1移动双臂机器人平台上进行实验。训练数据收集于一个商业爆米花售卖亭场景，包含1780条演示轨迹（总计10.22小时），涵盖一个长视野的爆米花舀取任务和一个短视野的关闭饮料柜门任务。</li>
<li><strong>任务</strong>：长视野爆米花舀取任务被分解为四个顺序子任务：1) 拿起纸杯；2) 取勺子；3) 舀爆米花；4) 将杯子放回桌子。</li>
<li><strong>评估指标</strong>：报告每个子任务的条件成功率（仅当该子任务可达时才计算成功率）。</li>
<li><strong>对比基线</strong>：包括同步的Fast-Slow VLA模型以及异步基线FiS-VLA。</li>
</ul>
<p><strong>关键结果</strong>：</p>
<ol>
<li><strong>整体性能</strong>：在爆米花舀取任务上，DuoCore-FS在四个子任务上的平均条件成功率达到**85.8%<strong>，显著优于同步基线（平均</strong>58.3%<strong>）和异步基线FiS-VLA（平均</strong>72.5%<strong>）。在关闭柜门任务上，DuoCore-FS成功率</strong>100%<strong>，同步基线为</strong>80%**。</li>
<li><strong>推理速度</strong>：DuoCore-FS支持30 Hz的全身动作块生成，比具有可比模型规模的现有VLA模型快约<strong>三倍</strong>。</li>
</ol>
<p><img src="https://arxiv.org/html/2512.20188v1/cup_scoop_in_distribution.png" alt="任务成功率和响应性对比"></p>
<blockquote>
<p><strong>图4</strong>：在分布内场景下的爆米花舀取任务性能对比。DuoCore-FS（橙色）在四个子任务上均取得了最高的条件成功率，尤其在后续子任务中优势明显，显示了其更好的长视野协调与鲁棒性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.20188v1/anomaly_case.png" alt="异常情况处理"></p>
<blockquote>
<p><strong>图5</strong>：异常情况（杯子意外翻倒）下的定性结果。DuoCore-FS能够从翻倒状态中恢复并成功完成任务，而同步基线则失败，展示了异步框架在处理意外干扰时更强的响应性和适应性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.20188v1/language_following_compare.png" alt="语言指令遵循对比"></p>
<blockquote>
<p><strong>图6</strong>：复杂语言指令遵循的定性对比。当指令变为“用左手舀爆米花”时，DuoCore-FS成功切换了主导手臂，而同步基线未能遵循指令，仍使用右手，突显了DuoCore-FS更强的语义理解和策略调整能力。</p>
</blockquote>
<p><strong>消融实验总结</strong>：<br>论文通过消融实验验证了关键组件的贡献：</p>
<ul>
<li><strong>桥接缓冲器设计</strong>：仅使用原始指令嵌入而不使用可学习融合查询，会导致性能显著下降，证明了融合查询对于传递有效高级指导的重要性。</li>
<li><strong>训练策略</strong>：移除跨时间尺度采样（即让快慢系统使用完全相同的观察进行训练）会导致性能下降，证实了该策略对于模拟异步部署、减少训练-推理差距的必要性。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>DuoCore-FS</strong>，一个真正异步并行的快-慢VLA框架，通过桥接缓冲器解耦语义推理与实时控制，实现了在利用大型VLM（如3B参数）的同时达到30Hz的高频全身动作生成。</li>
<li>设计了<strong>跨V-L-A对齐的桥接缓冲器</strong>和<strong>全身动作分词器</strong>，前者通过可训练的融合查询提供丰富的语义指导，后者为高维全身动作提供了紧凑统一的表示。</li>
<li>引入了<strong>跨时间尺度的协同训练策略</strong>，通过模拟异步时序进行端到端联合优化，确保了策略在部署时的一致性与性能。</li>
</ol>
<p><strong>局限性</strong>：论文提到，该方法需要相对大量的高质量演示数据（10+小时）进行训练。此外，虽然响应性增强，但对于极其快速动态的障碍物，纯反应式的快系统可能仍需与更高级的重新规划结合。</p>
<p><strong>启示</strong>：</p>
<ul>
<li>异步设计范式可有效解决大型基础模型推理速度与机器人实时控制需求之间的矛盾，为未来在机器人中部署更强大但更耗时的模型提供了可行路径。</li>
<li>桥接缓冲器作为一种“语义内存”的机制，允许高级意图以低频更新、持续影响高频控制，这种思想可扩展到其他需要混合时间尺度处理的智能体架构中。</li>
<li>端到端训练下的跨时间尺度对齐方法，对涉及不同频率模块协同工作的其他序列决策问题具有借鉴意义。</li>
</ul>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对现有视觉-语言-动作模型在全身机器人操控中因同步执行导致推理速度慢、控制稳定性差的问题，提出异步快慢VLA框架DuoCore-FS。其核心是通过潜在表示缓冲区连接慢速语义推理与高频动作生成路径，并采用全身动作标记器统一表示动作。该框架支持30亿参数VLM的同时，实现了30Hz的全身动作生成，速度提升约3倍。真实实验表明其任务成功率与响应性均显著优于同步基线。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.20188" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>