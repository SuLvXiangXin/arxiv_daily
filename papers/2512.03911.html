<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Autonomous Reinforcement Learning Robot Control with Intel’s Loihi 2 Neuromorphic Hardware - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Autonomous Reinforcement Learning Robot Control with Intel’s Loihi 2 Neuromorphic Hardware</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.03911" target="_blank" rel="noreferrer">2512.03911</a></span>
        <span>作者: Carl Glen Henshaw Team</span>
        <span>日期: 2025-12-03</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在空间和移动机器人等应用中，功耗是关键的约束因素。虽然基于GPU的数据驱动学习和深度强化学习（DRL）推动了机器人控制的进步，但其高能耗阻碍了在功耗敏感场景下的部署。同时，直接训练性能可与人工神经网络（ANN）媲美的脉冲神经网络（SNN）仍面临挑战，例如需要通过时间反向传播，训练时间通常比同结构ANN长约10倍。</p>
<p>本文针对机器人控制中高能耗的痛点，提出了一条结合ANN训练便利性与SNN执行能效的新路径。具体而言，本文的核心思路是：首先在仿真中使用标准DRL方法（如PPO）训练一个ANN控制策略，然后通过转换流程将其转化为适用于Intel Loihi 2神经形态硬件的Sigma-Delta脉冲神经网络（SDNN），最终实现低延迟、高能效的机器人控制推理。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文方法的整体流程（Pipeline）如下：1）在NVIDIA Omniverse Isaac Lab高保真物理仿真环境中，使用近端策略优化（PPO）算法训练一个用于控制Astrobee自由飞行机器人（6自由度）的ANN策略网络（Actor）；2）将该训练好的ANN转换为SDNN；3）将SDNN部署到Intel Loihi 2神经形态处理器上；4）在闭环仿真中评估其控制性能、延迟和能效。输入是机器人的12维观测状态（包括线速度、角速度、相对于目标的位置和姿态误差），输出是6维的力和扭矩控制指令。</p>
<p>核心模块是ANN到SDNN的转换。为确保兼容性，ANN需使用ReLU激活函数。转换时，网络各层被映射为SDNN的特殊层：输入层转换为Delta层，隐藏层转换为Sigma-Delta-ReLU层，输出层转换为Sigma层。Delta层的作用是差分编码，它仅在当前输入值<code>x[t]</code>与上一个参考值<code>x_ref[t-1]</code>的差值超过阈值<code>ϑ</code>（本文设为0.1）时，才会产生一个输出脉冲<code> s[t]</code>，并更新参考值（公式4）。这种机制实现了基于变化的稀疏通信。Sigma层作为解码器，在接收端对传入的脉冲进行累加，以重建原始信号（公式5）。Sigma-Delta-ReLU层则是一个封装了ReLU激活函数的Sigma和Delta组合。</p>
<p>与现有方法相比，本文的创新点具体体现在：1）首次将ANN到SDNN的转换流程应用于机器人控制任务，而非此前展示的视听信号处理；2）利用了Loihi 2对分级（整数）脉冲（graded spikes，支持24位整数幅度）的原生支持，使得量化后的SDNN可以直接高效映射到硬件；3）该方法可扩展至更深的网络（本文使用12x64x64x6的四层网络），而不局限于浅层SNN。在执行阶段，来自仿真的浮点观测值被量化后输入SDNN，在Loihi 2上完成整数运算，输出动作再被反量化回浮点数送入仿真环境。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在NVIDIA Isaac Lab仿真环境中进行，使用Astrobee机器人模型。评估了两个任务：1）<strong>Undock机动</strong>：沿X轴移动0.5米并保持姿态，与在国际空间站硬件上测试过的任务相同；2）<strong>随机机动</strong>：目标位置在初始位置±0.5米范围内随机，目标姿态在各轴±60度范围内随机。每个任务在10个随机种子下各运行10次。对比的基线是原始ANN在NVIDIA Quadro RTX 8000 GPU上的推理性能。评估指标包括控制精度（位置和姿态跟踪误差的均方根误差RMSE和最终误差）、延迟、吞吐量、能耗及能耗延迟积（EDP）。</p>
<p><img src="https://arxiv.org/html/2512.03911v1/figs/fig_position_error_timeseries.png" alt="位置跟踪误差"></p>
<blockquote>
<p><strong>图1</strong>：平均位置跟踪误差（米）随时间步长的变化。对比了GPU运行ANN（蓝、橙线）和Loihi 2运行SDNN（浅灰、深灰线）在10次随机机动和10次undock机动中的表现，阴影部分为95%置信区间。SDNN的最终位置误差更大。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.03911v1/figs/fig_orientation_error_timeseries_deg.png" alt="方向跟踪误差"></p>
<blockquote>
<p><strong>图2</strong>：平均姿态跟踪误差（度）随时间步长的变化。颜色含义同图1。SDNN的姿态控制精度，尤其是在随机任务中，低于GPU上的ANN。</p>
</blockquote>
<p>关键定量结果总结于表I和表II。在控制性能上，Loihi 2上的SDNN略逊于GPU上的ANN。例如，在随机机动任务中，SDNN的位置RMSE比ANN高0.083米，姿态RMSE高2.73度；最终位置误差和最终姿态误差也显著更大。这表明转换和量化过程引入了精度损失。</p>
<p><img src="https://arxiv.org/html/2512.03911v1/figs/fig_throughput_vs_energy_per_inf_gpu_loihi.png" alt="吞吐量与能耗对比"></p>
<blockquote>
<p><strong>图3</strong>：每次推理的吞吐量（次/秒）与能耗（焦耳）对比图。Loihi 2上的SDNN（灰点）聚集在低能耗、高吞吐量区域，而GPU上的ANN（蓝、橙点）则位于高能耗区域。清晰展示了能效与性能的权衡。</p>
</blockquote>
<p>在能效和速度方面，Loihi 2优势显著。如表II所示，对于随机任务，SDNN在Loihi 2上的总能效（每次推理0.013 J）仅为GPU（0.217 J）的约6%；动态能效（仅网络运算）仅为GPU的12.3%。同时，Loihi 2的吞吐量（<del>472 inf/s）是GPU（</del>202 inf/s）的2.3倍以上，延迟更低，能耗延迟积（EDP）仅为GPU的5%左右。</p>
<p><img src="https://arxiv.org/html/2512.03911v1/figs/astrobee_SDNN_GPU_inference.png" alt="定性结果对比"></p>
<blockquote>
<p>**图4(a)**：GPU运行ANN推理完成undock任务的示例可视化。机器人与目标位置/姿态箭头几乎完全重叠，表示精确到达。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.03911v1/figs/astrobee_SDNN_Loihi_inference.png" alt="定性结果对比"></p>
<blockquote>
<p>**图4(b)**：Loihi 2运行SDNN推理完成同一任务的示例。机器人（红色）与目标（绿色箭头）接近但未完全重叠，存在最终误差，但控制稳定，没有大幅偏离。</p>
</blockquote>
<p>消融实验方面，论文未进行严格的组件消融研究，但通过结果分析了性能差距的来源：主要源于将浮点观测值转换为脉冲并进行量化以适应Loihi 2整数运算所引入的误差。论文指出，未来可通过训练网络更好地适应SDNN的输入表示，或优化超参数来提升性能。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）<strong>验证了可行性</strong>：首次成功演示了将RL训练的ANN策略转换为SDNN，并部署在Loihi 2神经形态硬件上用于闭环机器人控制。2）<strong>量化了能效优势</strong>：尽管控制精度有折损，但SDNN在Loihi 2上实现了数量级级别的能效提升和更高的吞吐量，明确了性能与能效之间的权衡。3）<strong>提供了一条实用路径</strong>：为在空间探索等严苛资源受限环境中部署先进、自适应的数据驱动控制器提供了一条切实可行的技术途径。</p>
<p>论文自身提到的局限性包括：转换后的SDNN控制精度低于原始ANN；当前工作仅在仿真中验证，尚未在真实机器人或搭载Loihi 2的航天器上部署；所使用的控制网络相对较小。</p>
<p>本文对后续研究的启示包括：1）可以探索在ANN到SDNN的转换流程中引入针对性的训练或微调，以弥补精度损失。2）该方法可扩展至更大、更复杂的策略网络，届时神经形态硬件的SWaP优势可能更加显著。3）这项工作为神经形态计算与机器人学的结合提供了一个强有力的案例，鼓励社区进一步开发能直接利用脉冲稀疏性和事件驱动特性的新型学习算法。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对空间与移动机器人面临的功率约束问题，提出一种将强化学习训练的人工神经网络转换为脉冲Sigma-Delta神经网络，并部署至英特尔Loihi 2神经形态硬件的端到端流程。该方法结合了人工神经网络易于训练、仿实转换的优势与脉冲神经网络的高能效特性。以Astrobee自由飞行机器人控制为测试案例，在模拟环境中验证了该流程可实现低延迟、高能效的推理，证明了神经形态硬件用于机器人控制的可行性，为功耗受限环境中的实时控制提供了新途径。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.03911" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>