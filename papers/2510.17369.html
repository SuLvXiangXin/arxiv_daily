<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.17369" target="_blank" rel="noreferrer">2510.17369</a></span>
        <span>作者: Su, Haochen, Meo, Cristian, Stella, Francesco, Peirone, Andrea, Junge, Kai, Hughes, Josie</span>
        <span>日期: 2025/10/20</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作（VLA）模型（如RT-2、OpenVLA、π₀）已成为语言引导的通用机器人控制框架，在刚体串联机械臂（如UR5）上展现出强大的任务泛化能力。然而，主流方法几乎完全聚焦于刚体机器人，其固有的刚性限制了在需要安全、柔顺交互的人机共融环境中的应用。与此同时，软体连续机械臂因其固有的柔顺性和碰撞安全性，非常适合人机交互场景，但其非线性、欠驱动的动力学特性使得传统控制复杂，且VLA模型在此类平台上的部署尚属空白。这导致了一个关键的“具身鸿沟”：在刚体机器人上训练的策略能否有效迁移到动力学和形态完全不同的软体机器人上？本文针对这一具体痛点，首次系统性地研究了将VLA模型部署到软体连续机械臂上，通过设计一个结构化的微调流程，证明了即使存在巨大的动力学差异，经过针对性微调的VLA模型也能在软体平台上达到与刚体平台相当的性能。本文的核心思路是：提出并实施一个涵盖任务设计、数据收集、预处理、模型适配和评估的完整流程，将OpenVLA-OFT和π₀两种先进的VLA模型部署到定制的软体机器人上，通过实验验证微调对于桥接刚体与软体之间具身鸿沟的必要性和有效性。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文采用一个结构化的流程来研究VLA模型在软体机器人上的部署，该流程包括任务设计、数据收集、预处理、模型适配和评估五个阶段。输入是语言指令和多模态观测（第三人称图像、腕部图像、本体感知状态），输出是机器人末端执行器的连续动作序列。</p>
<p><strong>核心模块1：机器人平台与任务设计</strong>。研究使用UR5刚体机械臂作为基准，并使用定制的软体连续机械臂“Embuddy”作为软体平台。Embuddy由三个模块化部分组成：一个标准旋转关节和两个肌腱驱动的软体连续段，其结构由3D打印的热塑性聚氨酯（TPU）制成，具有重量轻（5kg）和欠驱动的特性，确保了固有的交互安全性。为确保公平比较，两者使用相同的摄像头设置（第三人称和腕部视角）和夹爪。</p>
<p><img src="https://arxiv.org/html/2510.17369v1/images/soft_robot_diagram.png" alt="软体机器人平台"></p>
<blockquote>
<p><strong>图1</strong>：实验使用的软体连续机器人。A: 机器人整体视图。B: 驱动与结构示意图，显示了肌腱、关节和电机。C: 单个软体段的细节视图。D: 软体与刚体（UR5）机器人的演示设置对比。</p>
</blockquote>
<p>设计了三个代表性任务：任务1（“将橙子放入盘子”）：简单的抓取放置；任务2（“将X放入盘子”，X为橙子或牛奶）：带选择性的抓取放置；任务3（“用棉花糖喂食人”）：近距离人机交互任务。</p>
<p><strong>核心模块2：数据采集与处理</strong>。通过摇杆遥操作机器人收集演示数据。对于软体机器人，使用分段常曲率（PCC）模型进行逆运动学解算，将肌腱长度与末端执行器位姿相关联。每个演示片段捕获的观测包括第三人称图像、腕部图像、本体感知状态（末端执行器位姿）和语言指令。采集后的图像经过裁剪和缩放，并过滤掉机器人几乎无运动的片段（如夹爪抓取或释放时）。最后，根据模型配置，将状态和动作的表示转换并填充到所需的维度和格式：OpenVLA-OFT使用RLDS格式，π₀使用LeRobot格式。本文开源了这些数据集。</p>
<p><strong>核心模块3：模型微调与推理</strong>。对于基于Llama 2 7B大语言模型的OpenVLA-OFT，为平衡精度与计算成本，采用低秩自适应（LoRA）技术进行全参数微调。对于基于较小VLM骨干PaliGemma（3B参数）的π₀，则进行全参数微调。推理时，在远程GPU上进行模型预测，本地PC实时捕获观测（图像、状态、指令）并发送至远程，模型预测动作块后返回本地执行，循环此过程直至任务完成或达到最大步数。</p>
<p><strong>创新点</strong>：本文的创新性主要体现在首次系统地将VLA模型部署于软体连续机械臂，并系统性地评估了“具身鸿沟”问题。与现有工作主要关注不同刚体平台间的迁移不同，本文挑战了动力学和形态学差异更大的刚体到软体的迁移，并证明了通过相对小规模的针对性微调即可实现有效桥接。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验平台为自定义软体机器人Embuddy和UR5刚体机器人。评估了OpenVLA-OFT和π₀两种VLA模型在三个设计任务上的性能。Baseline对比包括未经微调的原始模型（开箱即用）以及微调后的模型。</p>
<p>关键实验结果如下：首先，所有未经微调的原始模型（开箱即用策略）在软体机器人上均告失败。主要原因是软体机器人与刚体机器人的动力学不匹配，特别是从末端执行器位姿到内部构型的映射不同。由于各软体段存在最大弯曲角度限制，模型生成的适用于刚体机械臂的运动会导致软体机器人卡住。这突显了刚软机器人之间存在显著的领域差距，并证明了微调对于有效策略迁移的必要性。</p>
<p><img src="https://arxiv.org/html/2510.17369v1/x1.png" alt="成功率对比"></p>
<blockquote>
<p><strong>图2</strong>：OpenVLA-OFT和π₀在UR5和软体机器人上的推理成功率比较。左图显示，微调后的OpenVLA-OFT在UR5和软体机器人上，于任务1和任务2上取得了完全相同的成功率（均为100%）。这表明微调策略成功桥接了刚体到软体的领域鸿沟。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.17369v1/x2.png" alt="成功率对比"></p>
<blockquote>
<p><strong>图3</strong>：π₀在软体机器人上的推理成功率。右图显示，π₀经过微调后也能在软体机器人上取得较高的成功率，尽管在任务1和任务3上略低于OpenVLA-OFT。</p>
</blockquote>
<p>具体数值总结：微调后，OpenVLA-OFT在软体机器人上的任务1和任务2成功率均达到100%，与在UR5上的性能持平。π₀在软体机器人上经过微调后也取得了成功，但在任务1和任务3上的成功率略低于OpenVLA-OFT。值得注意的是，尽管π₀在刚体具身上表现出更好的泛化能力，但在经过适当微调后迁移到动力学完全不同的新平台时，OpenVLA-OFT的表现优于π₀。此外，即使存在较大的网络延迟，软体机器人控制回路仍能保持至少25Hz的频率运行。</p>
<p><strong>消融实验与组件贡献</strong>：核心的消融实验体现在“微调”与“不微调”的对比上。实验明确证明，微调是使VLA模型适应软体机器人动力学的关键组件。没有微调，模型完全无法工作；经过微调，模型性能达到与刚体基准相当的水平。这直接回答了关于“具身鸿沟”的核心问题，并量化了微调这一组件的贡献（从0%成功率提升至接近100%）。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) <strong>首次开源了软体机器人的演示数据集</strong>，为可重复的合规具身研究奠定了基础；2) <strong>首次系统性地将VLA模型部署于软体连续机械臂</strong>，并通过实验证明，通过针对性的微调可以有效地桥接刚体与软体机器人之间的“具身鸿沟”，使微调后的策略在软体平台上达到与刚体基准相当的高成功率；3) <strong>对比了两种先进的VLA模型（OpenVLA-OFT和π₀）在软体平台上的表现</strong>，发现尽管π₀在刚体上泛化更强，但在适应软体动力学后，OpenVLA-OFT取得了更优的性能。</p>
<p><strong>论文提到的局限性</strong>：本研究仅在单一自定义软体机器人平台和三个特定任务上进行了验证。未来研究需要将调查扩展到更广泛的任务类型和更多样化的合规机器人平台上。</p>
<p><strong>对后续研究的启示</strong>：这项工作证实了VLA模型的高级推理能力能够与软体机器人的内在安全性有效结合，为开发适用于人机共融环境的安全、自适应、智能的具身智能体指明了一个有前景的方向。它鼓励社区超越刚体机器人的范畴，探索VLA模型在更广泛机器人形态上的应用，并强调了为特定具身平台收集数据并进行针对性适配的重要性。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文研究如何将视觉-语言-动作（VLA）模型部署于软体连续机械臂，以解决现有VLA策略因训练数据集中于刚性机械臂而导致的“具身鸿沟”问题。论文提出结构化微调流程，评估了OpenVLA-OFT和π₀两种VLA模型在代表性操作任务上的表现。核心实验表明，未经微调的预训练策略因具身不匹配而失效，但通过针对性微调，软体机器人能达到与刚性机器人相当的性能，从而验证了微调对于桥接具身鸿沟的必要性，并展示了VLA模型与软体机器人结合可实现人机共存环境下的安全、灵活具身智能。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.17369" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>