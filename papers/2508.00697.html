<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>On-Device Diffusion Transformer Policy for Efficient Robot Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>On-Device Diffusion Transformer Policy for Efficient Robot Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.00697" target="_blank" rel="noreferrer">2508.00697</a></span>
        <span>作者: Dong Xu Team</span>
        <span>日期: 2025-08-01</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>扩散策略通过模仿学习在机器人操作任务中取得了显著成功，但其在资源受限的移动平台上的应用面临两大关键挑战：1）扩散策略需要多次去噪步骤，导致生成过程缓慢；2）标准架构参数数量庞大，内存占用高。这阻碍了其在移动机器人等平台上的实时应用。现有加速工作（如DeeR-VLA）虽能减少GPU计算，但其早期退出策略对移动平台并非最优。本文针对扩散策略在移动设备上部署的计算效率低下这一具体痛点，提出了一个名为LightDP的新框架。其核心思路是通过压缩去噪网络和减少采样步数两大策略，在保持竞争力的性能前提下，实现移动设备上的实时动作预测。</p>
<h2 id="方法详解">方法详解</h2>
<p>LightDP的整体目标是对预训练的策略模型进行加速（剪枝与蒸馏），然后将其部署到移动设备上。其核心创新在于将模型剪枝与一致性蒸馏整合在一个统一的框架中，以同时压缩模型大小并减少推理步数。</p>
<p>首先，论文对两种代表性的扩散策略架构进行了详细的延迟分析：DiffusionPolicy Transformer (DP-T) 和 MDT-V。分析揭示了模型瓶颈所在。</p>
<p><img src="https://arxiv.org/html/2508.00697v1/x1.png" alt="网络架构"></p>
<blockquote>
<p><strong>图1</strong>：MDT-V模型的网络架构。模型由三个主要组件构成：观测编码器（𝑬）、目标编码器（𝑮）和扩散变换器（𝑫）。</p>
</blockquote>
<p>如表1所示，在iPhone 13上，DP-T的扩散变换器（8层Transformer）单次推理延迟为0.906ms，但由于需要100次去噪步骤，总延迟高达90.6ms，成为主要瓶颈。MDT-V的扩散变换器（10步）总延迟为22.25ms，同样远高于其视觉编码器（7.56ms）。因此，加速的重点在于压缩扩散变换器并减少其调用次数（采样步数）。</p>
<p>LightDP的核心方法包含两个紧密耦合的部分：</p>
<ol>
<li><strong>通过学习的模型剪枝</strong>：目标是移除扩散变换器中的冗余层。传统剪枝方法（两阶段：先确定剪枝掩码，再微调）可能导致次优性能。LightDP采用单阶段剪枝方法，将每一层是否保留的二元掩码 $\mathcal{M}_i$ 建模为伯努利分布 $\text{Bernoulli}(p_i)$，其中门控分数 $p_i$ 作为可学习参数。在训练过程中，模型权重 $\hat{\phi}$ 和门控分数 $p_i$ 被联合优化，以最小化剪枝后的损失，从而显式地建模和优化剪枝后模型的性能可恢复性。门控分数的初始化基于奇异值分解（SVD）估算的层重要性。</li>
<li><strong>结合一致性蒸馏减少步数</strong>：为了在减少推理步数（NFE）的同时保持动作预测精度，LightDP将上述剪枝策略与一致性蒸馏相结合。</li>
</ol>
<p><img src="https://arxiv.org/html/2508.00697v1/x2.png" alt="训练流程"></p>
<blockquote>
<p><strong>图2</strong>：LightDP的训练流程。左侧为一致性蒸馏流程：学生模型 $f_\phi$ 由教师模型 $f_\psi$ 初始化并剪枝。给定数据 $( \boldsymbol{o}, \boldsymbol{a}, \mathbf{g} )$，添加噪声得到 $\boldsymbol{a}<em>t$，教师模型预测 $\boldsymbol{a}</em>{t+k}$，学生模型和目标模型 $f_{\phi^\star}$ 分别对 $\boldsymbol{a}<em>t$ 和 $\boldsymbol{a}</em>{t+k}$ 进行预测，并计算一致性损失。目标模型通过学生模型的动量进行更新。右侧展示了“通过学习剪枝”技术，即可学习的门控分数。</p>
</blockquote>
<p>整个训练流程（图2）统一了剪枝和蒸馏：学生模型从教师模型初始化，并应用上述可学习剪枝技术得到压缩结构。在一致性蒸馏中，学生模型和目标模型（通过动量更新与学生模型同步）被要求对同一轨迹上不同噪声水平的数据点输出一致的预测，损失函数为 $\mathcal{L}_{CD}$。通过这种方式，压缩后的学生模型能够学会用更少的步骤（论文中降至4步）生成高质量的动作序列。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在四个标准机器人操作数据集上进行评估：PushT、Robomimic（Can和Square任务）、CALVIN和LIBERO。实验平台包括iPhone 13（搭载16核Apple Neural Engine）和NVIDIA Jetson Orin NX。对比的基线方法包括原始DP-T、MDT-V模型，以及仅剪枝或仅蒸馏的变体。</p>
<p>关键实验结果如下：在PushT数据集上，原始DP-T的成功率为85.3%，延迟为90.6ms；经过LightDP加速后，模型在延迟降至2.72ms的同时，成功率保持在84.7%。在Robomimic Can任务上，原始MDT-V的成功率为85.1%，延迟22.25ms；LightDP模型延迟降至4.1ms，成功率为84.0%。在CALVIN和LIBERO等多任务、多模态数据集上，LightDP同样能在将延迟降低一个数量级（从约200ms降至约20ms）的同时，保持与原始模型相当的成功率。</p>
<p><img src="https://arxiv.org/html/2508.00697v1/x3.png" alt="消融实验"></p>
<blockquote>
<p><strong>图3</strong>：在PushT和Robomimic（Can）任务上的消融研究。对比了原始模型、仅剪枝模型、仅蒸馏模型以及完整的LightDP（剪枝+蒸馏）。结果表明，单独的剪枝或蒸馏都会导致性能下降，而两者结合的LightDP能在极低延迟下几乎完全恢复性能。</p>
</blockquote>
<p>消融实验（图3）清晰展示了各组件贡献：单独的剪枝或一致性蒸馏虽然能降低延迟，但都会带来明显的性能下降。而将两者结合的LightDP框架，能够在实现极低延迟（~2-4ms）的同时，使性能几乎完全恢复到原始水平，证明了统一框架的有效性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）首次系统性地探讨并实现了扩散策略在移动设备上的高效部署，提出了LightDP框架；2）通过可学习的单阶段剪枝技术，显式优化模型剪枝后的可恢复性；3）创新地将剪枝与一致性蒸馏统一在一个框架内，协同实现了模型压缩与采样步数缩减，在多个基准数据集上验证了其有效性。</p>
<p>论文提到的局限性包括：在CALVIN等非常复杂的多任务场景中，加速后的模型性能相比原始模型仍有轻微下降（约1-2%）。这对后续研究的启示是：需要进一步探索更高效的架构设计或训练范式，以在极度压缩的模型上处理高度复杂的多模态、长时序任务。此外，将此类加速框架与更先进的底层扩散模型或策略学习方法结合，也是一个有前景的方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对扩散策略在资源受限移动平台上部署时存在的计算效率低、内存占用大的问题，提出LightDP框架。通过**网络压缩**（采用统一的剪枝与重训练流程优化去噪模块）与**减少采样步骤**（结合一致性蒸馏技术）两项核心技术，显著提升推理速度。实验在PushT等多个标准数据集上验证，LightDP能在移动设备上实现实时动作预测，且性能与先进扩散策略相当。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.00697" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>