<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.12952" target="_blank" rel="noreferrer">2601.12952</a></span>
        <span>作者: Mingxuan Jiang Team</span>
        <span>日期: 2026-01-19</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>航天器交会对接控制的主流方法包括基于精确动力学模型的传统控制方法（如PID、模型预测控制MPC、滑模控制SMC）以及基于深度强化学习（DRL）的方法。前者严重依赖精确的模型，在存在未知扰动时鲁棒性受限；后者虽不显式依赖模型，但其性能高度敏感于奖励函数设计，且训练过程漫长。模仿学习（IL）通过从专家演示中直接学习策略，避免了上述问题，但行为克隆（BC）等简单IL方法难以捕捉交会对接这类长时域、强耦合任务中的时序依赖关系，导致生成的动作序列在时序上不一致、不稳定。本文针对传统方法对模型的依赖、DRL对奖励设计的敏感以及简单IL的长时域控制不稳定性等痛点，提出了一种基于模仿学习的航天器交会对接控制框架（IL-SRD）。其核心思路是：利用基于Transformer的架构学习专家演示中的长时域时序依赖，并引入锚定解码目标（ADT）机制和时间聚合机制，分别确保生成动作的物理一致性并抑制序列预测中的误差累积，从而实现无需模型、稳定可靠的六自由度控制。</p>
<h2 id="方法详解">方法详解</h2>
<p>IL-SRD方法的整体框架是一个基于Transformer的变分自编码器（VAE）编码器-解码器结构，旨在根据当前状态预测未来一段时域内的动作序列。</p>
<p><img src="https://arxiv.org/html/2601.12952v1/x1.jpg" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：IL-SRD网络结构。左侧为训练阶段：当前状态和未来的专家动作序列经投影网络嵌入后，与位置编码相加，输入到Transformer编码器中，编码器输出经线性层得到潜在变量的均值和方差，通过重参数化采样得到潜在变量z；解码阶段，潜在变量z和当前状态共同构成解码器记忆，解码器查询（Queries）由经过投影的、重复了n次（预测步长）的当前状态（即锚点）构成，解码器通过交叉注意力机制输出预测的动作序列。右侧为评估阶段：由于没有未来专家动作，潜在变量z设为零向量。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>专家演示生成</strong>：为解决遥操作演示存在的振荡和次优问题，本文采用非线性MPC生成高质量专家数据。MPC以状态误差、控制能耗和终端误差构建成本函数，并考虑动力学约束和执行器约束，通过序列二次规划（SQP）求解，生成平滑、节能且动力学一致的控制轨迹。共收集50条轨迹，每条2500步，并注入随机噪声以模拟扰动和传感器不确定性。</li>
</ol>
<p><img src="https://arxiv.org/html/2601.12952v1/x3.png" alt="专家演示分布"></p>
<blockquote>
<p><strong>图3</strong>：专家演示的状态分布。初始条件覆盖正负值，鼓励模型学习全局收敛行为而非平凡的映射；四元数标量分量收敛于1或-1，反映了四元数的符号歧义性。</p>
</blockquote>
<ol start="2">
<li><strong>VAE编码器</strong>：输入为当前状态 <code>s_t</code> 和未来n步的专家动作序列 <code>â_{t:t+n}</code>。两者分别通过投影网络 <code>ψ_s</code> 和 <code>ψ_a</code> 映射到共享的高维嵌入空间，拼接后加入位置编码 <code>P_VAE</code>，形成序列 <code>E</code>。Transformer编码器处理 <code>E</code>，通过自注意力机制捕捉状态与动作序列间的复杂时序依赖。编码器输出经线性层得到潜在变量z的均值 <code>μ</code> 和对数方差 <code>log σ²</code>，通过重参数化技巧 <code>z = μ + σ ⊙ ε</code> 采样得到z，z封装了专家演示的潜在结构。评估时，z设为零向量。</li>
<li><strong>锚定解码目标（ADT）机制</strong>：这是确保物理一致性的关键创新。解码器的查询（Queries）并非传统的可学习参数或位置编码，而是由经过投影的、重复了n次的当前状态构成。这意味着解码器在生成每个未来时刻的动作时，其“查询”都显式地锚定在同一个物理状态参考上。这种设计强制模型在预测动作时紧密关联当前物理状态，有效抑制了可能违反动力学或执行器约束的不合理动作偏差。</li>
<li><strong>解码器与时间聚合机制</strong>：解码器记忆 <code>M</code> 由潜在变量z和当前状态 <code>s_t</code> 的投影拼接而成。解码器以ADT生成的查询对记忆进行交叉注意力计算，最终输出预测的n步动作序列。<strong>时间聚合机制</strong>体现在：模型一次性预测一个动作序列（n步），而非逐步单步预测。这减少了解耦预测的总步数，从而在长时域任务中显著缓解了因每一步微小误差累积和放大而导致的性能退化问题。预测的动作序列会被循环执行，直到下一个预测周期。</li>
</ol>
<p><strong>创新点总结</strong>：与现有方法相比，IL-SRD的创新在于：1) 采用序列到序列的Transformer架构直接学习长时域控制策略，克服了简单BC的时序建模不足；2) 提出ADT机制，将解码过程锚定于物理状态，确保了动作生成的物理可行性与一致性；3) 通过序列预测结合时间聚合，有效抑制了长时域序列预测中的误差传播问题。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在自定义的航天器六自由度动力学仿真环境中进行验证。动力学模型基于线性Clohessy-Wiltshire方程（平动）和刚体旋转动力学（转动），使用四阶龙格-库塔法积分。评估指标包括任务成功率、平动/姿态误差、燃料消耗（ΔV）等。</p>
<p><strong>对比的Baseline方法</strong>：</p>
<ul>
<li><strong>MPC</strong>：生成专家演示的控制器，作为性能上限参考。</li>
<li><strong>滑模控制（SMC）</strong>：一种鲁棒性强的传统模型基控制器。</li>
<li><strong>深度强化学习（DRL）</strong>：基于PPO算法训练的控制器。</li>
<li><strong>行为克隆（BC）</strong>：简单的状态-动作映射模仿学习。</li>
</ul>
<p><img src="https://arxiv.org/html/2601.12952v1/x4.jpg" alt="定量结果对比"></p>
<blockquote>
<p><strong>图4</strong>：各方法在50次随机初始条件下的蒙特卡洛仿真结果对比。IL-SRD在成功率（100%）、终端位置误差（0.0023 m）、终端姿态误差（0.0007 rad）和燃料消耗（ΔV 0.8171 m/s）上均显著优于SMC、DRL和BC，性能最接近MPC。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.12952v1/x5.png" alt="轨迹对比"></p>
<blockquote>
<p><strong>图5</strong>：典型初始条件下各方法的控制轨迹对比。IL-SRD的轨迹平滑且收敛迅速，与MPC（专家）最为接近；SMC存在抖振；DRL收敛缓慢且有振荡；BC则完全发散。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.12952v1/x6.png" alt="消融实验"></p>
<blockquote>
<p><strong>图6</strong>：消融实验结果。(a) 移除ADT机制导致位置和姿态控制发散，证明了ADT对物理一致性的关键作用。(b) 移除时间聚合（即改为逐步预测）导致误差随时间累积放大，最终任务失败，证明了时间聚合对稳定长时域控制的必要性。</p>
</blockquote>
<p><strong>鲁棒性评估</strong>：在仿真中施加持续的外部力/力矩扰动和周期性正弦扰动。</p>
<p><img src="https://arxiv.org/html/2601.12952v1/x7.png" alt="扰动下性能"></p>
<blockquote>
<p><strong>图7</strong>：在持续未知扰动下，IL-SRD仍能维持100%成功率和接近无扰动的性能，而SMC和DRL的成功率分别下降至94%和86%，证明了IL-SRD强大的鲁棒性。</p>
</blockquote>
<p><strong>关键实验结果总结</strong>：</p>
<ul>
<li><strong>性能</strong>：IL-SRD在50次蒙特卡洛测试中达到<strong>100%<strong>成功率，平均终端位置误差</strong>0.0023 m</strong>，姿态误差<strong>0.0007 rad</strong>，燃料消耗<strong>0.8171 m/s</strong>，全面优于SMC、DRL和BC，且非常接近专家MPC的性能。</li>
<li><strong>消融实验</strong>：移除ADT机制导致控制完全发散；移除时间聚合（改为单步预测）导致误差累积和任务失败。这分别验证了<strong>ADT机制</strong>和<strong>时间聚合机制</strong>对于实现稳定、精确的长时域控制是不可或缺的核心组件。</li>
<li><strong>鲁棒性</strong>：在显著未知扰动下，IL-SRD保持了**100%**的成功率和稳定的性能，显著优于SMC和DRL。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了IL-SRD框架，首次将基于Transformer的序列到序列模仿学习成功应用于六自由度航天器交会对接这一复杂长时域控制任务，实现了无需精确动力学模型和复杂奖励设计的模型无关控制。</li>
<li>创新性地设计了锚定解码目标（ADT）机制，通过将解码查询锚定于当前状态，显式地强制了生成动作序列的物理一致性，有效避免了不合理或危险的控制指令。</li>
<li>引入了时间聚合机制，通过预测并执行动作序列而非单步动作，显著缓解了基于Transformer的序列模型在长时域预测中的误差累积问题，提升了控制的长期稳定性。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，该方法依赖于专家演示的质量。虽然本文使用MPC生成了高质量数据，但在实际应用中，获取大量覆盖所有可能工况的最优专家演示可能具有挑战性。此外，方法在极端、训练数据未覆盖的扰动下的表现仍有待进一步验证。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>数据效率与泛化</strong>：可以探索结合少量交互数据（在线学习或混合模仿学习与强化学习）来提升策略在分布外状态下的泛化能力和对未知扰动的适应性。</li>
<li><strong>专家数据来源</strong>：研究如何从非完美（如遥操作）甚至次优的演示中学习稳健策略，将极大提升方法的实用性和可部署性。</li>
<li><strong>架构扩展</strong>：当前方法主要处理状态输入，未来可扩展至多模态输入（如视觉图像），以实现更接近真实场景的感知与控制一体化。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对航天器交会对接控制方法依赖精确动力学模型、在轨鲁棒性有限的问题，提出了一种基于模仿学习的无模型控制框架IL-SRD。其核心创新在于引入了锚定解码器目标机制，通过状态相关的锚点显式约束控制生成过程，确保物理一致性；并采用时间聚合机制来抑制Transformer序列预测中的误差累积。大量仿真实验表明，该方法能实现精确、节能的六自由度交会对接控制，并在显著未知干扰下保持优异的鲁棒性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.12952" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>