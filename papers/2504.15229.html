<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Immersive Teleoperation Framework for Locomanipulation Tasks - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Immersive Teleoperation Framework for Locomanipulation Tasks</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2504.15229" target="_blank" rel="noreferrer">2504.15229</a></span>
        <span>作者: Boehringer, Takuya, Embley-Riches, Jonathan, Hammoud, Karim, Modugno, Valerio, Kanoulas, Dimitrios</span>
        <span>日期: 2025/04/21</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前机器人移动操作（Loco-manipulation）的远程操控系统，主流方法依赖于2D相机画面和摇杆控制，存在精度有限、沉浸感不足的局限性。尽管已有工作尝试集成虚拟现实（VR）技术以提升体验，但这些系统往往未能充分利用先进的可视化技术来有效处理复杂场景中的遮挡问题，也缺乏跨硬件平台的适应性。本文针对在遮挡环境下进行精细操作的具体痛点，提出将高斯泼溅（Gaussian Splatting）技术与VR相结合的新视角，以构建高保真、支持自由视角调整的虚拟环境。本文的核心思路是：通过高斯泼溅技术将远程操作场景抽象并重建为沉浸式VR环境，并采用“先移动、后操作”的两阶段框架，使操作者能够像在真实世界中一样直观地导航和操控机器人。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的框架是一个专为移动操作任务设计的两阶段VR远程操控系统，其整体流程如论文图2所示。框架包含两个主要阶段：移动阶段和操作阶段。在移动阶段，操作者通过传统控制界面（结合VR控制器和机器人基座的2D视频流）驱动机器人平台移动到目标位置。一旦抵达，系统切换至操作阶段，此时操作者在一个由高斯泼溅重建的虚拟场景中，通过直接拖拽虚拟机械臂末端执行器的方式，对真实机械臂进行精细操控。</p>
<p><img src="https://arxiv.org/html/2504.15229v1/x1.png" alt="框架结构"></p>
<blockquote>
<p><strong>图2</strong>：远程操控框架的结构示意图。框架分为两个阶段：移动阶段（Locomotion Phase），操作者通过界面控制机器人基座移动；操作阶段（Manipulation Phase），操作者在VR环境中通过高斯泼溅重建的场景操控机械臂。</p>
</blockquote>
<p>核心模块包括：</p>
<ol>
<li><strong>VR交互界面</strong>：基于Unity引擎开发，作为与操作者交互的枢纽。它通过ROS（机器人操作系统）与真实机器人通信。界面内集成了由Unity VFX Graph实现的高斯泼溅渲染效果。一个关键的创新控制策略是采用了“游戏式”的第三人称视角：将机械臂和场景的3D重建模型置于操作者面前，操作者可以在VR空间中自由环绕移动，并通过“抓取并拖拽”虚拟末端执行器来发送笛卡尔坐标指令，控制真实机械臂运动。同时，基座和末端执行器的真实相机画面会以画中画形式叠加在VR视图中，提供实时反馈。</li>
<li><strong>移动阶段</strong>：此阶段系统处于默认状态。机器人基座持续向VR界面传输2D视频流。操作者通过VR控制器发送速度指令 $(V_x, V_y)$ 控制基座移动。为减轻晕动症，2D视频被投射到VR环境中一个固定位置的屏幕上。</li>
<li><strong>基于高斯泼溅的环境重建</strong>：这是切换到操作阶段前的关键预处理步骤。首先，机械臂按预定轨迹运动，从多个视角采集场景的RGB图像。接着，使用运动恢复结构（SfM）从图像中估计相机位姿并生成稀疏3D点云。最后，利用高斯泼溅技术进行神经渲染训练，将场景表示为一组具有位置、协方差（定义形状和伸展）、颜色和不透明度属性的3D高斯分布。渲染时，每个高斯分布被投影为2D图像平面上的椭圆“泼溅”，最终合成高保真的3D模型。<br><img src="https://arxiv.org/html/2504.15229v1/extracted/6375751/figures/gaussianReconstructioncutFixed.jpg" alt="高斯泼溅重建场景"><blockquote>
<p><strong>图3</strong>：使用高斯泼溅技术在虚拟现实中重建的场景示例。该技术生成了包含遮挡物体的高保真3D环境。</p>
</blockquote>
</li>
<li><strong>操作阶段</strong>：在环境重建完成后激活。操作者置身于高斯泼溅重建的虚拟场景中，直接与虚拟机械臂交互进行操控。系统形成一个闭环：操作者移动虚拟末端执行器，其坐标通过ROS发送给真实机械臂控制器；真实机械臂的关节角度随后被反馈回Unity，用于更新VR中的机械臂模型，实现虚实同步。</li>
</ol>
<p>与现有方法相比，本文的创新点具体体现在：1) <strong>利用高斯泼溅进行沉浸式、抗遮挡的场景重建</strong>，而非依赖传统的2D视频流或简单的3D网格，提供了更逼真且支持自由探索视角的空间表示；2) <strong>采用了直观的“抓取-拖拽”式第三人称操控方式</strong>，突破了传统第一人称视角或摇杆映射的局限，充分利用了VR环境的沉浸感和空间自由度。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验部分主要包括一个用户研究（在模拟环境中）和两个真实机器人任务演示。</p>
<p><strong>用户研究</strong>：15名参与者在VR中执行一个复杂遮挡场景下的抓取-放置任务，对比了本文提出的Splat界面和一个基线界面。基线界面（图5）在VR中提供两个固定视角的机械臂相机画面（基座和末端），用户使用VR控制器的摇杆操控机械臂。<br><img src="https://arxiv.org/html/2504.15229v1/extracted/6375751/figures/baseline_view.jpg" alt="基线界面"></p>
<blockquote>
<p><strong>图5</strong>：基线界面，左侧显示来自机械臂基座的相机视图，右侧显示来自末端执行器的相机视图。<br>Splat界面（图6）则将用户置于高斯泼溅重建的虚拟场景中，可自由移动，并采用抓取-拖拽方式控制机械臂，同时叠加两个实时相机视图作为参考。<br><img src="https://arxiv.org/html/2504.15229v1/extracted/6375751/figures/splat_view.jpg" alt="Splat界面"><br><strong>图6</strong>：Splat界面，两个相机视图叠加在显示屏上。用户身处VR环境中，看到的是静态的高斯泼溅覆盖物体，并可以操控VR中显示的机械臂末端执行器。</p>
</blockquote>
<p><strong>关键定量结果</strong>：</p>
<ul>
<li><strong>任务效率</strong>：66%的参与者使用Splat界面更快地完成了首次任务，平均耗时减少了**43%**。</li>
<li><strong>用户偏好</strong>：<strong>93%</strong> 的参与者总体上更喜欢Splat界面，<strong>100%</strong> 的参与者推荐其未来使用（基线界面推荐率仅为53%）。在控制精度、任务速度和响应性方面，Splat界面也获得显著偏好。</li>
<li><strong>主观评分</strong>：如图7所示，在7分制量表上，Splat界面在易用性（5.53 vs. 4.33）、视觉反馈清晰度（5.80 vs. 4.87）、情境感知（6.13 vs. 4.13）、沉浸感（5.87 vs. 4.33）和认知负荷（5.60 vs. 4.40）等多个维度上均显著优于基线界面。<br><img src="https://arxiv.org/html/2504.15229v1/x2.jpg" alt="用户研究评分结果"><blockquote>
<p><strong>图7</strong>：用户研究中量表问题的结果，评估了两种界面的可用性和直观性。使用7点量表，1表示非常不同意，7表示非常同意。<br><img src="https://arxiv.org/html/2504.15229v1/extracted/6375751/figures/user_study_nonscaled_results.png" alt="非量表问题结果"><br><strong>图4</strong>：用户研究中非量表问题的结果，显示了参与者在控制精度、速度、响应性等方面的偏好分布。</p>
</blockquote>
</li>
</ul>
<p><strong>真实任务与定性结果</strong>：<br>硬件平台由Robotnik Summit-XL移动底座、Franka Emika机械臂、Intel RealSense D435i相机和Meta Quest 2 VR头显等组成。测试了两个场景：</p>
<ol>
<li><strong>按下被遮挡的按钮</strong>（图8）：机器人先移动到桌子旁（移动阶段），然后在VR中操作机械臂找到并按下被杂物遮挡的按钮（操作阶段）。<br><img src="https://arxiv.org/html/2504.15229v1/x3.jpg" alt="任务一场景"><blockquote>
<p><strong>图8</strong>：第一个操作场景的设置，机器人在杂乱环境中够到一个按钮。按钮被底座遮挡，从机器人相机视角无法直接看到。</p>
</blockquote>
</li>
<li><strong>依次点亮多个圆锥上的灯</strong>：机器人需要移动并接近多个圆锥，并操作机械臂按下每个圆锥上的开关。</li>
</ol>
<p><img src="https://arxiv.org/html/2504.15229v1/x4.jpg" alt="真实任务演示"></p>
<blockquote>
<p><strong>图9</strong>：操作者使用我们的远程操控框架执行两个移动操作任务的演示。(a)-(c) 机器人导航至目标并成功无碰撞地按下按钮。(d)-(f) 操作者使用框架接近每个圆锥并与之交互以点亮顶部的灯。</p>
</blockquote>
<p>定性结果表明，高斯泼溅能够高质量地重建被遮挡的物体（如按钮），操作者能轻松适应第三人称操控方式，利用多视角自由移动的能力显著提升了操作精度。系统成功完成了两项需要移动和精细操作相结合的任务。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：1) 提出了一个<strong>集成了VR界面的两阶段移动操作框架</strong>，清晰分离了导航与精细操控任务；2) 创新性地<strong>将高斯泼溅技术应用于远程操控场景重建</strong>，显著增强了沉浸感、空间感知和对遮挡的处理能力；3) 通过<strong>系统的用户研究</strong>定量和定性地验证了所提框架在效率、用户体验和操作性能上的显著优势。</p>
<p>论文自身提到的局限性主要在于高斯泼溅模型的生成需要时间（包括机械臂预规划运动、SfM和训练过程），这影响了切换到操作阶段的实时性。</p>
<p>本文工作对后续研究提供了重要启示：首先，证明了<strong>高质量、沉浸式的环境表示对于复杂远程操控任务具有巨大价值</strong>，尤其是在处理遮挡和需要空间理解时。其次，<strong>“抓取-拖拽”的第三人称交互范式</strong>为VR远程操控提供了新的设计思路。未来的研究方向包括：优化高斯泼溅的生成速度（如绕过SfM）、开发支持动态场景更新的高斯泼溅技术，以及将该框架适配到更多样化的机器人平台上以验证其可扩展性。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对移动操作任务中传统遥操作精度低、沉浸感差的问题，提出一种基于VR的沉浸式遥操作框架。核心技术是采用高斯泼溅技术，将远端场景抽象为高保真三维VR环境，支持视角自由调整以应对遮挡，实现直观的导航与操控。用户实验表明，该框架显著提升了操作效率与体验：66%参与者任务完成更快，平均耗时降低43%；93%用户更偏好此界面，100%推荐未来使用。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2504.15229" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>