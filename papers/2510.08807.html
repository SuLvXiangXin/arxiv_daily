<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.08807" target="_blank" rel="noreferrer">2510.08807</a></span>
        <span>作者: Yue Wang Team</span>
        <span>日期: 2025-10-09</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前机器人学习的数据集和基准主要集中于固定机械臂或带有简单夹具的移动平台，少数现有人形机器人数据集要么局限于固定环境，要么任务多样性不足，通常缺乏人机交互和下半身运动。此外，缺乏用于在人形数据上对基于学习的策略进行基准测试的标准化评估平台。本文针对人形机器人操作数据在多样性、具身化和评估标准化方面的缺口，提出了一个大规模、多样化的人形操作数据集，并配套了云评估平台。本文的核心思路是：通过高效的人为监督遥操作流程，收集涵盖丰富任务类别和多模态传感数据的大规模人形操作数据集，并构建一个云端评估平台，以支持策略的标准化测试与公平比较。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文的工作主要包含三部分：数据集构建、策略学习分析和云评估平台。整体框架旨在为开放世界人形操作提供一个从数据到评估的完整生态系统。</p>
<p><img src="https://arxiv.org/html/2510.08807v1/x1.png" alt="Humanoid Everyday Overview"></p>
<blockquote>
<p><strong>图2</strong>：Humanoid Everyday 概览。数据集覆盖7个不同类别的人形操作任务，包含丰富的多模态信息，并提供了一个基于云的标准化策略部署评估平台。</p>
</blockquote>
<p><strong>1. 数据集构建硬件与接口</strong><br>数据收集使用了两台Unitree人形机器人：29自由度（DoF）的G1（配备7-DoF三指灵巧手Dex3-1）和27-DoF的H1（配备6-DoF INSPIRE手）。机器人配备了Intel RealSense RGB-D相机和Livox LiDAR系统，G1的灵巧手还拥有触觉传感器。操作员佩戴Apple Vision Pro，利用其底部摄像头捕捉手腕和手指关键点。手指动作通过dex-retargeting系统映射到机器人灵巧手，手腕姿态通过基于Pinocchio的逆运动学算法转换为手臂关节命令，实现上半身完整遥操作。</p>
<p><strong>2. 高效可扩展的数据收集流程</strong><br>本文在Unitree官方遥操作库基础上，重新设计了一个多进程遥操作流水线，旨在实现大规模、高质量的数据采集。其核心创新在于将输入/输出数据流、逆运动学计算和机器人关节控制解耦到独立的进程中，并通过共享内存缓冲区实现快速、低延迟的进程间通信。</p>
<p><img src="https://arxiv.org/html/2510.08807v1/x2.png" alt="Data Collection Pipeline"></p>
<blockquote>
<p><strong>图3</strong>：数据收集流水线。(a) 将数据流、数据写入、机器人控制和IK计算分离到不同的进程和线程中，以确保可靠高效的数据收集。(b) 与官方系统相比，本文的流水线将控制延迟从500毫秒降低至2毫秒，并显著提升了数据收集效率。</p>
</blockquote>
<p>这种异步、非阻塞的设计将更多计算资源分配给IK求解器，从而实现了更平滑、更高频率（30Hz）的遥操作控制。同时，数据记录和传感器处理在主流水线进程的并行线程中异步处理，确保了时间对齐的数据收集。优化后的流水线使控制延迟从500毫秒降至2毫秒，并缩短了数据收集时间。</p>
<p><strong>3. 数据集的组成与结构</strong><br>Humanoid Everyday 数据集包含260个独特任务，总计10.3k条轨迹和超过300万帧数据。任务分为7个主要类别（见图4）：基本操作、可变形物体操作、关节物体操作、工具使用、高精度操作、人机交互以及运动操作。任务在室内和室外多种环境中执行，部分任务涉及下半身运动，增加了数据集的多样性。每条轨迹都包含以自我为中心的RGB视频、深度图、LiDAR点云、触觉反馈、IMU信息、关节位姿、关节动作以及自然语言任务描述，构成了一个多模态的综合数据集。</p>
<p><img src="https://arxiv.org/html/2510.08807v1/task_distribution.png" alt="Data Distribution"></p>
<blockquote>
<p><strong>图4</strong>：Humanoid Everyday 数据集中任务和技能类别的分布。</p>
</blockquote>
<p><strong>4. 云评估平台</strong><br>为了提供系统化、可复现的评估，本文引入了首个专为人形机器人设计的基于云的评估平台（图5）。该平台允许研究人员将训练好的策略部署到本地托管的人形机器人上。用户只需指定其策略服务器的IP和端口，系统便会将机器人端的实时视觉输入（RGB和深度图像）及状态信息流式传输给客户端。用户本地进行推理后将动作命令传回服务器，由实体机器人实时执行。平台还提供第一人称和第三人称视角的视频流供远程监控。该设计旨在降低硬件访问门槛，并标准化不同方法和用户间的评估流程。</p>
<p><img src="https://arxiv.org/html/2510.08807v1/platform.jpg" alt="Evaluation platform"></p>
<blockquote>
<p><strong>图5</strong>：Humanoid Everyday 引入了一个基于真实世界人形机器人设置的云评估平台。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>1. 实验设置与基准方法</strong><br>实验使用了Humanoid Everyday数据集。研究人员在数据集上训练并评估了七种代表性的模仿学习方法：Diffusion Policy (DP)、3D Diffusion Policy (DP3)、Action Chunking with Transformers (ACT)、OpenVLA、π₀-FAST、π₀.₅ 和 GR00T N1.5。对于基于视觉-语言-动作的大模型，采用了两阶段微调策略：先在完整数据集上微调，再在特定任务类别的数据上进一步适配。实验涵盖了全部七个任务类别，每个任务进行10次试验。</p>
<p><img src="https://arxiv.org/html/2510.08807v1/experiments.jpg" alt="Experiment Setup"></p>
<blockquote>
<p><strong>图7</strong>：实验设置。展示了来自七个类别的代表性推理任务。黄色区域表示略有变动的任务执行区域，箭头显示机器人的手臂轨迹。</p>
</blockquote>
<p><strong>2. 模仿学习策略性能分析</strong><br>关键定量结果如表II所示。总体而言，由于数据集动作空间维度高（总计28 DoFs），所有端到端的模仿学习策略在人形操作任务上都面临挑战。DP3在多数情况下优于DP，作者假设3D点云观测对环境变化具有更强的鲁棒性，但在运动操作任务中，因点云帧间变化巨大，其可靠性下降。ACT整体表现不佳，因其未能有效结合视觉反馈，容易过拟合演示轨迹。相比之下，大规模VLA模型凭借其预训练先验，表现出更一致和稳定的性能，尤其在需要精度和鲁棒性的可变形物体操作和运动操作任务上。GR00T N1.5凭借在多个大规模人形数据集上的广泛预训练，获得了最强的整体性能（平均成功率51%）。然而，所有策略在最具挑战性的类别上均表现不佳，例如在“将玫瑰插入花瓶”的高精度操作任务中，几乎所有策略的成功率均为0%。</p>
<p><strong>3. 消融实验：Humanoid Everyday 作为预训练先验的有效性</strong><br>为了验证数据集能否作为有效的预训练先验，研究者在人机交互任务上进行了消融实验，对比了“直接任务特定微调”和“使用Humanoid Everyday预训练后再任务特定微调”两种策略。</p>
<p><img src="https://arxiv.org/html/2510.08807v1/humanoid_prior_ablation.png" alt="Ablation on Humanoid Everyday Pretraining"></p>
<blockquote>
<p><strong>图8</strong>：Humanoid Everyday 预训练的消融实验。直接任务特定微调与使用Humanoid Everyday进行两阶段微调的性能对比。</p>
</blockquote>
<p>结果如图8所示，先使用Humanoid Everyday进行预训练，再进行任务特定适配，能够一致地提升所有VLA模型的性能。这表明接触多样化的人形行为数据提供了一个有用的先验，有助于下游操作任务的学习。</p>
<p><strong>4. 云平台评估效率</strong><br>云评估平台的运行效率如图6所示。系统在电池耗尽前可持续运行超过100分钟，期间仅因电机过热需要三次人工干预，其余时间均保持了较高的评估效率。</p>
<p><img src="https://arxiv.org/html/2510.08807v1/intervention_eval.png" alt="Evaluation Steps per Minute with Human Interventions"></p>
<blockquote>
<p><strong>图6</strong>：带有人工干预的每分钟评估步数。评估在电池耗尽前持续运行超过100分钟，仅因电机过热需要三次人工干预，系统在其余过程中保持了持续的高评估效率。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献有三点：1) 提出了一个通过优化遥操作流水线收集的大规模、多模态、多样化的人形操作数据集Humanoid Everyday；2) 在该数据集上对代表性策略学习方法进行了系统性分析，揭示了它们在各类任务上的优势与局限；3) 推出了首个专为人形机器人设计的云评估平台，以支持标准化、可复现的评估。</p>
<p>论文自身提到的局限性包括：仅评估了现有的模仿学习策略架构，这些策略在处理高维动作空间时性能下降，表明需要更专业的模型设计；此外，当前的云评估系统尚不支持自动场景重置，因为现有策略的鲁棒性不足以让人形机器人在无人协助下恢复环境。</p>
<p>这项工作为通用人形操作研究提供了宝贵的数据基础和评估基准。其启示在于：大规模、多样化的真实世界数据对于训练鲁棒的人形策略至关重要；现有的模仿学习方法，尤其是未针对高维全身控制优化的方法，在面对复杂人形任务时存在明显瓶颈；建立一个公平、易访问的评估平台是推动领域协同发展的关键。未来的研究可以基于此数据集开发更强大的策略模型，并进一步完善评估系统的自动化能力。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对当前人形机器人数据集局限于固定环境、任务多样性不足且缺乏标准化评估的问题，提出了Humanoid Everyday数据集。该数据集通过高效人监督遥操作管道，收集了包含RGB、深度、LiDAR和触觉输入的多模态数据及自然语言注释，涵盖7大类260个任务，总计10.3k轨迹和300多万帧数据。同时，引入了基于云的评估平台以支持标准化策略部署，并分析了代表性策略学习方法的优劣。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.08807" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>