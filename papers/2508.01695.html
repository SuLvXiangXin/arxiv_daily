<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>DexReMoE:In-hand Reorientation of General Object via Mixtures of Experts - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>DexReMoE:In-hand Reorientation of General Object via Mixtures of Experts</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.01695" target="_blank" rel="noreferrer">2508.01695</a></span>
        <span>作者: Wan, Jun, Liu, Xing, Dong, Yunlong</span>
        <span>日期: 2025/08/03</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>灵巧的手内物体重定向是机器人学中的一个核心挑战，要求控制策略能够处理多样化的物体几何形状、保持稳定抓握并执行精确的复杂方向轨迹。尽管强化学习在灵巧操作领域取得了进展，例如针对特定物体（如立方体）或单一轴旋转的策略，但现有方法在处理复杂几何形状的泛化方面仍存在显著局限。先前的工作要么专注于单一物体或简单几何体，要么在处理复杂形状时面临困难，且通常需要大量训练资源。本文针对“将手内重定向可靠地泛化到具有复杂形状的物体”这一具体痛点，提出了一个新的方向：采用专家混合（Mixture-of-Experts， MoE）框架。本文的核心思路是训练多个针对不同复杂形状的专家策略，并通过一个门控网络根据物体几何动态整合这些专家，同时结合物体类别信息作为特权输入来增强形状表示，从而实现跨广泛物体的泛化。</p>
<h2 id="方法详解">方法详解</h2>
<p>DexReMoE框架的整体流程分为两个主要阶段：基础策略学习和MoE策略训练。其核心思想是先学习一个通用的基础策略和编码器，然后通过微调得到多个专精于不同形状类别的专家策略，最后训练一个轻量级门控网络来动态融合专家输出，以适应多样化的物体几何。</p>
<p><img src="https://arxiv.org/html/2508.01695v1/model.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：DexReMoE框架总览。左侧为基础策略学习阶段，联合训练点云编码器μ_pc、物体编码器μ_e和基础策略π_base。中间为专家策略训练阶段，将π_base微调为四个专家策略{π_ei}。右侧为MoE策略训练阶段，冻结所有编码器和专家，仅训练门控网络π_gate，根据物体特征嵌入和类别向量计算专家权重，加权求和得到最终动作。</p>
</blockquote>
<p><strong>整体框架与输入输出</strong>：在基础策略学习阶段，系统接收的观察o_t包括最近三帧的关节位置和已执行的动作历史。特权信息e_t则包含物体的物理状态（质量、质心、位姿、速度等）和形状描述符。形状描述符由点云编码器μ_pc（基于PointNet++）提取的32维特征向量与6维one-hot类别向量拼接而成。物理状态与形状描述符拼接后，再经过物体编码器μ_e压缩为一个66维的外在嵌入z_t。最终，基础策略π_base的输入是观察o_t和嵌入z_t，输出是控制机械手的动作a_t。为了控制平滑性，对输出动作应用了指数移动平均。</p>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>基础策略与编码器训练</strong>：使用PPO算法联合优化π_base、μ_pc和μ_e。奖励函数设计是关键，它由三部分组成：r1是成功到达目标位姿的稀疏奖励；r2是鼓励减少物体与目标之间位置和旋转误差的稠密奖励（包含位置误差惩罚和旋转误差倒数奖励）；r3是惩罚过大关节角速度和动作幅值的正则项，以促进平滑控制。论文特别指出，未包含物体掉落惩罚，因为这抑制了探索行为。</li>
<li><strong>专家策略微调</strong>：基础策略收敛后，冻结μ_pc和μ_e。将π_base的参数复制初始化四个专家策略{π_ei}，每个专家随后仅在单一特定形状类别的数据上进行微调，从而使其擅长处理该类几何形状。</li>
<li><strong>MoE门控网络训练</strong>：在部署阶段，仅训练一个轻量级的门控网络π_gate。其输入是物体编码器产生的特征嵌入z_t（包含形状信息）和物体类别向量。π_gate输出一组权重，用于对四个冻结的专家策略的输出进行加权求和，从而生成最终动作。这种设计实现了针对性的专业化与广泛的泛化能力。</li>
</ol>
<p><strong>创新点</strong>：<br>与现有方法相比，DexReMoE的主要创新体现在：1) <strong>架构创新</strong>：首次将MoE框架系统性地应用于灵巧手内重定向任务，通过多个专业化专家和动态路由机制应对几何多样性。2) <strong>表示创新</strong>：提出了一种新颖的物体形状表示，将点云编码与物体类别信息相结合，并融入现有的特权信息解耦框架，形成了紧凑而富有表现力的特征嵌入。3) <strong>训练策略</strong>：采用先通用后专业的两阶段训练流程，避免了直接训练MoE的复杂性，并缓解了灾难性遗忘问题。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：方法在仿真中训练和评估，使用了包含超过150个具有显著形状变化的物体模型的数据集。评估场景设定为极具挑战性的“空中重定向”，即机械手朝下抓握物体并在空中进行旋转。实验平台未明确说明，但提及了Isaac Gym。性能核心指标是平均连续成功次数。</p>
<p><strong>对比方法</strong>：论文对比了多个基线方法：1) <strong>单一策略</strong>：使用所有物体数据训练一个统一策略。2) <strong>集成策略</strong>：训练多个策略并平均其输出。3) <strong>微调策略</strong>：将基础策略在测试物体上直接微调。4) **DexReMoE (Ours)**：本文提出的方法。</p>
<p><img src="https://arxiv.org/html/2508.01695v1/baseline.png" alt="主要结果对比"></p>
<blockquote>
<p><strong>图4</strong>：不同方法在测试集物体上的连续成功次数分布（箱形图）及平均性能（虚线）。DexReMoE（红色）的中位数和平均性能（19.5）显著高于所有基线，且分布更集中，表明其性能更稳定、泛化能力更强。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ul>
<li><strong>整体性能</strong>：DexReMoE在150个多样化物体上取得了平均19.5的连续成功次数。</li>
<li><strong>最差情况性能</strong>：DexReMoE将最差情况下的连续成功次数从最佳基线的0.69大幅提升至6.05，显著增强了鲁棒性。</li>
<li><strong>收敛速度</strong>：在训练过程中，DexReMoE比单一策略基线收敛更快。</li>
</ul>
<p><img src="https://arxiv.org/html/2508.01695v1/ablation2.png" alt="消融实验"></p>
<blockquote>
<p><strong>图5</strong>：消融实验结果。从左至右分别为：完整DexReMoE、不使用类别信息、不使用点云特征（仅用类别）、以及使用均匀专家权重（非自适应门控）。完整模型性能最佳，表明点云特征和类别信息均不可或缺，且自适应门控机制至关重要。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.01695v1/tsen.jpg" alt="专家权重可视化"></p>
<blockquote>
<p><strong>图6</strong>：t-SNE可视化展示了不同形状物体（不同颜色）在门控网络权重空间中的分布。同类物体聚集，不同类物体分离，证明门控网络能根据几何形状有效区分并激活相应的专家。</p>
</blockquote>
<p><strong>消融实验总结</strong>：<br>消融实验验证了各核心组件的贡献：1) <strong>移除类别信息</strong>：性能下降，表明类别先验有助于门控网络进行更有效的路由。2) <strong>移除点云特征（仅用类别）</strong>：性能显著下降，证明几何细节信息对于处理同类物体内的变化和未见过的形状至关重要。3) <strong>使用均匀权重（非自适应门控）</strong>：性能最差，说明动态根据物体特征选择专家是MoE框架有效的关键。</p>
<p><img src="https://arxiv.org/html/2508.01695v1/dataset.png" alt="物体数据集示例"></p>
<blockquote>
<p><strong>图7</strong>：实验中使用的部分物体模型，展示了形状的多样性，包括训练分布内和分布外的物体。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了DexReMoE框架，通过MoE机制将多个针对特定几何形状的专家策略与一个自适应门控网络相结合，实现了对广泛复杂形状物体的通用手内重定向。</li>
<li>设计了一种新颖的物体形状表示方法，将点云编码与物体类别向量融合，并集成到特权信息中，形成了高效且富有表现力的特征嵌入。</li>
<li>在包含数百个物体的仿真实验中进行了全面评估，证明了该方法在平均性能、最差情况鲁棒性和收敛速度上均优于现有基线，展现了出色的泛化能力。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到的局限性包括：1) 方法依赖于仿真中可用的特权信息（如精确的物体物理属性）。2) 专家数量是预先固定的（4个），这可能限制了对更细粒度或更多样形状类别的泛化能力。3) 工作目前仅在仿真中进行验证，未涉及真实的sim-to-real转移。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>动态专家架构</strong>：可以探索专家数量或结构能够根据任务复杂度动态调整的MoE框架。</li>
<li><strong>减少对特权信息的依赖</strong>：未来工作可以研究如何仅从视觉（如深度相机）或本体感知输入中推断出必要的物体特征表示，以迈向实际部署。</li>
<li><strong>门控机制改进</strong>：可以研究更高效或可解释的门控网络设计，例如基于注意力机制的路径选择。</li>
<li><strong>跨模态学习</strong>：将触觉反馈等信息纳入到特征表示和门控决策中，可能进一步提升在复杂接触场景下的性能。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人手内物体重定向任务，旨在解决现有方法难以泛化至复杂几何形状物体的核心挑战。提出的DexReMoE框架采用混合专家模型，为不同复杂形状训练多个专家策略，并引入物体类别信息作为特权输入以增强形状表征。通过强化学习在仿真中训练，并在空中手抓取的最难场景中评估。实验表明，该方法在150个多样物体上平均连续成功次数达19.5，并将最差情况性能从0.69显著提升至6.05。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.01695" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>