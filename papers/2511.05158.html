<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Follow-Me in Micro-Mobility with End-to-End Imitation Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Follow-Me in Micro-Mobility with End-to-End Imitation Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2511.05158" target="_blank" rel="noreferrer">2511.05158</a></span>
        <span>作者: Jorge Peña Queralta Team</span>
        <span>日期: 2025-11-07</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前自主跟随（Follow-Me）任务的主流方法主要分为基于距离-位置和基于感知的两类。基于位置的方法依赖高精度的相对定位来跟踪目标轨迹，但可能面临计算资源需求高、在复杂环境中定位不连续等挑战。基于感知的方法（如使用视觉、激光雷达）则通过检测、跟踪和学习来计算状态与控制策略，但深度学习方法的实际部署常受限于近似不稳定、安全性问题及复杂性。在微移动性平台（如辅助轮椅）的商业应用中，除了传统的机器人指标（如时间、距离），用户体验和舒适度至关重要，而这一点在现有研究中未得到充分重视。本文针对这一痛点，提出使用端到端模仿学习（Imitation Learning）来开发控制器，旨在获得比手动调优控制器更平滑、整体性能更优的控制策略，从而优化用户体验。核心思路是：通过收集人类专家操作轮椅跟随目标的演示数据，训练神经网络模型，使其能够直接从超宽带（UWB）传感器观测中预测出平滑的速度控制指令，以模仿人类的移动模式和决策。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的端到端模仿学习跟随框架，其整体流程分为演示阶段、训练阶段和部署阶段。在演示阶段，由人类操作员远程操控轮椅，平滑安全地跟随一个领导者，同时记录来自两个UWB设备的测距（r1, r2）和测角（a1, a2）数据，以及相应的线速度和角速度控制命令（v, ω），形成数据集。在训练阶段，将此数据集用于监督学习，训练模型以从UWB观测映射到连续的速度命令。在部署阶段，训练好的模型接收实时UWB数据，直接输出控制命令，驱动轮椅自主跟随目标。</p>
<p><img src="https://arxiv.org/html/2511.05158v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：左图为配备UWB射频节点用于跟随任务的DAAV轮椅；右图为跟随控制器的基本结构。UWB数据输入模仿学习控制器，后者输出速度命令。同时，激光雷达数据输入专有的情境感知和动态物体跟踪模块，用于避障。</p>
</blockquote>
<p>核心模块是用于回归的模仿学习模型。本文比较了三种模型：支持向量机（SVM）、单层多层感知机（MLP）和单层长短期记忆网络（LSTM）。MLP和LSTM均使用32个单元，以均方误差（MSE）为损失函数，并采用ADAM优化器（学习率0.1）进行训练。LSTM的创新之处在于其能够捕捉时序依赖性，通过考虑领导者过去多个时间步的历史表现来做出决策。鉴于UWB数据的高频率（50Hz），模型使用了一个2秒（即100组数据）的移动时间窗口作为输入。</p>
<p>与现有方法相比，本文的创新点具体体现在：1）将端到端模仿学习应用于基于UWB的跟随任务，直接学习从传感器观测到控制动作的映射，避免了传统方法中分模块（如定位、规划、控制）可能引入的误差和复杂度。2）利用UWB数据（测距和/或测角）进行训练，框架具备向其他传感器模态泛化的潜力。3）明确以提升用户体验（如运动平滑性、舒适度）为优化目标。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验使用了在真实世界场景中收集的110秒UWB演示数据集（频率50Hz）。对比的基线方法是论文中提到的“先前使用的基线控制器”（baseline model），以及三种模仿学习模型（SVM， MLP， LSTM）。评估平台是DAAV的全向自主轮椅，该平台已在苏黎世和维也纳机场累计完成超过100公里的自主导航。</p>
<p>关键实验结果如下：在模型性能评估（表I）中，LSTM模型在训练和测试集上均取得了最低的MSE（当使用测距和测角组合输入时，测试MSE为0.0160），显著优于MLP（0.0509）和SVM（0.0437）。这表明LSTM能够更准确地拟合专家的控制策略。</p>
<p><img src="https://arxiv.org/html/2511.05158v1/fig/follow_me_diagram_short.png" alt="性能对比表"></p>
<blockquote>
<p><strong>表I</strong>：不同模型在10次迭代中的平均性能对比。展示了不同输入组合（仅测距R1,R2、仅测角A1,A2、两者结合）下，各模型输出速度（vx, ωz）的训练与测试MSE。LSTM模型在组合输入下表现最佳。</p>
</blockquote>
<p>在真实世界验证中，进行了三个实验。表II总结了不同模型在各种场景下的平均绝对误差（MAE）和平均距离。实验1和2涉及更广泛的运动模式，实验3侧重于保持一致的跟随距离。结果表明，使用测距和测角组合输入的LSTM模型获得了最佳的角度跟踪精度（MAE角度最低，如实验1为4.41度），而MLP模型在平均距离上误差最低。</p>
<p><img src="https://arxiv.org/html/2511.05158v1/x2.png" alt="轨迹与距离图"></p>
<blockquote>
<p><strong>图3</strong>：三个不同实验中领导者与跟随者的轨迹及相对距离随时间变化图。展示了跟随轮椅在不同模型控制下的跟踪平滑度和距离保持能力。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2511.05158v1/x3.png" alt="用户体验指标对比"></p>
<blockquote>
<p><strong>图4</strong>：基线模型与三种端到端深度学习模型在用户体验代理指标上的对比。(a) 角度偏移：偏移接近零意味着跟随轮椅指向领导者，符合用户体验期望，LSTM表现最佳。(b) 线速度：低方差与更平滑的乘坐体验相关，所有模仿学习模型的速度方差均显著低于基线。</p>
</blockquote>
<p>消融实验方面，论文通过比较不同输入（仅测距、仅测角、两者结合）评估了各组件贡献。结果表明，结合测距和测角信息的LSTM模型性能最优。同时，对比不同模型结构（SVM、MLP、LSTM）发现，能够建模时序依赖的LSTM贡献最大，其生成的控制动作更平滑、更符合人类驾驶习惯，从而直接提升了跟踪的舒适度。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）证明了端到端模仿学习能够为微移动性平台的跟随任务生成比手动调优基线更平滑、用户体验更佳的控制器，显著提升了跟踪舒适度。2）提出了一个基于UWB观测的模仿学习框架，该框架可泛化至不同的传感器输入组合（仅测距、仅测角或两者结合），增强了实用性。3）将所提系统成功集成到DAAV的生产代码库中，并在真实的机场动态拥挤环境中进行了验证，证明了其在实际部署中的鲁棒性和可靠性。</p>
<p>论文自身提到的局限性包括：演示数据集相对较小（110秒），可能限制模型在更复杂或未见场景中的泛化能力。</p>
<p>对后续研究的启示：这项工作表明，模仿学习是优化机器人系统以人为中心指标（如舒适度）的有效途径。未来的研究可以探索使用更大规模、更多样化的数据集进行训练，或结合强化学习以进一步提升性能和安全边界。此外，该框架可扩展至融合多模态传感器输入（如结合UWB与视觉），以应对更复杂的感知挑战。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对自主微移动平台（如辅助轮椅）在动态拥挤环境中实现“跟随”任务时，如何优化用户体验与舒适度（而非仅关注时间、距离等传统指标）的核心问题展开研究。提出采用端到端模仿学习方法，通过深度神经网络学习人类演示数据，直接生成控制策略。实验表明，该方法相比手动调优控制器能提供更平滑、性能更优的跟随控制，使自主轮椅在现实部署中实现了先进的舒适度水平。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2511.05158" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>