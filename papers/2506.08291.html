<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>TensorTouch: Calibration of Tactile Sensors for High Resolution Stress Tensor and Deformation for Dexterous Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>TensorTouch: Calibration of Tactile Sensors for High Resolution Stress Tensor and Deformation for Dexterous Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.08291" target="_blank" rel="noreferrer">2506.08291</a></span>
        <span>作者: Do, Won Kyung, Strong, Matthew, Swann, Aiden, Lei, Boshu, Kennedy III, Monroe</span>
        <span>日期: 2025/06/09</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>目前，高级灵巧操作（如从平面捏起硬币或操纵缠绕物体）需要处理多个物体或表面之间的多接触交互，这超出了仅依赖视觉和本体感知的能力范围。光学触觉传感器能提供丰富信息，但其原始输出图像缺乏可解释性和跨传感器的可迁移性。现有方法要么只能处理小变形（1-5mm位移），要么缺乏对大变形的详细物理建模。当策略直接基于未处理的触觉图像训练时，会与特定传感器硬件紧耦合，导致难以泛化。本文针对这些痛点，提出通过校准触觉传感器，提取具有物理意义的、可解释的力与应力信息，以实现传感器无关的表征，从而提升复杂接触场景下的操作能力。核心思路是集成有限元分析与深度学习，从光学触觉传感器图像中提取像素级分辨率的应力张量、变形场和力分布。</p>
<h2 id="方法详解">方法详解</h2>
<p>TensorTouch框架的整体流程包括三个主要阶段：1）基于动作捕捉的数据收集，同步记录压头位姿、六维力/力矩和触觉图像；2）有限元分析模拟，基于收集的位姿和力数据，计算传感器凝胶的变形、应力张量和接触力；3）神经网络训练，学习从触觉图像到FE模拟输出的映射。</p>
<p><img src="https://arxiv.org/html/2506.08291v1/extracted/6527257/Figures/Fig_main_pipeline2.jpg" alt="方法框架总览"></p>
<blockquote>
<p><strong>图2</strong>：TensorTouch整体流程。我们捕获真实世界的压头位姿、力和传感器图像，并使用有限元模拟仿真凝胶变形和传感器运动。生成的变形和应力张量被投影回2D图像。右侧图像（a-e）显示了对应的有限元结果：（a）位移，（b）法向应力，（c）剪切应力，（d）接触法向力，（e）接触剪切力。每个图像的R/G/B通道编码X/Y/Z分量。最后，训练一个深度网络将传感器图像对映射到应力张量输出。</p>
</blockquote>
<p><strong>核心模块一：数据收集与模拟</strong>。为获得多样化且精确的配对数据，作者设计了一个基于动作捕捉的系统（图3）。该系统使用8台高速相机追踪带有反光标记的压头模块（集成力/力矩传感器），允许操作者手持进行随机、多点的接触。关键创新在于使用多样化的压头形状来防止网络过拟合。作者从YCB数据集中选取12种物体，通过算法处理其网格，生成具有不同几何特征（如锐边、平滑曲面）的3D打印压头（图4左）。对于每次接触序列，系统从动作捕捉数据中提取关键点，以在FE模拟中精确复现运动轨迹。</p>
<p><strong>核心模块二：有限元分析</strong>。FE分析在Abaqus中完成，用于模拟光学触觉传感器（考虑其具体形状和材料属性）在与多样化压头接触时的力学响应。模拟输入是压头的6D位姿轨迹，输出则是传感器表面每个有限元节点的三维位移向量、柯西应力张量（分解为法向和剪切分量）以及积分得到的接触力。这些3D物理量被投影到2D图像平面（与触觉相机视角对齐），生成用于网络训练的“真值”图像（图2右）。</p>
<p><strong>核心模块三：神经网络架构</strong>。网络的目标是学习从原始触觉图像到上述物理量2D投影图的映射。作者采用了一个轻量级的分层视觉Transformer（HiViT）作为主干网络（图9）。输入是当前帧和前一帧的触觉图像（用于捕捉动态信息），网络通过编码器-解码器结构，输出五个通道的预测图，分别对应：三维位移（U）、三维法向应力（σ_n）、三维剪切应力（τ）、三维接触法向力（F_n）和三维接触剪切力（F_s）。每个输出通道都是三通道图像，编码XYZ分量。</p>
<p><img src="https://arxiv.org/html/2506.08291v1/extracted/6527257/Figures/Fig_network.jpg" alt="网络架构"></p>
<blockquote>
<p><strong>图9</strong>：TensorTouch神经网络架构。采用分层视觉Transformer（HiViT）作为编码器，处理当前帧和前一帧的触觉图像对。解码器输出五个不同的物理量：位移（U）、法向应力（σ_n）、剪切应力（τ）、接触法向力（F_n）和接触剪切力（F_s），每个都是三通道（XYZ）的密集预测图。</p>
</blockquote>
<p><strong>创新点</strong>：1) <strong>数据收集</strong>：动作捕捉系统支持自然、随机的6D运动和多接触场景，成本低于多机器人系统；使用源自YCB数据集的多样化压头形状，迫使网络学习大变形的通用物理规律，而非记忆特定图案。2) <strong>物理建模</strong>：有限元分析能够精确模拟各种3D形状传感器的大变形，提供像素级的应力张量和力分布真值，超越了仅估计单点力或小变形的方法。3) <strong>网络设计</strong>：轻量级HiViT网络直接输出密集的、多物理量的校准信息，实现了从图像到可迁移物理表征的端到端学习。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：使用自建的数据集，包含约20万组数据点，涵盖12种不同的压头形状、单点及双点接触。传感器为定制化的半球形光学触觉传感器（基于DenseTact设计）。评估指标包括位置估计误差（mm）、力估计误差（N）以及在一个双绳选择性抓取任务中的成功率。</p>
<p><strong>对比方法</strong>：与多种基线方法对比，包括：1) <strong>Poisson</strong>：基于泊松方程的经典GelSight形变重建方法。2) <strong>Sparsh</strong>：一种基于光流的自监督触觉编码器。3) <strong>iFEM 2.0</strong>：一种基于逆有限元的方法。4) <strong>ResNet + FCN</strong>：使用ResNet-18编码器和全卷积解码器的基准网络。</p>
<p><img src="https://arxiv.org/html/2506.08291v1/extracted/6527257/Figures/force_combined_.jpg" alt="定量结果：力估计"></p>
<blockquote>
<p><strong>图13</strong>：接触力估计的定量比较。TensorTouch（红色）在法向力（Fn）和剪切力（Fs）的均方根误差（RMSE）上均优于所有基线方法。例如，在法向力估计上，TensorTouch误差约为0.5N，而其他方法普遍高于0.7N。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.08291v1/extracted/6527257/Figures/pos_combined_.jpg" alt="定量结果：位置估计"></p>
<blockquote>
<p><strong>图14</strong>：接触位置估计的定量比较。TensorTouch（红色）的位置误差最小（约0.8mm），显著优于其他方法（误差普遍大于1.2mm），实现了亚毫米级精度。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>物理量估计精度</strong>：TensorTouch在位置估计上达到约0.8mm的RMSE，优于所有基线（&gt;1.2mm）。在力估计上，法向力和剪切力RMSE分别约为0.5N和0.5N，同样显著优于对比方法。</li>
<li><strong>双绳选择性抓取任务</strong>：在一个需要区分两根相同绳子的动态操作任务中，基于TensorTouch估计的力信息进行决策，机器人手取得了90%的成功率，证明了校准信息对高级灵巧操作的有效性。</li>
<li><strong>泛化能力</strong>：在未见过的压头形状和双接触场景下的测试表明，TensorTouch相比基线具有更好的泛化性能。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.08291v1/extracted/6527257/Figures/Fig_qualitative_results_2.jpg" alt="定性结果"></p>
<blockquote>
<p><strong>图12</strong>：TensorTouch预测结果的定性可视化。从左到右列分别为：输入触觉图像、预测的位移场（U）、法向应力（σ_n）、剪切应力（τ）。各行展示了单点接触、双点接触以及使用未见过的压头形状（“YCB Clamp”）接触的结果。预测与有限元模拟生成的真值高度吻合。</p>
</blockquote>
<p><strong>消融实验</strong>：</p>
<ul>
<li><strong>压头形状多样性</strong>：训练时仅使用球形压头会导致在未见形状上性能大幅下降，而使用多样化YCB压头形状训练的网络泛化能力更强。</li>
<li><strong>网络架构</strong>：将主干网络从HiViT替换为ResNet会导致所有物理量的估计误差增加，证明了所选用架构的有效性。</li>
<li><strong>输入帧数</strong>：使用当前帧和前一帧的双帧输入比仅使用单帧输入性能更好，尤其是在估计动态的剪切力时。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个<strong>综合的有限元分析框架</strong>，能够为各种3D形状的光学触觉传感器建模多接触交互和大变形，从而生成高空间分辨率的接触信息真值。</li>
<li>提出了一种<strong>新颖的神经网络架构</strong>，利用轻量级分层视觉Transformer，将触觉图像高效地映射到整个传感器表面的应力张量、接触力和变形场。</li>
<li>开发了一个<strong>基于动作捕捉的数据收集系统</strong>，能够配对触觉图像与来自多样化物体几何形状的精确接触位姿和力测量。</li>
</ol>
<p><strong>局限性</strong>：论文提到，该方法依赖于有限元模拟来生成训练数据，模拟的准确性受材料模型参数（如凝胶的超弹性系数）影响。虽然使用了实物数据校准，但完美的物理一致性难以保证。此外，整个流程（FE模拟+网络训练）的计算成本较高。</p>
<p><strong>启示</strong>：TensorTouch为光学触觉传感器提供了一种获得校准物理输出的强大方法，尤其适用于需要处理大变形和复杂接触的软体操作任务。其“传感器无关”的输出表征（如标准化的力/应力）有望促进触觉感知策略在不同硬件间的迁移，提高了触觉感知在机器人灵巧操作中的实用性和可扩展性。未来工作可探索更高效的材料建模方法，或利用生成式模型进一步缩小仿真与现实的差距。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人灵巧操作中，现有光学触觉传感器原始图像缺乏可解释性与可迁移性的问题，提出TensorTouch校准框架。该框架的核心技术方法是**结合有限元分析与深度学习**，从传感器图像中**提取像素级分辨率的应力张量、变形场及力分布**。实验表明，该系统实现了**亚毫米级位置精度与精确的力估计**，并在基于触觉运动检测选择性抓取双弦的任务中取得了**90%的成功率**。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.08291" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>