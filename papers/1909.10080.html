<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Whole-Body Geometric Retargeting for Humanoid Robots - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Whole-Body Geometric Retargeting for Humanoid Robots</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/1909.10080" target="_blank" rel="noreferrer">1909.10080</a></span>
        <span>作者: Darvish, Kourosh, Tirupachuri, Yeshasvi, Romualdi, Giulio, Rapetti, Lorenzo, Ferigo, Diego, Chavez, Francisco Javier Andrade, Pucci, Daniele</span>
        <span>日期: 2019/09/22</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人遥操作结合了人类的认知能力与机器人的物理能力，使其能够在危险或人类难以到达的环境中执行任务。当前低层级的遥操作核心在于将人体运动重定向到机器人。主流方法主要分为两类：配置空间重定向和任务空间重定向。配置空间重定向（典型架构见图2）首先通过人体模型和逆运动学计算人体关节角度/速度，再通过定制化的映射转换为机器人关节角度/速度。其关键局限在于需要为不同的人体受试者和机器人模型寻找定制化的映射关系，且当人体与机器人运动学结构不同（如肩关节构型差异）时处理复杂。任务空间重定向（典型架构见图3）则先将人体链节在笛卡尔空间中的测量值按固定比例映射到机器人空间，再基于机器人模型求解逆运动学。其局限在于比例因子可能导致机器人工作空间缩小或精度损失，且优化参数可能导致机器人产生非拟人化的内部构型，令操作者不适。</p>
<p>本文针对现有方法缺乏可扩展性的关键痛点，即难以轻松适配不同人体用户和具有不同几何、运动学结构的人形机器人。论文提出了一种新的视角：直接基于机器人模型，通过几何映射将人体链节运动重定向到对应的机器人链节。其核心思路是，通过一个预先定义的固定旋转矩阵，将人体链节的姿态测量值直接转换到对应的机器人链节坐标系下，从而将重定向问题表述为一个仅依赖机器人模型的逆运动学优化问题，实现了对不同人和不同机器人的通用适配。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的全身遥操作架构如图4所示。操作者通过Oculus头显接收机器人摄像头传来的视觉反馈，通过Joypad控制机器人手部，通过Cyberith虚拟现实跑步机提供移动信息，并通过Xsens全身动作捕捉服获取各人体链节相对于惯性坐标系的运动学信息。这些信息输入到重定向模块，输出期望的关节值，再传递给全身控制器驱动机器人。</p>
<p><img src="https://i.imgur.com/placeholder1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图4</strong>：全身遥操作架构。展示了从人体操作者（使用头显、动作捕捉服、手柄和跑步机）到机器人（接收关节指令并反馈图像）的完整数据流。图中编号指示了人体链节与机器人链节之间的帧对应关系。</p>
</blockquote>
<p>核心的重定向方法如图5所示。该方法仅需要人体链节的旋转矩阵 ( ^I\mathbf{R}^H ) 和角速度 ( ^I\boldsymbol{\omega}^H ) 测量值以及机器人的URDF模型。其关键在于一个离线计算的、从机器人链节坐标系到对应人体链节坐标系的固定旋转矩阵 ( ^H\mathbf{R}^R )。通过将此矩阵与人体测量值结合，可得到机器人链节在惯性系中的期望姿态 ( ^I\mathbf{R}^{R*} = ^I\mathbf{R}^H {}^H\mathbf{R}^R )。( ^H\mathbf{R}^R ) 的计算方法是：将机器人和人体模型摆放在相似的关节构型下（如图4所示姿态），手动识别对应链节坐标系间的相对旋转。</p>
<p><img src="https://i.imgur.com/placeholder2.png" alt="重定向流程"></p>
<blockquote>
<p><strong>图5</strong>：运动学全身运动重定向框图。输入是人体受试者测量值和机器人URDF模型，通过结合固定的旋转映射和逆运动学求解，直接输出机器人关节值，无需定制化的人体模型或复杂的映射步骤。</p>
</blockquote>
<p>得到期望的机器人链节姿态后，通过求解逆运动学问题来计算机器人关节位置。该问题被表述为一个基于动力学系统的优化问题。定义第i个链节的姿态误差 ( \mathbf{E}_i ) 和角速度误差 ( \mathbf{V}_i ) 如公式(4a)(4b)所示。目标是使误差动力学系统 ( \mathbf{V} + K\mathbf{E} = 0 ) 收敛，其中 ( K ) 为增益矩阵。因此，通过求解带正则化项和线性不等式约束（如关节限位）的二次规划（QP）问题(5)，得到系统广义速度 ( \boldsymbol{\nu}(t) )，积分后即得期望的关节位置 ( \mathbf{s}(t) )。</p>
<p>与现有方法相比，本方法的创新点具体体现在：1) <strong>直接使用机器人模型</strong>：无需为不同的人体用户建立定制化的人体模型或进行复杂的关节/任务空间映射，提高了系统的可扩展性和易用性。2) <strong>几何映射</strong>：通过固定的 ( ^H\mathbf{R}^R ) 矩阵实现对人体链节姿态的直接几何转换，即使人体与机器人对应肢体的自由度不同，也能实现拟人化的运动重定向。3) <strong>统一的优化求解</strong>：将重定向问题统一为一个基于机器人模型的QP逆运动学问题，自然地处理了机器人自身的运动学约束。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：使用Xsens动作捕捉系统实时捕获人体链节旋转和角速度。重定向实验使用了两位不同人体受试者的运动数据。为验证可扩展性，在多个机器人模型上进行了运动学重定向实验，包括：32自由度的iCub、24自由度的NAO、30自由度的Atlas人形机器人，以及15自由度的Baxter双臂机器人。此外，还在一个66自由度的人体模型上进行了演示。全身遥操作实验则在53自由度的iCub机器人上进行，分别集成了两种先进的全身控制器：基于动量控制的平衡控制器和基于DCM的行走控制器。</p>
<p><strong>重定向实验结果</strong>：图6展示了将不同人体受试者的运动重定向到不同机器人模型的Rviz可视化结果。第一行为第一位受试者单脚站立（右脚），第二行为第二位受试者单脚站立（左脚）。结果表明，该方法能成功地将全身运动重定向到具有不同自由度、不同尺寸的机器人模型，甚至是非人形的固定基座机器人（Baxter）。</p>
<p><img src="https://i.imgur.com/placeholder3.png" alt="重定向可视化"></p>
<blockquote>
<p><strong>图6</strong>：将人体运动全身重定向到不同模型的Rviz可视化。包括人体模型、Nao、iCub、Atlas和Baxter机器人。上下两行分别对应两位不同受试者的不同站立姿势，证明了方法对不同人和不同机器人的适用性。</p>
</blockquote>
<p>图7展示了将人体运动重定向到iCub机器人的具体性能。上图显示人体右肘关节角度与iCub对应关节角度的跟踪情况。在约13秒时，人体做出了对机器人不可行的肘部构型，逆运动学求解器找到了一个能最小化链节旋转误差的可行解。下图对比了人体右小腿链节与iCub对应链节的旋转矩阵（用欧拉角表示），显示了良好的跟踪效果。</p>
<p><img src="https://i.imgur.com/placeholder4.png" alt="重定向性能"></p>
<blockquote>
<p><strong>图7</strong>：将人体运动重定向到iCub机器人的性能。上图：人体与机器人右肘关节角度。下图：人体与机器人右小腿链节旋转矩阵（欧拉角形式）对比，表明即使运动学结构不同，链节姿态也能被有效重定向。</p>
</blockquote>
<p><strong>遥操作实验结果</strong>：</p>
<ol>
<li><p><strong>与平衡控制器集成</strong>：图8展示了实验快照，机器人单脚站立平衡的同时，跟踪来自重定向的全身关节参考。图9显示了CoM和部分关节的跟踪情况。CoM的x、y分量被良好跟踪以保持稳定在支撑多边形内，z分量则允许一定运动以执行重定向动作。部分关节（如躯干俯仰/翻滚、左膝）跟踪良好，而频繁运动的关节（如右肩俯仰/翻滚、左踝俯仰）则因平滑滤波引入的延迟而跟踪略有滞后。<br><img src="https://i.imgur.com/placeholder5.png" alt="平衡实验快照"></p>
<blockquote>
<p><strong>图8</strong>：使用平衡控制器进行全身重定向的实验快照。机器人在左腿上保持平衡的同时，复现操作者的上身和手臂姿态。<br><img src="https://i.imgur.com/placeholder6.png" alt="平衡跟踪结果"><br><strong>图9</strong>：平衡控制器实验中，质心（CoM）和关节角度的跟踪情况。蓝色为期望值（来自重定向或固定参考），橙色为实际值。垂直虚线对应图8中的快照时刻，展示了在平衡约束下关节的跟踪性能。</p>
</blockquote>
</li>
<li><p><strong>与行走控制器集成</strong>：图10展示了实验的三个阶段：第一阶段和第三阶段为双足站立静止期，第二阶段为行走期。行走期间，仅启用了上半身的重定向。图11显示了CoM和上半身关节的跟踪情况。CoM的x、y分量在整个实验中被精确跟踪。在站立阶段（第一阶段），关节重定向跟踪良好，误差低；在行走阶段（第二阶段），为重定向任务设置的增益被设为零以避免影响行走稳定性，因此关节跟踪误差增大；行走停止后（第三阶段），恢复高增益，跟踪误差再次降低。<br><img src="https://i.imgur.com/placeholder7.png" alt="行走实验阶段"></p>
<blockquote>
<p><strong>图10</strong>：使用行走控制器进行全身重定向的实验阶段：(1)双足站立阶段（启用手臂重定向），(2)行走阶段（仅行走控制，手臂重定向增益为零），(3)恢复双足站立阶段（重新启用手臂重定向）。<br><img src="https://i.imgur.com/placeholder8.png" alt="行走跟踪结果"><br><strong>图11</strong>：行走控制器实验中，质心（CoM）和上半身关节的跟踪情况。蓝色为期望值，橙色为实际值。紫色和绿色垂直线分别标示行走阶段的开始和结束。可见在行走阶段，关节跟踪误差增大，因为重定向增益被暂时禁用。</p>
</blockquote>
</li>
</ol>
<p><strong>消融实验与组件贡献</strong>：论文虽未设置传统的消融实验，但通过在不同机器人模型（不同自由度、构型）和不同人体受试者上的重定向实验，以及集成两种不同原理的全身控制器进行实时遥操作，充分验证了所提几何重定向框架本身的鲁棒性、可扩展性和有效性。核心组件——基于固定旋转矩阵 ( ^H\mathbf{R}^R ) 的几何映射和基于机器人模型的QP逆运动学求解——是方法成功的关键。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出了一种新颖的、基于几何映射的全身运动重定向框架，它直接利用机器人URDF模型，通过一个固定的旋转矩阵将人体链节运动转换到机器人链节，极大地增强了对不同人体用户和不同机器人模型的可扩展性。2) 将重定向问题表述为一个统一的、基于动力学系统的逆运动学优化问题（QP），能够自然地处理机器人的运动学约束和关节限位。3) 通过广泛的运动学重定向实验和与两种先进全身控制器（平衡与行走）集成的实时遥操作实验，全面验证了所提框架的有效性和实用性。</p>
<p>论文自身提到的局限性包括：在平衡控制器实验中，机器人的质心参考是独立于人体的；在行走控制器实验中，仅限于上半身重定向，且质心和脚部轨迹参考也独立于人体。这意味着当前框架尚未实现人体运动对机器人平衡和步态的直接、全身性驱动。</p>
<p>这项工作对后续研究的启示在于：它为实现更自然、更直观的人形机器人遥操作提供了一个强大且可扩展的底层重定向解决方案。未来的工作可以沿着论文指出的方向，探索如何将人体运动信息（如躯干和骨盆运动）也用于生成机器人的质心、脚部乃至全身的协调运动参考，从而实现真正意义上由人体动作直接驱动的、动态的全身遥操作。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人遥操作中的人体运动重定向问题，提出了一种基于机器人模型逆运动学的全身几何重定向框架。该方法的核心是增强系统的可扩展性，使不同用户能够以最小改动远程操作不同机器人模型，并在构型空间层面实现直观的人机交互。论文通过在多机器人模型上进行全身重定向演示，并利用两种先进的全身体控制器进行遥操作实验，验证了该方法的有效性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/1909.10080" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>