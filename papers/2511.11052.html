<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2511.11052" target="_blank" rel="noreferrer">2511.11052</a></span>
        <span>作者: Lin Shao Team</span>
        <span>日期: 2025-11-14</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在机器人操作领域，当物体因几何约束、潜在碰撞或物体特性而无法被稳定抓取时，仅依赖抓取的操作往往变得不可行或效率低下。非抓取操作（如推、戳、滑）能显著拓宽机器人的操作能力。然而，构建一个能够泛化不同任务、物体和环境，并无缝整合抓取与非抓取操作的统一框架极具挑战：机器人需要决定何时调用非抓取技能、为每个场景选择合适的操作基元，并将抓取与非抓取策略组合成鲁棒的多步骤计划。</p>
<p>现有方法存在关键局限：专注于单一非抓取基元的策略无法根据场景上下文在多个选项中选择或整合抓取操作；经典的任务与动作规划框架依赖大量手工制作的领域知识，限制了在新物体和环境中的适应性；基于视觉语言模型的规划器将任务表示为自然语言子目标或图像空间路点，无法在所有空间方向上完全指定非抓取动作（例如，诱导旋转的戳动），且通常缺乏闭环计划修正。</p>
<p>本文针对上述痛点，提出了AdaptPNP框架。其核心思路是利用视觉语言模型解释场景和任务指令，生成一个高层计划骨架，然后通过基于数字孪生的物体中心中间层预测期望的物体位姿以进行“心理预演”，最后通过控制模块合成低级指令，并利用连续的执行反馈实现在线任务计划修正和自适应重规划。</p>
<h2 id="方法详解">方法详解</h2>
<p>AdaptPNP是一个三阶段的、由视觉语言模型驱动的任务与动作规划框架，旨在自适应地选择和组合抓取与非抓取技能。整体流程如下：首先，任务规划器根据视觉观察和文本指令生成一个混合操作基元序列（计划骨架）；其次，针对骨架中的每个基元，在数字孪生中生成并筛选候选的6自由度物体目标位姿（子目标）；最后，低级执行模块将子目标转化为机器人轨迹并执行，执行结果（成功或失败及错误信息）反馈给反思器，用于迭代修正计划。</p>
<p><img src="https://arxiv.org/html/2511.11052v1/figs/Pipeline.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：AdaptPNP的整体流程。从指令和场景图像开始，任务规划器生成初始计划（例如，直接推），该计划在数字孪生中进行心理预演以采样6D目标位姿。执行失败后，反思器分析错误并为规划器提供反馈，从而重新规划（例如，抓取并移动）。此循环持续进行，直至成功计划（例如，推到边缘然后抓取）完成任务。</p>
</blockquote>
<p><strong>核心模块与技术细节：</strong></p>
<ol>
<li><p><strong>计划骨架生成与反思</strong>：该模块包含两个VLM子模块。</p>
<ul>
<li><strong>任务规划器</strong>：接收视觉观察和文本任务指令，结合预定义的操作基元集合（包括非抓取基元“推”、“旋转”和抓取基元“抓取”、“移动到”、“释放”），通过思维链推理生成初始的计划骨架。该骨架是一个操作基元序列，每个基元附带离散参数（如目标物体、相关区域）。</li>
<li><strong>VLM反思器</strong>：当低级执行失败时，反思器接收来自控制器的文本错误信息和新的场景观察。它分析失败的根本原因，并将推理结果反馈给任务规划器，以生成修订后的计划骨架。这个闭环反思机制使系统能够在多个语义合理但物理不可行的计划中进行筛选。</li>
</ul>
</li>
<li><p><strong>子目标位姿生成</strong>：此阶段将高层的计划骨架转化为具体的、物理可行的6D物体目标位姿，作为连接规划与执行的中间表示。</p>
<ul>
<li><strong>位姿采样</strong>：首先，VLM根据当前计划基元将指令细化到具体区域描述（如“物体最近的桌边”）。接着，另一个视觉基础模型将该描述定位到图像像素坐标，并反投影到3D世界点。围绕此点，根据操作类型允许的自由度（例如，推操作采样x, y, 偏航角）采样候选物体位姿。每个候选位姿在数字孪生中进行物理仿真以验证可行性（如物体是否翻倒或掉落），剔除不可行选项后，将排名前四的可行位姿渲染成图像提示。</li>
<li><strong>VLM选择</strong>：VLM根据渲染的图像提示、当前技能和下一个技能，选择最合适的候选位姿。该6D位姿即成为当前操作基元执行的子目标。</li>
</ul>
</li>
<li><p><strong>低级执行与反馈</strong>：此模块将数字孪生中生成的子目标位姿映射到真实或仿真的执行环境中，并驱动机器人完成动作。</p>
<ul>
<li><strong>动作基元控制器</strong>：系统采用启发式策略将物体从初始位姿驱动到目标子目标位姿。例如，对于“推”操作，通过沿目标方向向量推动并对接触点施加法向力来对齐位置和偏航角；“旋转”操作则通过在对侧边缘施力诱导物体绕支撑边旋转。抓取、移动和释放操作则利用现成的抓取检测和运动规划器完成。</li>
<li><strong>反馈与重规划</strong>：如果执行失败（如逆运动学无解、碰撞），控制器会生成错误消息。该错误消息与新的场景观察一同传递给VLM反思器，进而触发任务规划器的重规划。</li>
</ul>
</li>
</ol>
<p><strong>创新点</strong>：与现有方法相比，AdaptPNP的创新主要体现在：1）提出了一个由VLM驱动、支持闭环反思的自适应任务规划框架，能够动态组合抓取与非抓取技能；2）引入了基于数字孪生的6D物体位姿作为中间表示，有效弥合了语义规划与物理执行之间的鸿沟，并保证了动作的物理可行性；3）通过物体中心的接口（仅传递目标位姿而非具体关节指令），降低了数字孪生与真实环境间的动力学差异影响，支持跨 embodiment 迁移。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：评估在仿真（IsaacSim）和真实世界环境中进行。仿真实验选取了八项具有代表性的混合抓取/非抓取操作任务，分为三类：物体对齐、外在于操作性和工具使用。任务设计使物体初始状态往往无法直接抓取（如太薄、与表面齐平）。每个任务进行10次独立试验，初始条件和目标位姿均加入随机扰动。成功标准包括位置误差小于3cm且方向误差小于10度，并允许最多三次重规划。</p>
<p><strong>对比基线</strong>：</p>
<ul>
<li><strong>MPC</strong>：基于模型的预测路径积分方法。</li>
<li><strong>RL</strong>：近端策略优化算法。</li>
<li><strong>MoKA</strong>：基于VLM、使用2D关键点作为中间表示的层次规划方法。</li>
<li><strong>MolmoAct</strong>：在2D图像中生成路点和机器人轨迹的VLM方法。</li>
<li><strong>OpenVLA</strong>：端到端的视觉语言动作模型。</li>
</ul>
<p><img src="https://arxiv.org/html/2511.11052v1/figs/setup.png" alt="任务设置"></p>
<blockquote>
<p><strong>图3</strong>：任务设置。评估涵盖八项仿真任务（上两行）和四项真实世界任务（最后一行）。每个场景中，最终目标位姿显示为半透明物体，目标区域由黄色覆盖层指示。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<p>TABLE II : Quantitative Results of Simulation Tasks ( ↑ )</p>
<table>
<thead>
<tr>
<th align="left">Method</th>
<th align="center">Box</th>
<th align="center">Book</th>
<th align="center">Edge</th>
<th align="center">Wall</th>
<th align="center">Slope</th>
<th align="center">Slot</th>
<th align="center">Tool Hook</th>
<th align="center">Tool Pusher</th>
</tr>
</thead>
<tbody><tr>
<td align="left">MPC</td>
<td align="center">8/10</td>
<td align="center">1/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
</tr>
<tr>
<td align="left">RL</td>
<td align="center">9/10</td>
<td align="center">3/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
</tr>
<tr>
<td align="left">MOKA</td>
<td align="center">2/10</td>
<td align="center">0/10</td>
<td align="center">1/10</td>
<td align="center">3/10</td>
<td align="center">2/10</td>
<td align="center">1/10</td>
<td align="center">1/10</td>
<td align="center">0/10</td>
</tr>
<tr>
<td align="left">MolmoAct</td>
<td align="center">3/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">1/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
</tr>
<tr>
<td align="left">OpenVLA</td>
<td align="center">1/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
<td align="center">0/10</td>
</tr>
<tr>
<td align="left"><strong>Ours</strong></td>
<td align="center"><strong>9/10</strong></td>
<td align="center"><strong>7/10</strong></td>
<td align="center"><strong>6/10</strong></td>
<td align="center"><strong>8/10</strong></td>
<td align="center"><strong>5/10</strong></td>
<td align="center"><strong>9/10</strong></td>
<td align="center"><strong>6/10</strong></td>
<td align="center"><strong>3/10</strong></td>
</tr>
</tbody></table>
<p>如表II所示，AdaptPNP在绝大多数任务上显著优于所有基线方法。MPC和RL在简单的“Box Alignment”任务上表现尚可，但在需要长视野、非单调策略（如绕开障碍）的任务上性能急剧下降。基于VLM的基线方法（MoKA, MolmoAct）和端到端模型（OpenVLA）整体成功率很低，表明它们在处理需要复杂物理推理和精确空间控制的混合操作任务时存在不足。AdaptPNP则通过层次化规划、物理验证的中间表示和闭环反馈，有效解决了这些挑战。</p>
<p><strong>消融实验分析</strong>：论文通过消融实验验证了两个关键设计的贡献。移除<strong>闭环反思机制</strong>后，系统无法从执行失败中学习并调整计划，在面对物理不可行的初始计划时成功率下降。移除<strong>6D物体位姿中间表示</strong>（例如，退化为2D关键点），则无法精确指定旋转等操作，在外在于操作性和需要对物体进行三维操纵的任务上性能显著降低。实验表明，二者对于处理复杂的混合操作任务都至关重要。</p>
<p><strong>真实世界实验</strong>：</p>
<p><img src="https://arxiv.org/html/2511.11052v1/figs/real.png" alt="真实世界实验"></p>
<blockquote>
<p><strong>图4</strong>：真实世界实验。展示了AdaptPNP在真实机器人上成功执行“Book Alignment”（左）和“Edge Extrinsic Dexterity”（右）任务的序列。机器人能够根据场景灵活运用旋转、推和抓取等技能完成任务。</p>
</blockquote>
<p>在真实机器人平台上进行的四项任务实验进一步验证了框架的有效性。系统成功处理了书本对齐、利用桌边外在于操作性等场景，展示了其从仿真到真实的迁移能力。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了AdaptPNP，一个通用的、可泛化的操作框架，能够根据任务需求、物体特性和环境约束自适应地选择和协调抓取与非抓取技能。</li>
<li>引入了基于数字孪生的物体中心中间表示（6D目标位姿），通过“心理预演”生成物理信息丰富的子目标，有效桥接了规划与执行间的语义-物理鸿沟。</li>
<li>通过广泛的仿真与真实实验，在需要协调抓取/非抓取技能的多样化复杂操作场景中验证了框架的优越性能。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，数字孪生与真实环境之间可能存在动力学差距（如摩擦系数、物体质量分布），这可能导致在数字孪生中物理可行的位姿在真实执行中失败。尽管框架通过物体中心接口和反思机制部分缓解了此问题，但差距依然存在。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>混合技能组合</strong>：展示了将高层语义推理（VLM）与底层物理验证（数字孪生/仿真）相结合，是实现复杂、多样化机器人操作的有效路径。</li>
<li><strong>中间表示的重要性</strong>：6D物体位姿作为一种与具体机器人形态解耦的中间表示，为构建更通用、可迁移的操作系统提供了思路。</li>
<li><strong>闭环学习</strong>：集成执行反馈的在线反思与重规划机制，是提高机器人系统在不确定、动态环境中鲁棒性的关键。未来可探索如何更高效地从失败中学习，或利用历史经验优化初始规划。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人操作中抓取（P）与非抓取（NP）技能自适应集成的核心挑战，提出AdaptPNP框架。该框架基于视觉语言模型（VLM）生成任务计划骨架，利用数字孪生中间层预测对象姿态，并通过控制模块实现在线反馈与重新规划。在模拟和真实环境的混合操作任务中评估，验证了框架能有效组合P和NP技能，推动通用机器人操作能力发展。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2511.11052" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>