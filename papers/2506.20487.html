<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>A Survey of Behavior Foundation Model: Next-Generation Whole-Body Control System of Humanoid Robots - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>A Survey of Behavior Foundation Model: Next-Generation Whole-Body Control System of Humanoid Robots</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.20487" target="_blank" rel="noreferrer">2506.20487</a></span>
        <span>作者: Yuan, Mingqi, Yu, Tao, Ge, Wenqi, Yao, Xiuyong, Wang, Huijiang, Chen, Jiayu, Li, Bo, Zhang, Wei, Zeng, Wenjun, Chen, Hua, Jin, Xin</span>
        <span>日期: 2025/06/25</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人因其类人形态和高自由度，在复杂运动控制、人机交互和通用物理智能方面展现出巨大潜力。然而，由于其复杂的动力学、欠驱动特性以及多样化的任务需求，实现高效的人形机器人全身控制（Whole-Body Control, WBC）仍是一个根本性挑战。传统基于模型的WBC方法（如基于质心的模型预测控制和分层二次规划求解器）虽然奠定了理论基础并在早期机器人上得到应用，但其任务设计、增益调参依赖于大量人工，面对不平坦地形或动态转换等复杂行为时显得脆弱且不灵活。随后兴起的基于学习的方法（如强化学习和模仿学习）在获取复杂技能方面显示出潜力，例如DeepMimic框架结合运动捕捉数据学习动态技能，TRILL方法在真实世界双手机器人任务中达到85%的成功率。然而，这些方法普遍面临样本效率低、仿真到现实的鸿沟、对新场景泛化能力差、需要针对新任务进行大量重新训练等局限。</p>
<p>本文针对上述学习型控制器泛化能力有限、适应新场景成本高的核心痛点，提出了<strong>行为基础模型（Behavior Foundation Model, BFM）</strong>这一新范式。BFM借鉴了通用基础模型（如GPT-4）的思路，通过在大规模、多样化的行为数据（如人类演示、智能体-环境交互数据）上进行预训练，学习可重用的基础技能和广泛的行为先验，从而能够以零样本或快速适应的方式应对广泛的下游任务。本文的核心思路是对应用于人形机器人WBC的BFM进行一次全面综述，系统梳理其预训练流程、适应策略、应用、局限与未来机遇。</p>
<h2 id="方法详解">方法详解</h2>
<p>BFM的核心在于通过预训练学习广泛的行为先验，并通过高效的适应策略应用于下游任务。其整体框架如论文图3所示，清晰地划分了预训练和适应两大阶段。</p>
<p><img src="https://arxiv.org/html/2506.20487v5/x3.png" alt="预训练与适应策略总览"></p>
<blockquote>
<p><strong>图3</strong>：本综述讨论的BFM预训练流程与适应策略概览。预训练阶段（左侧）主要包含三种范式：目标条件学习、内在奖励驱动学习和前向后向表示学习。适应阶段（右侧）包括常见的微调技术（如全参数微调、LoRA）以及面向分层控制的策略（如利用LLM等生成模型进行高层规划）。</p>
</blockquote>
<p><strong>预训练阶段</strong>旨在从大规模数据源中学习可重用的基础技能和行为先验。当前方法主要分为三类：</p>
<ol>
<li><strong>目标条件学习</strong>：智能体的行为以特定目标为条件进行训练，目标可以是指定状态、目标函数或外部任务描述。其优势在于学习到更灵活、可迁移的策略。这又衍生出两个子方向：<ul>
<li><strong>基于运动跟踪的技能学习</strong>：通过跟踪运动捕捉数据或专家演示的密集参考监督来学习技能。例如，<strong>TeamPlay</strong>框架通过类似DeepMimic的方法模仿大量足球运动数据，学习底层控制器，然后用于特定训练（如带球、射门）的RL微调。<strong>ASE</strong>和<strong>CALM</strong>框架通过对抗性模仿学习与无监督RL结合，学习可生成多样物理合理行为的潜空间条件控制器，作为下游任务的通用运动先验。<strong>HugWBC</strong>则探索不依赖预收集运动数据，通过将WBC重构为自监督的命令跟踪问题，从环境交互中学习鲁棒的移动技能。</li>
<li><strong>从基础技能到高层目标执行</strong>：使BFM能够解释和执行语言指令等多任务高层目标。<strong>MoConVQ</strong>引入基于VQ-VAE离散潜码的统一运动控制框架，支持运动跟踪、交互控制、文本生成运动等任务，并可结合LLM。<strong>MaskedMimic</strong>将物理角色控制视为通用运动补全问题，通过两阶段训练（全约束运动跟踪和部分约束VAE策略蒸馏），能够根据掩码关键帧、物体或文本指令生成全身运动。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2506.20487v5/x4.png" alt="目标条件学习工作流"></p>
<blockquote>
<p><strong>图4</strong>：目标条件学习的工作流程，通过训练策略以实现由目标嵌入指定的多样化目标状态，从而实现多功能的技能获取。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.20487v5/x5.png" alt="MaskedMimic示例"></p>
<blockquote>
<p><strong>图5</strong>：通过目标条件学习训练的BFM代表MaskedMimic，支持多样化的控制模态，并能在不同任务间实现无缝过渡。</p>
</blockquote>
<ol start="2">
<li><strong>内在奖励驱动学习</strong>：智能体不依赖明确的外部任务奖励，而是由鼓励探索、技能发现或新颖性检测的<strong>内在奖励</strong>信号驱动。其优化目标是最大化内在奖励的累积回报。代表性方法包括：<strong>ICM</strong>基于对下一状态的预测误差提供内在奖励，鼓励探索不可预测的环境；<strong>DIAYN</strong>通过最大化潜在技能变量与环境状态之间的互信息，鼓励发现多样化的、可重用的技能；<strong>RE3</strong>专注于最大化状态覆盖，鼓励访问过去经验中频率低的状态。这类方法通常在单一环境/任务上训练，行为先验的广度和直观性可能不如基于大数据集的方法，但其无监督技能发现和探索的特性符合BFM预训练的一些关键属性。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.20487v5/x6.png" alt="内在奖励驱动学习工作流"></p>
<blockquote>
<p><strong>图6</strong>：内在奖励驱动学习的工作流程。智能体通过自监督的奖励信号训练以探索和理解环境，从而实现非定向的技能获取。</p>
</blockquote>
<ol start="3">
<li><strong>前向后向表示学习</strong>：此类方法在无奖励的转移数据上进行无监督训练，学习前向嵌入网络（FEN）和后向嵌入网络（BEN）。在测试时，可以与特定的奖励函数结合，无需额外学习或规划即可为广泛的奖励函数类推断出近似最优的策略。<strong>FB-IL</strong>首次引入了BFM概念，提出了基于后继度量的框架，能够通过前向后向状态特征匹配，仅需最少演示即可即时模仿多样化行为，并支持行为克隆、奖励推断和分布匹配等多种模仿学习范式。</li>
</ol>
<p><strong>适应阶段</strong>旨在将预训练好的BFM高效应用于具体下游任务。主要策略包括：</p>
<ol>
<li><strong>微调技术</strong>：包括全参数微调（FFT）、低秩适应（LoRA）等方法。此外，还有如<strong>TaskTokens</strong>、<strong>ReLA/LoLA</strong>等工作，通过调整潜在任务向量或引入适配器模块，在低计算成本下实现快速适应。</li>
<li><strong>面向分层控制</strong>：将BFM作为底层控制器，与高层规划器（如大语言模型LLM、扩散模型）结合。高层规划器处理抽象目标并生成子任务，由BFM执行，从而完成复杂的长周期任务。例如，<strong>LangWBC</strong>、<strong>LeVERB</strong>等工作探索了利用LLM进行高层任务分解和规划，由BFM负责具体运动执行。</li>
</ol>
<p>与现有方法相比，BFM的创新点在于其<strong>“预训练-适应”范式</strong>。它不同于为每个任务从头训练的传统学习型控制器，也不同于灵活性有限的传统模型基控制器。BFM通过大规模预训练沉淀出通用的、可组合的行为基元与先验知识，从根本上提升了策略的泛化能力和适应新任务的效率。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>本文作为一篇综述性论文，并未报告统一的、可量化的对比实验，而是系统梳理和总结了相关BFM方法的研究进展、核心思路及其展示的能力。论文通过分类和列举大量代表性工作（见表II），并分析其动机与特性，来论证BFM范式的有效性与前景。</p>
<p><img src="https://arxiv.org/html/2506.20487v5/x2.png" alt="人形机器人全身控制器演进图"></p>
<blockquote>
<p><strong>图2</strong>：人形机器人全身控制器的演进图谱，展示了从传统模型基方法到灵活的学习基方法，最终朝向能在多样场景中解决广泛任务的通才（即BFM）发展的趋势。</p>
</blockquote>
<p>论文列举了众多已成功在真实人形机器人上部署的BFM相关方法（在表II中用*标出），例如<strong>HugWBC</strong>、<strong>HOVER</strong>、<strong>CLONE</strong>、<strong>TWIST</strong>系列、<strong>BFM4Humanoid</strong>等，这从实践层面证明了BFM范式的可行性。文中也提及了部分方法展示的具体性能，例如：</p>
<ul>
<li><strong>TRILL</strong>方法结合VR遥操作与WBC，在真实世界双手机器人任务中取得了<strong>85%的成功率</strong>。</li>
<li><strong>HOVER</strong>框架实现了在真实环境中，单个统一策略在移动、操作、导航等任务间的<strong>无缝切换</strong>，展示了通用目的控制能力。</li>
<li><strong>MaskedMimic</strong>等框架展示了在模拟环境中，根据文本指令、掩码关键帧等多样化条件生成复杂、物理合理的全身运动的能力。</li>
</ul>
<p>本文的主要“实验结果”体现在对现有BFM研究全景的系统性刻画上。图3提供的分类框架，以及表II对数十种方法的归类，本身就是一个重要的研究成果，为后续研究者提供了清晰的路线图。论文通过分析指出，BFM的核心优势在于其通过预训练获得的<strong>强大行为先验</strong>和<strong>快速适应能力</strong>，这使其能够克服传统方法泛化性差、学习型方法适应成本高的局限。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为以下三点：</p>
<ol>
<li><strong>首次系统性综述</strong>：这是首篇专注于行为基础模型（BFM）发展，特别是其在人形机器人全身控制中应用的综述文章，为这一新兴领域提供了全面的概览和清晰的发展脉络。</li>
<li><strong>提出清晰的分类框架</strong>：系统地将BFM的构建方法划分为目标条件学习、内在奖励驱动学习和前向后向表示学习三大预训练范式，并总结了微调与分层控制两大类适应策略，为理解和比较不同方法提供了统一视角。</li>
<li><strong>指明未来方向与挑战</strong>：论文不仅总结了BFM的应用潜力，还深入探讨了当前局限（如对高质量数据集的依赖、高计算成本、安全验证挑战等）、未来机遇（如多模态融合、因果推理、具身基础模型结合）以及相关的风险与伦理问题，为后续研究提供了重要指引。</li>
</ol>
<p>论文自身提到的局限性主要源于其综述性质，它整合了现有研究但未提出新的算法或进行直接的实验对比。然而，文中详细分析了当前BFM面临的普遍挑战，例如：预训练需要<strong>大规模、高质量、多样化的行为数据</strong>，其收集与标注成本高昂；模型训练和部署的<strong>计算开销巨大</strong>；将BFM安全可靠地部署到复杂的物理世界中，面临<strong>仿真到现实的鸿沟、实时性要求、安全性验证</strong>等严峻挑战；此外，BFM的决策过程通常缺乏可解释性，在需要高安全性的应用中存在风险。</p>
<p>本文对后续研究的启示在于，BFM代表了迈向<strong>可扩展、通用化人形机器人智能</strong>的一条关键路径。研究者应关注如何构建更高效的数据收集与合成管道、设计更样本高效和安全稳定的训练算法、开发更轻量级的适应技术，并积极探索BFM与视觉-语言-动作模型、大语言模型等其他基础模型的融合，以实现更高层次的场景理解、任务规划和人机交互能力。同时，必须同步推进相关安全与伦理框架的建设。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文综述了人形机器人全身控制（WBC）领域的新范式——行为基础模型（BFM）。核心问题是解决人形机器人因复杂动力学、欠驱动特性及多样任务需求而导致的高效全身控制难题，并克服传统学习方法对新场景需重复训练的局限。BFM的关键技术在于利用大规模预训练学习可重用的基础技能和广泛的行为先验，从而实现对新下游任务的零样本或快速适应。论文指出，BFM为构建可扩展、通用的人形机器人智能控制框架提供了关键路径，显著提升了控制策略的适应性和泛化能力。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.20487" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>