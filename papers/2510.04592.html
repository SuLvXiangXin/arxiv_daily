<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.04592" target="_blank" rel="noreferrer">2510.04592</a></span>
        <span>作者: Wenjie Song Team</span>
        <span>日期: 2025-10-06</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人领域近年来的进步很大程度上由模仿学习驱动，但其严重依赖于大规模、高质量的演示数据。然而，收集此类数据，特别是针对移动操作机器人的数据，仍然是一个重大挑战。移动操作器需要在部分可观测的动态环境中协调基座移动和手臂操作，维度高、任务复杂。因此，现有研究大多集中于更简单的桌面场景，移动操作领域相对未被充分探索。当前主流的数据收集方法依赖专家遥操作或基于VR的远程遥操作，这些方法耗时费力且难以扩展。基于仿真的数据生成方法虽然能大规模收集数据，但现有框架主要面向固定基座操作器，对需要全身协调的移动操作场景支持有限。</p>
<p>本文针对移动操作领域高质量演示数据稀缺这一具体痛点，提出了一个基于数字孪生的可扩展学习和数据生成框架MobRT。其核心思路是：通过集成虚拟运动学链和全身运动规划，在仿真中自动生成大量、多样且物理一致的全身移动操作演示轨迹，并结合少量真实世界演示，以高效训练出泛化能力强的策略。</p>
<h2 id="方法详解">方法详解</h2>
<p>MobRT的整体框架包含三个关键组成部分：仿真中的演示生成、真实世界演示的适应，以及基于混合数据的策略训练。输入是任务场景的数字孪生模型和任务定义，输出是可用于训练策略的演示数据集以及训练好的策略模型本身。</p>
<p><img src="https://arxiv.org/html/2510.04592v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：MobRT流程总览。框架集成了三个关键组件：(1) 仿真中的演示生成：通过资产标注、操作动作生成和全身运动规划实现大规模、低成本的数据收集；(2) 真实世界演示的适应：利用少量真实轨迹捕获真实动力学和传感器噪声以补充仿真数据；(3) 混合数据策略训练：多模态编码器处理视觉和本体感知输入，基于Transformer的扩散策略学习协调移动基座和手臂动作以完成全身任务。</p>
</blockquote>
<p><strong>核心模块1：仿真演示生成</strong><br>该模块旨在自动生成高质量的演示轨迹，包含四个子步骤：</p>
<ol>
<li><strong>数字孪生资产与标注</strong>：利用PartNet-Mobility、UniDoorManip和RoboTwin-OD等数据集获取物体的数字孪生模型，并通过AIGC和凸分解（CoACD）进行处理以确保物理一致性。为物体标注6-DoF抓取姿态，并为某些刚性物体（如容器和盘子）定义功能轴以指示其用途。</li>
<li><strong>生成操作动作</strong>：针对两种主要任务类型采用不同策略。对于刚性物体间的交互（如放置），利用标注的功能轴对齐两个物体的轴。对于铰接物体操作（如开门），采用虚拟运动学链（VKC）框架：在末端执行器到达目标姿态并抓取铰接部件后，利用仿真器提供的运动学模型，采样关节角度序列并计算出末端执行器需要跟踪的轨迹，从而将复杂的操作简化为末端轨迹跟踪问题。</li>
<li><strong>全身运动规划</strong>：为了产生协调的基座-手臂运动，采用全身运动规划。其优化目标是在将末端执行器驱动至目标姿态的同时，最小化控制代价，并满足底盘软约束（如保持固定朝向、避免碰撞）。规划出的轨迹进一步使用时优路径参数化（TOPP-RA）算法进行后处理，以确保动态可行性。框架也支持底盘和手臂的独立轨迹生成，与开合夹爪动作共同构成一组运动基元，用于组合成多样的任务工作流。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.04592v1/x3.png" alt="生成仿真演示"></p>
<blockquote>
<p><strong>图3</strong>：生成仿真演示。(a) 功能轴对齐以合成拾放动作；(b) 使用VKC生成铰接物体操作；(c) 全身规划与独立规划的对比；(d) 随机化环境重置以获得多样且经过验证的数据。</p>
</blockquote>
<ol start="4">
<li><strong>环境重置与验证</strong>：在执行轨迹后，会验证任务是否成功（如物体间距是否低于阈值、目标关节是否达到指定角度），过滤无效轨迹。每次重置时，对物体位置、朝向、大小、机械臂初始构型、地面和物体纹理、光照条件进行大量随机化，以确保数据多样性和后续学习的鲁棒性。</li>
</ol>
<p><strong>核心模块2：策略学习</strong><br>本文提出一个新的基线策略，该策略基于Transformer神经网络，并在扩散策略框架下进行训练。</p>
<ul>
<li><strong>基于流匹配的动作生成</strong>：采用基于最优传输理论的流匹配（Flow Matching）方法，而非传统的扩散模型。它学习一个时间相关的向量场，能以更少的步骤将噪声样本传输到专家动作，实现更快、更稳定的推理。结合动作分块（Action Chunking）技术以提高时间一致性。损失函数为 ℒ_FM = 𝔼_τ,𝐙,𝐀 ∥ v(τ,𝐗_t, o_t) − (𝐀−𝐙) ∥²，其中v是策略网络的输出。</li>
<li><strong>网络架构</strong>：策略模型由多模态编码器和基于Transformer的解码器组成。RGB观测使用预训练的ResNet-18骨干网络处理。点云输入则先将不同相机的点云转换到统一坐标系后融合，再用共享的PointEncoder编码。本体感知状态和带噪声的动作序列分别通过独立的MLP编码。解码器交替使用自注意力和交叉注意力层，其中交叉注意力用于与多模态编码器输出交互，自注意力用于平滑动作序列。</li>
<li><strong>与真实数据协同训练</strong>：为弥补纯仿真数据在动力学、传感器噪声和执行延迟方面的不足，策略使用仿真数据和少量真实数据共同训练。训练时以相等概率从仿真演示集 D_sim^m 和真实演示集 D_real^m 中采样，总损失为两者期望损失之和。</li>
</ul>
<p><strong>创新点</strong>：与现有方法相比，MobRT的创新主要体现在：1) 专门针对移动操作设计了全身运动规划模块，生成协调的基座-手臂运动，而非先导航后操作的分离式策略；2) 利用VKC框架自动化生成铰接物体操作的末端轨迹，避免了手工编码运动；3) 提出了一个结合流匹配和Transformer的新基线策略，并利用仿真与真实混合数据训练，提升了泛化性能。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>仿真平台与数据集</strong>：使用支持GPU加速和光线追踪的ManiSkill3物理仿真器。铰接物体操作任务使用PartNet-Mobility和UniDoorManip数据集中的橱柜和洗碗机构建。拾放任务基于RoboTwin-OD数据集设计，但要求操作过程中基座移动。</li>
<li><strong>真实机器人平台</strong>：由Galaxea A1机械臂安装在Ranger Mini 3移动基座上构成。使用三个Intel RealSense D435i相机（两个全局，一个腕部）提供观测。为增强仿真到真实的迁移，对仿真深度图添加了模拟真实传感器噪声的扰动（边缘伪影、随机孔洞），并对点云进行了体素下采样和统计离群点去除。</li>
<li><strong>对比基线方法</strong>：评估了ACT、DP (Diffusion Policy)、DP3 (点云版DP) 和 iDP3 (改进版DP3) 等基线算法，并与本文提出的RGB-based和Point Cloud-based策略进行对比。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>基准评估与数据有效性</strong>：在三个代表性任务（打开橱柜抽屉、放置容器、打开洗碗机）上，使用不同数量（50, 100, 200）的MobRT生成演示训练各基线策略。结果（表I）显示，对于大多数方法和任务，成功率随着演示数量的增加而显著提高，验证了MobRT生成数据的有效性及其与任务成功的强相关性。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.04592v1/images/task_exec.png" alt="任务执行"></p>
<blockquote>
<p><strong>图5</strong>：仿真中MobRT的任务执行。展示了包括打开抽屉、洗碗机以及物体放置在内的代表性任务，体现了全身协调和顺序操作能力。</p>
</blockquote>
<ol start="2">
<li><p><strong>本文策略的性能</strong>：如表II所示，本文提出的策略（RGB-based和Point Cloud-based）在所有任务和数据量下均 consistently 优于基线方法。例如，在“打开洗碗机”任务中，使用50条演示时，最佳基线成功率为30%，而本文RGB-based方法达到60%。在低数据区域（50条演示）优势尤为明显，平均成功率比基线高出21.1%至26.7%，体现了方法的鲁棒性和数据效率。</p>
</li>
<li><p><strong>点云预处理的影响</strong>：实验发现DP3和iDP3在“放置容器”任务上性能提升有限。分析指出，这些方法使用的最大池化（max pooling）对背景噪声和杂乱环境敏感。而本文的点云策略通过对点云数据进行标记化（tokenization）处理，保留了空间细节，从而在移动机器人平台上表现更鲁棒。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2510.04592v1/images/real_experiment.png" alt="真实实验"></p>
<blockquote>
<p><strong>图7</strong>：真实世界实验。展示了利用300条仿真演示和仅20条真实演示训练的策略，成功在真实机器人上完成开门和移动基座拾放任务，实现了有效的仿真到真实迁移。</p>
</blockquote>
<ol start="4">
<li><strong>仿真到真实迁移</strong>：如图1和真实实验所示，通过结合300条仿真演示和仅20条真实演示进行训练，策略能够成功迁移到真实机器人，完成铰接物体交互和移动基座拾放任务，证明了框架在真实场景中的实用性。</li>
</ol>
<p><strong>消融实验总结</strong>：实验虽未以标准消融形式列出，但通过对比不同数据量下的性能、不同传感器模态（RGB vs. Point Cloud）的结果、以及本文策略与基线策略的差异，实质上验证了大规模仿真数据、全身运动规划生成的协调轨迹、以及本文提出的Transformer-based扩散策略架构各自对性能提升的贡献。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了 <strong>MobRT框架</strong>，一个专为移动操作器设计的、灵活的可扩展数据生成与学习平台，能够高保真仿真复杂的全身移动操作场景并自动生成高质量演示。</li>
<li>建立了基于MobRT生成数据的<strong>综合基准</strong>，并用于在仿真和真实环境中广泛评估多种基线方法，证明了生成数据的有效性。</li>
<li>提出了一个<strong>新的基线控制策略</strong>，该策略基于Transformer和流匹配，在移动操作任务上优于现有基线，为后续研究提供了更强的比较基础。</li>
</ol>
<p><strong>局限性</strong>：论文提到，仿真生成的轨迹主要基于运动规划，可能无法完全捕获真实机器人系统的全部复杂性（如精确动力学、传感器噪声、执行延迟）。因此，仍然需要少量真实数据来弥补这一差距，以实现有效的仿真到真实迁移。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>数字孪生与自动化数据生成</strong>：MobRT展示了利用数字孪生和自动化规划技术大规模生成复杂任务数据的潜力，为数据匮乏的移动操作等领域提供了新的解决方案思路。</li>
<li><strong>全身协调策略学习</strong>：框架强调并实现了全身运动规划与策略学习的结合，表明协调基座与手臂的运动对于完成复杂移动操作任务至关重要，这应是未来算法设计的重要方向。</li>
<li><strong>仿真与真实数据的融合</strong>：工作验证了“大规模仿真数据+小规模真实数据”协同训练模式的有效性，为降低真实机器人学习成本、提高学习效率提供了可行路径。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对移动操作机器人缺乏大规模高质量演示数据的问题，提出MobRT框架。该框架基于数字孪生，通过虚拟运动控制与全身运动规划，自主生成铰接物体交互（如开门）和移动底座拾放任务的仿真演示数据。实验表明，仅用300个仿真演示和20个真实演示，即可实现成功的模拟到现实迁移，显著提升策略的泛化能力和任务成功率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.04592" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>