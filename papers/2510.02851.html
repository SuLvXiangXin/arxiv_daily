<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Action Deviation-Aware Inference for Low-Latency Wireless Robots - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Action Deviation-Aware Inference for Low-Latency Wireless Robots</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.02851" target="_blank" rel="noreferrer">2510.02851</a></span>
        <span>作者: Seong-Lyun Kim Team</span>
        <span>日期: 2025-10-03</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>为支持从自动驾驶到工业机器人操控等延迟敏感的AI应用，6G愿景是通过超可靠低延迟通信（HRLLC）连接移动设备、边缘和云端的计算资源，实现分布式机器学习。在此背景下，推测解码（speculative decoding）可促进分布式部署模型的协同推理：一个轻量级的设备端草案模型（draft model）本地生成草案，而一个能力更强的远程目标模型（target model）在服务器上通过推测采样（speculative sampling）并行验证和修正它们，从而在不损失准确性的前提下降低延迟。然而，与自回归文本生成不同，通常用于具身AI应用的行为克隆策略（behavior cloning policies）无法并行验证和修正多个草案，因为每个生成的动作都依赖于前一个动作执行后更新的观测。因此，本文提出<strong>动作偏差感知混合推理（ADAHI）</strong>，其核心思路是：基于与目标模型拒绝概率强相关的动作偏差，选择性地传输和验证草案，仅在必要时调用服务器操作，从而在保留推测采样准确性增益的同时，减少通信和计算开销。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的ADAHI框架旨在为基于向量量化行为变换器（VQ-BeT）的机器人策略实现低延迟协同推理。其核心是引入“动作偏差”作为本地判断是否需要触发服务器端推测采样的指标。</p>
<p><img src="https://arxiv.org/html/2510.02851v2/architecture.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：动作偏差感知混合推理（ADAHI）架构。(a) VQ-BeT操作：给定观测 $o_t$，代码预测头生成代码本嵌入向量的概率分布，偏移头（一个MLP）计算一个小的连续偏移。(b) 设备端草案模型生成动作后，计算其与过去动作指数移动平均的欧氏距离，得到动作偏差 $\Delta(t)$。(c) 当 $\Delta(t) &gt; \Delta_{th}$ 时，将嵌入向量索引、草案模型的概率分布 $\mathbf{q}_t$ 和观测 $o_t$ 传输至服务器进行推测采样，修正后的动作传回本地设备。</p>
</blockquote>
<p><strong>整体流程</strong>：在每一步推理中，设备端草案模型根据当前观测生成动作草案及其概率分布。随后，计算该动作的“动作偏差”。若偏差低于预设阈值 $\Delta_{th}$，则认为该动作被目标模型接受的概率高，直接执行该草案动作，跳过与服务器的通信。若偏差超过阈值，则触发传输，将观测、草案概率分布和采样得到的嵌入向量索引发送至服务器。服务器端目标模型生成其自身的概率分布，对每个代码本的草案嵌入向量执行推测采样进行验证和可能的修正，并将最终确定的嵌入向量索引传回设备端，解码为连续动作后执行。</p>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>动作偏差计算</strong>：动作偏差 $\Delta(t)$ 用于估计当前草案动作被目标模型拒绝的概率。其计算灵感来源于金融领域的均值回归。首先计算过去动作的指数移动平均（EMA）：$\bar{\mathbf{a}}<em>t = (1-\alpha)\bar{\mathbf{a}}</em>{t-1} + \alpha a_{t-1}$，其中 $\alpha$ 为平滑因子。然后计算净偏差 $\Delta_{\text{net}}(t) = | a_t - \bar{\mathbf{a}}<em>t |<em>2$。最终的动作偏差是净偏差经过历史标准差 $\sigma</em>{\Delta</em>{net}}$ 归一化的结果：$\Delta(t) = \Delta_{\text{net}}(t) / \sigma_{\Delta_{net}}$。论文通过实验证明，动作偏差与目标模型对主代码本嵌入向量的拒绝概率存在强相关关系（对数或线性关系）。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.02851v2/rejectprob.png" alt="动作偏差与拒绝概率关系"></p>
<blockquote>
<p><strong>图2</strong>：三个用例中动作偏差与拒绝概率的关系图。每个用例的相关系数至少为0.9457，基于超过50,000个动作数据。球平衡任务呈对数关系，厨房操作和集群控制任务呈线性关系。</p>
</blockquote>
<ol start="2">
<li><strong>选择性传输与服务器端推测采样</strong>：传输决策基于动作偏差阈值 $\Delta_{th}$。一旦决定传输，服务器端目标模型 $M_p$ 会根据接收到的观测生成其概率分布 $\mathbf{p}_t$。对于每个代码本 $i$，草案模型采样的嵌入向量 $d_i$ 会根据以下规则被接受或拒绝：若 $q_i(t) \leq p_i(t)$，则接受；否则以概率 $1 - p_i(t)/q_i(t)$ 拒绝。若被拒绝，则从一个调整后的分布 $\tilde{p}<em>i(t)$ 中重新采样，该分布由 $\tilde{p}</em>{i,v}(t) = \max(q_v(t)-p_v(t), 0) / \sum_k \max(q_k(t)-p_k(t), 0)$ 定义，以确保最终输出与直接从目标模型 $\mathbf{p}_t$ 采样在分布上一致。</li>
</ol>
<p><strong>创新点</strong>：与现有方法相比，ADAHI的主要创新在于：1) 将原本用于自回归文本生成的推测解码机制，适配到非自回归、具有状态依赖性的连续机器人动作生成场景；2) 提出了“动作偏差”这一新颖的本地代理指标，用于高效预测服务器拒绝概率，从而实现智能的选择性传输，避免了现有混合推理方法（对每个动作都进行推测采样）带来的不必要通信和计算开销。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在一个由Windows笔记本电脑（作为本地设备）和服务器通过Wi-Fi（IEEE 802.11ac）连接的物理测试床上进行。评估了三个模拟用例（如图3所示）：厨房环境操作、球平衡和无人机集群控制。对比的基线方法包括：仅使用草案模型、混合推理（对每个动作都进行推测采样）、随机推理（以与ADAHI相同的传输率随机触发传输）以及仅使用目标模型。</p>
<p><img src="https://arxiv.org/html/2510.02851v2/benchmark.png" alt="实验用例"></p>
<blockquote>
<p><strong>图3</strong>：ADAHI评估的三个用例（从左至右）：厨房环境操作、球平衡和集群控制。</p>
</blockquote>
<p><strong>关键实验结果</strong>：<br>如表I和图4所示，ADAHI在性能与延迟之间取得了优异平衡。</p>
<ul>
<li><strong>性能保持</strong>：在任务成功率方面，ADAHI显著优于随机推理（例如在球平衡任务中高出10.8个百分点），并且非常接近甚至达到混合推理及仅目标模型的水平（例如在球平衡任务中达到混合推理97.2%的成功率）。在均方误差（MSE）指标上也呈现类似趋势。</li>
<li><strong>延迟降低</strong>：相较于对每个动作都进行推测采样的混合推理基线，ADAHI通过选择性传输，将传输率和服务器操作降低了约40%，从而将平均每动作延迟降低了39.2%（例如在球平衡任务中降低了16.06 ms），并将动作吞吐量提高了15.2 s⁻¹。</li>
<li><strong>最坏情况性能</strong>：从动作吞吐量的累积分布函数（CDF）看，ADAHI在低分位数（如2.5%）处具有更高的吞吐量（16.4 s⁻¹ vs 13.9 s⁻¹），表明其最坏情况下的延迟性能更优。</li>
</ul>
<p><img src="https://arxiv.org/html/2510.02851v2/latency_throughput.png" alt="延迟与吞吐量结果"></p>
<blockquote>
<p><strong>图4</strong>：（左）各推理方法的平均每动作延迟、任务成功率和动作吞吐量分解。（右）ADAHI与混合推理的动作吞吐量累积分布函数，虚线标记了各自2.5%分位数，显示ADAHI在最坏情况下性能更优。</p>
</blockquote>
<p><strong>消融实验分析</strong>：通过调整阈值 $\Delta_{th}$ 来控制传输率（TR）的实验表明，当传输率降至约0.6以下时，任务成功率开始急剧下降。因此，论文最终设定的阈值使得三个用例的传输率在54.3%到60.3%之间（见表I“TR”列）。此外，ADAHI的真实跳过比率（TSR，即被跳过的动作确实不需要服务器修正的概率）显著高于随机推理，证明了动作偏差作为选择标准的高效性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>首次将推测采样应用于机器人运动控制，提出了ADAHI框架，在延迟和精度约束下实现了设备-服务器协同推理。</li>
<li>提出并设计了“动作偏差”这一指标，用于有效估计草案动作被目标模型拒绝的概率，为选择性传输提供了依据。</li>
<li>构建了包含真实无线通信的物理测试床，通过实验验证了ADAHI能够显著降低端到端延迟（降低39.2%）和通信开销（减少约40%），同时保持接近最优模型的性能（达到97.2%的任务成功率）。</li>
</ol>
<p><strong>局限性</strong>：论文明确指出，动作偏差目前仅在VQ-BeT这一种行为克隆策略上进行了验证。虽然VQ-BeT适用范围广泛，但该方法在其他策略架构上的普适性有待进一步研究。</p>
<p><strong>后续启示</strong>：本研究为6G时代分布式机器人智能提供了一个可行的推理加速框架。其核心思想——利用本地可计算的、与模型间输出差异相关的代理指标来指导协同决策——可以扩展到其他非自回归的、需要低延迟协同推理的具身AI任务中。未来的工作可以探索适用于其他策略模型（如扩散策略）的“偏差”或“不确定性”度量方法。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对无线机器人低延迟推理中，行为克隆策略因动作依赖观测而无法并行验证多个动作草案的问题，提出动作偏差感知混合推理（ADAHI）。该方法通过动作偏差预测目标模型的拒绝概率，仅当偏差较大时选择性调用服务器进行验证与修正，从而减少不必要的通信与计算。实验表明，ADAHI将传输与服务器操作降低约40%，端到端延迟减少39.2%，任务成功率可达基线（每草案均调用推测采样）的97.2%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.02851" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>