<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>From Grounding to Manipulation: Case Studies of Foundation Model Integration in Embodied Robotic Systems - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>From Grounding to Manipulation: Case Studies of Foundation Model Integration in Embodied Robotic Systems</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.15685" target="_blank" rel="noreferrer">2505.15685</a></span>
        <span>作者: Sui, Xiuchao, Tian, Daiying, Sun, Qi, Chen, Ruirui, Choi, Dongkyu, Kwok, Kenneth, Poria, Soujanya</span>
        <span>日期: 2025/05/21</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，自然语言正成为具身机器人学的通用接口。以视觉语言模型（VLM）、多模态大语言模型（MLLM）和视觉语言动作模型（VLA）为代表的基础模型（FM）能够桥接语言与动作，使机器人遵循自由形式的指令。然而，实现可部署的语言驱动自主性仍面临巨大挑战：机器人需要将模糊指令映射到物理世界（指令落地），在未见过的物体、场景和形态上可靠执行（泛化执行），并以有限数据实现这些目标（高效适应）。目前，不同FM集成策略如何有效应对这些相互竞争的需求尚缺乏深入探索。</p>
<p>本文针对这一痛点，通过两个具体的案例研究，实证比较了三种主流的FM集成范式：将感知与规划隐式统一的端到端VLA模型、使用VLM的模块化流水线以及使用MLLM作为协调器的智能体范式。核心思路是：通过设计指令落地和物体操控两个案例研究，实证比较端到端VLA、模块化VLM流水线和MLLM智能体这三种集成策略，揭示它们在系统规模、泛化能力和数据效率等方面的权衡，为实际系统构建提供指导。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文系统性地分析并比较了三种将基础模型集成到语言引导机器人系统中的策略。</p>
<p><img src="https://arxiv.org/html/2505.15685v2/x2.png" alt="三种FM集成策略"></p>
<blockquote>
<p><strong>图2</strong>：三种FM集成策略。a) 端到端VLA模型：直接将视觉观察和语言指令映射为底层动作。b) 模块化VLM流水线：由专门的VLM处理感知并输出符号化场景信息（如边界框），再由下游规划器生成动作。c) MLLM智能体：MLLM作为认知中枢，通过工具调用协调视觉工具（如检测器）并发出高层动作原语给底层控制器。</p>
</blockquote>
<p><strong>1. 端到端VLA模型</strong>：这类模型以端到端方式运行，直接将视觉观察和自然语言指令翻译成底层动作，无需解耦的感知、语言和控制模块。其内部主要有两种主流范式：</p>
<ul>
<li><strong>自回归模型</strong>：逐步生成动作，每一步都基于当前感知输入和先前输出。它们通常将视觉和语言编码到共享潜在空间，然后使用基于Transformer的解码器自回归地预测控制令牌（如关节角度）。</li>
<li><strong>扩散模型</strong>：通过从噪声中逐步去噪来生成整个动作轨迹，以换取更好的轨迹连贯性。它们同样编码视觉和语言，但应用扩散过程迭代地将动作序列细化为可行轨迹。</li>
<li><strong>优势与局限</strong>：优势在于通过大规模预训练获得跨任务和机器人形态的泛化潜力。局限在于受限于高质量、多样化机器人数据的稀缺性，预训练偏差可能导致在未见任务、环境或形态上性能下降，且在真实世界部署中表现脆弱，需要高效适应策略。</li>
</ul>
<p><strong>2. 模块化VLM流水线</strong>：在此范式中，感知由专门的VLM处理，输出符号化的场景信息（如2D/3D边界框、分割掩码），下游规划器或策略模块则消费这种结构化表示来生成底层动作。语言通道因此与运动控制解耦。</p>
<ul>
<li><strong>优势与局限</strong>：优势在于<strong>可解释性</strong>（检测结果可直接检查）和<strong>高效率</strong>（模型参数量通常在1亿至6亿，仅为10B规模MLLM的约1%-6%）。局限在于<strong>交互刚性</strong>（相比MLLM灵活性不足）和<strong>流水线脆弱性</strong>（感知错误会无缓解地传播）。</li>
</ul>
<p><strong>3. 多模态LLM智能体作为协调器</strong>：在此范式中，MLLM接收原始用户指令，通过函数调用有选择地调用视觉工具（如检测器或深度估计器），在上下文中对其输出进行推理，并向底层控制器发出高层动作原语。MLLM智能体将大型工具调用语言模型置于控制循环的中心。</p>
<ul>
<li><strong>优势与局限</strong>：优势在于强大的<strong>视觉常识推理</strong>能力、<strong>精细的指令遵循</strong>和<strong>动态规划</strong>支持。局限在于<strong>资源密集</strong>，对部署（尤其是移动机器人平台）构成挑战。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p>实验通过两个案例研究展开：<strong>指令落地</strong>和<strong>机器人操控</strong>。研究使用了在杂乱桌面环境中收集的新基准数据集（图3）以及LIBERO模拟基准和真实机器人部署。</p>
<p><img src="https://arxiv.org/html/2505.15685v2/x3.png" alt="实验设置"></p>
<blockquote>
<p><strong>图3</strong>：两个案例研究的实验设置。顶部为操控案例研究收集的自我中心视频数据。底部是指令落地任务的示例设置，包含带有数字标签的视觉提示和三种形式的复杂指令。</p>
</blockquote>
<p><strong>1. 指令落地案例研究结果</strong></p>
<ul>
<li><strong>零样本物体落地</strong>：评估模型在杂乱开放场景中识别物体的能力（表2）。关键发现包括：1）专用于模块化流水线的GroundingDINO准确率约0.3-0.4，在处理特征不明显的物体和开放场景时表现脆弱；2）Gemini 2.5-Pro和GPT-5以0.82的平均分取得顶级性能；3）开源模型仍落后，LLaMA 3.2-Vision 90B达到顶级私有模型性能的84%；4）VLA中使用的感知骨干（如PaliGemma-3B）落地能力有限，这引发了关于如何为具身系统选择或改进感知模块的设计问题。</li>
</ul>
<p><img src="https://arxiv.org/html/2505.15685v2/x4.png" alt="复杂指令落地性能"></p>
<blockquote>
<p><strong>图4</strong>：模块化VLM流水线与MLLM在复杂指令落地任务上的性能对比。子图(a)和(b)分别展示了私有模型、开源模型及其INT4量化变体在隐式、基于属性和基于关系指令上的宏观准确率。</p>
</blockquote>
<ul>
<li><strong>零样本复杂指令落地</strong>：任务为多项选择题，模型需根据三种指令类型选择正确物体索引（图4）。关键发现：1）对于<strong>隐式指令</strong>（如“我需要一个工具来拧紧螺丝”），模块化VLM流水线因缺乏嵌入式功能推理而表现不佳，MLLM凭借强大视觉常识表现良好；2）<strong>关系推理</strong>（如“拿起螺丝刀前面的杯子”）对所有模型都更具挑战性，准确率显著下降；3）<strong>量化效应</strong>：INT4量化使模型尺寸减小超70%，但在LLaMA 3.2 Vision上，它对隐式和关系指令落地的影响不成比例（相对准确率下降14%-17%），而属性落地更鲁棒（仅损失4%），这突显了需要细粒度量化策略以在资源约束下保留关键推理能力。</li>
</ul>
<p><strong>2. 机器人操控案例研究结果</strong><br>研究聚焦于VLA模型的<strong>技能适应</strong>能力，通过微调来评估其适应新任务和部署条件的效果。</p>
<p><img src="https://arxiv.org/html/2505.15685v2/x5.png" alt="部分微调结果"></p>
<blockquote>
<p><strong>图5</strong>：VLA（OpenVLA和π0）在自定义数据集上的部分微调结果，与从头训练的Diffusion Policy（DP）和ACT对比。VLA需要更多训练轮次才能收敛，且表现出更高的性能方差。</p>
</blockquote>
<ul>
<li><strong>真实世界技能适应</strong>：包括部分微调和完全微调。<ul>
<li><strong>部分微调</strong>：在针对螺丝刀拾取任务的小型自定义数据集上，紧凑的任务专用策略（如DP、ACT）能稳定、快速收敛。而通用策略（如OpenVLA、π0）则需要更多迭代才能达到可比精度，且方差更大，这反映了十亿参数规模带来的优化缓慢和不稳定问题（图5）。</li>
<li><strong>完全微调</strong>：在更大基准上微调后，评估模型在分布外物体操控、空间关系推理和多物体取放任务上的性能（图6）。结果显示，NORA在这些任务上取得了最高成功率，而SpatialVLA和OpenVLA在某些任务上失败或表现不稳定。</li>
</ul>
</li>
</ul>
<p><img src="https://arxiv.org/html/2505.15685v2/x6.png" alt="完全微调VLA的成功率"></p>
<blockquote>
<p><strong>图6</strong>：完全微调后的VLA在多物体取放、分布外物体操控和空间关系推理任务上的成功率。NORA实现了最高性能。</p>
</blockquote>
<ul>
<li><strong>模拟技能适应</strong>：在LIBERO模拟基准上的测试结果（表3）表明，微调后的π0模型在所有任务上均优于基线，取得了最高的成功率。对NORA的消融实验显示，动作分块（AC）技术在大多数模拟任务上能持续提升性能。</li>
</ul>
<table>
<thead>
<tr>
<th align="left">Models</th>
<th align="center">LIBERO-Spatial</th>
<th align="center">LIBERO-Object</th>
<th align="center">LIBERO-Goal</th>
<th align="center">LIBERO-Long</th>
<th align="center">Average</th>
</tr>
</thead>
<tbody><tr>
<td align="left">OpenVLA finetuned</td>
<td align="center">84.7</td>
<td align="center">88.4</td>
<td align="center">79.2</td>
<td align="center">53.7</td>
<td align="center">76.5</td>
</tr>
<tr>
<td align="left"><strong>π0 finetuned</strong></td>
<td align="center"><strong>96.8</strong></td>
<td align="center"><strong>98.8</strong></td>
<td align="center"><strong>95.8</strong></td>
<td align="center"><strong>85.2</strong></td>
<td align="center"><strong>94.15</strong></td>
</tr>
<tr>
<td align="left">π0-FAST finetuned</td>
<td align="center">96.4</td>
<td align="center">96.8</td>
<td align="center">88.6</td>
<td align="center">60.2</td>
<td align="center">85.5</td>
</tr>
<tr>
<td align="left">SpatialVLA finetuned-AC</td>
<td align="center">88.2</td>
<td align="center">89.9</td>
<td align="center">78.6</td>
<td align="center">55.5</td>
<td align="center">78.1</td>
</tr>
<tr>
<td align="left">NORA-finetuned</td>
<td align="center">85.6</td>
<td align="center">87.8</td>
<td align="center">77.0</td>
<td align="center">45.0</td>
<td align="center">73.9</td>
</tr>
<tr>
<td align="left">NORA-finetuned-AC</td>
<td align="center">85.6</td>
<td align="center">89.4</td>
<td align="center">80.0</td>
<td align="center">63.0</td>
<td align="center">79.5</td>
</tr>
<tr>
<td align="left">NORA-Long-finetuned</td>
<td align="center">92.2</td>
<td align="center">95.4</td>
<td align="center">89.4</td>
<td align="center">74.6</td>
<td align="center">87.9</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>表3</strong>：在LIBERO模拟基准四个任务套件上的成功率（%），每个任务评估500次试验。微调后的π0模型取得了最高性能。</p>
</blockquote>
<ul>
<li><strong>鲁棒性评估</strong>：在环境中引入干扰物体后，OpenVLA和NORA的性能均大幅下降，突显了当前VLA模型对新颖条件的敏感性。</li>
<li><strong>关键结论</strong>：当前VLA在<strong>适应与泛化</strong>（需要大量数据和长时间训练才能适应分布偏移）和<strong>鲁棒性</strong>（对分布偏移和模拟到真实的迁移敏感）方面仍存在显著局限。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1）在共享的具身任务上实证分析了三种FM集成范式，揭示了它们在模型规模、性能、泛化与数据效率之间的权衡；2）发布了用于评估指令落地和物体操控的数据集与代码，并提供了一个完整的端到端抓娃娃机机器人系统作为真实世界FM集成演示；3）提供了对最先进VLA和MLLM的及时见解，调查了其能力与失败模式，提炼出实用权衡以指导从业者为语言驱动的具身智能体选择FM技术栈。</p>
<p>论文自身指出的局限性主要涉及部署约束：<strong>数据稀缺</strong>（机器人数据收集成本高）、<strong>高效推理</strong>（VLA计算负担重，影响实时性）、<strong>可解释性与安全性</strong>（大多数FM缺乏明确的机制），以及<strong>评估标准化</strong>的缺失。</p>
<p>本研究对后续工作的启示在于：1）需要为具身系统专门设计或改进感知模块，或从大规模模型中蒸馏出紧凑、接地能力强的感知模块以支持高效部署；2）需要细粒度的模型量化策略，以在压缩模型时更好地保留关键的推理能力；3）VLA需要算法进步（如参数高效的适应、抗偏差的预训练、更强的感知骨干）和系统级的数据改进，以解决其数据效率低、适应慢和鲁棒性脆弱的根本问题，从而迈向可靠部署。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文研究如何将基础模型有效集成到具身机器人系统中，以实现复杂的指令跟随与动作生成。核心比较了三种集成范式：端到端视觉-语言-动作模型、基于多模态大语言模型的智能体，以及模块化视觉-语言模型流水线。通过指令落地和物体操控两个案例研究，实验揭示了这些范式在系统规模、泛化能力和数据效率方面存在显著的权衡关系，为语言驱动的物理智能体设计提供了实证依据。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.15685" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>