<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.03599" target="_blank" rel="noreferrer">2510.03599</a></span>
        <span>作者: Majid Khadiv Team</span>
        <span>日期: 2025-10-04</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前基于强化学习（RL）的机器人运动技能学习，无论是敏捷的四足运动还是灵巧的物体操作，通常采用任务特定的目标进行训练，例如期望速度、位置或物体目标姿态。这种方法使得策略难以泛化到未见过的场景，需要针对新任务从头训练。例如，感知型运动策略在训练过的崎岖地形上表现良好，但无法直接迁移到立足点更稀疏、风险更高的地形（如踏脚石）。同样，从桌上拿起物体与堆叠物体具有相似的底层运动技能，但传统的任务特定训练方法阻碍了跨任务泛化。</p>
<p>本文的核心痛点是缺乏一个能够统一多种接触密集型任务（涵盖运动与操作）的基础抽象表示。作者提出，接触（Contact）是几乎所有运动与操作行为的核心：运动需要协调的足部落地，操作依赖于有目的的手-物交互。然而，在现有的RL框架中，接触通常被视为运动优化的副产品而隐式处理，这限制了策略在共享底层运动原理的任务间的泛化能力。</p>
<p>本文的核心思路是：将接触作为统一的物理原语，通过定义接触目标（期望的接触位置、时序和主动末端执行器）序列来表征任务，并训练一个单一的目标条件RL策略来实现给定的接触计划，从而执行多种运动与操作任务。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架由一个高层规划器和一个低层的目标条件RL策略构成。高层规划器生成接触目标序列（对于操作任务还包括物体目标姿态），作为即时目标提供给策略。策略的职责是输出关节力矩，以实现这些接触目标，从而完成各种长时程任务。本文预设了实现各种任务所需的接触目标，但该方法可与更复杂的学习型接触规划器或从图像/视频中提取的接触目标集成。</p>
<p><img src="https://arxiv.org/html/2510.03599v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：本文接触显式框架概览。高层规划器生成接触目标（以及用于操作的物体姿态目标），作为即时目标提供给目标条件RL策略去完成。核心在于提出的接触显式表示，用于训练四足/人形机器人的多步态运动策略和人形机器人的多任务双手操作策略。</p>
</blockquote>
<p>该方法将任务形式化为一个目标条件的马尔可夫决策过程。策略的观测除了本体感知状态（如关节位置、速度），还包括明确的接触目标信息：当前及下一时刻所有末端执行器的接触序列（二元指示器）、在基座坐标系下的当前及下一时刻接触位置、以及当前接触目标的剩余命令持续时间。</p>
<p>接触目标对于一个末端执行器e定义为 <code>g_e^con = {p_e^con, S_e^con, I_e^con}</code>，分别对应接触的3D位置、持续时间和一个表示是否需要接触的二元指示器。对于操作任务，目标<code>g_e</code>还额外包含物体的目标姿态<code>{p_obj, θ_obj}</code>。</p>
<p>创新的核心在于对接触阶段的显式建模和相应的密集奖励设计。作者将每个末端执行器的接触过程分解为三个阶段：分离（Detach）、到达（Reach）和保持（Hold）。</p>
<p><img src="https://arxiv.org/html/2510.03599v1/x3.png" alt="接触阶段"></p>
<blockquote>
<p><strong>图3</strong>：机器人末端执行器在不同接触阶段的简单示意图（针对固定的命令持续时间S）。在分离阶段，末端执行器脱离接触并可自由移动。在到达阶段，末端执行器被引导向期望的接触位置。在保持阶段，它维持该接触。</p>
</blockquote>
<p>阶段判定依赖于二元接触指示器和剩余命令持续时间s。具体地：</p>
<ul>
<li><strong>到达阶段</strong>：当二元指示器为0（不应接触）且剩余时间s小于阈值δ时，策略需引导末端执行器到达目标接触位置。</li>
<li><strong>保持阶段</strong>：当二元指示器为1（应接触）时，策略需维持末端执行器在目标位置的接触。</li>
<li><strong>分离阶段</strong>：当二元指示器为0且剩余时间s大于δ时，末端执行器应避免任何接触。</li>
</ul>
<p>基于此，作者设计了对应的奖励函数来引导策略学习：</p>
<ul>
<li>**到达奖励 <code>r_t,e^reach</code>**：激励末端执行器在到达阶段接近目标接触位置，奖励随距离减小而增加。</li>
<li>**保持奖励 <code>r_t,e^hold</code>**：激励机器人在保持阶段维持接触，如果接触发生在期望位置则获得额外奖励（<code>α_hold &gt; 0</code>时）。</li>
<li>**分离奖励 <code>r_t,e^detach</code>**：是一个标量奖励，激励智能体在此阶段不进行任何接触。</li>
<li>**操作姿态奖励 <code>r_t,obj^pose</code>**：额外激励跟踪物体的目标位置和旋转。</li>
</ul>
<p>总接触奖励为所有末端执行器的各阶段奖励之和，对于操作任务还需加上物体姿态奖励。此外，训练中还添加了关节速度、加速度、扭矩等常用惩罚项以鼓励平滑行为。</p>
<p>与现有方法相比，本文的创新点在于：1) 提出了一个以接触为基本原语的、统一运动与操作的任务表示；2) 通过显式定义接触阶段和设计对应的密集奖励，使一个单一策略能够学习执行多种不同的接触模式，而无需为每个任务设计特定奖励或提供密集参考轨迹。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在IsaacLab仿真环境中进行，使用PPO算法和循环神经网络（GRU）架构进行训练。评估涉及多种机器人形态和任务：</p>
<ol>
<li><strong>四足机器人</strong>：执行多种步态（小跑、溜蹄、蹦跳、跳跃、爬行）。</li>
<li><strong>人形机器人</strong>：执行多种双足（走、跳）和四足（爬、溜蹄、跳）运动模式。</li>
<li><strong>人形机器人双手操作</strong>：执行“重摆”（在空中保持接触并跟踪物体多种姿态）和“重定向”（在桌上反复接触以连续旋转物体45度）任务。</li>
</ol>
<p>对比的基线方法包括：使用速度目标训练的运动策略、为每个步态单独训练的单任务策略、以及使用独热（one-hot）任务编码而非接触状态的操作策略。</p>
<p><img src="https://arxiv.org/html/2510.03599v1/x5.png" alt="速度跟踪误差对比"></p>
<blockquote>
<p><strong>图5</strong>：在所有x-y方向上的速度跟踪误差对比。网格中每个单元是x和y速度的组合。红线表示训练期间见过的速度组合。接触显式策略（左）比速度目标策略（右）能覆盖更广的速度范围，尤其是在未训练过的横向移动（vx=0）时表现更佳。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.03599v1/x6.png" alt="多任务与单任务策略对比"></p>
<blockquote>
<p><strong>图6</strong>：多步态策略（M）与单步态策略（S）在更广命令持续时间范围内的接触位置跟踪误差（L2范数）和接触计划偏差（汉明距离）对比。多任务策略在所有测试步态和持续时间上都具有最低的接触计划偏差，表明其通过共享结构获得了更好的鲁棒性和泛化能力。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.03599v1/x7.png" alt="未见物体形状泛化"></p>
<blockquote>
<p><strong>图7</strong>：在不同任务上对未见物体形状的跟踪误差对比。接触显式策略（使用接触状态）相比使用独热任务编码的基线策略（无接触状态），在圆柱体和球体等未见形状上泛化性能更好。对于球体上的重定向任务，接触显式策略甚至出现了 emergent retrying 行为来应对物体滚动。</p>
</blockquote>
<p>关键实验结果总结：</p>
<ul>
<li><strong>运动泛化（未见速度/方向）</strong>：接触显式策略在训练分布外的速度指令上，其跟踪误差覆盖的范围远大于传统的速度目标策略，尤其在横向移动等未训练方向上表现出色。</li>
<li><strong>多任务 vs. 单任务</strong>：单一的多步态策略在接触计划偏差上普遍低于多个单步态策略，且接触位置跟踪精度相当（误差在2厘米内），证明了多任务学习能利用步态间的共享结构。</li>
<li><strong>操作泛化（未见物体形状）</strong>：接触显式策略在训练未见过的圆柱体和球体上，物体姿态跟踪误差显著低于使用独热编码的基线策略。</li>
<li><strong>操作泛化（未见物体姿态）</strong>：如表I所示，当物体目标姿态超出训练分布范围时，接触显式策略在位置误差（0.115±0.003 m vs. 0.129±0.003 m）和旋转误差（0.390±0.006 rad vs. 0.455±0.007 rad）上均优于基线，且方差更小，表现更稳定。</li>
</ul>
<p>消融实验主要体现在与不同目标表示（速度目标、独热编码）的对比上，结果一致表明接触显式表示在跨任务泛化和对分布外场景的鲁棒性方面具有显著优势。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：</p>
<ol>
<li><strong>提出了一个统一的接触显式任务表示</strong>：将接触（位置、时序、主动末端）作为基本物理原语，为多任务运动与操作学习提供了共同基础。</li>
<li><strong>实现了一个单一的多技能策略</strong>：基于该表示，通过目标条件RL训练出的单一策略能够在不同形态的机器人（四足、人形）上执行多种运动步态和双手操作任务。</li>
<li><strong>实证证明了卓越的泛化能力</strong>：与任务特定策略或其他目标表示相比，接触显式策略在未见过的速度指令、步态参数、物体形状和物体姿态上展现出更强、更稳定的泛化性能。</li>
</ol>
<p>论文自身提到的局限性在于，当前的高层接触规划器是预设的。作者指出，未来工作可以将其与学习型高层规划器结合，以实现复杂环境中的自主长时程运动操作；同时计划探索抓握式交互并提升仿真到现实的鲁棒性。</p>
<p>这项工作对后续研究的启示是：对于物理交互任务，将关注点从具体的运动轨迹或任务语义，下沉到更本质的“接触”交互层面，可能是一种实现更通用、更可扩展的机器人技能学习的有效途径。这种以接触为中心的视角为构建层次化技能系统（低层接触执行器+高层任务规划器）奠定了坚实基础。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出一种基于接触显式表示的多任务运动与操作策略统一学习框架。核心问题是解决传统任务专用策略泛化能力差、难以适应新场景的问题。方法上，将任务统一定义为接触目标序列（位置、时序、末端执行器），并训练目标条件强化学习策略来实现接触计划。实验在四足/人形机器人的多种步态与双手操作任务上验证，结果表明：单个策略可控制不同形态机器人完成多样任务，且接触显式推理显著提升了策略对未见场景的泛化能力。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.03599" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>