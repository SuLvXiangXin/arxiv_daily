<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.14820" target="_blank" rel="noreferrer">2507.14820</a></span>
        <span>作者: Guangyao Zhai Team</span>
        <span>日期: 2025-07-20</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人高级操作任务需要灵活的6自由度抓取估计作为基础功能。现有方法主要分为两类：一类是直接基于点云生成抓取姿态的方法（如PointNetGPD），但其对小物体和传感器噪声敏感；另一类是基于RGB图像推断3D信息的方法，但这需要昂贵的标注（如表面法线）或对SO(3)空间进行离散化。近年来，KGN系列方法采用了一种折中方案：首先从图像中预测抓取关键点的2D热图，然后通过不可微的透视n点（PnP）算法计算6自由度姿态。然而，这种方法存在两个关键局限性：一是PnP算法的非可微性阻碍了3D监督信号直接反向传播到网络前端，导致只能依赖2D关键点监督；二是仅使用四个关键点求解PnP对噪声非常敏感。本文针对“如何在使用高效2D表示的同时，融入精细的3D监督以提升抓取预测精度”这一痛点，提出了通过概率性2D-3D对应学习进行优化的新视角。本文的核心思路是：在保留KGN系列高效2D关键点表示的基础上，引入一个可微的概率PnP层，并辅以关键点置信度图，从而实现对加权重投影误差的建模，使3D监督能够端到端地优化整个网络。</p>
<h2 id="方法详解">方法详解</h2>
<p><img src="https://arxiv.org/html/2507.14820v2/x2.png" alt="方法总览"></p>
<blockquote>
<p><strong>图2</strong>：KGN-Pro方法整体框架。输入是一对RGB-D图像，通过关键点提取器获得关键点图（Keypoint Map），同时通过置信度提取器获得每个2D关键点的置信度得分。结合夹爪模型的3D角点，建立2D-3D对应关系X。通过重投影函数在X上估计一个抓取姿态分布p(y|X)。随后从分布中采样抓取姿态，并通过最近邻匹配（Nearest-Neighbor Matching）与真实标签匹配，获得对应的姿态监督，进而用目标分布t(y)来正则化p(y|X)。</p>
</blockquote>
<p>KGN-Pro的整体流程如下：输入是一对RGB-D图像，网络首先通过一个编码器（基于DLA-34骨干网络并增强可变形卷积）提取多尺度特征。随后，特征被送入两个主要模块：关键点提取器和置信度提取器。关键点提取器输出<strong>关键点图</strong>，置信度提取器输出<strong>2D置信度图</strong>。基于预测的2D关键点、已知的夹爪3D角点模型以及置信度，构建2D-3D对应关系，并通过<strong>概率PnP层</strong>计算出一个抓取姿态的概率分布。最后，通过<strong>最近邻匹配</strong>为该分布找到最接近的真实抓取姿态作为监督目标，并使用KL散度损失进行优化。</p>
<p>核心模块与技术细节：</p>
<ol>
<li><strong>关键点提取与表示</strong>：与先前KGN工作一致，关键点图包含三个部分：(a) <strong>中心热图H</strong>：每个像素是抓取中心点的概率；(b) <strong>中心亚像素偏移图S</strong>：用于细化中心点的整数坐标；(c) <strong>中心到关键点偏移图O</strong>：记录中心点到四个关键点的位移。推理时，首先根据热图筛选潜在抓取中心，然后利用S和O计算出所有四个关键点的精确2D坐标（公式5）。</li>
<li><strong>置信度提取器</strong>：这是一个新颖的模块，为每个预测的2D关键点生成一个置信度权重$w_i^{2D}$。该权重反映了该关键点在2D-3D对应关系中的可靠性，用于在后续的重投影误差计算中进行加权。</li>
<li><strong>概率PnP与2D-3D对应学习</strong>：这是方法的核心创新。传统PnP是确定性的且不可微。KGN-Pro将其转化为一个概率问题。给定一个候选姿态$y$，每个2D-3D对应点对$x_i$的重投影误差$E_i(y)$被视为服从高斯分布。考虑所有对应点，并引入置信度权重，得到观测数据的似然函数（公式6）：<br>$p(X|y) \propto \exp -\frac{1}{2}\sum_{i=1}^{N} |w_i^{2D}E_i(y)|^2$。<br>通过贝叶斯定理（假设无信息先验），可以得到姿态的后验分布$p(y|X)$。为了训练网络，需要让这个预测的分布接近真实的抓取姿态分布。</li>
<li><strong>最近邻匹配与损失函数</strong>：由于一个场景中可能存在多个可行的抓取姿态（多模态），不同于物体姿态估计中单一目标的情况，本文采用<strong>最近邻匹配</strong>为每个预测的抓取分布$p(y|X)$找到最接近的一个真实抓取姿态$\hat{y}<em>j$，并将其视为一个狄拉克分布形式的目标分布$t(y)$。通过最小化预测分布$p(y|X)$与目标分布$t(y)$之间的KL散度来训练网络。最终的KL散度损失$L</em>{KL}$（公式7）包含两项：第一项$L_{pred}^j$是预测分布的对数似然的近似（通过自适应多重重要性采样计算，公式3），鼓励网络预测合理的姿态分布；第二项是匹配到的真实姿态$\hat{y}_j$上的加权重投影误差，直接拉近预测与真实姿态的距离。</li>
<li><strong>总损失</strong>：网络总损失是多个损失的加权和（公式8）：$L = \lambda_H L_H + \lambda_S L_S + \lambda_O L_O + \lambda_{KL} L_{KL}$。其中$L_H$（中心热图）使用二值焦点损失，$L_S$和$L_O$（偏移图）使用L1损失，$L_{KL}$是上述的KL散度损失。</li>
</ol>
<p>与现有方法相比，创新点具体体现在：</p>
<ul>
<li><strong>可微的概率PnP层</strong>：解决了传统KGN中PnP模块不可微、无法接收3D监督的瓶颈，实现了端到端的3D信号反向传播。</li>
<li><strong>2D置信度图</strong>：动态评估每个关键点的可靠性，使网络在优化重投影误差时能聚焦于更可信的对应点，提升了鲁棒性。</li>
<li><strong>多模态最近邻匹配</strong>：适应抓取预测中多候选目标的特点，为每个预测分布提供有效的3D监督目标。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在模拟和真实机器人平台进行。使用了与KGN相同的合成数据集进行训练和评估，该数据集涵盖圆柱体、圆环、长棒、球体、半球体、立方体六类物体，包含单物体和多物体场景。数据集按80%/20%划分训练集和测试集。</p>
<p>对比的基线方法包括：<strong>CenterGrasp</strong>（基于点云隐式重建）、<strong>Contact-GraspNet</strong>（基于点云预测接触对齐姿态）、<strong>KGN</strong>（原有关键点+PnP方法）、以及一个作为消融对比的<strong>Direct3D</strong>（使用相同骨干网络直接回归3D姿态）。</p>
<p>关键实验结果：</p>
<ol>
<li><strong>单物体场景抓取成功率</strong>：在测试的50个新场景中，KGN-Pro取得了最高的成功率。当夹爪闭合距离容差设为0.1时，成功率达96.1%；在更严格的0.01容差下，成功率仍保持领先，达到71.2%。</li>
<li><strong>多物体场景抓取覆盖率</strong>：在多物体场景中，KGN-Pro的抓取覆盖率（生成的抓取姿态覆盖真实可行抓取的比例）显著高于其他方法，达到84.9%，而KGN为77.6%，CenterGrasp为66.3%。</li>
</ol>
<p><img src="https://arxiv.org/html/2507.14820v2/x3.png" alt="定性结果对比"></p>
<blockquote>
<p><strong>图3</strong>：单物体与多物体场景下，KGN-Pro、KGN和CenterGrasp生成的抓取姿态可视化对比。可以看出，KGN-Pro生成的抓取在角度多样性和准确性上具有明显优势。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.14820v2/x4.png" alt="定量结果曲线"></p>
<blockquote>
<p><strong>图4</strong>：单物体评估（左）与多物体评估（右）的定量结果曲线图。左图显示了在不同夹爪闭合距离容差下的抓取成功率，KGN-Pro（Ours）始终领先。右图显示了抓取覆盖率随生成抓取数量变化的曲线，KGN-Pro的覆盖率最高。</p>
</blockquote>
<ol start="3">
<li><strong>消融实验</strong>：论文通过消融实验验证了各组件的重要性。主要结论包括：<ul>
<li><strong>置信度图的作用</strong>：移除置信度图（即所有权重设为1）会导致性能下降，证明了其加权机制的有效性。</li>
<li><strong>概率PnP的作用</strong>：与直接回归3D姿态（Direct3D）和使用传统PnP（KGN）相比，使用概率PnP的KGN-Pro性能最佳，验证了概率建模和端到端3D监督的优势。</li>
<li><strong>最近邻匹配的作用</strong>：与使用所有真实抓取进行监督的替代方案相比，最近邻匹配策略能提供更准确、更聚焦的监督信号，从而提升性能。</li>
</ul>
</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：</p>
<ol>
<li>提出了<strong>KGN-Pro</strong>，一种新颖的抓取预测网络，它巧妙地将高效的纯2D关键点表示与通过概率PnP层实现的直接3D优化相结合，解决了先前方法无法端到端利用3D监督的问题。</li>
<li>设计了<strong>2D置信度图</strong>和<strong>最近邻匹配</strong>机制。置信度图在重投影误差最小化中加权关键点贡献；最近邻匹配则为多候选抓取预测提供了精确的3D监督目标，共同实现了有效的2D-3D对应学习。</li>
<li>在模拟和真实世界的实验表明，KGN-Pro在抓取覆盖率和成功率上均优于现有先进方法，特别是在处理小物体和噪声方面表现出更强的鲁棒性。</li>
</ol>
<p>论文自身提到的局限性主要在于：尽管方法对噪声具有鲁棒性，但在极端噪声条件下性能仍会下降。此外，方法依赖于已知的夹爪3D模型来建立2D-3D对应。</p>
<p>对后续研究的启示：KGN-Pro的概率性建模思路为结合2D效率与3D精度的视觉任务提供了新范式。其置信度学习机制可以扩展到其他需要评估特征可靠性的对应问题中。未来工作可以探索如何将此类方法应用于更复杂的夹爪模型、动态场景，或者与大规模语言-视觉模型结合，实现更智能的指令化抓取。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对6-DoF机器人抓取估计中现有方法对小物体和传感器噪声敏感、依赖昂贵3D注释或存在离散化问题，提出KGN-Pro网络。该方法通过概率PnP层学习2D-3D对应关系，利用RGB-D图像生成关键点图和置信图，加权重投影误差以实现端到端优化。实验表明，KGN-Pro在抓取覆盖率和成功率上优于现有方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.14820" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>