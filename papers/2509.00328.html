<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Mechanistic interpretability for steering vision-language-action models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Mechanistic interpretability for steering vision-language-action models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.00328" target="_blank" rel="noreferrer">2509.00328</a></span>
        <span>作者: Häon, Bear, Stocking, Kaylene, Chuang, Ian, Tomlin, Claire</span>
        <span>日期: 2025/08/30</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作（VLA）模型是实现通用具身智能体的一条有前景的路径，它们能够快速适应新任务、模态和环境。然而，解释和引导VLA模型的方法远不及经典机器人流程，后者建立在明确的运动学、动力学和控制模型之上。这种机制性洞察的缺乏是学习策略在现实机器人中部署的核心挑战，因为现实应用对鲁棒性和可解释性要求极高。受到大语言模型（LLM）机制可解释性研究的启发，本文首次提出了一个通过内部表征来解释和引导VLA模型的框架，能够在推理时直接干预模型行为。本文的核心思路是：通过分析Transformer前馈层（FFN）的激活在词元嵌入基上的投影，识别出与动作选择存在因果关联的稀疏语义方向（如速度、方向），并利用这些方向在无需微调、奖励信号或环境交互的情况下，实时调控模型行为。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的框架旨在对VLA模型进行可解释的激活层面引导。整体流程如论文图1所示，其输入是任务描述和图像/状态观察，输出是机器人动作。核心步骤包括：1) 提取FFN向量；2) 将其投影到VLA词元空间；3) 根据语义对齐进行聚类；4) 在推理时注入激活以调控行为。</p>
<p><img src="https://arxiv.org/html/2509.00328v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：引导视觉-语言-动作（VLA）模型的框架。我们提取FFN向量，将其投影到VLA词元空间，通过语义对齐进行聚类，并在推理时注入激活以调控行为。</p>
</blockquote>
<p>该方法的技术基础在于对Transformer FFN层的分析。FFN操作可表述为：<code>FFN(x) = f_θ(x)^T W_θ</code>，其中<code>x</code>是层输入，<code>f_θ(x)</code>是输入依赖的激活向量，<code>W_θ</code>是输入独立的参数矩阵。将<code>W_θ</code>的第<code>i</code>行记为值向量<code>w_θ^(i)</code>，则FFN输出可重写为这些值向量的加权和：<code>FFN(x) = Σ_i [f_θ(x)]_i w_θ^(i)</code>。这些值向量与输入无关，可视为FFN输出的基函数。由于它们与Transformer的最终输出处于同一线性空间，可被解释为对可能输出词元的概率分布。因此，可以根据值向量赋予最高概率的词元集为其分配语义含义。</p>
<p>引导方法的具体操作是：给定FFN的残差输入<code>x</code>，我们覆盖激活<code>f_θ(x)</code>的一个子集<code>S</code>（对应与某个控制概念，如“快速”、“向上”、“小心”对齐的可解释神经元簇），使用固定标量<code>α</code>进行覆盖（公式3），从而计算得到引导后的FFN输出（公式4）。这会在残差流中引入一个偏移<code>Δx = FFN_steered(x) - FFN(x)</code>，该偏移在Transformer中传播并调制最终的VLA动作词元分布。</p>
<p>本文的创新点在于首次将LLM机制可解释性中分析FFN值向量的方法系统性地应用于大型机器人模型（VLA），并证明了无需任何额外训练数据即可识别语义概念并实现零样本行为引导。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：本文在两个开源VLA模型上评估方法：OpenVLA（7B参数）和 π₀-FAST（3B参数）。仿真实验在LIBERO-Long基准测试的10个长视野操作任务上进行。物理机器人实验在UR5机械臂上进行，执行拾放任务。</p>
<p><strong>基线方法</strong>：在物理实验中，对比了以下基线：(1) 无任何干预的默认模型；(2) 在提示词前添加描述性词语（如“low”）；(3) 对随机选择的向量进行上权重引导干预。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>VLA内部表征分析</strong>：论文首先分析了VLA训练和微调对内部概念的影响。图2(a)表明，VLA训练后，FFN值向量中具有可解释模式和语义模式的比率与预训练的VLM基模型相似，说明语义组织得以保留。图2(b)显示动作词元出现在VLA的所有层中，表明模型从早期计算就开始持续推理和细化控制动作。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.00328v1/x2.png" alt="VLA训练对概念的影响"></p>
<blockquote>
<p><strong>图2</strong>：VLA训练将动作词元纳入FFN值向量，但保留了VLM预训练中的语义含义。(a) 值向量顶部词元中有意义的模式。(b) 动作词元被纳入VLA的每一层。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.00328v1/x3.png" alt="微调对概念的影响"></p>
<blockquote>
<p><strong>图3</strong>：任务微调主要影响FFN值向量中的动作词元。(a) 微调主要上权重或下权重动作词元。(b) 微调诱导了跨值向量的动作词元分布更加专门化（更不通用）。</p>
</blockquote>
<ol start="2">
<li><strong>仿真引导实验（运动干预）</strong>：通过手动选择与运动幅度语义（快/慢）对齐的值向量构建簇进行干预。如图5(a)所示，在10个长视野任务上，“快速”簇始终导致更大的末端执行器位移，平均比“慢速”簇提升27.73%，某些配置下最大增益达148.54%。所有10组对比均显示出统计学显著差异（p &lt; 0.001）。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.00328v1/x5.png" alt="仿真引导结果"></p>
<blockquote>
<p><strong>图5</strong>：仿真结果：使用值向量干预引导OpenVLA。(a) 运动幅度干预。快速簇始终导致更大的末端执行器位移。(b) 时间定位干预。在不同模型深度注入“向上”簇的效果。</p>
</blockquote>
<ol start="3">
<li><p><strong>仿真引导实验（时间定位干预）</strong>：研究干预发生层的位置对效果的影响。使用kNN聚类提取“向上”主题簇，并将其注入到早期层、晚期层或所有层。如图5(b)所示，全层干预产生的平均Y方向位移最大（μ=0.098），其次是晚期层（μ=0.086）和早期层（μ=0.007）。这与运动语义集中在模型后期阶段的预期一致。</p>
</li>
<li><p><strong>物理机器人引导实验</strong>：在UR5上执行“低/高运输”和“慢/快运输”两个任务。通过手动选择语义对齐的向量簇进行干预。结果如图7所示：</p>
<ul>
<li>在“低/高运输”任务中，“低”干预产生了整体最低的轨迹（最大高度最低）。</li>
<li>在“慢/快运输”任务中，“慢”干预导致了最慢的整体运动（平均步间位移最小）。</li>
<li>相反方向的干预（“高”、“快”）与无干预基线行为相似，可能因为基线轨迹已被模型视为“高”和“快”。</li>
<li>随机向量干预与无干预基线差异极小，表明选择语义有意义的向量能更有效地引导模型。</li>
<li>修改提示词的影响弱于本文的引导干预。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2509.00328v1/x6.png" alt="物理机器人任务"></p>
<blockquote>
<p><strong>图6</strong>：物理机器人实验：在UR5上引导π₀。(a) 低/高运输任务。(b) 慢/快运输任务。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.00328v1/x7.png" alt="物理机器人结果"></p>
<blockquote>
<p><strong>图7</strong>：物理机器人实验：二元控制对立。(a) 低/高运输任务：末端执行器最大高度的分布。(b) 慢/快运输任务：连续动作间平均末端执行器位移的分布。</p>
</blockquote>
<p><strong>消融实验总结</strong>：实验系统地消融了不同因素：</p>
<ul>
<li><strong>干预层位置</strong>：证明了全层干预效果最强，但晚期层干预在更高强度和大簇规模下也能匹配全层效果。</li>
<li><strong>干预向量的语义相关性</strong>：对比语义簇干预与随机向量干预，证明了语义选择的有效性。</li>
<li><strong>干预与提示词修改</strong>：证明了激活干预比单纯修改语言提示对行为的影响更直接、更强。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>机制性发现</strong>：首次证明VLA模型在经过机器人数据训练后，其内部FFN层仍保留了大量可解释的语义结构（如“快”、“慢”、“上”），且这些语义概念与动作选择存在因果关联。</li>
<li><strong>零样本控制方法</strong>：提出了一种通用的激活引导方法，能够在无需微调、奖励或环境交互的情况下，通过干预稀疏的语义神经元簇来实时调制机器人行为，实现了零样本行为控制。</li>
<li><strong>跨模型与场景验证</strong>：在仿真（OpenVLA on LIBERO）和物理机器人（π₀ on UR5）上成功验证了该方法的有效性，展示了其作为机器人基础模型透明控制接口的潜力。</li>
</ol>
<p><strong>局限性</strong>（论文自身提及）：</p>
<ol>
<li><strong>语义模糊性与表征漂移</strong>：基于词元相似度的聚类方法可能混淆不同的行为（如“慢且小心” vs “慢且卡住”），且值向量的含义可能随模型、任务和上下文发生漂移。</li>
<li><strong>微调与可操纵性</strong>：尚未完全理解VLA微调如何影响内部概念的可操纵性，微调可能使预训练概念更难访问或与行为对齐度降低。</li>
<li><strong>评估范围与泛化性</strong>：实验主要局限于机械臂拾放任务，需要扩展到移动平台、双手操作及非结构化环境，以验证控制的稳定性、泛化能力和与人类意图的对齐。</li>
</ol>
<p><strong>对后续研究的启示</strong>：<br>这项工作为具身基础模型开辟了一条新的、可解释的行为调控途径。激活引导技术未来可在模型检查、审计和安全干预中发挥重要作用。后续研究可以探索更精细的概念解耦方法（如稀疏自编码器）在机器人领域的适用性，研究微调过程中可操纵方向的演化规律，并将该方法扩展到更复杂的机器人形态和动态任务中，以推动构建透明、可引导且语义 grounded 的机器人控制工具。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对Vision-Language-Action模型在机器人部署中缺乏机制性解释、影响鲁棒性和可解释性的核心问题，提出首个通过内部表示解释与引导VLA的框架。关键技术包括：将Transformer层的前馈激活投影到令牌嵌入基，识别与动作选择因果关联的稀疏语义方向（如速度、方向）；并引入通用激活引导方法，在推理时实时调节行为，无需微调或奖励信号。实验在π0和OpenVLA两个开源VLA模型上验证，在LIBERO仿真和UR5物理机器人上成功实现了零-shot行为控制，证明了该框架的有效性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.00328" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>