<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.22380" target="_blank" rel="noreferrer">2507.22380</a></span>
        <span>作者: Brendan Tidd Team</span>
        <span>日期: 2025-07-30</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前机器人模仿学习的主流方法是基于Transformer的架构，例如动作分块Transformer (Action Chunking Transformer, ACT)，它们擅长处理高维观测并建模时序依赖。然而，这些方法在面对训练与部署环境之间的分布偏移时，泛化能力较弱，限制了其实际应用。一个关键的局限性在于“因果混淆”，即模型可能学习到观测中与任务无关的特征（如背景颜色、无关物体）与专家动作之间的虚假相关性，导致在新的、缺少这些无关特征的环境中性能急剧下降。</p>
<p>先前工作（如De Haan等人，2019）试图通过因果结构学习来解决此问题，但其强假设要求观测必须具有解耦的表示，这在复杂的机器人操作任务中难以满足。本文针对这一具体痛点，提出了新的视角：理论上论证了在模仿学习策略的因果图建模中，解耦表示并非学习因果结构函数的必要条件。核心思路是提出一个简单的因果结构学习框架，可轻松嵌入现有的模仿学习架构（如ACT），通过干预策略来学习观测组件与专家动作之间的因果关系，从而提升策略对不可预测环境变化的泛化能力。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的方法Causal-ACT，是在ACT模仿学习框架基础上，集成了一个因果结构学习模块。整体流程如下：首先，使用现成的卷积编码器（如ResNet-18）从图像观测中提取特征表示。然后，一个因果发现模块学习一个因果图，该图描述了观测特征维度与动作之间的因果关系。接着，基于学习到的因果图，通过干预（将非因果相关的特征维度置零）来提取仅与动作有因果关系的特征子集。最后，这个因果相关的特征子集被送入ACT的Transformer解码器，用于预测动作序列。</p>
<p><img src="https://arxiv.org/html/2507.22380v1/x3.png" alt="Causal-ACT框架"></p>
<blockquote>
<p><strong>图3</strong>：Causal-ACT方法整体框架。左侧为训练阶段：观测图像通过编码器得到特征，因果发现模块学习因果图并生成因果掩码，掩码后的因果特征与目标动作一起输入ACT解码器进行训练。右侧为测试阶段：使用学习到的因果掩码提取特征，输入训练好的ACT解码器产生动作。</p>
</blockquote>
<p>核心模块是因果发现模块。其具体作用是学习一个二值化的邻接矩阵 <code>G</code>，其中元素 <code>G_{ij}=1</code> 表示第 <code>i</code> 个观测特征维度是第 <code>j</code> 个动作维度的直接原因（父节点）。为实现可微优化，论文使用Gumbel-Softmax trick来参数化 <code>G</code>。该模块与策略网络联合优化，其损失函数包含两部分：1）标准的行为克隆损失，确保预测动作接近专家演示；2）一个因果正则化项，鼓励学习到的因果图是稀疏的，并符合从数据中推断出的条件独立性关系（通过HSIC独立性测试进行近似）。优化过程通过干预（即应用因果掩码）来实现，迫使策略仅依赖于被识别为因果相关的特征。</p>
<p>与现有方法（如De Haan等人2019年的工作）相比，核心创新点在于<strong>移除了对观测特征解耦表示的要求</strong>。论文第4.2节从理论上证明了，在模仿策略的特定因果图结构下（动作仅受部分观测影响，且观测间允许存在非时序的因果关系），即使观测特征内部存在纠缠（如图2中的虚线箭头），也能保证学习到的结构因果函数是唯一可解的（uniquely solvable），从而可以一致地估计真实的因果机制。</p>
<p><img src="https://arxiv.org/html/2507.22380v1/x2.png" alt="模仿策略的因果图示例"></p>
<blockquote>
<p><strong>图2</strong>：模仿策略的因果图示例。每个时间步t，策略π基于观测X^t的一个子集选择动作A^t。动作与不可观测的外生变量U共同导致下一时刻观测X^{t+1}。虚线箭头表示观测维度之间可能存在的（非时序）因果关系，这表明表示可以是纠缠的。实线箭头表示因果影响，例如X_2是观测的一部分，但对策略没有因果影响。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在MuJoCo模拟的ALOHA双臂机器人平台上进行。任务设定为：机器人用一只手臂抓取初始位于红色区域的目标立方体（红色），然后将其转移给另一只手臂。为了测试泛化能力，训练环境中包含了六个分散注意力的立方体（无关特征），而测试环境则移除了这些分散物，模拟不可预测的部署环境变化。</p>
<p>对比的基线方法包括：1) 原始ACT方法；2) 使用领域随机化（Domain Randomization, DR）增强的ACT，即在训练时随机化分散立方体的纹理和位置。评价指标是任务成功率。</p>
<p>关键实验结果如下：在训练分布内（即测试环境也包含分散物），ACT、ACT+DR和Causal-ACT都达到了接近100%的成功率。然而，在分布外测试（移除分散物）下，原始ACT的成功率从100%骤降至约20%，表现出严重的因果混淆和泛化失败。ACT+DR将成功率提升至约60%，但需要大量的仿真数据增强。本文的Causal-ACT方法取得了最佳性能，成功率恢复至约80%，显著缓解了泛化问题。</p>
<p><img src="https://arxiv.org/html/2507.22380v1/x1.png" alt="训练与测试环境可视化"></p>
<blockquote>
<p><strong>图1</strong>：训练环境（左）与测试环境（右）可视化。红色方块和文字仅表示目标立方体初始位置的采样范围，并不包含在观测中。注意训练环境中有六个分散注意力的立方体，而测试环境中没有。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.22380v1/x4.png" alt="成功率对比曲线"></p>
<blockquote>
<p><strong>图4</strong>：不同方法在分布外测试环境下的成功率学习曲线。Causal-ACT（橙色）显著优于原始ACT（蓝色），并且超越了使用领域随机化的ACT（绿色）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.22380v1/x5.png" alt="消融实验：因果组件的影响"></p>
<blockquote>
<p><strong>图5</strong>：消融实验。移除因果发现模块（“Causal-ACT w/o causal”）导致性能下降至与ACT相当，证明了因果结构学习组件的必要性。同时展示了学习到的因果掩码的稀疏性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.22380v1/x6.png" alt="定性结果：注意力可视化"></p>
<blockquote>
<p><strong>图6</strong>：注意力可视化。Causal-ACT（右）的注意力更集中于任务相关的目标立方体上，而原始ACT（左）的注意力则分散到了无关的立方体上，这直观地解释了其泛化失败的原因。</p>
</blockquote>
<p>消融实验表明，移除因果发现模块（即不使用因果掩码）的Causal-ACT变体性能大幅下降至与原始ACT相当，验证了因果结构学习组件的关键贡献。此外，学习到的因果图是稀疏的，符合预期。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献有三点：1）明确识别并形式化了模仿学习中的因果混淆问题，将其视为泛化能力弱的一个关键原因；2）从理论上放宽了先前因果模仿学习方法对解耦表示的要求，证明了在观测特征纠缠的情况下，只要满足模仿策略因果图的特定条件，结构因果函数仍然是可学习的；3）提出了实用框架Causal-ACT，将因果结构学习无缝嵌入现代模仿学习架构，并通过仿真实验验证了其能显著提升策略对分布偏移的鲁棒性。</p>
<p>论文自身提到的局限性在于实验目前仅在仿真环境中进行，未来需要在真实机器人系统上进一步验证。</p>
<p>这项工作对后续研究的启示在于：为提升机器人学习系统的泛化能力提供了一条基于因果推理的新路径。它表明，通过显式地建模和学习观测与动作之间的因果结构，可以有效剥离任务无关的虚假关联，从而获得更本质、更稳健的技能表示。这种方法减少了对大规模数据收集或精心设计的领域随机化的依赖，为实现更高效的模仿学习提供了可能。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>该论文针对机器人模仿学习在环境变化下泛化能力差的问题，指出其核心原因是观察数据中的“因果混淆”——模型错误关联了任务无关特征与专家动作。为消除混淆，作者提出Causal-ACT方法，将因果结构学习嵌入基于Transformer的策略模型（如ACT），无需依赖解纠缠表征，可直接从卷积编码器（如ResNet-18）中学习观察分量与动作间的因果关系。实验在MuJoCo仿真的ALOHA双手机器人臂上进行，结果表明该方法能显著缓解现有模仿学习算法的泛化问题。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.22380" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>