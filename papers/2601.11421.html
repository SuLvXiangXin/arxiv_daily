<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.11421" target="_blank" rel="noreferrer">2601.11421</a></span>
        <span>作者: Yong-Lu Li Team</span>
        <span>日期: 2026-01-16</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前机器人学习领域涌现了大量数据集（如Open X-Embodiment、Agibot、RoboCOIN）和相应的任务设计。然而，这些数据集往往缺乏系统性的设计原则，任务高度重叠，主要集中在“抓取并持有”等少数常见行为上，缺乏对复杂和长尾任务的覆盖。这导致两个关键问题：1）训练出的模型存在显著偏差，在现实场景中作为预训练模型时，除了常见任务外泛化能力有限；2）不同研究提出的新方法通常在各自选择的少数常见任务上评估，缺乏统一的任务设计标准，使得公平比较变得困难。本文针对现有机器人任务设计和评估中多样性不足、长尾行为缺失的痛点，提出了GM-100基准，旨在通过精心设计的100个多样化、挑战性的任务来全面评估具身智能体。其核心思路是基于人类-物体交互基元和物体可供性，系统地生成和筛选任务，覆盖广泛交互和长尾行为，推动机器人数据集任务设计向多样化和复杂化发展。</p>
<h2 id="方法详解">方法详解</h2>
<p>GM-100基准的构建是一个系统化的流程，其整体框架如图2所示，目标是生成一个既多样又可行的机器人任务列表。</p>
<p><img src="https://arxiv.org/html/2601.11421v1/x2.png" alt="GM-100构建流程"></p>
<blockquote>
<p><strong>图2</strong>：GM-100基准的构建流程。该过程始于收集现有机器人任务，随后利用HAKE中的人类交互基元和大语言模型进行语义扩展以覆盖长尾交互。生成的候选任务经过LLM和人类专家的混合严格过滤，以确保硬件可行性和数据收集友好性。最终，选出100个高优先级任务，并为其制定详细的交互标准和录制模板视频。</p>
</blockquote>
<p><strong>流程与核心模块</strong>：</p>
<ol>
<li><strong>任务收集与分析</strong>：首先收集Agibot、π0.5等现有工作中的任务，去重并基于语义进行分类。分析发现现有任务描述中存在明显的动词偏向（如图1所示），验证了任务设计重叠和长尾缺失的问题。</li>
<li><strong>语义扩展与LLM生成</strong>：基于从HAKE、OCL等人类动作理解研究中获得的人类-物体交互基元和物体可供性，精心挑选一系列从高频到低频的代表性交互基元。利用Qwen3大语言模型，在统一的任务设计提示下，自动生成大量候选任务。具体步骤包括：对动作基元进行词义消歧以确保语义唯一性；提示模型枚举与每个动作语义和物理相关的物体；基于这些动作-物体对合成具体的任务实例并精炼描述。</li>
<li><strong>混合过滤与任务选择</strong>：对生成的任务进行过滤。首先使用LLM自动评分任务的机器人可执行性，然后由五位人类专家作为黄金标准进行最终筛选。此过程确保所选任务在当前硬件约束下可行，且适合基于遥操作的数据收集。结合多LLM和人类专家的评估对任务进行评分和优先级排序。</li>
<li><strong>任务实例化</strong>：对高优先级任务，设计具体的交互细节并选择合适物体（例如从淘宝网选购），建立明确的任务完成评估标准，并为未来超越成功率（SR）的度量奠定基础。同时，录制人类完成这些任务的模板视频以指导数据收集。最终选出100个任务构成GM-100基准的第一版。</li>
</ol>
<p><strong>创新点</strong>：与现有工作主要依赖设计者主观判断、日常活动或应用场景来设计任务不同，GM-100的创新性在于其任务设计原则的转变。它不依赖现实世界任务的实用性（以避免人类偏见），而是遵循物理常识和低级操作知识（“如何”层面的可供性）作为生成和筛选任务的唯一标准，从而系统性地覆盖长尾、罕见但重要的交互行为。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准/数据集</strong>：GM-100任务列表及在其上收集的中等规模数据集（超过13,000条遥操作轨迹）。</li>
<li><strong>实验平台</strong>：使用两个具有不同运动学结构、双臂设计和主摄像头视角的机器人平台：Agilex Cobot Magic（前伸臂结构，头戴摄像头）和Dobot Xtrainer（内折臂结构，俯视摄像头），如图3所示。这为评估提供了多样性。</li>
<li><strong>基线模型</strong>：评估了多个基线模型，包括Diffusion Policy (DP)、π0、π0.5和GR00T。这些模型在收集的每个任务的100条轨迹上从头训练（DP）或微调（VLA模型）直至收敛。</li>
<li><strong>评估指标</strong>：成功率（SR）、部分成功率（PSR，针对多步骤复杂任务提供更细粒度的评估）以及动作预测误差（MSE和L1损失）。</li>
</ul>
<p><img src="https://arxiv.org/html/2601.11421v1/x3.png" alt="GM-100数据集与平台"></p>
<blockquote>
<p><strong>图3</strong>：GM-100数据集使用的两个不同机器人平台：Agilex Cobot Magic（左）和Dobot Xtrainer（右）。任务1-10在两个平台上各收集了130条轨迹，任务11-100仅在Cobot Magic平台上收集数据。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>真实世界性能</strong>：在Xtrainer平台上对前10个任务的评估结果（表1）显示，不同模型性能差异显著。平均成功率（SR）从DP的1.6%、π0的4.4%到π0.5的24.9%不等，证明了GM-100任务能够有效区分当前VLA模型的性能。部分任务（如0007、0008）对某些模型极具挑战性（SR为0%），而π0.5在多个任务上表现相对较好，但整体成功率仍不高，突显了任务的挑战性。</li>
</ol>
<p><img src="https://arxiv.org/html/2601.11421v1/x4.png" alt="部分成功率热力图"></p>
<blockquote>
<p><strong>图4</strong>：Cobot Magic平台上的部分成功率（PSR）热力图。颜色强度表示PSR。该图直观展示了不同模型（行）在不同任务（列）上的细粒度性能差异，进一步证实了基准的区分能力。</p>
</blockquote>
<ol start="2">
<li><strong>动作预测误差分析</strong>：表2展示了在Xtrainer平台上的动作预测误差。π0.5在大多数任务上取得了最低的MSE和L1损失（平均MSE 0.0029，L1 0.0234），而DP的平均误差最高（MSE 0.0047，L1 0.0328）。</li>
<li><strong>离线损失与在线性能的相关性</strong>：图5将归一化MSE与物理部分成功率（PSR）进行对比。结果显示，动作预测误差与物理成功率之间存在明显的负相关关系。π0.5（红色）在几乎所有任务上都能最小化归一化MSE（左侧条形较短）同时获得最高的PSR（右侧条形较长）。这表明在给定环境中，高精度的动作建模是成功物理交互的前提。</li>
</ol>
<p><img src="https://arxiv.org/html/2601.11421v1/x5.png" alt="归一化MSE与PSR对比"></p>
<blockquote>
<p><strong>图5</strong>：任务级别的归一化MSE（左）和部分成功率（右）跨模型对比图。清晰显示了π0.5在最小化预测误差和实现更高成功率方面的优势，以及DP预测误差较大时成功率较低的趋势。</p>
</blockquote>
<p><strong>组件贡献</strong>：虽然没有传统的消融实验，但任务构建流程本身体现了核心组件的贡献。<strong>基于人类交互基元和LLM的语义扩展</strong>是生成多样化、覆盖长尾任务的关键；<strong>结合LLM自动评分与人类专家筛选的混合过滤</strong>机制则保证了最终任务集的硬件可行性与数据收集友好性，这是基准得以落地实施的基础。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>系统性地指出了当前机器人任务设计与评估的局限性</strong>，即过度集中于常见任务、缺乏多样性和长尾覆盖，导致模型偏差和评估不公平。</li>
<li><strong>提出了GM-100基准及一套系统化的任务设计方法</strong>。该方法基于人类-物体交互基元和物体可供性，利用LLM生成并结合专家筛选，产生了100个细节导向、覆盖广泛交互和长尾行为的任务。</li>
<li><strong>建立了配套的数据集并验证了基准的有效性</strong>。在两个不同机器人平台上收集了超过13K条轨迹，并对多个主流基线模型进行了评估，结果表明GM-100任务既具备可执行性，又足够挑战，能够有效区分不同模型的性能。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，由于当前机器人学习模型仍显著受测试者能力和环境条件的影响，构建一个绝对公平的物理测试环境是不切实际的。因此，GM-100选择了一个开放、社区驱动的评估范式，但这可能引入一定的主观性和不一致性。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>倡导透明、社区驱动的评估范式</strong>：GM-100不仅是一个基准，更是一个开放平台。它鼓励研究者上传自己的结果和证据视频，通过社区共识而非严格的中心化测试来建立长期评估，这为机器人学习领域的评测提供了新思路。</li>
<li><strong>为任务设计提供了系统化、原则化的新思路</strong>：将任务设计的基础从主观应用场景转向客观的物理交互基元，有助于生成更全面、无偏的任务集，推动学习智能体向具备更类人能力的方向发展。</li>
<li><strong>作为未来研究的基础</strong>：GM-100是“GM-X”系列的第一步，其任务列表、设计方法和开放生态为后续构建更大规模、更复杂的机器人学习“奥林匹克”奠定了基础。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对当前机器人学习数据集中任务设计单一、缺乏系统性，导致模型评估不全面、难以公平比较的问题，提出了名为“Great March 100”的评估基准。其核心技术方法是基于对现有任务设计的系统分析与扩展，并结合人-物交互原语和物体可供性的洞见，精心设计了100个覆盖广泛交互和长尾行为的多样化任务。实验结果表明，GM-100中的任务不仅具备可执行性，而且具有足够的挑战性，能够有效区分当前各类视觉语言动作模型的性能。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.11421" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>