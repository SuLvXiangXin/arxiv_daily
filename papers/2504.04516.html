<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>DexSinGrasp: Learning a Unified Policy for Dexterous Object Singulation and Grasping in Densely Cluttered Environments - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>DexSinGrasp: Learning a Unified Policy for Dexterous Object Singulation and Grasping in Densely Cluttered Environments</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2504.04516" target="_blank" rel="noreferrer">2504.04516</a></span>
        <span>作者: Xu, Lixin, Liu, Zixuan, Gui, Zhewei, Guo, Jingxiang, Jiang, Zeyu, Zhang, Tongzhou, Xu, Zhixuan, Gao, Chongkai, Shao, Lin</span>
        <span>日期: 2025/04/06</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在机器人操作领域，从杂乱环境中抓取物体是一个基础且具有挑战性的问题。现有方法主要分为两类：一类是针对灵巧手的抓取策略，它们通常在物体松散分布的场景中工作，通过分割点云或图像来提取场景信息以定位抓取点，但在密集杂乱环境中，由于缺乏显式的物体分离（Singulation）训练，当目标物体被紧密包围时，这些方法往往失败。另一类是针对两指夹爪的“推-抓”协同方法，它们认识到在密集杂乱中需要先分离物体再抓取，但由于夹爪的机械限制，需要将目标物体完全隔离，导致分离效率低下。</p>
<p>本文针对<strong>密集杂乱环境中目标物体初始状态下不可抓取</strong>这一具体痛点，提出了利用<strong>灵巧手的高自由度（DoF）进行高效物体分离以辅助抓取</strong>的新视角。与依赖夹爪推动或仅关注抓取的方法不同，本文强调利用灵巧手手指的灵活性，在手掌保持相对静止的情况下，仅通过手指动作来分离周围物体，从而为抓取创造空间，实现更高效的操作。本文的核心思路是：通过设计一个统一的奖励函数，利用强化学习训练一个能协同进行物体分离与抓取的策略，并辅以杂乱排列课程学习和策略蒸馏，以解决训练难题并实现真实世界部署。</p>
<h2 id="方法详解">方法详解</h2>
<p>DexSinGrasp 的整体框架是一个分阶段的训练与部署流程。首先，在仿真环境中，利用包含物体状态等特权信息的观测，通过<strong>杂乱排列课程学习</strong>逐步训练出性能强大的“教师”策略。然后，使用这些教师策略收集带有视觉观测（点云）的数据，最后通过<strong>行为克隆</strong>训练一个基于视觉的“学生”策略，以利于在真实机器人上部署。</p>
<p><img src="https://arxiv.org/html/2504.04516v3/img/overview.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：DexSinGrasp 框架总览。左侧为教师策略训练阶段，采用课程学习从简单到复杂（物体数量和排列方式）的任务中逐步训练。右侧为学生策略训练阶段，利用教师策略收集的视觉观测-动作数据对，通过行为克隆训练一个基于点云输入的可部署策略。</p>
</blockquote>
<p><strong>核心模块1：统一奖励设计</strong>。为了克服分别训练分离与抓取策略导致的协同性差和执行时间长的问题，本文设计了一个分段奖励函数，将分离与抓取无缝整合到一个学习目标中。奖励函数根据手掌/手指与目标物体的距离分为两个阶段：当距离较远时（<code>d_t^P ≥ 0.06 或 d_t^J ≥ 0.2</code>），奖励 <code>r_t^P</code>（鼓励手掌接近）、<code>r_t^J</code>（鼓励手部连杆接近）和 <code>r_t^S</code>（鼓励分离目标与周围物体）主导，引导策略接近并分离物体。当手掌和手指足够接近目标时（<code>d_t^P &lt; 0.06 且 d_t^J &lt; 0.2</code>），则额外添加 <code>r_t^F</code>（鼓励指尖接触）、<code>r_t^L</code>（鼓励抬起）、<code>r_t^G</code>（鼓励移向目标点）和 <code>r_t^B</code>（额外奖励）等抓取相关奖励。<strong>关键创新</strong>在于分离奖励 <code>r_t^S</code> 贯穿始终，激励策略在整个过程中主动分离目标物体，从而实现了分离动作与抓取动作的自然协同与过渡。</p>
<p><strong>核心模块2：杂乱排列课程学习</strong>。由于直接在密集或随机排列的杂乱环境（定义为“需分离的杂乱，SNC”）中训练策略非常困难，本文设计了课程学习方案。课程基于物体排列的密度和多样性渐进增加难度：1) 首先在<strong>单物体（SO）</strong> 场景训练基础抓取。2) 然后在<strong>密集排列（Dense Arrangement）</strong> 任务上，依次训练 D-4（4个周围物体）、D-6、D-8。3) 接着以 D-8 策略为起点，在<strong>随机排列（Random Arrangement）</strong> 任务上，依次训练 R-4、R-6、R-8。最终，分别从 D-8 和 R-8 训练中提取出针对两种杂乱类型的教师策略。所有训练均使用 PPO 算法。</p>
<p><img src="https://arxiv.org/html/2504.04516v3/img/clutter_table.png" alt="杂乱设置"></p>
<blockquote>
<p><strong>图3</strong>：密集与随机排列设置示意图。密集排列使用1x1立方体紧密包围目标；随机排列使用不同尺寸（1x1, 1x2, 1x3）的立方体随机放置。D/R-n 表示具有 n 个周围物体的任务。</p>
</blockquote>
<p><strong>核心模块3：师生策略蒸馏</strong>。为了获得可部署的、仅依赖视觉观测的策略，本文采用行为克隆进行蒸馏。首先，使用训练好的两个教师策略（分别针对密集和随机杂乱）在各类任务（D/R-4/6/8）中收集 1000 条轨迹数据，包含视觉观测（场景点云）和教师动作。然后，训练一个学生策略网络，其输入将教师策略中的物体状态和分离距离等特权信息，替换为场景点云的中心点坐标以及一个<strong>冻结权重</strong>的预训练点云编码器（来自 UniGraspTransformer）提取的 128 维视觉特征。学生策略通过模仿教师的动作来学习。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在 Isaac Gym 仿真环境中进行评估，并进行了真实世界实验。定义了两类基准任务：密集排列（D-4/6/8）和随机排列（R-4/6/8），其中 D-8 和 R-8 为典型的 SNC 场景。使用立方体物体进行训练和主要测试。</p>
<p><strong>对比基线</strong>：</p>
<ol>
<li><strong>GraspReward-Only</strong>：仅使用抓取奖励（不含分离奖励）在单物体环境训练的策略，直接在杂乱场景测试。</li>
<li><strong>Multi-Stage</strong>：两阶段方法，分别训练分离策略和抓取策略，并按条件顺序执行（模仿 SOPE）。</li>
</ol>
<p><strong>评估指标</strong>：成功率（SR，目标物体被抬升到指定目标位置的比例）和平均步数（AS，完成抓取所需步数平均值，失败按最大步数300计）。</p>
<p><strong>关键定量结果</strong>：</p>
<ul>
<li>在密集排列任务（表II）中，本文的<strong>教师策略</strong>取得了压倒性优势：平均成功率 98%（D-4:98%, D-6:99%, D-8:97%），远高于 Multi-Stage 的 72% 和 GraspReward-Only 的 39%。同时，平均步数 118 步也显著低于两个基线（215 步和 249 步）。<strong>学生策略</strong>平均成功率为 89%，虽略低于教师，但仍显著优于基线，且步数（135步）保持高效。</li>
<li>在随机排列任务（表III）中，趋势一致：<strong>教师策略</strong>平均成功率 96%（R-4:97%, R-6:96%, R-8:94%），平均步数 97 步；<strong>学生策略</strong>平均成功率 88%，平均步数 109 步。两者均优于 Multi-Stage（成功率79%，步数168）和 GraspReward-Only（成功率56%，步数216）。</li>
</ul>
<p><strong>消融分析与组件贡献</strong>：实验结果表明，统一策略相比多阶段方法在成功率和效率上均有大幅提升，验证了统一奖励设计促进协同的有效性。课程学习的必要性通过训练曲线分析得到证实，直接从 SNC 任务开始训练成功率极低，而通过课程学习能稳定提升至高性能。学生策略的成功验证了蒸馏框架的有效性，能够将教师策略的知识迁移到仅依赖点云的策略上。</p>
<p><img src="https://arxiv.org/html/2504.04516v3/img/qualitative_3.jpg" alt="定性结果1"></p>
<blockquote>
<p><strong>图4</strong>：在密集排列（D-8）任务上的定性结果对比。从左至右为 GraspReward-Only、Multi-Stage 和 DexSinGrasp (Ours) 的策略执行过程。可以看出，本文方法能更有效地利用手指分离物体并完成抓取。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.04516v3/img/irregular2.png" alt="泛化测试"></p>
<blockquote>
<p><strong>图5</strong>：在训练未见的不规则形状物体（如圆柱、椭球、十字形）上的泛化性能。DexSinGrasp 的学生策略展现了良好的泛化能力，而基线方法表现不佳。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.04516v3/img/realworld.jpg" alt="真实世界实验"></p>
<blockquote>
<p><strong>图6</strong>：真实世界部署。将训练好的学生策略部署到搭载 Leap Hand 灵巧手和 RealSense 相机的 xArm 机械臂上，成功在由立方体和日常物品构成的密集杂乱场景中完成物体分离与抓取。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出了一个<strong>统一的强化学习策略</strong>，首次实现了灵巧手在密集杂乱环境中物体分离与抓取的高效协同，显著提升了成功率和操作效率。2) 设计了<strong>杂乱排列课程学习</strong>和<strong>师生策略蒸馏</strong>框架，有效解决了复杂场景下的训练难题，并获得了可部署的视觉策略。3) 通过系统实验，验证了<strong>利用手指灵活性进行分离</strong>相较于依赖手掌移动或两阶段解耦方法的显著优势。</p>
<p>论文自身提到的局限性包括：1) 主要在桌面二维平面（物体高度相同）的杂乱场景中进行测试，未涉及三维堆叠的杂乱。2) 训练阶段主要使用立方体形状。</p>
<p>本工作对后续研究的启示包括：1) 展示了统一策略在连续操作任务中的优势，可激励更多“感知-动作”协同任务的研究。2) 课程学习与策略蒸馏的结合为复杂灵巧操作任务的仿真到现实转移提供了可行路径。3) 未来可探索更复杂的三维杂乱、更多样的物体几何与材质，以及结合大型视觉-语言模型进行更智能的任务理解与规划。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出DexSinGrasp方法，解决灵巧手在密集杂乱环境中因物体遮挡难以抓取目标的核心问题。该方法学习统一策略，将物体分离与抓取结合，关键技术包括杂乱排列课程学习以增强泛化能力，以及策略蒸馏实现可部署视觉抓取。实验表明，在密集杂乱任务中，该方法在效率和抓取成功率上均优于基线方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2504.04516" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>