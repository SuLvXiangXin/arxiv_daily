<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>DataMIL: Selecting Data for Robot Imitation Learning with Datamodels - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>DataMIL: Selecting Data for Robot Imitation Learning with Datamodels</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.09603" target="_blank" rel="noreferrer">2505.09603</a></span>
        <span>作者: Dass, Shivin, Khaddaj, Alaa, Engstrom, Logan, Madry, Aleksander, Ilyas, Andrew, Martín-Martín, Roberto</span>
        <span>日期: 2025/05/14</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人学习领域近期通过整合大规模、多样化的数据集来训练通用策略，取得了显著进展。然而，这些通用策略虽然在多种任务上平均表现良好，但在具体的、专门化的任务上往往表现不佳，通常需要利用新获取的任务特定数据进行进一步的微调。通过协同训练，将任务特定数据与大型先验数据集中精心挑选的子集相结合，可以产生更好的专用策略。但简单地选择数据（例如，基于语义或视觉相似性等人类直觉的质量概念进行筛选）可能会损害下游性能。当前主流的数据选择方法依赖于启发式规则，未能考虑数据点对策略性能的真实影响。</p>
<p>本文针对“如何从现有大型数据集中挑选能真正提升特定任务性能的数据”这一具体痛点，提出了一个基于数据模型（datamodels）范式的、以策略性能为导向的端到端数据选择新视角。其核心思路是：绕过基于相似性的启发式方法，直接估计每个数据点对最终任务成功率的影响，并据此选择最能提升策略性能的数据子集。</p>
<h2 id="方法详解">方法详解</h2>
<p>DataMIL 的整体目标是在给定先验数据集 (\mathcal{D})、学习算法 (\mathcal{A}) 和目标度量 (\mathcal{M})（如成功率）的情况下，找到一个数据子集 (\mathcal{D&#39;} \subset \mathcal{D})，使得在该子集上训练得到的策略性能 (\mathcal{M}(\mathcal{A}(\mathcal{D&#39;}))) 最大化。直接优化此目标因涉及大量策略训练和昂贵的环境交互（rollout）而不可行。DataMIL 的关键创新在于引入数据模型 (\hat{f}: 2^{\mathcal{D}} \rightarrow \mathbb{R}) 来近似预测 (\mathcal{M}(\mathcal{A}(\mathcal{D&#39;})))，从而将原始优化问题转化为对数据模型 (\hat{f}) 的优化。</p>
<p><img src="https://arxiv.org/html/2505.09603v1/extracted/6439549/figures/mill.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：DataMIL 方法概览。（左）基于相似性的方法选择相近样本（黄色），但这些样本并不总是对学习有益。DataMIL 基于数据对策略性能的影响来评估数据，选择能带来策略改进的样本。（中）我们估计数据模型，为每个样本根据其对策略性能的影响打分，并选择得分最高的样本进行训练。（右）DataMIL 探索了两种适用于机器人学的数据模型估计方法：回归估计和基于元梯度的估计。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><p><strong>数据模型估计</strong>：DataMIL 采用线性数据模型，即 (\hat{f}(\mathcal{D&#39;}) = \sum_{z_i \in \mathcal{D&#39;}} \tau(z_i))，其中 (\tau(z_i)) 表示数据点 (z_i) 对目标度量的加性影响。论文探索了两种估计 (\tau(z_i)) 的方法：</p>
<ul>
<li><strong>回归估计器</strong>：通过采样 (N) 个随机数据子集 (\mathcal{D}_j \subset \mathcal{D})，在每个子集上训练策略并评估其真实性能 (\mathcal{M}(\mathcal{A}(\mathcal{D}_j)))，然后求解线性回归问题（公式3）来拟合每个数据点的 (\tau(z_i))。此法准确但计算成本高。</li>
<li><strong>元梯度估计器</strong>：当目标函数 (\mathcal{M}) 对模型参数可微时，可利用影响函数的思想，通过少量模型训练高效地估计 (\tau(z_i))。此法显著提升了大规模策略（如 Octo）数据模型估计的效率。</li>
</ul>
</li>
<li><p><strong>适应机器人学习的挑战</strong>：</p>
<ul>
<li><strong>避免环境交互的代理目标</strong>：由于真实环境交互昂贵且目标函数不可微，DataMIL 提出使用一个可微的代理度量 (\mathcal{\widehat{M}}) 来代替真实成功率 (\mathcal{M})。具体而言，(\mathcal{\widehat{M}}(\pi, \mathcal{D}<em>{target}) = \frac{1}{|\mathcal{D}</em>{target}|} \sum_{(s,a) \in \mathcal{D}<em>{target}} -\mathcal{L}</em>{BC}(\pi(s), a))，即策略在少量任务特定验证集 (\mathcal{D}_{target}) 上的行为克隆（BC）损失的负值。这避免了 rollout，并使目标可微，从而能使用高效的元梯度估计器。</li>
<li><strong>数据聚类</strong>：为减少单个数据点影响力估计的噪声，DataMIL 将数据点聚类（例如按子轨迹、整个轨迹或任务聚类），并在聚类级别而非单个样本级别估计影响力。聚类粒度根据数据集大小和计算预算进行权衡。</li>
<li><strong>缓解分布偏移</strong>：当从包含不同本体、场景的异构数据集（如 OXE）中选择数据时，分布偏移问题严重。为此，DataMIL 在估计数据模型时，会将一部分目标任务数据与先验数据混合训练，以更好地将策略学习与目标领域对齐。</li>
</ul>
</li>
</ol>
<p><strong>创新点</strong>：与现有基于相似性启发式的方法相比，DataMIL 的创新在于：1) <strong>端到端性能感知</strong>：直接以提升策略性能为目标进行数据选择，而非依赖可能与性能脱钩的相似性度量；2) <strong>引入可微代理目标</strong>：解决了机器人学习中因环境交互昂贵且不可微而无法直接应用数据模型框架的关键难题；3) <strong>高效估计</strong>：通过元梯度估计器和聚类策略，使方法能够扩展到大规模机器人数据集和策略。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：论文在超过60个仿真和现实世界操纵任务上验证 DataMIL。使用的基准/数据集包括：MetaWorld（50个任务）、LIBERO 基准（10个任务）、Open X-Embodiment（OXE）数据集（用于4个现实世界任务）。实验平台涵盖仿真环境和真实机器人硬件。</p>
<p><strong>对比基线</strong>：对比方法包括：1) <strong>使用全部先验数据</strong>；2) <strong>仅使用目标演示数据</strong>；3) <strong>基于启发式的数据选择方法</strong>，如基于视觉相似性、状态-动作接近度的方法。</p>
<p><strong>关键实验结果</strong>：</p>
<ul>
<li><strong>代理目标有效性验证</strong>：在 MetaWorld 的 pick-place-wall 任务上，比较了使用真实 rollout 成功率（DM-rollouts）、使用代理目标的回归估计（DataMIL-rg）和使用代理目标的元梯度估计（DataMIL-meta）进行数据选择的效果。</li>
</ul>
<p><img src="https://arxiv.org/html/2505.09603v1/x1.png" alt="代理指标对比"></p>
<blockquote>
<p><strong>图2</strong>：比较不同数据模型估计方法选择数据后训练策略的真实成功率。结果显示，使用代理目标（DataMIL-rg）仅导致性能小幅下降，而元梯度估计器（DataMIL-meta）在速度提升8倍的同时，性能下降也很小。三者均显著优于使用全部数据或仅用目标数据的基线。</p>
</blockquote>
<ul>
<li><strong>仿真任务性能</strong>：在 MetaWorld 的50个任务上，DataMIL 相比最先进的基线方法实现了平均10%的性能提升。在 LIBERO 的10个多任务、长视野任务上，DataMIL 也 consistently 优于基线。</li>
</ul>
<p><img src="https://arxiv.org/html/2505.09603v1/x3.png" alt="MetaWorld结果"></p>
<blockquote>
<p><strong>图3</strong>：在 MetaWorld 50个任务上的平均成功率。DataMIL（橙色）显著优于所有基线方法，包括使用全部数据（All Data）、仅用目标数据（Target Only）以及各种基于相似性的启发式方法。</p>
</blockquote>
<ul>
<li><strong>现实世界与大规模数据集应用</strong>：DataMIL 成功地从超大规模、异构的 OXE 数据集中为4个新的现实世界任务（涉及新的机器人本体和场景）筛选数据。经过 DataMIL 筛选数据微调后的策略，性能大幅优于直接使用 OXE 数据微调的基线策略。</li>
</ul>
<p><strong>消融实验</strong>：论文通过消融实验分析了各组件贡献。关键结论包括：1) <strong>代理目标</strong>是可行的，且是使数据模型应用于机器人学的关键；2) <strong>聚类策略</strong>对于在大规模数据集中获得稳定的影响力估计至关重要；3) <strong>缓解分布偏移</strong>的技术（在估计时加入部分目标数据）对于在 OXE 这类异构数据集上取得良好效果是必要的。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>将数据模型框架引入机器人模仿学习</strong>：提出了首个以端到端、性能感知的方式为机器人策略进行数据选择的方法 DataMIL。</li>
<li><strong>提出可微的代理目标函数</strong>：通过利用任务特定验证集上的行为克隆损失作为代理，绕过了机器人学中环境交互昂贵且不可微的障碍，使高效的数据模型估计成为可能。</li>
<li><strong>展示了大规模异构数据集的有效利用</strong>：在包括 OXE 在内的多个数据集和超过60个任务上验证了方法的有效性，证明了其能够从海量先验数据中为新任务、新本体筛选出有益数据。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，数据模型的估计（即使是高效的元梯度方法）仍然需要一定的计算成本。对于极大规模的数据集，完全精确的影响力计算可能仍具挑战。</p>
<p><strong>对后续研究的启示</strong>：DataMIL 的工作强调了直接优化数据选择以提升最终任务性能的重要性，而非依赖间接的启发式规则。这为机器人学习社区如何更高效地利用不断增长的大型数据集指明了新方向。未来工作可以探索更高效的数据模型估计方法，或将此框架与主动学习、课程学习等范式相结合。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>论文解决机器人模仿学习中，从大型先验数据集选择数据以提升任务特定性能的核心问题。现有方法基于启发式（如语义或视觉相似性）选择数据，可能损害下游性能。为此，提出DataMIL框架，基于数据模型（datamodels）范式，以策略驱动的方式端到端选择数据，直接优化任务成功；关键是用代理损失函数避免昂贵环境滚动。实验在60多个模拟和真实操作任务（包括Open X-Embodiment数据集）验证，实现了成功率的持续提升，性能优于多个基线。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.09603" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>