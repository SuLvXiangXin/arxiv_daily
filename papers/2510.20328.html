<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>MemER: Scaling Up Memory for Robot Control via Experience Retrieval - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>MemER: Scaling Up Memory for Robot Control via Experience Retrieval</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.20328" target="_blank" rel="noreferrer">2510.20328</a></span>
        <span>作者: Chelsea Finn Team</span>
        <span>日期: 2025-10-23</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，遵循语言指令并具备泛化能力的机器人操作策略取得了显著进展。然而，这些策略普遍存在一个关键局限：缺乏长期记忆能力。在部分可观测的现实环境中，机器人需要依赖过去的信息来完成复杂任务。现有方法主要面临两个问题：1) 直接以长序列的高维图像/视频历史作为条件输入，计算成本高昂且容易在协变量偏移下变得脆弱；2) 对历史进行无差别的子采样，则可能丢失相关信息或引入冗余。本文针对机器人策略如何高效、鲁棒地利用长时记忆这一痛点，提出了一个新颖的分层策略框架。核心思路是训练一个高层策略，主动地从过往经验中选择并跟踪相关的关键帧，结合近期帧生成子任务指令，供一个低层策略执行，从而实现对长时依赖关系的有效推理。</p>
<h2 id="方法详解">方法详解</h2>
<p>MemER采用分层策略框架，其整体流程如图1所示。高层策略负责基于记忆进行规划，低层策略负责执行具体的机器人控制。</p>
<p><img src="https://arxiv.org/html/2510.20328v1/figures/architecture_v2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：MemER架构。高层策略处理任务指令、选定的关键帧（如有）以及来自基座和腕部相机的近期图像，生成低层语言子任务和候选关键帧（如有）。低层策略使用子任务、当前图像和机器人关节状态来产生动作。候选关键帧由关键帧过滤器处理，得到用于下一次推理输入的关键帧。</p>
</blockquote>
<p><strong>核心模块与技术细节：</strong></p>
<ol>
<li><p>**高层策略 (π_h)**：基于Qwen2.5-VL-7B-Instruct进行微调。在每一步推理时，其输入包括：1) 每个相机最近N帧的近期上下文 <code>R_t</code>；2) 高级任务指令 <code>l_t</code>；3) 先前选定的关键帧集合 <code>K_t</code>（最多8帧）。其输出为两项：i) 当前要执行的子任务 <code>l&#39;_t</code>；ii) 从近期上下文中选出的候选关键帧集合 <code>J_t</code>。因此，高层策略建模的条件分布为 <code>π_h(l&#39;_t, J_t | R_t, K_t)</code>。视觉编码器和投影层的权重在微调时被冻结以提高效率。</p>
</li>
<li><p><strong>关键帧过滤器与记忆构建</strong>：这是MemER的核心创新。高层策略在每个时间步都可能提名候选关键帧，关键帧过滤器的作用是合并这些提名，形成稳定、非冗余的记忆。具体采用一维单链接聚类算法（见图3）。算法将所有历史提名的时间索引（保留重复项）聚合成簇，每个簇内索引的最大间隔不超过d帧（实验中d=5）。对于每个簇，选择所有提名索引的中位数作为该簇的代表关键帧，并加入选定关键帧集合 <code>K_t</code> 中。此方法任务无关，能覆盖整个观测流，并通过聚合重复提名来选出最具代表性的帧。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2510.20328v1/figures/clustering_voting.png" alt="关键帧聚类"></p>
<blockquote>
<p><strong>图3</strong>：对提名帧进行一维单链接聚类。在每个时间步，高层策略提名候选关键帧（橙色高亮）。所有候选关键帧随时间聚合，使用合并距离d=5帧进行聚类，得到不相交的簇。每个簇中，彩色条表示该时间戳观测获得的提名数量，条的高度与提名次数成正比。我们通过取所有候选帧的中值关键帧来为每个簇选择一个代表帧，并将其添加到记忆中。</p>
</blockquote>
<ol start="3">
<li><p>**低层策略 (π_l)**：基于在DROID数据集上预训练的 <code>π_0.5</code> 模型进行微调。它接收高层策略生成的子任务 <code>l&#39;_t</code>、当前图像 <code>I_t</code> 和本体感知状态 <code>q_t</code>，输出未来一段时间内的动作块 <code>A_t</code>，建模分布 <code>π_l(A_t | I_t, q_t, l&#39;_t)</code>。</p>
</li>
<li><p><strong>模型合并</strong>：为避免微调导致模型失去预训练基座的鲁棒性，采用了权重插值策略：<code>θ = (1-α)·θ_pre + α·θ_ft</code>，其中 <code>θ_pre</code> 是预训练的Qwen2.5-VL-7B-Instruct权重，<code>θ_ft</code> 是在三个记忆任务上微调后的权重。根据相关研究，设置 <code>α=0.8</code>。</p>
</li>
<li><p><strong>部署与数据</strong>：高层和低层策略异步运行，分别以约1Hz和2Hz的频率进行推理。仅需约50条带有子任务标注的遥操作演示轨迹和10-15条干预演示，即可微调出高性能的策略。关键帧的标注采用半自动规则：人工为每种类型的子任务指定选取规则（如选取该子任务段的第一帧、最后一帧或不选），然后自动应用于所有演示。</p>
</li>
</ol>
<p><strong>创新点</strong>：与直接扩展上下文窗口或简单压缩历史的方法相比，MemER的创新在于让策略<strong>主动学习</strong>选择和维护一个动态的、任务相关的关键帧记忆库。这既解决了长上下文带来的计算和泛化问题，又避免了无差别采样导致的信息丢失或冗余。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在真实机器人（Franka机械臂，配备基座和腕部相机）上评估了三个需要长时记忆（长达数分钟）的复杂操作任务（见图4）：1) <strong>物体搜索</strong>：在多个不透明箱子中依次寻找多个物体，需记住已搜索过的箱子内容；2) <strong>计数舀取</strong>：向两个碗中舀取指定数量的两种食材，需记住已舀取的数量；3) <strong>除尘替换</strong>：取下架子上的物体，除尘后再放回原处，需记住物体的原始位置和已除尘的架子。</p>
<p><img src="https://arxiv.org/html/2510.20328v1/figures/tasks.png" alt="实验任务"></p>
<blockquote>
<p><strong>图4</strong>：评估中使用的三个任务。跨越三个领域，我们评估复杂指令、中间子任务和关键帧预测。每个方法每个任务报告20次试验的性能。</p>
</blockquote>
<p><strong>对比基线</strong>：</p>
<ol>
<li><strong>无历史</strong>：高层策略仅看当前帧（类似当前机器人基础模型）。</li>
<li><strong>短历史</strong>：高层策略看最近N=8帧。</li>
<li><strong>长历史</strong>：高层策略看最近N=32帧。</li>
<li><strong>人类高层</strong>：由人类提供正确的子任务（性能上限估计）。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.20328v1/x1.png" alt="主要结果"></p>
<blockquote>
<p><strong>图5</strong>：主要结果。我们的方法在三个需要长时记忆的任务上明显优于无历史、短历史（8帧上下文）和长历史（32帧上下文）基线。其性能与人类高层策略相当。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ul>
<li>如图5和表1所示，MemER在所有任务上都显著优于基线方法。在物体搜索任务中，MemER在60次检索机会中成功59次，并57次使用了最优路径，远高于无历史基线（32次成功，25次最优）。在计数舀取任务中，MemER的错误舀取次数仅为1次，而无历史基线高达61次。在除尘替换任务中，MemER各项子任务成功率均超过90%。</li>
<li>长历史基线（32帧）性能虽有提升，但仍比MemER平均低34%，且其约1秒的推理时间已接近闭环控制的容忍极限。</li>
</ul>
<p><strong>消融实验与分析</strong>：</p>
<p><img src="https://arxiv.org/html/2510.20328v1/x2.png" alt="模态与模型合并结果"></p>
<blockquote>
<p><strong>图6</strong>：（左）模态结果。仅使用图像表示记忆比仅使用文本或文本加图像的基线表现更好。我们假设高层策略过度索引记忆中的文本标记，导致其忽略了视觉输入中的重要细节。（右）模型合并结果。将我们微调的高层策略权重与预训练的Qwen2.5-VL-7B-Instruct权重合并，有助于维持或提升所有任务的性能。</p>
</blockquote>
<ul>
<li><strong>记忆表示模态</strong>（图6左）：比较了用图像、文本描述、以及图像+文本描述作为记忆表示的方式。实验发现，<strong>仅使用图像</strong>作为记忆表示效果最好。作者推测，当记忆中包含文本时，高层策略可能过度依赖文本标记而忽略了视觉细节。</li>
<li><strong>模型合并</strong>（图6右）：验证了权重插值（α=0.8）的有效性，模型合并维持或提升了所有任务的性能，证明了其对于保持模型鲁棒性的重要性。</li>
<li><strong>与专有VLM对比</strong>：实验发现，现有的基于API的专有VLM（如GPT-4V）不足以推理机器人操作任务中的功能特性，因此微调开源模型是必要的。</li>
<li><strong>泛化能力</strong>：在物体搜索任务中测试了面对未见过的物体的泛化能力，MemER取得了75%的成功率，显著优于无记忆基线（10%）。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了MemER，一个通过经验检索来扩展机器人记忆的分层框架，其核心是让高层策略主动学习选择和维护一个动态的关键帧记忆库。</li>
<li>设计了一个高效、任务无关的关键帧过滤算法（基于单链接聚类），能够从流式观测中构建非冗余的视觉记忆。</li>
<li>在三个需要长达数分钟记忆的真实世界长时程操作任务上进行了全面验证，仅用少量演示数据微调，性能即大幅超越多种基线，并与人类高层规划者表现相当。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ol>
<li>性能依赖于低层策略的执行能力，低层策略的失败会直接影响整体任务成功率。</li>
<li>关键帧的选择和记忆容量（最多8帧）可能存在限制，对于极其复杂的任务，可能需要更精细的记忆管理策略。</li>
<li>高层策略的推理频率（1Hz）与低层策略（2Hz）之间存在权衡，可能影响对快速变化场景的响应。</li>
</ol>
<p><strong>启示</strong>：<br>MemER展示了让机器人策略具备“选择性记忆”能力的有效途径。其框架兼容现有的视觉-语言-动作模型，为将长时记忆能力集成到通用机器人系统中提供了可行方案。未来的工作可以探索更智能的记忆更新与遗忘机制、结合其他模态（如触觉）的记忆，以及将此类方法应用于更广泛的任务领域。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文旨在解决机器人策略缺乏长期记忆能力的问题，以处理需要分钟级记忆的复杂长时程操作任务。提出MemER分层框架：高层策略学习从历史经验中筛选和跟踪相关关键帧，结合近期观察生成文本指令，驱动底层策略执行。该方法兼容现有视觉-语言-动作模型，能高效推理长时依赖。实验在三个真实世界长时程操作任务上验证，MemER优于先前方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.20328" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>