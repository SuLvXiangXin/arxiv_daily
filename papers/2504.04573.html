<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>DexTOG: Learning Task-Oriented Dexterous Grasp with Language - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>DexTOG: Learning Task-Oriented Dexterous Grasp with Language</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2504.04573" target="_blank" rel="noreferrer">2504.04573</a></span>
        <span>作者: Zhang, Jieyi, Xu, Wenqiang, Yu, Zhenjun, Xie, Pengfei, Tang, Tutian, Lu, Cewu</span>
        <span>日期: 2025/04/06</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前任务导向抓取（TOG）的研究主要集中于二指平行夹爪，这类方法通过判断接触点是否位于功能部件（affordance）区域内，从基础的稳定抓取中筛选出任务相关的抓取。然而，二指夹爪灵活性有限，限制了可执行任务的复杂性。相比之下，灵巧手具有高自由度的配置空间，能执行更丰富的操作任务，但针对灵巧手的TOG研究较少，且面临三大挑战：1) <strong>任务约束</strong>：系统需理解任务意图并将其作为抓取规划的约束；2) <strong>多模态有效抓取</strong>：给定任务约束下，目标物体上可能存在多个非唯一的最优抓取姿态，系统需支持这种多模态分布；3) <strong>高自由度</strong>：需要在手部高维配置空间中搜索有效抓取，并考虑力稳定性。</p>
<p>本文针对上述痛点，提出了一个名为 <strong>DexTOG</strong> 的新框架，其核心思路是：利用语言引导的扩散模型（DiffuTOG）在灵巧手配置空间中直接生成符合任务描述的抓取姿态，并配套开发了一个从粗到精的数据引擎，用于自动生成和验证大规模灵巧手TOG数据（DexTOG-80K数据集）。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架包含两个阶段：抓取生成与抓取执行验证。在生成阶段，DiffuTOG模型根据物体点云、任务文本描述和手部模型，通过去噪扩散过程生成抓取提案，随后通过一个测试时优化器调整姿态以避免碰撞。在执行验证阶段（主要用于数据构建时的自动标注），使用优化后的抓取姿态作为初始状态，训练基于状态的强化学习策略来完成任务，成功执行的抓取才被最终标记为任务导向抓取。</p>
<p><img src="https://arxiv.org/html/2504.04573v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：DexTOG方法整体流程。左侧为抓取生成阶段：DiffuTOG接收物体点云、任务文本和手部模型条件，通过迭代去噪生成抓取姿态，随后进行碰撞处理优化。右侧为抓取执行验证阶段：将优化后的姿态作为初始状态，通过强化学习策略执行任务以验证抓取有效性，该阶段主要用于数据集构建。</p>
</blockquote>
<p><strong>核心模块与技术细节：</strong></p>
<ol>
<li><p>**扩散抓取生成模型 (DiffuTOG)**：</p>
<ul>
<li><strong>输入</strong>：物体点云 $\mathcal{O} \in \mathbb{R}^{N_1 \times 3}$，任务文本描述 $\mathcal{T}$，手部模型 $\mathcal{M}$。</li>
<li><strong>输出</strong>：灵巧手抓取姿态 $\mathcal{G}_k = (R_k, t_k, q_k)$，包含手腕旋转 $R \in SO(3)$、平移 $t \in \mathbb{R}^3$ 和关节姿态 $q \in \mathbb{R}^J$。</li>
<li><strong>抓取姿态表示</strong>：为解决四元数加法与旋转增量不对应的问题，采用6D旋转表示法（两个3D向量），使噪声添加对应于旋转的增量。</li>
<li><strong>条件嵌入</strong>：<ul>
<li><strong>物体编码器</strong>：将补充零向量的物体点云 $\mathcal{O}&#39;$ 通过PointNet编码为128维向量 $Emb_O$。</li>
<li><strong>手部编码器</strong>：在每次去噪迭代中，根据当前姿态 $\mathcal{G}_k$ 通过前向运动学得到手部点云 $\mathcal{H}_k$，补充全1向量后通过另一个PointNet编码为128维向量 $Emb_H$。</li>
<li><strong>任务编码器</strong>：使用OpenAI的<code>text-embedding-ada-002</code>模型获取1536维文本嵌入，再通过3层MLP压缩为256维向量 $Emb_T$。</li>
</ul>
</li>
<li><strong>训练过程</strong>：条件嵌入与抓取姿态特征拼接后，输入由多个MLP组成的“Diffu Unit”去噪网络 $\epsilon_\theta$。损失函数结合了标准的扩散损失 $L_D$（预测噪声与真实噪声的MSE）和手部点云重建损失 $L_R$，总损失为 $L = L_D + \lambda_R L_R$。</li>
</ul>
</li>
<li><p>**数据引擎 (DexTOG)**：</p>
<ul>
<li>采用从粗到精、从稀疏到稠密的流程构建训练数据。</li>
<li><strong>步骤1（粗筛）</strong>：为物体生成大量与任务无关的稳定抓取姿态，然后针对每个任务应用启发式规则（例如，手指需靠近功能部件）粗略过滤出任务相关抓取。</li>
<li><strong>步骤2（扩散模型增强）</strong>：利用过滤后的抓取训练DiffuTOG。得益于扩散模型的多模态特性，DiffuTOG能够生成物体附近更多样化的任务相关抓取姿态。</li>
<li><strong>步骤3（RL验证与精标）</strong>：由于前两步得到的抓取可能仍与后续任务不完全对齐，使用目标条件强化学习策略来尝试执行任务，仅将成功执行的抓取姿态作为最终的高质量任务导向抓取标签。此流程实现了数据生成的自动化闭环。</li>
</ul>
</li>
</ol>
<p><strong>创新点</strong>：</p>
<ul>
<li>首次将语言条件扩散模型引入高自由度灵巧手的任务导向抓取生成。</li>
<li>提出了一个集成启发式规则、扩散模型和RL验证的自动化数据引擎，高效构建了大规模、高质量的灵巧手TOG数据集。</li>
<li>采用了更适用于扩散过程的6D旋转表示法，提升了训练稳定性。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>数据集</strong>：使用自建的DexTOG-80K数据集进行评估，包含5类任务（订书机按压、喷雾瓶按压按钮、喷雾瓶扣动扳机、瓶盖扭转、圆珠笔按压）在80个铰接物体上的8万个抓取姿态。</li>
<li><strong>基线方法</strong>：由于缺乏开源的灵巧手TOG方法，作者将两个任务无关的灵巧手抓取方法（GraspTTA和Unidexgrasp）适配到TOG设置，通过后处理筛选接触点位于功能区域的抓取，记为GraspTTA-TOG和Unidexgrasp-TOG。</li>
<li><strong>评估指标</strong>：任务无关抓取的成功率（抓取稳定性）；任务导向抓取的成功率（抓取稳定性且能成功执行下游任务）。</li>
</ul>
<p><strong>关键实验结果</strong>：<br>在任务无关抓取评估中，DiffuTOG达到了86.5%的成功率，显著高于GraspTTA-TOG（71.7%）和Unidexgrasp-TOG（62.6%）。在更具挑战性的任务导向抓取评估中，DiffuTOG的成功率为74.4%，而两个基线方法分别仅为53.7%和43.5%。这证明了DiffuTOG在生成同时满足稳定性和任务功能需求的抓取方面的优越性。</p>
<p><img src="https://arxiv.org/html/2504.04573v1/x4.png" alt="定性结果"></p>
<blockquote>
<p><strong>图4</strong>：DiffuTOG与基线方法的定性对比。DiffuTOG生成的抓取（绿色）能更好地将手指放置在功能部件附近（如喷雾瓶的按钮、扳机），而基线方法（红色）的抓取往往只关注稳定性，忽视了任务需求。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.04573v1/x5.png" alt="消融实验"></p>
<blockquote>
<p><strong>图5</strong>：消融实验分析。（a）移除任何条件（物体、手部、任务）都会导致性能下降，其中任务条件的影响最大，验证了语言引导的必要性。（b）比较不同的旋转表示法，6D表示优于四元数和9D表示。（c）测试时碰撞优化能有效提升抓取质量分数。（d）数据引擎中每个组件（启发式过滤H、扩散模型D、RL验证R）的贡献，三者结合（H+D+R）能产生最优质的数据用于训练。</p>
</blockquote>
<p><strong>消融实验总结</strong>：</p>
<ul>
<li><strong>条件嵌入</strong>：任务描述条件对性能影响最大，移除后任务导向抓取成功率大幅下降；物体和手部条件也对性能有重要贡献。</li>
<li><strong>旋转表示</strong>：6D旋转表示法在生成质量和训练稳定性上均优于四元数和9D表示法。</li>
<li><strong>测试时优化</strong>：碰撞处理优化能有效改善生成抓取的物理可行性。</li>
<li><strong>数据引擎组件</strong>：启发式规则（H）、扩散模型增强（D）和RL验证（R）三者缺一不可，共同作用才能生成高质量的训练数据。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>DiffuTOG模型</strong>：提出了首个语言条件扩散模型，用于生成灵巧手的任务导向抓取，有效解决了高自由度空间中的多模态抓取规划问题。</li>
<li><strong>DexTOG数据引擎</strong>：设计了一个自动化的数据生成与验证管道，以从粗到精的方式高效构建大规模、高质量的灵巧手TOG数据。</li>
<li><strong>DexTOG-80K数据集</strong>：发布了一个包含8万个抓取姿态的新数据集，涵盖了5类常见操作任务，为灵巧手操作研究提供了宝贵的资源。</li>
</ol>
<p><strong>局限性</strong>：<br>论文提到，当前数据集规模（80个物体，5个任务）和任务类型仍有限。实验主要在仿真中进行，未涉及真实的物理交互不确定性。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>扩散模型在机器人中的应用</strong>：展示了扩散模型在处理机器人领域多模态、高维输出规划问题上的潜力。</li>
<li><strong>数据驱动的系统构建</strong>：提供了一种结合经典规则、学习模型和物理验证的自动化数据构建范式，可推广至其他复杂机器人技能学习场景。</li>
<li><strong>仿真到真实的迁移</strong>：未来的工作可以集中在将训练好的模型迁移到真实灵巧手上，并探索在更开放、多样化的任务和物体上的泛化能力。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出DexTOG，旨在解决灵巧手任务导向抓取的核心难题：在特定任务约束下，从高自由度空间寻找非唯一的最优抓取姿态。为应对任务理解、多模态抓取和高自由度搜索的挑战，论文提出了一个语言引导的扩散学习框架，其核心是扩散模型DexDiffu以及支持其训练的数据引擎。该方法在仿真实验中取得了77.1%的成功率，显著优于基线，尤其在工具使用等任务上表现出色，并构建了包含8万抓取样本的DexTOG-80K数据集。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2504.04573" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>