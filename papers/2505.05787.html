<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Demystifying Diffusion Policies: Action Memorization and Simple Lookup Table Alternatives - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Demystifying Diffusion Policies: Action Memorization and Simple Lookup Table Alternatives</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.05787" target="_blank" rel="noreferrer">2505.05787</a></span>
        <span>作者: He, Chengyang, Liu, Xu, Camps, Gadiel Sznaier, Sartoretti, Guillaume, Schwager, Mac</span>
        <span>日期: 2025/05/09</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在机器人模仿学习领域，扩散策略（Diffusion Policy）因其在复杂、高维操作任务中展现出的出色灵活性和鲁棒性而成为主流方法。该方法将视觉运动策略建模为去噪扩散概率模型，能够处理多模态动作分布并输出长时程动作序列。然而，其成功背后的原因一直是个谜。一个关键矛盾在于：扩散策略通常在50-200个演示（小数据集）上训练，却拥有与在数十亿图像上训练的生成模型相当的超大规模参数量（通常超过1亿），并且训练过程会持续到训练损失很低而测试损失很高——这是机器学习中经典的过拟合信号。在通常认知中，过拟合会导致糟糕的泛化性能，但扩散策略的这种过拟合似乎是其取得强大测试性能所必需的。</p>
<p>本文针对这一具体痛点，提出了一个令人惊讶的新视角：扩散策略本质上是在记忆一个动作查找表，并且这对机器人任务是有益的。作者认为，在数据稀疏的情况下，没有足够的数据密度让模型学习动作泛化。因此，扩散策略在运行时，会在潜在空间中找到测试图像最接近的训练图像，并回忆与之关联的训练动作序列，从而提供反应能力，而无需动作泛化。</p>
<p>本文的核心思路可概括为：1）通过系统的实证证据论证扩散策略通过记忆而非泛化来工作；2）基于此洞察，提出一个显式实现动作序列查找表的轻量级替代策略——动作查找表。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文首先对扩散策略的行为进行了深入分析，然后基于分析提出了新的动作查找表策略。</p>
<p><strong>扩散策略分析框架</strong>：作者通过一个简化的二维点分布学习实验，阐明了生成模型的四种泛化机制。关键发现是，当使用高容量模型（如扩散策略）在小数据集上训练时，模型倾向于记忆单个训练样本，而不是在它们之间进行泛化或插值。</p>
<p><img src="https://arxiv.org/html/2505.05787v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：在星形一维流形上均匀分布的2D点训练生成模型。橙色为训练样本，黑色为扩散随机种子，青色线显示去噪流方向，蓝色为最终推理结果。(c) 展示了扩散策略所在的机制：高容量模型在小数据集上训练时，会近似记忆数据集，而不进行泛化。所有推理结果（蓝色）覆盖在训练数据（橙色）点上，本质上实现了一个查找表。</p>
</blockquote>
<p>为了验证扩散策略是否隐式实现了动作查找表，作者设计了一系列杯子抓取实验。实验设置了分布内（InD）和分布外（OOD）等多种测试场景，包括插值、外推和引入视觉干扰物（甚至猫狗图片）。作者定义了一个“相似性分数”来衡量推理动作序列与训练序列的接近程度。分数为1表示完美复现训练轨迹，0.5表示在两个最近训练轨迹的中点插值。</p>
<p><strong>动作查找表策略整体框架</strong>：基于扩散策略实为查找表的假设，作者提出了动作查找表策略，旨在显式、高效地实现这一过程。ALT策略分为训练和推理两个阶段。</p>
<p><img src="https://arxiv.org/html/2505.05787v1/x4.png" alt="方法框架"></p>
<blockquote>
<p><strong>图5</strong>：ALT策略的对比学习训练阶段（黄色虚线以上）和推理阶段（以下）。推理过程分为两步：绿色箭头表示用训练好的模型构建ALT潜在空间和记忆库；蓝色箭头代表实时推理过程，即编码新观测并查找最近邻动作序列。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>输入与融合编码器</strong>：每个时间步的数据包括机器人手部相机图像、第三方视角相机图像和末端执行器姿态。作者设计了一个融合编码器，将这些多模态输入整合为一个统一的嵌入向量。图像编码使用预训练的ResNet-18作为骨干网络，以利用其在大规模数据上学到的通用视觉特征。</li>
<li><strong>对比学习训练</strong>：编码器通过对比学习进行训练。对每个样本应用两种不同的数据增强，生成两个增强视图，并输入融合编码器得到对应的嵌入。使用NT-Xent损失函数，鼓励同一样本的不同增强视图的嵌入在潜在空间中彼此接近，而不同样本的嵌入彼此远离。嵌入会进行L2归一化，以确保相似度计算的稳定性。</li>
<li><strong>构建记忆库与推理</strong>：训练完成后，将所有训练数据（观测和对应的未来动作序列）通过编码器映射到潜在空间，构建一个记忆库。在推理时，将新的观测输入编码器得到其嵌入，然后在潜在空间中查找与之欧氏距离最近的训练样本嵌入，并直接输出该训练样本关联的已记忆的动作序列。</li>
<li><strong>创新点</strong>：与扩散策略相比，ALT的创新在于<strong>显式化</strong>了查找过程。它用一次前向传播的最近邻搜索，替代了扩散策略耗时的迭代去噪步骤（通常需要几十步）。此外，通过设定潜在空间距离阈值，ALT可以天然地提供一个简单的OOD检测器，当运行时图像与所有训练图像距离过远时发出警告。</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准任务</strong>：自定义的杯子抓取机器人操作任务。</li>
<li><strong>数据集</strong>：30个专家演示，杯子位置在工作空间中均匀分布。</li>
<li><strong>对比方法</strong>：标准的扩散策略（作为主要比较对象）。</li>
<li><strong>评估指标</strong>：自定义的相似性分数（用于分析记忆行为）、任务成功率、推理时间、内存占用。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>扩散策略的记忆行为验证</strong>：在分布内测试中，扩散策略输出的动作序列与对应训练序列几乎完美重叠，相似性分数接近1.0。即使在引入OOD干扰物（包括猫狗图片）的极端情况下，扩散策略仍然输出与某个训练序列高度相似的行动，相似性分数依然接近1.0，而不是产生 erratic 行为或试图泛化。</li>
</ol>
<p><img src="https://arxiv.org/html/2505.05787v1/x3.png" alt="相似性分数"></p>
<blockquote>
<p><strong>图4</strong>：推理轨迹与训练轨迹之间的相似性分数（蓝色柱）和平均距离（橙色线）。最近邻与次近邻轨迹之间存在巨大差距，表明推理结果与特定训练示例强烈对齐，支持记忆假说。</p>
</blockquote>
<ol start="2">
<li><strong>ALT与扩散策略性能对比</strong>：在相同的抓取任务上，ALT策略达到了与扩散策略相当的成功率。</li>
</ol>
<p><img src="https://arxiv.org/html/2505.05787v1/extracted/6424164/figures/dp_analysis/exp.png" alt="性能对比"></p>
<blockquote>
<p><strong>图6</strong>：不同方法在杯子抓取任务上的性能对比。ALT（Ours）与扩散策略（Diffusion Policy）性能相当。</p>
</blockquote>
<ol start="3">
<li><strong>效率优势</strong>：ALT在推理速度和内存占用上具有巨大优势。其单次推理耗时仅为扩散策略的0.0034倍（快约300倍），内存占用仅为扩散策略的0.0085倍（小于1%）。</li>
</ol>
<p><img src="https://arxiv.org/html/2505.05787v1/x5.png" alt="效率对比"></p>
<blockquote>
<p><strong>图7</strong>：不同策略的推理延迟比较。ALT的推理速度远超扩散策略。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2505.05787v1/x6.png" alt="内存对比"></p>
<blockquote>
<p><strong>图8</strong>：不同策略的GPU内存占用比较。ALT的内存占用极低。</p>
</blockquote>
<p><strong>消融实验</strong>：论文通过二维流形学习的简化实验（图2）进行了概念上的消融，展示了模型容量和数据量对“记忆”与“泛化”行为的影响。在高容量、小数据（扩散策略机制）下，模型表现为记忆/查找表；只有当数据量足够大时，高容量模型才表现出真正的泛化。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>揭示了扩散策略的工作本质</strong>：通过严谨的实验分析，提出了有力证据表明在小数据机制下，扩散策略的强大性能并非源于动作空间的泛化，而是通过记忆训练动作序列并实现一个隐式的查找表。</li>
<li><strong>提出了高效轻量的替代方案</strong>：基于上述洞察，设计了动作查找表策略。该策略显式地实现了查找过程，在保持与扩散策略相当性能的同时，实现了数百倍的推理加速和两个数量级的内存节省，并内置了简单的OOD检测能力。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ul>
<li>论文自身提到，当演示数据集变得非常大且密集覆盖动作流形时，扩散策略可能会进入真正的泛化机制（如图2d所示）。但在当前机器人模仿学习的数据规模下，记忆机制占主导。</li>
<li>ALT策略的性能依赖于对比学习编码器构建的潜在空间质量。在训练数据极度稀疏或变化极大的动态任务中，其查找机制的适用性可能需要进一步验证。</li>
</ul>
<p><strong>对后续研究的启示</strong>：</p>
<ul>
<li><strong>重新思考小数据模仿学习</strong>：对于数据有限的机器人学习任务，“记忆”或“查找”可能是一种简单而有效的策略，而非需要避免的缺陷。这为设计高效策略提供了新思路。</li>
<li><strong>追求可解释性与效率</strong>：扩散策略虽然性能强大，但其计算成本高且工作原理不透明。ALT展示了通过构建更简单、可解释的模型来匹配复杂模型性能的可能性，特别是在资源受限的机器人平台上。</li>
<li><strong>重视数据分布与模型容量的匹配</strong>：研究强调了在评估策略时，理解其工作于“记忆机制”还是“泛化机制”的重要性。这取决于模型容量与训练数据量和分布之间的相对关系。</li>
</ul>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文揭示了扩散策略在机器人操作任务中表现出色的原因，并提出了一种高效替代方案。核心发现是：扩散策略本质上通过隐式记忆，在潜在空间查找与测试图像最接近的训练图像，并直接调用其关联的动作序列，而非学习动作泛化。基于此，作者提出轻量级的动作查找表（ALT）策略，使用对比图像编码器进行显式查找。实验表明，在小数据集上，ALT性能与扩散模型相当，但推理时间仅需0.0034倍，内存占用仅需0.0085倍，并能提供有效的分布外检测标志。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.05787" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>