<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Interactive Expressive Motion Generation Using Dynamic Movement Primitives - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Interactive Expressive Motion Generation Using Dynamic Movement Primitives</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2504.06735" target="_blank" rel="noreferrer">2504.06735</a></span>
        <span>作者: Hielscher, Till, Bulling, Andreas, Arras, Kai O.</span>
        <span>日期: 2025/04/09</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>目前，社交机器人要生成富有表现力的运动，方法多样，包括基于动画原则的手工调制、基于学习的成本函数或策略映射，以及近期利用生成式AI的方法。然而，现有方法存在关键局限性：手工调制方法（如为特定机器人设计动画序列）耗时且难以泛化；针对特定原则设计的数学模型缺乏统一性；而基于深度学习的方法则通常数据效率低、缺乏可解释性，且难以实现复杂的在线自适应行为。</p>
<p>本文针对机器人表现性运动生成缺乏一个<strong>可学习、可解释、可调制、在线可适应且可组合的统一模型</strong>这一痛点，提出了一个新颖的视角：利用机器人模仿学习中成熟的<strong>动态运动基元</strong>（DMPs）作为底层数学框架，来统一实现经典的“动画十二原则”中的关键部分。DMPs基于弹簧阻尼系统设计，其数学特性（如稳定性、目标导向性）使其天然适合此项任务。本文的核心思路是：<strong>通过DMPs学习一个参考运动轨迹，然后通过一组直观、低维的调制参数，对编码在DMPs中的各个动画原则进行独立或组合的强度调节，从而从单一基础模型生成多样且细腻的表现性运动。</strong></p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架如论文图1所示。输入包括从人类专家（如动作捕捉、动画师）或规划算法获得的<strong>演示轨迹</strong>，以及用户定义的<strong>调制参数</strong>（对应各个动画原则的强度）。输出是经过调制的、富有表现力的<strong>机器人运动轨迹</strong>。核心流程是：首先使用局部加权回归（LWR）从演示轨迹中学习标准DMP模型的权重；然后，根据调制参数，对DMP方程中的相应部分进行数学变换，生成最终运动。</p>
<p><img src="https://arxiv.org/html/2504.06735v2/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：方法整体框架。输入为演示轨迹（黑色虚线）和调制参数，输出为调制的表现性运动（红色和蓝色实线）。某些原则定义了主要和次要运动，分别用不透明和半透明关节表示。</p>
</blockquote>
<p>核心模块是对DMP基础方程的扩展，以实现对特定动画原则的调制。基础DMP方程（针对单个维度）为二阶非线性微分方程：<code>τ²ÿ = α(β(g - y) - τẏ) + f(x)</code>，其中<code>y</code>为位置，<code>g</code>为目标，<code>f(x)</code>为强迫项。多维度问题为每个维度分配独立的吸引子系统和强迫项，但共享相同的相位变量<code>x</code>。</p>
<p>本文在标准DMP基础上，编码并实现了八个动画原则（及一个交互目标调制）的数学调制方法，每个都对应一个调制参数<code>p</code>（见表I）：</p>
<ol>
<li>**弧线 (𝒫_Arc)**：通过使用高斯核<code>G(σ)</code>对DMP权重<code>w</code>进行卷积（<code>p_Arc &gt; 0</code>时平滑/宽弧）或非锐化掩模（<code>p_Arc &lt; 0</code>时锐化/窄弧）来调节轨迹的平滑度。</li>
<li>**预备动作 (𝒫_Ant)**：在运动开始时的一个短时间窗口<code>T_Ant</code>内，反转系统的加速度（<code>ÿ‘ = -p_Ant * ÿ</code>），以产生反向预备动作。仅应用于<code>N_Ant</code>个最重要的关节维度。</li>
<li>**慢入慢出 (𝒫_Slow)**：通过一个反S形相位调制函数<code>φ_Slow(n_t)</code>替换线性相位，使运动在开始和结束时变慢。</li>
<li>**时间控制 (𝒫_Time)**：包含两方面调制：一是通过缩放因子<code>p_Time</code>直接缩放总执行时间<code>τ</code>；二是通过自定义的相位函数<code>φ_Time(n_t)</code>实现沿轨迹的任意速度变化（如慢-&gt;快）。</li>
<li>**夸张 (𝒫_Exa)**：通过缩放因子<code>p_Exa</code>缩放强迫项<code>f</code>（<code>p_Exa &gt; 1</code>为夸大，<code>&lt; 1</code>为削弱，<code>= 0</code>则退化为无特征地向目标运动），以放大或削弱运动的关键特征。</li>
<li>**次要动作 (𝒫_Sec)**：将源关节（主要动作）的速度<code>ẏ_source</code>以比例<code>p_Sec</code>叠加到目标关节的位置上（<code>y_target‘ = y_target + δ p_Sec ẏ_source</code>），产生支持性动作。</li>
<li>**跟随动作 (𝒫_Follow)**：使从属身体部位（目标关节）的加速度<code>ÿ_target</code>受到主体部位（源关节）反向加速度的影响（<code>ÿ_target‘ = ÿ_target - δ p_Follow ÿ_source</code>），产生滞后和摆动效果。要求源和目标关节在同一运动链中且旋转轴对齐。</li>
<li>**随机化 (𝒫_Rand)**：向DMP权重<code>w</code>添加按权重平均值缩放的随机噪声<code>ϵ</code>，使重复运动更自然。</li>
<li>**交互目标 (𝒫_Goal)**：利用DMP固有的目标导向性，通过更新目标位置<code>g</code>（例如，根据视觉检测到的人或物体），实现在线实时调整运动方向，同时保持手势特征。</li>
</ol>
<p><img src="https://arxiv.org/html/2504.06735v2/x2.png" alt="相位调制"></p>
<blockquote>
<p><strong>图2</strong>：用于进度调制的相位调整。(a) <code>φ_Slow(n_t)</code> 实现慢入慢出；(b) <code>φ_Time(n_t)</code> 实现不同的速度变化模式（慢-&gt;快，快-&gt;慢）。虚线为学习时使用的线性相位。</p>
</blockquote>
<p>与现有方法相比，本文的创新点在于：<strong>首次提出了一个基于统一、物理可信的数学模型（DMPs）来自动化、参数化地实现动画原则的框架</strong>。它克服了手工调制的局限性，并相较于深度学习方案，具有数据效率高、可解释性强、天然支持在线适应和组合的优点。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验平台与数据集</strong>：实验在仿真环境和三个真实机器人平台上进行：Pepper（人形）、Daryl（移动机械臂）和Yellow（协作机械臂）。演示轨迹来源于3D人体姿态追踪、动画师绘制的运动曲线或规划算法。</p>
<p><strong>Baseline方法</strong>：实验主要进行自身方法的验证和消融，通过对比调制前后的运动，以及组合不同调制参数的效果，来证明方法的有效性。用户研究部分，将本方法生成的运动与未经调制的原始（中性）运动进行对比。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>概念验证（单维与高维）</strong>：图3展示了在一维演示轨迹上，应用各个独立动画原则调制的效果。图4展示了在3D笛卡尔空间（球面轨迹）上，<code>𝒫_Arc</code>、<code>𝒫_Exa</code>和<code>𝒫_Ant</code>等原则的调制依然保持其特性。</li>
</ol>
<p><img src="https://arxiv.org/html/2504.06735v2/x3.png" alt="单维调制"></p>
<blockquote>
<p><strong>图3</strong>：各动画原则在一维轨迹上的独立调制效果。虚线为演示轨迹。清晰展示了宽弧/窄弧(a)、预备动作(b)、整体时间缩放(c)、进度变化(d)、夸张(e)、次要动作(f)、跟随动作(g)和随机化(h)的效果。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.06735v2/x4.png" alt="高维调制"></p>
<blockquote>
<p><strong>图4</strong>：在3D空间轨迹上对选定原则的调制。(a) <code>𝒫_Arc</code> 调制轨迹弧线；(b) <code>𝒫_Exa</code> 和 <code>𝒫_Ant</code> 调制保持了一维时的特性。</p>
</blockquote>
<ol start="2">
<li><strong>多原则组合与机器人应用</strong>：图5展示了在Pepper机器人上，组合多个动画原则（<code>𝒫_Time</code>, <code>𝒫_Exa</code>, <code>𝒫_Ant</code>, <code>𝒫_Sec</code>）生成复杂、富有表现力的“指向”和“挥手”动作。</li>
</ol>
<p><img src="https://arxiv.org/html/2504.06735v2/x5.png" alt="Pepper组合调制"></p>
<blockquote>
<p><strong>图5</strong>：在Pepper机器人上组合多个动画原则（<code>𝒫_Time</code>, <code>𝒫_Exa</code>, <code>𝒫_Ant</code>, <code>𝒫_Sec</code>）生成表现性动作（指向和挥手）。</p>
</blockquote>
<ol start="3">
<li><strong>用户研究</strong>：一项有30名参与者的用户研究评估了本方法。参与者观看了由本方法生成的调制运动与原始中性运动的视频（Pepper和Daryl机器人），并从自然度、表现力、愉悦度等维度进行评分。</li>
</ol>
<p><img src="https://arxiv.org/html/2504.06735v2/x6.png" alt="用户评分"></p>
<blockquote>
<p><strong>图6</strong>：用户研究评分结果（5分制）。调制后的运动在所有维度（自然、表现力、愉悦、不怪异）上均显著优于原始中性运动，平均提升21.7%至42.8%。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.06735v2/x7.png" alt="用户反馈词云"></p>
<blockquote>
<p><strong>图7</strong>：用户对调制运动的定性反馈词云。“自然”、“流畅”、“像人”是高频正面词汇。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.06735v2/x8.png" alt="评分分布"></p>
<blockquote>
<p><strong>图8</strong>：各评分维度的详细分布。调制运动（橙色）的评分明显向高分端集中。</p>
</blockquote>
<ol start="4">
<li><strong>消融与参数分析</strong>：图9展示了在Pepper机器人上，仅改变单个调制参数（如<code>p_Exa</code>）或组合多个参数，可以连续地产生一系列具有不同表现力的运动。图10展示了同一组调制参数可以应用于不同运动学结构的机器人（Pepper, Daryl, Yellow），生成具有相似表现力特征的运动，证明了方法的跨平台泛化能力。</li>
</ol>
<p><img src="https://arxiv.org/html/2504.06735v2/x9.png" alt="参数变化"></p>
<blockquote>
<p><strong>图9</strong>：通过连续改变单个（如<code>p_Exa</code>）或组合调制参数，可以从一个基础“挥手”演示生成一系列表现力不同的运动。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.06735v2/x10.png" alt="跨机器人泛化"></p>
<blockquote>
<p><strong>图10</strong>：同一组调制参数（<code>𝒫_Time</code>, <code>𝒫_Exa</code>, <code>𝒫_Ant</code>, <code>𝒫_Sec</code>）应用于三个不同机器人，产生具有一致表现力特征的运动。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>统一框架</strong>：首次将动态运动基元（DMPs）作为统一数学模型引入，用于实现和调制动画原则，为机器人表现性运动生成提供了一个可学习、可解释、可在线调制的解决方案。</li>
<li><strong>参数化与组合性</strong>：定义了一组直观、低维的调制参数，对应关键的动画原则。这些参数可以独立或组合调整，使得从单一基础模型生成多样且细腻的表达成为可能。</li>
<li><strong>实验验证</strong>：通过仿真、在三种不同运动学结构的真实机器人上的演示，以及用户研究，全面验证了该框架在生成有效、自然且被用户喜爱的表现性运动方面的能力。</li>
</ol>
<p><strong>局限性</strong>：论文提到，某些原则（如次要动作<code>𝒫_Sec</code>和跟随动作<code>𝒫_Follow</code>）的实现依赖于对机器人运动学结构的了解，需要手动或通过规则指定关节间的源-目标关系及逆关系。此外，相位调制函数（如<code>φ_Time</code>）的设计可能需要基于特定需求进行定制。</p>
<p><strong>对后续研究的启示</strong>：本工作为基于物理模型的、可解释的表现性运动生成开辟了新路径。未来研究可以探索自动推断关节间调制关系的方法，将调制参数与更高层的语义（如情感、意图）进行关联，或将该框架与基于学习的感知模块更紧密地结合，实现完全自主的、上下文感知的表现性交互。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文旨在解决社交机器人如何生成富有表现力的运动以增强人机交互的问题。提出基于动态运动基元（DMPs）实现动画十二原则的新方法，通过弹簧阻尼系统设计支持参数化调制与运动分解。在三种机器人平台上的实验表明，该方法能用单一基础模型生成多样且细腻的表达。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2504.06735" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>