<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2511.05996" target="_blank" rel="noreferrer">2511.05996</a></span>
        <span>作者: Jun Liu Team</span>
        <span>日期: 2025-11-08</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>类别级6D物体姿态估计旨在为已知类别中未见过的物体实例预测其3D旋转、平移和尺度，而铰接物体（如柜门、抽屉）的位姿跟踪则更具挑战性，因其存在固有的运动学约束。现有方法主要面临两大关键局限性：一是<strong>姿态无效性与奇异性</strong>，许多方法在欧几里得空间中优化SE(3)相关参数（如欧拉角），可能导致违反正交性约束的无效旋转矩阵，且欧拉角存在万向节锁问题，四元数存在符号歧义；二是<strong>跟踪方法的效率与鲁棒性</strong>，传统方法通常依赖逐帧的密集预测或位姿更新，计算成本高，难以适用于实时点云流，且忽略了帧间运动的连续性。</p>
<p>本文针对上述痛点，提出了在SE(3)李群流形上进行类别级铰接物体位姿跟踪的新视角。核心思路是：提出一个基于点对特征的跟踪框架（PPF-Tracker），首先在SE(3)空间对点云进行准规范化，然后利用SE(3)不变性，通过加权点对特征预测位姿投票参数，最后结合关节轴的语义信息，对所有部件施加统一的运动学约束，以实现高效、鲁棒的连续跟踪。</p>
<h2 id="方法详解">方法详解</h2>
<p>PPF-Tracker的整体框架将跟踪任务建模为帧间位姿增量估计问题。给定初始位姿和点云序列，框架通过三个核心阶段输出每一帧每个部件的6D位姿与尺度：1) <strong>准规范化</strong>，利用时间先验将点云变换到准规范空间；2) <strong>基于SE(3)不变性的增量学习</strong>，通过加权点对特征预测SE(3)不变参数，并投票得到李代数增量；3) <strong>基于运动学约束的优化</strong>，对初步预测的部件位姿施加关节约束进行细化。</p>
<p><img src="https://arxiv.org/html/2511.05996v1/pipeline.png" alt="方法框架总览"></p>
<blockquote>
<p><strong>图2</strong>：PPF-Tracker方法整体框架。输入为点云序列和初始位姿。流程主要包括：准规范化（将当前帧点云变换到以关键帧为参考的准规范空间）、加权点对特征提取与SE(3)不变参数预测、李代数增量投票与累积、以及基于运动学约束的位姿优化。最终输出优化后的每部件6D位姿。</p>
</blockquote>
<p><strong>核心模块一：准规范化 (Quasi-Canonicalization)</strong><br>为利用连续帧的时间先验并减少累积误差，该方法将点云序列划分为以关键帧为边界的时间片段。对于第 <code>i</code> 个片段，将其第一帧（关键帧）的位姿逆变换 <code>𝒦_i^k = (T_n^k)^{-1}</code> 应用于该片段内所有帧的点云，此过程称为准规范化。变换后的准规范点云 <code>𝒫_bar_t^k</code> 用于预测相对于该关键帧的相对变换 <code>ΔT_t^k</code>。论文进一步提出了<strong>动态关键帧选择策略</strong>：通过计算预测点云与观测点云之间的倒角距离和豪斯多夫距离，定义一个能量函数 <code>𝔈_t</code>。当能量值低于阈值 <code>φ=0.01</code> 时，认为当前帧可靠，将其更新为下一个时间片段的关键帧，从而灵活应对跟踪过程中的误差累积。</p>
<p><img src="https://arxiv.org/html/2511.05996v1/x1.png" alt="时间片段与动态关键帧示意图"></p>
<blockquote>
<p><strong>图3</strong>：时间片段与动态关键帧示意图。序列被划分为多个时间片段，每个片段以关键帧开始。<code>[i]=n</code> 表示第 <code>i</code> 个关键帧对应原始序列的第 <code>n</code> 帧。当某帧的能量 <code>𝔈_t</code> 低于阈值时，它将被选为下一个片段的关键帧。</p>
</blockquote>
<p><strong>核心模块二：基于SE(3)不变性的增量学习</strong><br>该方法不直接回归位姿变换 <code>ΔT_t^k</code>，而是通过投票预测其在李代数空间中的增量 <code>Δξ_t^k ∈ 𝔰𝔢(3)</code>，再利用指数映射得到 <code>ΔT_t^k</code>，这保证了旋转矩阵的正交性。</p>
<ol>
<li><strong>加权点对特征（PPF）与参数预测</strong>：从观测点云中均匀采样N个点对 <code>(p_i, p_j)</code>。传统PPF对所有点对赋予相同权重，而本文提出<strong>加权PPF</strong>，根据点对法向量夹角 <code>θ_ij</code> 计算权重 <code>v_ij = 1 - λ|cos θ_ij|</code>（<code>λ=0.5</code>），对法向量接近平行（夹角约0°或180°）的点对赋予较低权重，对接近垂直（夹角约90°）的点对赋予较高权重，以更好区分三维特征。使用PointNet++处理点对的SE(3)不变特征 <code>ℱ_ij</code>，预测每部件的SE(3)不变参数 <code>(μ_t^k, ν_t^k, α_t^k, β_t^k, γ_t^k)</code>，其中 <code>(μ, ν)</code> 与平移相关，<code>(α, β)</code> 与旋转相关，<code>γ</code> 与尺度相关。</li>
</ol>
<p><img src="https://arxiv.org/html/2511.05996v1/weighted_ppf.png" alt="传统与加权的点对示意图"></p>
<blockquote>
<p><strong>图5</strong>：传统点对（a）与加权点对（b）示意图。加权策略根据点对法线夹角分配不同重要性，夹角接近90°的点对（红色）权重更高。</p>
</blockquote>
<ol start="2">
<li><strong>李代数变换与投票</strong>：将预测的SE(3)不变参数通过投票机制转换为李代数增量 <code>Δξ_t^k</code>。如图6所示，平移参数 <code>(μ, ν)</code> 定义了部件中心可能位于的圆，旋转参数通过圆锥曲线和斐波那契球上的投票来确定方向。最终，通过累加李代数增量得到当前帧的位姿李代数表示：<code>ξ_t^k = Σ_i Δξ_[i]^k + ξ_0^k</code>，再通过指数映射 <code>T_t^k = exp(ξ_t^k)</code> 得到SE(3)位姿。</li>
</ol>
<p><img src="https://arxiv.org/html/2511.05996v1/voting.png" alt="投票方案示意图"></p>
<blockquote>
<p><strong>图6</strong>：投票方案示意图。（a）平移投票：部件中心被约束在由参数 <code>(μ, ν)</code> 定义的圆上。（b）旋转投票：使用具有均匀分布容器的斐波那契球进行投票累积。</p>
</blockquote>
<p><strong>核心模块三：基于运动学约束的优化</strong><br>由于上述框架将每个部件视为独立刚体，可能导致运动学链上的不连续。因此，该方法引入一个综合能量函数对初步预测的位姿 <code>T_hat_t^k</code> 进行优化。</p>
<ul>
<li>**几何对齐项 <code>𝔈_geo</code>**：最小化观测点云（经预测位姿逆变换后）与规范点云之间的差异。</li>
<li>**运动学项 <code>𝔈_kin</code>**：对于连接两个部件的第 <code>j</code> 个关节轴点 <code>q^j</code>，强制要求两个部件变换后的轴点位置一致，以此施加关节约束。<br>综合能量函数为 <code>𝔈_comp = 𝔈_geo + 𝔈_kin</code>，通过优化该函数得到物理上更一致、更准确的最终位姿 <code>(T_hat_t^k)_optim</code>。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>数据集</strong>：在三个数据集上评估：基于PartNet-Mobility重建的合成数据集 <strong>PM-Videos</strong>、基于ReArt-48的半合成数据集 <strong>ReArt-Videos</strong>、以及真实世界场景数据集 <strong>RobotArm-Videos</strong>。</li>
<li><strong>对比方法</strong>：与类别级/铰接物体姿态估计的先进方法对比，包括 <strong>A-NCSH</strong>、<strong>CAPTRA</strong>、<strong>ContactArt</strong> 和 <strong>GAPS</strong>。</li>
<li><strong>评估指标</strong>：旋转误差（度）、平移误差（毫米）、3D IoU（%）和每帧推理时间（秒）。</li>
</ul>
<p><strong>关键定量结果</strong>：<br>在PM-Videos数据集上的综合对比结果如下表所示。PPF-Tracker在大多数类别和部件上取得了最低的旋转和平移误差，同时保持了较短的推理时间（例如，笔记本电脑部件平均0.07秒/帧），展现了精度与效率的平衡。</p>
<p><img src="https://arxiv.org/html/2511.05996v1/artimage.png" alt="PM-Videos数据集上的定量结果对比"></p>
<blockquote>
<p><strong>表1</strong>：在PM-Videos数据集上与SOTA方法的对比。PPF-Tracker（Ours）在多数情况下取得了最低的旋转误差（Rotation Error）和平移误差（Translation Error），推理时间（Inference Time）也具有竞争力。加粗数据表示最优结果。</p>
</blockquote>
<p><strong>定性结果</strong>：<br><img src="https://arxiv.org/html/2511.05996v1/ReArtMix-Franka_short.png" alt="PM-Videos数据集上的定性跟踪结果"></p>
<blockquote>
<p><strong>图7</strong>：在PM-Videos数据集上的定性跟踪结果可视化。展示了PPF-Tracker对不同铰接物体（如眼镜、剪刀）在多帧序列中的位姿跟踪效果，预测位姿（彩色）与真实位姿（灰色）吻合度高。</p>
</blockquote>
<p><strong>消融实验</strong>：<br>论文通过消融实验验证了两个核心组件的贡献：</p>
<ol>
<li><strong>运动学约束</strong>：移除运动学约束优化模块后，旋转误差平均增加约5.5°，平移误差平均增加约0.074 mm，证明了该约束对于保证部件间运动一致性的必要性。</li>
<li><strong>关键帧策略</strong>：对比了无关键帧、固定关键帧和动态关键帧（DKS）三种策略。实验表明，无关键帧时累积误差最大；固定关键帧能缓解但效果有限；动态关键帧策略性能最佳，能自适应地选择可靠帧作为参考，有效抑制了长期跟踪的误差漂移。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个在SE(3)流形上进行类别级铰接物体位姿跟踪的新框架PPF-Tracker，通过准规范化和李代数增量预测，解决了传统方法中的姿态无效性、奇异性及累积误差问题。</li>
<li>设计了加权点对特征算法来预测SE(3)不变参数，并引入了基于关节轴的部件级优化，以尊重铰接物体的运动学约束，提升了跟踪的准确性与一致性。</li>
<li>在合成、半合成及真实世界数据集上进行了广泛实验，验证了该方法在精度、效率和泛化能力上的优越性。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到，最初的固定关键帧策略缺乏灵活性，可能导致不准确性，因此后续改进为动态关键帧选择策略。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>动态策略的泛化</strong>：动态关键帧选择策略的成功表明，自适应机制对于长序列跟踪至关重要，可启发后续研究设计更高效、更鲁棒的关键帧或参考帧更新准则。</li>
<li><strong>运动学建模的扩展</strong>：当前方法主要针对旋转关节（轴约束）。未来工作可探索如何将类似的运动学约束优化模块扩展到更复杂的关节类型（如棱柱关节、球关节）。</li>
<li><strong>多模态融合</strong>：PPF-Tracker主要处理点云输入。结合RGB图像的语义和纹理信息，可能进一步提升在遮挡、光照变化等复杂真实场景下的跟踪鲁棒性。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对类别级关节物体在动态环境中的6-DoF姿态跟踪难题，提出PPF-Tracker框架。核心方法包括：在SE(3)李群空间对点云进行准规范化，利用点对特征（PPF）的SE(3)不变性预测姿态参数，并结合关节轴语义信息施加统一运动学约束。该框架在合成与真实场景数据上系统评估，展现了强大的泛化能力与鲁棒性，有效支持连续、稳定的多帧姿态跟踪。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2511.05996" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>