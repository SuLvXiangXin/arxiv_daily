<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Imagine, Verify, Execute: Memory-guided Agentic Exploration with Vision-Language Models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Imagine, Verify, Execute: Memory-guided Agentic Exploration with Vision-Language Models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.07815" target="_blank" rel="noreferrer">2505.07815</a></span>
        <span>作者: Lee, Seungjae, Ekpo, Daniel, Liu, Haowen, Huang, Furong, Shrivastava, Abhinav, Huang, Jia-Bin</span>
        <span>日期: 2025/05/12</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在通用机器人学习中，探索能力至关重要，尤其是在开放环境中，密集奖励、明确目标或任务监督都稀缺。强化学习（RL）是当前主流方法，通常使用内在奖励或目标采样来鼓励探索。然而，这些方法在高维、语义丰富的真实世界机器人场景中面临挑战：它们缺乏语义理解，可能导致行为随机、低效甚至危险。视觉语言模型（VLM）因其丰富的语义知识和推理能力，为引导探索提供了新视角，但其生成的想象往往缺乏物理动态的“落地”基础，可能产生物理上不可行、冗余或不安全的转移，且缺乏对过往交互的结构化记忆，导致探索效率低下。</p>
<p>本文针对VLM想象缺乏物理基础与记忆引导的关键痛点，提出了IVE（Imagine, Verify, Execute）框架。其核心思路是：模仿人类好奇心驱动的探索过程，利用VLM进行语义想象，同时引入基于经验的验证模块和记忆模块，对想象的场景转移进行物理可行性过滤和新颖性引导，最终通过动作工具执行，从而生成多样、有意义且物理上可行的探索数据。</p>
<h2 id="方法详解">方法详解</h2>
<p>IVE是一个完全自动化的、VLM驱动的智能体探索系统，其整体框架包含三个核心模块（场景描述器、探索器、验证器）和两个辅助模块（记忆、动作工具）。流程始于当前观察，依次经过场景描述、想象、验证、执行，并将结果存入记忆，形成闭环。</p>
<p><img src="https://cdn.mathpix.com/cropped/2025_09_11_3d6c9c3b2e5a1d8b7c67g-1.jpg?height=1276&width=1874&top_left_y=362&top_left_x=254" alt="方法框架"></p>
<blockquote>
<p><strong>图3</strong>：IVE系统概述。给定观察 <code>o_t</code>，场景描述器构建语义场景图 <code>G_t</code>。探索器利用此表示、当前观察和检索到的历史场景图，生成（“想象”）一个候选的未来场景图 <code>Ĝ_{t+1}</code> 和一个技能序列 <code>μ_{t}^{1:N}</code>。验证器利用最近的交互历史评估这些想象转移的可行性。如果通过验证，技能通过动作工具实例化为低级动作并由机器人执行；否则，探索器接收反馈并重新规划。</p>
</blockquote>
<p><strong>核心模块详解</strong>：</p>
<ol>
<li><strong>场景描述器</strong>：作为系统前端，该VLM模块将原始RGB观察 <code>o_t</code> 抽象为结构化的场景图 <code>G_t = (V, E)</code>，其中 <code>V</code> 是对象（节点）集合，<code>E</code> 是对象间有向、类型化的语义关系（边，如“堆叠在...上”、“靠近”）。这种符号化表示降低了原始感官数据的推理复杂度。</li>
<li><strong>探索器</strong>：这是一个VLM组件，输入包括当前观察 <code>o_t</code>、对应场景图 <code>G_t</code> 以及从记忆中检索的相关历史经验。其核心作用是“想象”：生成一个未来场景图 <code>Ĝ_{t+1}</code>，该图保留 <code>G_t</code> 的对象集但改变其边结构（代表新的空间或功能关系）。同时，它生成一个实现该转移的高层技能序列 <code>μ_{t}^{1:N}</code>（如 <code>move(红杯， 堆叠在， 托盘)</code>）。为了促进新颖性，探索器会将 <code>Ĝ_{t+1}</code> 与记忆中的场景图进行比较，鼓励多样且未见过的转移。</li>
<li><strong>验证器</strong>：该模块负责监督探索器提出的技能序列，评估想象转移的合理性、物理可行性和稳定性。与探索器不同，验证器会考虑一个更广的时间窗口，访问最近的 <code>h</code> 个转移 <code>{G_{t-h}, μ_{t-h}^{1:N}, ..., G_{t-1}, μ_{t-1}^{1:N}}</code> 作为经验先验。它预测执行可能的结果，并与目标图进行比较，同时进行稳定性检查（如检测不稳定的物体放置、遮挡）。验证器输出一个结构化的反馈信号 <code>f_t</code>，包含二进制决策（“是”/“否”）以及拒绝原因（如不可行、不稳定）。</li>
<li><strong>记忆</strong>：动态存储先前遇到的所有场景图 <code>G</code>。在每一步，探索器和验证器都可以查询记忆。探索器使用基于图编辑距离的检索（公式1：<code>{G_j ∈ M | dist(G_t, G_j) &lt; τ}</code>）来获取与当前场景图结构相似的过去场景图，以此引导新颖（非冗余）的想象。验证器则利用记忆中的历史转移作为可行性评估的经验依据。</li>
<li><strong>动作工具</strong>：将探索器生成的高层技能序列 <code>μ_{t}^{1:N}</code> 转换为机器人可执行的低级动作序列 <code>A_{t}^{1:N}</code>。每个技能被实例化为与机器人本体和操作约束对齐的预定义任务原语（例如，基于关系的放置、基于区域的放置、整理器）。</li>
</ol>
<p><strong>创新点</strong>：与现有方法相比，IVE的创新在于将VLM的语义想象能力与基于经验的物理验证、以及记忆引导的新颖性搜索紧密结合。它并非直接执行VLM的想象输出，而是通过验证器进行“物理接地”过滤，并通过记忆避免重复探索，从而实现了既语义丰富又物理可行的、类似于人类好奇心的结构化探索。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>Benchmark/数据集</strong>：模拟环境使用VimaBench桌面环境；真实世界环境使用UR5e机械臂与桌面物体。</li>
<li><strong>Baseline方法</strong>：<ul>
<li><strong>RL基线</strong>：SAC结合内在奖励方法RND和RE3。</li>
<li><strong>人类基线</strong>：专家（有明确目标）、新手（自由交互）、手动移动物体。</li>
</ul>
</li>
<li><strong>评估指标</strong>：探索多样性（访问的唯一场景图数量、状态熵）、下游任务性能（行为克隆任务成功率、世界模型预测精度）。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>探索多样性显著优于RL基线</strong>：如图5所示，IVE在访问的状态熵上比RL基线提高了4.1到7.8倍，并且达到了专家人类所展现的场景多样性的82%到122%。论文分析RL方法在像素级新颖性与语义有意义交互之间的差距是其表现不佳的原因。</li>
</ol>
<p><img src="https://cdn.mathpix.com/cropped/2025_09_11_3d6c9c3b2e5a1d8b7c67g-2.jpg?height=862&width=1874&top_left_y=1764&top_left_x=254" alt="探索能力评估"></p>
<blockquote>
<p><strong>图5</strong>：在模拟和真实世界环境中的探索能力评估。上图展示了访问的唯一场景图数量的增长曲线，下图展示了以熵衡量的访问状态多样性。IVE在多样性和探索效率上均显著优于RL基线，并与人类专家表现相当。</p>
</blockquote>
<ol start="2">
<li><strong>消融实验揭示各组件关键作用</strong>：如图6所示，移除关键模块会导致性能下降。<ul>
<li><strong>移除记忆</strong>：导致发现的唯一场景数减少22%，熵和信息增益降低，凸显了记忆对于新颖性感知规划的重要性。</li>
<li><strong>移除探索器（改用基于规则的探索器）</strong>：导致唯一场景数减少27%。</li>
<li><strong>移除验证器</strong>：性能也出现下降，但赋能度保持相对稳定，可能是因为验证器提议的整理动作更少，而这类动作本身更具随机性。</li>
<li><strong>随机动作工具选择器</strong>：表现最差，发现的唯一场景图数量不到IVE的一半。</li>
</ul>
</li>
</ol>
<p><img src="https://cdn.mathpix.com/cropped/2025_09_11_3d6c9c3b2e5a1d8b7c67g-3.jpg?height=862&width=1874&top_left_y=2638&top_left_x=254" alt="消融研究"></p>
<blockquote>
<p><strong>图6</strong>：IVE的消融研究。（上图）每个变体的示意图，灰色部分表示被移除的模块。（下图）通过访问的唯一场景图数量、熵、赋能度和信息增益衡量探索性能。结果显示记忆、探索器和验证器都是有效探索的关键组件。</p>
</blockquote>
<ol start="3">
<li><strong>下游任务性能优异</strong>：<ul>
<li><strong>行为克隆</strong>：如表1所示，使用IVE收集的数据训练的策略，在任务成功率上比使用RL探索数据训练的策略高出最多+58%，并且达到了与人类演示数据相当的性能水平。</li>
<li><strong>世界模型学习</strong>：如表2所示，使用IVE数据训练的世界模型（DINO-WM）在预测准确性（SSIM和LPIPS指标）上，其表现最接近使用人类收集数据训练出的模型，优于RL基线。</li>
</ul>
</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>提出好奇心驱动的探索框架IVE</strong>：通过结合记忆引导的想象与物理合理性预测，在具身智能体中模拟了类人的好奇心，显著提升了探索的语义多样性和物理可行性。</li>
<li><strong>实现了基于VLM的无奖励数据收集</strong>：开发了一个完全自动化的系统，无需外部奖励、演示或预定义目标，即可生成语义丰富的交互数据，其场景多样性接近人类专家水平。</li>
<li><strong>验证了下游任务的有效性</strong>：通过大量实验证明，IVE收集的经验数据能够有效支持下游策略学习和世界模型训练，性能匹配或超越基于人类演示数据训练的模型。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ol>
<li><strong>VLM推理延迟</strong>：VLM-based reasoning引入了一些延迟，可通过使用更轻量化的模型来缓解。</li>
<li><strong>动作工具依赖手动定义</strong>：限制了复杂任务的可扩展性，未来可集成学习到的策略作为工具。</li>
<li><strong>依赖开放词汇检测</strong>：在物体被遮挡或全新时可能导致失败，未来可通过融入多视角感知或交互式发现来提高鲁棒性。</li>
</ol>
<p><strong>对后续研究的启示</strong>：<br>IVE展示了将VLM的强语义推理与具身系统的物理约束、历史记忆相结合，是实现高效、安全、有意义机器人探索的有效途径。其“想象-验证-执行”的循环范式为构建更通用的自主探索智能体提供了新思路，后续工作可专注于扩展动作工具库、集成学习到的技能、以及提升在动态和部分可观测环境中的鲁棒性。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对开放环境中机器人探索时视觉语言模型（VLM）输出不接地气、难以判断想象的状态转换是否物理可行的问题，提出了IVE框架。该框架受人类好奇心启发，通过VLM将RGB-D观察抽象成语义场景图，依次执行“想象”新场景、“验证”其物理可行性、“执行”生成技能序列三个步骤。实验表明，IVE在模拟和真实桌面环境中比强化学习基线实现了更丰富多样的探索，访问状态的熵提升4.1至7.8倍，且其收集的经验能有效支持下游策略学习，性能接近或优于基于人类演示训练的策略。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.07815" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>