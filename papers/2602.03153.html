<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>When Attention Betrays: Erasing Backdoor Attacks in Robotic Policies by Reconstructing Visual Tokens - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>When Attention Betrays: Erasing Backdoor Attacks in Robotic Policies by Reconstructing Visual Tokens</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.03153" target="_blank" rel="noreferrer">2602.03153</a></span>
        <span>作者: Li, Xuetao, Fu, Pinhan, Huang, Wenke, Pan, Nengyuan, Yang, Songhua, Zhao, Kaiyan, Wan, Guancheng, Li, Mengde, Xuan, Jifeng, Li, Miao</span>
        <span>日期: 2026/02/03</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作（VLA）模型通过下游微调来增强机器人能力，但这一过程使其面临后门攻击风险。攻击者可以在预训练数据中下毒，植入隐秘的后门，该后门在推理时一旦被触发，即可诱导机器人执行有害行为。现有的防御方法主要分为两类：数据中心的防御（如分析特征签名或聚类）和模型中心的防御（如剪枝可疑神经元或注入噪声）。然而，这些方法要么缺乏对多模态后门内部机制的理解，要么因需要全模型重新训练而计算成本过高，对于拥有数十亿参数的VLA模型而言不切实际。</p>
<p>本文针对上述两个关键痛点：1) 高攻击成功率且对清洁性能影响小的后门机制是什么？2) 如何在不重新训练VLA模型的情况下设计测试时防御？论文提出了新的视角：通过分析模型内部表征，发现了一种“深层注意力抢夺”现象，即后门在深层网络中将模型的注意力从任务相关物体重定向到触发器区域，且触发器的嵌入会形成一个紧致簇，紧邻清洁特征流形，从而增强了隐蔽性。</p>
<p>本文的核心思路是：基于上述洞察，提出一个名为Bera的测试时后门擦除框架，该框架通过潜在空间定位检测具有异常注意力的图像令牌，利用深层注意力线索屏蔽可疑区域，并重建一个无触发器的图像，从而在不重新训练模型的情况下破坏触发器与不安全动作之间的映射。</p>
<h2 id="方法详解">方法详解</h2>
<p>Bera是一个即插即用的测试时防御框架，其整体流程分为三个核心步骤：1) 基于特征的后门定位；2) 基于注意力的过滤；3) 无触发器图像重建。输入是可能包含触发器的观测图像和指令，输出是经过“净化”的图像，该图像随后被送入机器人策略以产生安全动作。</p>
<p><img src="https://arxiv.org/html/2602.03153v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：Bera工作流程。步骤❶：通过对比测试时嵌入与清洁参考流形，定位异常图像令牌。步骤❷：利用多层注意力信息修剪误检，过滤出与触发器相关的区域。步骤❸：通过局部掩码策略和擦除解码器重建无触发器的视图。</p>
</blockquote>
<p><strong>1. 特征引导的后门定位</strong>：该方法首先利用下游成功任务片段中的清洁数据构建一个参考特征分布。具体地，从最终层视觉令牌中估计一个多元高斯分布的均值μ和协方差矩阵Σ（经岭正则化稳定），并定义一个马氏距离接受区域A。对于测试输入的每个令牌嵌入bj，计算其马氏距离分数sj = (bj - μ)⊤ Σ⁻¹ (bj - μ)。将分数超过阈值τα的令牌标记为异常，形成初始的异常令牌集合ℐ_anom。这些令牌索引直接对应图像中的区域，从而实现了与触发器身份无关的定位。</p>
<p><strong>2. 注意力驱动的过滤机制</strong>：为了提升定位精度并过滤掉与运动学无关的异常（如动态背景），该方法进一步分析深层注意力图。对于从中间层到最终层的每一层l，计算跨注意力头的平均注意力图，并导出图像令牌的显著度向量v(l)。然后，使用高斯混合模型（GMM，K=6，与机器人手臂自由度匹配）对显著度进行聚类，选择平均显著度最高的簇作为该层的触发器候选集ℐ_filter(l)。最终，跨层的过滤器候选集取并集，并与特征定位得到的异常集取交集，得到最终的后门令牌集合：ℐ_backdoor = ℐ_anom ∩ ℐ_filter。这确保了检测结果在物理上的合理性。</p>
<p><strong>3. 无触发器图像重建</strong>：受掩码自编码器（MAE）启发，该方法训练一个轻量级解码器来重建图像。在训练阶段，随机选择5%至25%的令牌作为“中毒令牌”进行掩码，并训练解码器根据全局嵌入和剩余可见令牌的嵌入来重建完整图像。在推理阶段，使用前两步定位出的ℐ_backdoor集合构造一个针对触发器的选择性掩码M_backdoor，而非随机掩码。然后，解码器利用原始图像的全局嵌入和被掩码后的局部嵌入，重建出“净化”后的图像x̃。这一过程利用图像的全局结构线索来恢复被掩码区域，从而消除了触发器，同时保留了任务关键特征。</p>
<p>与现有方法（如DeDe的随机掩码）相比，Bera的创新点在于：1) <strong>机制驱动的检测</strong>：首次利用“深层注意力抢夺”和嵌入空间聚类现象进行定位；2) <strong>精准的局部干预</strong>：结合统计特征异常和注意力模式过滤，实现高精度触发器区域定位，再进行针对性图像重建，最大程度减少对语义内容的破坏。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：研究在真实机器人平台上进行了评估，包括一个桌面机器人、两个人形机器人和一个UR5机械臂。使用了包含1600个演示的真实世界数据集，涵盖四个操纵任务：抓取芬达罐、抬起立方体、抽取纸巾和握手。后门触发器为红色瓶盖、圆形块和棋盘格图像，以30%的中毒率注入，目标动作为危险配置（如碰撞）。评测基于两个代表性的VLA骨干网络：OpenVLA和DexGraspVLA。</p>
<p><strong>对比方法</strong>：对比了六种基线方法：无防御、ZIP（零样本扩散净化）、UNICORN（触发器反演）、BTI-DBF(P)（解耦良性表征）、SampDetox（随机腐蚀与去噪）、SparseVLM（令牌稀疏化）以及DeDe（随机掩码重建）。</p>
<p><img src="https://arxiv.org/html/2602.03153v1/x5.png" alt="实验结果表"></p>
<blockquote>
<p><strong>表I</strong>：Bera与先前防御方法的对比。报告了清洁性能（CP）、攻击成功率（ASR）和权衡性能（TP）。Bera在显著降低ASR（最低至3.33%）的同时，保持了高CP，从而获得了最高的TP分数（普遍超过80%），综合性能显著优于所有基线。</p>
</blockquote>
<p><strong>关键实验结果</strong>：如表I所示，在OpenVLA和DexGraspVLA上，Bera均能极大幅度降低攻击成功率（ASR）。例如在OpenVLA的握手任务中，ASR从无防御的90%降至6.67%。同时，Bera的清洁性能（CP）下降很小，与无防御模型相当（多数在70%-90%）。这使得其权衡性能（TP）在所有任务和模型上都达到最高，显著优于其他防御方法。这证明了Bera能有效消除后门，同时保持正常的机器人交互性能。</p>
<p><strong>消融实验</strong>：<br><img src="https://arxiv.org/html/2602.03153v1/x6.png" alt="消融实验"></p>
<blockquote>
<p><strong>表II</strong>：Bera模块消融研究。分别移除特征引导定位（FBL）、注意力过滤机制（AFM）或解码器，评估恢复性能（RP）。三者结合时性能最佳，平均RP达87.51%，证明了每个模块的必要性和协同作用。</p>
</blockquote>
<p>消融实验（表II）验证了各模块的贡献：单独使用FBL（无AFM过滤）会导致较多误检，损害重建质量（RP 57.50%）；单独使用AFM（无FBL定位）效果尚可但非最优（RP 78.75%）；仅定位和过滤而不重建（无解码器）无法破坏映射（RP 68.33%）。三者结合实现了最优的恢复性能，平均RP高达87.51%。</p>
<p><strong>定性分析</strong>：<br><img src="https://arxiv.org/html/2602.03153v1/x3.png" alt="注意力可视化"></p>
<blockquote>
<p><strong>图3</strong>：分层注意力可视化。在浅层，清洁输入和中毒输入的注意力模式基本一致；在深层，中毒输入的注意力明显被“抢夺”至触发器相关特征，证实了论文的核心洞察。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.03153v1/x4.png" alt="嵌入空间可视化"></p>
<blockquote>
<p><strong>图4</strong>：(a) t-SNE可视化显示中毒图像令牌（黑色）在正常特征分布旁形成紧致簇。(b) 擦除框架通过掩码异常特征并利用解码器重建净化图像，破坏了触发器到不安全动作的映射。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献有三点：1) <strong>机制发现</strong>：揭示了VLA模型中后门攻击的“深层注意力抢夺”机制及其在嵌入空间形成紧致簇的特性，为理解多模态后门提供了新视角。2) <strong>方法创新</strong>：提出了Bera，首个基于该洞察的测试时后门擦除框架，通过特征定位、注意力过滤和图像重建，在不重新训练模型的情况下有效防御后门。3) <strong>实用性强</strong>：Bera是一个即插即用的模块，易于部署，并在多个真实机器人平台和任务上验证了其有效性和通用性。</p>
<p>论文提到的局限性包括：1) 需要在半白盒设置下访问模型的令牌嵌入和注意力图（尽管许多VLA部署提供此类分析API）。2) 方法主要针对图像嵌入的触发器，对于高度自适应或跨模态协同的复杂触发器，其鲁棒性有待进一步验证。</p>
<p>本工作对后续研究的启示在于：为防御多模态模型的后门攻击开辟了一条不依赖重训练的新路径，强调了利用模型内部表征（如注意力、嵌入几何）进行攻击检测和缓解的潜力。未来的工作可以探索如何将类似的原理应用于纯语言或音频模态的后门防御，或者研究在完全黑盒设置下的近似防御策略。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人视觉-语言-动作模型在下游微调时易受后门攻击的问题，提出了一种无需重新训练的高效防御框架Bera。该方法基于对后门“注意力劫持”机制的新发现，通过潜在空间定位检测异常注意力的视觉标记，利用深层线索掩蔽可疑区域，并重建无触发图像以切断后门映射。实验表明，Bera能在维持模型正常性能的同时，显著降低攻击成功率，有效恢复被后门操控的策略输出。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.03153" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>