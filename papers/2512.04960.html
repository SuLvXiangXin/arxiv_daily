<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.04960" target="_blank" rel="noreferrer">2512.04960</a></span>
        <span>作者: Danica Kragic Team</span>
        <span>日期: 2025-12-04</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，通过模仿学习获得的视觉运动策略在复杂操作任务中表现出良好性能，但通常难以达到基于传统控制方法的精度和速度。远程操作系统的根本局限在于操作员与机器人之间的形态不匹配。例如，机器人可能具备人类无法轻易完成的关节运动能力（如旋转躯干180度），或者人类难以持续绕单一轴旋转（如拧瓶盖），而机器人可以简单地驱动末端关节实现。因此，机器人形态优势难以通过1:1映射的远程操作被充分利用。</p>
<p>本文针对上述痛点，提出了一种新视角：允许操作员在演示过程中无缝集成预定义例程，并让学习到的策略在推断时也能自主触发这些例程，从而结合开环精确控制与闭环视觉运动策略的优势。核心思路是：引入远程操作增强原语（Teleoperation Augmentation Primitives， TAPs），使操作员能在演示中触发预定义例程；并扩展视觉运动扩散策略，使其学习在任务执行中自主触发TAPs，形成混合扩散模型。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架分为两部分：一是支持TAPs的远程操作数据收集系统，二是能够触发TAPs的混合扩散模型推理框架。</p>
<p><img src="https://arxiv.org/html/2512.04960v1/imgs/fig_1_HD.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：混合扩散模型概述。在远程操作期间，专家可以通过语音或（AR）控制器输入触发远程操作增强原语（TAP）。混合扩散模型在执行过程中也学习触发此类TAP例程，在任务中利用例程。</p>
</blockquote>
<p><strong>核心模块1：远程操作增强原语（TAPs）</strong><br>TAPs是操作员在认为有益于提高演示质量时可以触发的原语，旨在解决模仿学习中远程操作演示收集时的特定缺陷。具体分为三类：</p>
<ol>
<li><strong>轴锁定</strong>：允许操作员锁定机器人工具坐标系或基坐标系中的一个或多个轴（X, Y, Z, 横滚，俯仰，偏航）。这在需要保持特定末端执行器方向或沿主轴直线运动时非常有用。</li>
<li><strong>栖息路径点</strong>：允许操作员为（长时域）任务的特定阶段预定义一组路径点，并可在任何时候触发预设路径点，命令机器人移动到该点。这在仅使用末端执行器摄像头、任务相关物体可能离开视野时特别有用，能确保场景回到视野并提供下一任务步骤的统一起始位置。</li>
<li><strong>（开环）例程</strong>：允许操作员在任务中选择的点触发预定义的（参数化）开环原语，以利用机器人的形态优势。例如，对于拧瓶盖任务，可以设计一个包含“夹紧→逆时针旋转→张开→顺时针旋转→夹紧→逆时针旋转→直线上升”的例程。旋转次数、夹爪力等可通过参数设置。本文展示的例程是开环的，但框架不限于此，也支持触发具有闭环反馈或由强化学习驱动的子策略例程。</li>
</ol>
<p><img src="https://arxiv.org/html/2512.04960v1/imgs/taps_modalities.png" alt="触发方式"></p>
<blockquote>
<p><strong>图2</strong>：触发TAP的不同方式：通过语音命令(a)、AR按钮界面(b)，或通过直接映射并以触觉模式作为确认(c-专家用户)。</p>
</blockquote>
<p><strong>触发TAPs的交互方式</strong>：为适应不同操作员偏好，TAPs可通过三种方式触发：</p>
<ul>
<li><strong>语音</strong>：按下控制器上的预定义组合键启动语音识别，说出命令（如“锁定X轴”），使用Whisper-Tiny模型进行语音转文本，并通过计算Levenshtein距离匹配预定义TAP列表。</li>
<li><strong>增强现实（AR）</strong>：通过AR头显查看控制器上的AR菜单，使用控制摇杆方向激活标有TAP选项的AR按钮。</li>
<li><strong>触觉反馈</strong>：供高级用户使用，无需佩戴头显，通过控制器不同的振动脉冲模式来感知激活的菜单和可用TAP，通常通过预选任务所需TAP并单键触发。</li>
</ul>
<p><img src="https://arxiv.org/html/2512.04960v1/imgs/tasks.png" alt="TAP类型"></p>
<blockquote>
<p><strong>图3</strong>：不同类型的TAPs及示例任务。a) 小瓶抽吸，其中旋转轴锁定对操作员有用；b) 开容器液体转移，部署栖息路径点以使相应容器进入视野；c) 容器拧开，在正确位置触发开环拧开例程。</p>
</blockquote>
<p><strong>核心模块2：混合扩散模型</strong><br>模型架构如图1底部所示。输入观察值，包括RGB图像（$O_t$）和机器人6D末端执行器位姿（$x_t$），送入视觉运动扩散策略块。策略预测未来$n$个时间步的动作$a_t$到$a_{t+n}$以及TAPs。在推理循环中（算法1），只要没有推理正在运行（约每3个时间步），就持续预测新动作和TAPs，并将当前时间步的动作和TAP发送给处理TAPs的机器人控制器（算法2）。</p>
<p>在机器人控制器中（算法2）：</p>
<ul>
<li>如果没有TAP激活且接收到的TAP未被触发，则正常执行策略动作。</li>
<li>如果接收到TAP，则以开环方式执行该TAP直至完成。在此期间，策略（一直在默默预测动作）的动作被忽略。TAP一旦完成，策略立即无缝恢复控制，无任何延迟或中断。</li>
<li>策略库中包含所有预定义的、策略可触发的TAP；策略指示在给定时间步应执行哪个TAP。如果策略在同一时间步触发两个TAP（非期望行为），则执行TAP库中优先级较高的那个。</li>
</ul>
<p><strong>创新点</strong>：与现有混合策略（如HYDRA结合稀疏路径点与密集控制）相比，本文的创新在于提供了一个完整的框架，允许操作员在演示过程中直接将混合例程集成到数据中，同时策略框架学习在任务需要时触发这些例程，实现了从演示到策略执行的端到端“混合”能力。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在三个真实世界任务上验证方法，任务设置如图3所示：</p>
<ol>
<li><strong>小瓶抽吸</strong>：机器人配备注射器，从安装在可任意旋转球体上的小瓶中抽取液体。操作员使用<strong>轴锁定</strong>TAP（锁定所有旋转轴）以保持针头对齐。</li>
<li><strong>开容器液体转移</strong>：机器人用注射器从右侧化学容器抽取液体并注入左侧容器。使用<strong>栖息路径点</strong>TAP，使操作员能始终回到初始路径点，抽取液体后激活另一个路径点使目标容器清晰可见。</li>
<li><strong>容器拧开</strong>：另一只机器人臂（非策略控制）握住带螺纹盖的容器。任务是将机器人移动到容器上方，抓住盖子并将其拧下。使用<strong>开环例程</strong>TAP（拧开例程）。</li>
</ol>
<p><strong>基准与评估</strong>：对比基线为无法触发TAPs的扩散策略。基线必须将TAP例程产生的轨迹作为整体策略的一部分来学习。每个任务随机化7个初始条件（基线和混合扩散使用相同种子），每个起始位置执行3次，每个策略每个任务共21次 rollout。</p>
<p><img src="https://arxiv.org/html/2512.04960v1/imgs/result_p.png" alt="实验结果"></p>
<blockquote>
<p><strong>图4</strong>：三个任务的实验结果，每个任务7个新颖起始位置，各重复3次。比较混合扩散（HD）与基线扩散（D）方法。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ul>
<li><strong>小瓶抽吸</strong>：混合扩散（HD）与基线扩散（D）性能非常相似，成功率分别为<strong>62%</strong> 和**57%**。轴锁定TAP主要有助于操作员提高演示质量，但如果训练数据质量高，策略可以学会保持方向。</li>
<li><strong>开容器液体转移</strong>：HD以<strong>71%</strong> 的成功率略微优于基线的**62%**。栖息路径点对任务成功率至关重要，但策略可以在不触发例程的情况下学会返回有利位置。TAP使过程更结构化，在更长时域任务中可能有潜力，但如果操作员没有TAP也会移动到路径点，则收益有限。</li>
<li><strong>容器拧开</strong>：HD表现出显著性能优势，成功率为**67%<strong>，而基线仅为</strong>38%**。分析失败案例发现，基线难以执行多次旋转，并试图在盖子仍固定在瓶子上时过早提起。这是因为盖子完全关闭与旋转一次后的观察差异极小，导致策略在这些情况下存在多模态分布（是旋转还是提起），从而成功率下降。而混合方法在正确位置触发例程时，能通过开环确保旋转足够次数以完全拧开瓶子。</li>
</ul>
<p><strong>消融实验</strong>：实验本身通过对比有无TAP触发能力的策略，验证了不同TAP组件（轴锁定、路径点、开环例程）的贡献。结果表明，对于依赖重复性、形态优势动作的任务（如拧开），<strong>开环例程</strong>的贡献最大，带来了近30个百分点的性能提升。而轴锁定和栖息路径点主要贡献于<strong>改善演示质量</strong>，对最终策略性能的提升相对有限。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>提出了远程操作增强原语（TAPs）框架</strong>：定义了三种类型（轴锁定、栖息路径点、开环例程）以及多种触发方式（语音、AR、触觉），旨在改善演示质量并充分利用机器人形态。</li>
<li><strong>提出了混合扩散模型</strong>：扩展了视觉运动扩散策略，使其能够学习并自主触发TAPs，将开环例程与闭环视觉运动策略有机结合。</li>
<li><strong>在真实机器人任务上进行了验证</strong>：实验表明，该方法能有效提升某些任务（尤其是需要利用形态优势的重复性任务）的策略性能，其中容器拧开任务的成功率从38%提升至67%。</li>
</ol>
<p><strong>局限性</strong>：论文提到，由于TAPs是开环的，且策略理论上可以在任何时间触发TAP，因此存在触发TAP导致任务失败并超出训练数据支持范围的风险。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>扩展TAP类型</strong>：将TAPs扩展到包含闭环反馈控制器或通过强化学习等方式学习的子策略，以增强鲁棒性和适应性。</li>
<li><strong>自动TAP发现</strong>：研究如何从失败演示或操作员行为模式中自动识别有益的原语，减少手动设计工作量。</li>
<li><strong>层次化组合</strong>：开发能按顺序组合多个TAPs的层次化混合扩散模型，以扩展到更复杂的长期任务。</li>
<li><strong>跨 embodiment 和任务迁移</strong>：研究TAPs在不同机器人形态和任务间的可迁移性，以构建更通用的操作策略。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对模仿学习获得的视觉运动策略在精度和速度上不及传统控制方法的问题，提出混合扩散模型。核心方法是将开环例程与视觉运动扩散策略相结合，并开发了远程操作增强原语（TAPs），允许演示者无缝执行锁定特定轴、移动至路径点等预定义例程，且模型在推理时能自主触发TAPs。该方法在真实世界的移液、液体转移和容器拧开等任务中得到了验证。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.04960" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>