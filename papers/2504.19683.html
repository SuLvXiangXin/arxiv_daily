<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>GPA-RAM: Grasp-Pretraining Augmented Robotic Attention Mamba for Spatial Task Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>GPA-RAM: Grasp-Pretraining Augmented Robotic Attention Mamba for Spatial Task Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2504.19683" target="_blank" rel="noreferrer">2504.19683</a></span>
        <span>作者: Sheng, Juyi, Liu, Yangjun, Xu, Sheng, Yang, Zhixin, Liu, Mengyuan</span>
        <span>日期: 2025/04/28</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人模仿学习通过观察和模仿示教者动作来获取技能，在机器人操作领域取得了显著进展。当前主流方法主要依赖于Transformer架构进行多模态特征融合，如PerAct、RVT、RVT2和ARP+等方法。然而，这些方法面临两个关键局限性：首先，它们对整体操作过程的学习往往忽略了精细的初始抓取，而次优的初始抓取姿态会严重影响后续精细操作（如堆叠杯子、孔轴装配）的成功率；其次，基于Transformer的方法在处理长序列（如高分辨率多视角RGB-D流）时存在二次计算复杂度，导致计算延迟，阻碍了实时部署。</p>
<p>本文针对“初始抓取不精确”和“模型计算效率低”这两个具体痛点，提出了新的解决视角。一方面，提出抓取预训练增强（GPA）框架，在不额外收集和标注抓取姿态数据的前提下，利用任务演示数据中固有的抓取知识来增强模型的精细抓取感知能力。另一方面，提出机器人注意力Mamba（RAM）架构，将注意力机制与线性复杂度的状态空间模型（Mamba）相结合，旨在高效捕获复杂空间特征的同时保持实时推理性能。本文的核心思路是：通过GPA与RAM的协同，构建一个同时兼顾操作精度与推理效率的统一框架，适用于离散和连续动作生成。</p>
<h2 id="方法详解">方法详解</h2>
<p>GPA-RAM的整体框架包含两个核心模块：用于高效空间特征提取的Robotic Attention Mamba (RAM) 和用于增强精细抓取技能的Grasp-Pretraining Augmentation (GPA)。该框架处理点云、RGB-D图像、语言指令和机器人本体感知等多模态输入，预测下一个关键帧的机器人动作（包括末端执行器位置、旋转、夹持器状态和碰撞指示）。</p>
<p><img src="https://arxiv.org/html/2504.19683v3/x2.png" alt="方法总览"></p>
<blockquote>
<p><strong>图2</strong>：GPA-RAM在RLBench基准测试上的整体框架。主要包括RAM和GPA两大模块。输入包括点云、RGB-D、语言指令和本体感知。RAM通过粗-细两阶段处理提取空间语义特征，GPA通过预训练且冻结的抓取姿态检测器提取抓取特征。二者在GPA的预训练位置融合模块中进行特征融合，最终预测3D空间中的下一个关键动作。</p>
</blockquote>
<p>**Robotic Attention Mamba (RAM)**：该模块旨在解决Transformer的二次复杂度问题，并高效整合多模态信息。其工作流程采用粗到细的细化策略。首先，从RGB-D图像重建的点云被渲染成更多视角的虚拟图像以增强空间感知。在粗阶段，虚拟图像特征、语言特征（通过CLIP提取）和本体感知特征被输入到粗粒度RAM (C-RAM) 中。C-RAM输出一个热图，其最大值对应的坐标被提取为粗略关注位置。随后，在该坐标周围进行上采样，获取新的观察区域，并输入到细粒度RAM (F-RAM) 中进行进一步细化，最终输出精细的空间特征 <strong>F_RAM</strong>。</p>
<p><img src="https://arxiv.org/html/2504.19683v3/x3.png" alt="网络架构细节"></p>
<blockquote>
<p><strong>图3</strong>：Robotic Attention Mamba和Grasp-Pretraining Augmentation的网络架构细节。左：Mamba块的结构。中：单阶段RAM的流程，包括并行单视角注意力提取特征、多视角与语言特征融合，以及通过空间Mamba块进行对比学习。右：GPA的架构，视觉和语言特征由抓取姿态检测器学习，并通过空间注意力与RAM特征融合，随后经过上采样和MLP层进行动作预测。</p>
</blockquote>
<p>RAM的核心创新在于其混合架构。它首先使用并行单视角注意力块提取独立视角特征，然后将多视角特征与语言特征对齐。关键的是，在注意力块之后引入了Mamba块。Mamba将展平的视觉补丁视为连续序列进行建模，能够以线性复杂度捕获复杂3D场景中的长程空间依赖关系，从而在保持高效计算的同时增强全局上下文感知。</p>
<p>**Grasp-Pretraining Augmentation (GPA)**：该模块旨在解决深度网络在抽象和泛化过程中丢失精细操作特征（如物体操作可供性和高分辨率抓取线索）的问题。GPA的关键思想是利用任务演示数据中自然包含的抓取姿态知识。具体实施分为两步：首先，使用从专家演示中提取的抓取姿态，预训练一个抓取姿态检测器，使其学会捕获关键的抓取特征。在正式训练阶段，移除该检测器的输出头，将其作为特征提取器（可冻结或微调）。其次，通过一个预训练位置融合模块（PLoFusion），将预训练的抓取特征与RAM模块提取的、经过空间对齐的特征在空间维度上进行拼接，并通过自注意力机制进行融合。这种设计缩短了知识传递路径，确保了局部精细抓取信息在高层任务规划中得以保留。</p>
<p><strong>动作预测</strong>：融合后的GPA特征 <strong>F_GPA</strong> 被输入到不同的MLP中，分别预测旋转动作（离散化为72类）、夹持器状态和碰撞指示。同时，这些特征被上采样生成一个细粒度位置热图，热图中激活值最高的位置被选为下一个目标平移位置。</p>
<p>与现有方法相比，GPA-RAM的创新点具体体现在：1) 提出了通用的GPA框架，无需额外抓取数据标注即可增强任意机器人学习网络的抓取感知；2) 设计了RAM混合架构，首次将注意力机制与Mamba相结合用于机器人空间特征提取，实现了精度与效率的平衡。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>论文在模拟和真实世界环境中进行了广泛实验，使用了以下基准和数据集：</p>
<ol>
<li><strong>RLBench多任务基准</strong>：一个基于关键帧的离散动作生成基准，包含“关罐子”、“将方环插入红色栓”等多种任务。</li>
<li><strong>ALOHA双手连续操作任务</strong>：一个连续动作生成基准，用于测试双手精细操作。</li>
</ol>
<p>对比的基线方法包括：PerAct、RVT、RVT2、ARP+等当前最先进的方法。</p>
<p><strong>关键实验结果</strong>：<br>在RLBench多任务基准上，GPA-RAM取得了平均87.5%的成功率，相比RVT2 (79.3%) 提升了8.2%，相比ARP+ (84.9%) 提升了2.6%。在ALOHA双手连续任务上，GPA-RAM在特定任务上将成功率从16%提升至56%（提升40%），在另一任务上从86%提升至98%（提升12%）。在推理速度方面，GPA-RAM达到了约71 FPS，展示了优异的实时性能。</p>
<p><img src="https://arxiv.org/html/2504.19683v3/x4.png" alt="RLBench结果对比"></p>
<blockquote>
<p><strong>图4</strong>：在RLBench 18个任务上的成功率对比。GPA-RAM（橙色）在绝大多数任务上超越了基线方法（如RVT2蓝色，ARP+绿色），尤其在“stack cups”、“insert onto square peg”等需要精细抓取的任务上优势明显。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.19683v3/x5.png" alt="ALOHA结果对比"></p>
<blockquote>
<p><strong>图5</strong>：在ALOHA双手连续任务上的成功率对比。GPA-RAM在“Insertion”和“Folding”两个任务上均取得了最高成功率，显著优于ACT等基线方法。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.19683v3/x6.png" alt="消融实验"></p>
<blockquote>
<p><strong>图6</strong>：GPA和RAM模块的消融实验结果。左图显示，移除GPA或RAM都会导致性能下降，验证了二者的必要性。右图显示，RAM（使用Mamba）在保持高性能的同时，推理速度远超基于Transformer的版本。</p>
</blockquote>
<p><strong>消融实验总结</strong>：<br>消融实验验证了各个组件的贡献。移除GPA模块会导致性能显著下降，证明了抓取预训练增强对精细操作的重要性。将RAM中的Mamba替换为标准的Transformer注意力层会导致推理速度大幅下降（从<del>71 FPS降至</del>25 FPS），而性能略有降低或持平，这凸显了Mamba在提升效率方面的关键作用。实验表明，GPA和RAM的协同工作是实现高精度与高实时性平衡的关键。</p>
<p><img src="https://arxiv.org/html/2504.19683v3/x7.png" alt="真实世界实验"></p>
<blockquote>
<p><strong>图7</strong>：真实机器人实验的定性结果。GPA-RAM成功完成了开抽屉、堆叠杯子、挂毛巾等复杂操作任务，展示了其从模拟到真实世界的良好泛化能力。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2504.19683v3/x8.png" alt="故障案例分析"></p>
<blockquote>
<p><strong>图8</strong>：失败案例分析。展示了在极端遮挡或非常规物体姿态情况下，GPA-RAM可能出现的抓取或操作失败，为后续改进指明了方向。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：1) 提出了Grasp-Pretraining Augmentation (GPA)，一种无需额外抓取标注、通过利用演示数据中固有抓取知识来增强精细操作感知的通用框架；2) 设计了Robotic Attention Mamba (RAM)，一种融合注意力与线性复杂度状态空间模型（Mamba）的混合架构，在保持强大空间特征提取能力的同时实现了高效的实时推理；3) 构建了统一的GPA-RAM框架，并在多个模拟与真实机器人平台上验证了其卓越性能，在精度和速度上均优于先前方法。</p>
<p>论文自身提到的局限性包括：方法性能可能受到预训练抓取检测器质量的制约；在极端遮挡或高度非常规物体姿态的场景下，抓取和操作仍可能失败（如图8所示）。</p>
<p>本工作对后续研究的启示在于：1) <strong>混合架构的有效性</strong>：表明结合注意力（擅长局部关系建模）与状态空间模型（擅长长序列高效建模）的混合范式是解决机器人学习中精度-效率权衡的一个有前景的方向。2) <strong>技能分解与集成</strong>：通过GPA展示了一种将底层技能（抓取）知识显式集成到端到端学习流程中的有效方法，这可以扩展到其他关键子技能（如插入、旋转）。3) <strong>效率优先的设计</strong>：随着机器人任务复杂度和数据维度的提升，推理效率将成为与精度同等重要的设计考量，RAM为此提供了参考。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人操作中因初始抓取不佳导致任务失败的问题，提出GPA-RAM统一框架。核心方法包括：1) GPA抓取预训练增强框架，无需额外数据即可提升抓取感知；2) RAM架构，融合注意力机制与状态空间模型(SSM)，在保持高效推理的同时捕捉复杂空间特征。实验表明，该框架在RLBench基准上成功率较优方法最高提升8.2%，在ALOHA双手任务上最高提升40%，同时推理速度达约71 FPS，实现了精度与响应速度的平衡。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2504.19683" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>