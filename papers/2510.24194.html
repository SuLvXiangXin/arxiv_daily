<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.24194" target="_blank" rel="noreferrer">2510.24194</a></span>
        <span>作者: Aviv Tamar Team</span>
        <span>日期: 2025-10-28</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>行为克隆是一种从专家演示中学习序列决策的简单有效方法。当前，针对多任务或任务变体的泛化，行为克隆仍需要大量数据，现有改进方法包括数据增强、仿真以及在大规模演示数据上微调基础模型。然而，一个尚未被探索的方面是<strong>专家本身</strong>：许多任务可以通过多种方式解决，是否某些行为比其他行为泛化得更好？近期零样本强化学习的研究表明，某些探索性行为比目标导向、奖励最大化的行为泛化得更好。本文针对行为克隆中<strong>专家演示行为对多任务泛化影响</strong>这一具体痛点，提出了一个新视角：通过向专家引入信息瓶颈（“眼罩”），促使其表现出更具探索性、更少任务依赖性的行为，从而提升克隆策略的泛化能力。本文核心思路是：克隆“盲眼”专家（即任务信息被部分屏蔽的专家）的行为，比克隆完全知情专家的行为，在未见任务上泛化得更好。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文方法的整体框架分为两个阶段：专家演示阶段和策略克隆阶段。在演示阶段，专家策略 π^E 根据当前观察（可能被屏蔽）和历史信息生成动作；克隆阶段则使用收集到的（未屏蔽的）观察-动作轨迹数据，通过标准的行为克隆算法（最小化负对数似然损失）训练目标策略 π_hat。</p>
<p><img src="https://arxiv.org/html/2510.24194v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：学习过程示意图。注意，观察上的掩码仅适用于盲眼专家，而记录在轨迹中的观察在两种情况下都是未掩码的。</p>
</blockquote>
<p>方法的核心模块是应用于专家的<strong>信息瓶颈（“眼罩”）设计</strong>，其具体作用是在专家演示时，有选择地屏蔽其观察中与特定任务实例高度相关的信息。这迫使专家无法直接采用针对该任务的最优、最短路径策略，而必须通过<strong>非平凡的探索</strong>来理解并解决任务。由于这种探索行为对特定任务的依赖更小，因此被假设能产生更好的跨任务泛化。技术上，为了捕捉专家依赖历史的探索行为，克隆策略使用了能够处理观察序列的架构，如循环神经网络或Transformer。</p>
<p>与现有方法相比，本文的创新点具体体现在：<strong>它并未改变用于训练策略的观察数据，也无需修改行为克隆算法本身，而是通过改变专家生成演示数据的方式（即引入信息瓶颈）来提升泛化性能</strong>。这种方法与提升泛化的其他技术（如数据增强、基础模型）是正交且互补的。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>本文在两类 benchmark 上进行了实验：1) <strong>模拟环境</strong>：使用 Procgen 基准测试中的“迷宫”和“抢劫”游戏；2) <strong>真实机器人平台</strong>：基于功能操作基准的机器人插孔任务。</p>
<p>对比的基线方法是克隆标准（完全知情）专家行为的策略 (π_BC)。本文方法克隆盲眼专家行为的策略记为 π_BC-BF。</p>
<p>关键实验结果如下：<br>在Procgen实验中，π_BC-BF 在训练关卡上的性能与 π_BC 相近，都能接近最高任务得分。然而，在未见测试关卡上，π_BC-BF 的得分稳步提升，而 π_BC 则明显过拟合，测试得分随着训练略有下降。</p>
<p><img src="https://arxiv.org/html/2510.24194v1/x3.png" alt="训练与测试性能对比"></p>
<blockquote>
<p><strong>图3</strong>：Procgen迷宫和抢劫游戏中，策略在训练关卡（左图对）和未见测试关卡（右图对）上的得分随训练轮次的变化。π_BC-BF 在测试集上展现出更好的泛化性能。</p>
</blockquote>
<p>为了排除“盲眼专家演示轨迹更长、步数更多”这一混淆因素，作者额外训练了一个策略 π_BC-ext，它使用两倍于 π_BC 的标准专家轨迹（以匹配 π_BC-BF 的总步数）。结果显示，即使数据量翻倍，π_BC-ext 在测试集上仍然过拟合，性能远不及 π_BC-BF。</p>
<p><img src="https://arxiv.org/html/2510.24194v1/x4.png" alt="匹配步数后的性能对比"></p>
<blockquote>
<p><strong>图4</strong>：在Procgen迷宫中，即使使用更多标准专家数据（π_BC-ext）以匹配盲眼专家的总步数，其测试性能仍然过拟合，而 π_BC-BF 泛化良好。</p>
</blockquote>
<p>在真实机器人插孔任务中，训练集包含6种形状，测试集包含4种未见形状。π_BC-BF 在训练形状上的平均成功率为 86.7%，在未见测试形状上的平均成功率为 65.0%。而 π_BC 在训练形状上成功率为 86.7%，在测试形状上仅为 37.5%。这表明 π_BC-BF 的泛化性能显著优于 π_BC。</p>
<p><img src="https://arxiv.org/html/2510.24194v1/x7.png" alt="机器人任务成功率"></p>
<blockquote>
<p><strong>图7</strong>：机器人插孔任务中，π_BC 和 π_BC-BF 在训练形状（左）和未见测试形状（右）上的成功率对比。π_BC-BF 在未见形状上表现更优。</p>
</blockquote>
<p>消融实验方面，本文的理论分析指出泛化误差上界与 √(I/m) 相关，其中 I 是专家可获取的任务信息量，m 是演示的任务数量。实验通过设计不同的信息瓶颈（在Procgen中改变视野范围，在机器人任务中改变孔洞图像的掩码比例）来验证这一关系。结果显示，随着信息瓶颈的加强（I 减小），克隆策略的测试性能呈现先升后降的趋势，存在一个最优的掩码程度。</p>
<p><img src="https://arxiv.org/html/2510.24194v1/x8.png" alt="信息瓶颈强度的影响"></p>
<blockquote>
<p><strong>图8</strong>：在Procgen迷宫中，不同信息瓶颈强度（视野半径）对克隆策略测试性能的影响，存在一个最优的掩码程度。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出了 <strong>“盲眼专家”范式</strong>，首次系统性地探索并证明了通过限制专家信息来诱导更具探索性的演示行为，可以显著提升行为克隆策略在多任务上的泛化能力，并为此提供了理论分析（泛化误差上界与 √(I/m) 相关）；2) 在<strong>模拟游戏（Procgen）和真实机器人操作任务</strong>上进行了广泛实验，验证了该方法的有效性；3) 为面向泛化的演示数据收集，乃至大规模基础模型的数据构建，提供了一种新的、有原则的指导思路。</p>
<p>论文自身提到的局限性主要在于理论分析所做的假设，如专家策略是确定性的、动作空间有限、策略类别有限等。尽管作者讨论了克服这些假设的潜在途径，但在最一般情况下的理论扩展仍具挑战性。</p>
<p>本文工作对后续研究的启示包括：1) 可将“盲眼专家”思想扩展到更复杂的领域和专家类型（如AI专家）；2) 探索如何自动设计或学习最优的信息瓶颈（“眼罩”），而无需人工设定；3) 将该方法与数据增强、基础模型预训练等其他提升泛化的技术相结合，可能产生叠加效应。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文研究行为克隆（BC）中策略对任务变化的泛化问题，旨在减少所需演示数量。提出**蒙眼专家**方法：隐藏部分任务信息，迫使专家进行非平凡探索。理论分析表明泛化误差与√(I/m)成正比（I为专家获得的信息量，m为演示任务数）。在真实机器人插孔任务和Procgen视频游戏上的实验表明，克隆蒙眼专家比克隆完全知情专家在未见任务上泛化更好，且所需演示更少。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.24194" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>