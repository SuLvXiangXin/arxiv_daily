<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Teaching Transformers to Solve Combinatorial Problems through Efficient Trial & Error - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Teaching Transformers to Solve Combinatorial Problems through Efficient Trial & Error</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.22023" target="_blank" rel="noreferrer">2509.22023</a></span>
        <span>作者: Christos Tzamos Team</span>
        <span>日期: 2025-09-26</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>尽管大语言模型（LLMs）在多种语言任务上表现出色，但在解决组合问题（如可满足性问题、旅行商问题甚至基础算术）时仍存在困难。现有方法主要分为两类：一类是依赖定制架构的神经符号方法（如递归关系网络、循环Transformer），它们通常采用单次前向预测的直接求解方式，缺乏错误恢复机制且推理过程不透明；另一类是更接近LLM范式的工作，例如通过模仿人类预设的解题策略步骤来训练因果Transformer，但其能力受限于训练数据中的策略，无法解决需要超越既定逻辑步骤的难题。这些方法的共同关键局限性在于，模型无法进行试错、回溯以从错误中恢复。</p>
<p>本文针对LLMs在组合推理中缺乏系统探索和纠错能力的痛点，提出了一种新颖的“试错”视角。核心思路是：将模仿学习与显式的深度优先搜索（DFS）探索策略相结合，训练一个标准的解码器Transformer（GPT-2变体）在应用基础规则后，进行“有根据的猜测”，并在遇到冲突时回溯，从而高效地遍历解空间直至找到正确答案。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架是一个集成了规则应用、猜测和回溯的迭代过程。输入是数独谜题的初始状态（已填充单元格序列），输出是完整的解题步骤序列，其中最后赋予每个单元格的值即为最终解。核心流程遵循DFS算法：模型首先反复应用四条基本数独规则（对应“唯余解”和“隐式唯一候选数”策略）填充所有可确定的单元格；若谜题仍未解决，则进入猜测阶段，选择一个未解单元格及其一个合法候选值作为猜测填入；之后再次应用规则；若导致冲突（死胡同），则回溯至上一个猜测点，尝试该单元格的其他候选值；此过程循环直至解出谜题或达到序列长度上限。</p>
<p><img src="https://arxiv.org/html/2509.22023v2/figures/transcript_fig.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：训练转录本示例。蓝色括号表示规则应用步骤中每个输出token的多个有效标签。黄色括号显示模型在给定层级达到猜测token时的有效候选集。选中的猜测用黄色轮廓的灰色圆圈表示。如果导致死胡同，则在同一单元格进行后续猜测。</p>
</blockquote>
<p>核心模块与技术细节包括：</p>
<ol>
<li><strong>动作级分词</strong>：与先前工作使用三个独立token（行、列、值）不同，本文将每一步“走法”编码为一个三位数token（范围111-999），分别代表行、列、值。这使输入序列长度缩短为原来的1/3，提升了训练和推理效率。</li>
<li><strong>多目标损失函数</strong>：在组合谜题求解的任意步骤，常存在多个合法的下一步。因此，本文不使用标准的单目标交叉熵损失，而是采用对当前步骤所有合法下一步token的概率求和的多目标交叉熵损失：<code>-∑_(i∈S) log p_i</code>，其中S是合法下一token集合。这为模型提供了更丰富的学习信号，使其能同时考虑多个合理延续。</li>
<li><strong>DFS探索与回溯机制</strong>：训练数据转录本模拟了完整的DFS过程，包含“规则结束”、“猜测层级”、“死胡同”等特殊token，以教导模型何时猜测、何时回溯。模型通过学习这些转录本，内化了系统的试错搜索行为。</li>
</ol>
<p>与现有方法相比，创新点具体体现在：1) 摒弃复杂的人工策略，仅依赖最基本的数独规则，结合可学习的猜测/回溯机制，实现了更强的泛化能力；2) 提出的动作级分词和多目标损失优化了训练效率和效果；3) 整个框架仅使用标准的因果Transformer，无需定制架构或外部工具调用。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：使用标准的GPT-2架构（8层，8头，42M参数）。训练和评估主要基于一个高效的、均匀随机生成数独谜题的生成器（SudokuPy），以确保分布的无偏性和可重复性。此外，还在多个公共数据集上进行了测试：随机生成测试集、Kaggle未过滤数据集、Kaggle过滤数据集（仅包含可用7种策略解决的谜题）以及RRN数据集。</p>
<p><strong>对比基线</strong>：包括基于定制架构的RRN、循环Transformer，基于LLM范式的因果Transformer，以及最新的掩码扩散模型（MDM）。</p>
<p><img src="https://arxiv.org/html/2509.22023v2/x1.png" alt="实验结果对比"></p>
<blockquote>
<p><strong>图1</strong>：在10万个随机生成的数独谜题上与先前最先进模型的棋盘准确率对比。由于部分模型在不同数据集上训练，我们使用随机数独生成器重新训练它们，并用阴影条报告其提升后的准确率。</p>
</blockquote>
<p><strong>关键结果</strong>：本文提出的试错因果Transformer在随机测试集上达到了98.9%的棋盘准确率，显著超越了所有基线。相较于最相近的因果Transformer基线，在Kaggle未过滤集上绝对提升了31.7%，在Kaggle过滤集上提升了12.3%。即使在定制架构模型表现最好的RRN数据集上，本文方法也达到了99.4%的准确率，展示了其强大性能。</p>
<p><img src="https://arxiv.org/html/2509.22023v2/x2.png" alt="训练曲线"></p>
<blockquote>
<p><strong>图3</strong>：三种不同分词和损失函数配置的模型变体在训练期间的规则逻辑准确率。本文的紧凑编码（动作级分词）结合多目标损失（绿线）能最快达到接近完美的规则应用能力。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.22023v2/x3.png" alt="准确率曲线"></p>
<blockquote>
<p><strong>图4</strong>：在训练期间，使用生成器样本评估的模型在随机、Kaggle未过滤和RRN数据集上的棋盘准确率。在随机和Kaggle集上的学习曲线高度一致，验证了生成器采样的均匀性；RRN数据集则显得更容易。</p>
</blockquote>
<p><strong>消融实验</strong>：图3和图4的对比显示，动作级分词相比三元组分词能加速学习，而结合多目标损失能进一步大幅提升学习效率，使模型更快地掌握规则应用和整体解题能力。</p>
<p><strong>超越模仿学习——优化猜测</strong>：论文进一步提出优化目标，即最小化解题所需的猜测步骤（期望长度）。通过分析发现，约99.8%的随机数独在应用规则后，仅需一次正确猜测（即存在“后门”）即可解决。在此“单层猜测”和“非自适应”的简化设定下，该问题被形式化为一个上下文最小和集合覆盖问题。基于此，作者提出了一种新的损失函数，旨在直接最小化解题长度。实验表明，在此设定下训练的模型，其解题长度可与知晓所有单元格正确答案（但不知哪个是后门）的预言机模型相媲美，甚至优于之前的模仿学习多级猜测方法。这是因为优化方法在训练时只使用包含正确猜测的成功轨迹，让模型更专注于学习直接导向解的高价值决策。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>提出通用的试错推理框架</strong>：将模仿学习与深度优先搜索结合，使标准Transformer能够通过猜测和回溯解决组合问题，该框架理论上适用于任何NP问题（验证器高效即可）。</li>
<li><strong>实现SOTA性能并展示泛化性</strong>：在数独任务上达到99%的准确率，超越了所有先前的神经网络方法；在另一个NP完全问题（1-in-3 SAT）上也达到了99%的准确率，证明了框架的通用性。</li>
<li><strong>对猜测过程进行理论分析与优化</strong>：将猜测步骤的形式化分析与上下文最小和集合覆盖问题联系起来，并提出了一种优于标准交叉熵损失的新损失函数，以优化解题效率。</li>
<li><strong>提供标准化基准与工具</strong>：发布了高效的、均匀随机生成数独的Python库，促进了可重复研究和流式训练。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，该方法依赖于问题存在高效的验证器。此外，对猜测优化的理论分析基于“单层猜测”和“非自适应”的简化假设，虽然在此设定下效果显著，但与完整的、多层的自适应DFS搜索相比仍是一种近似。</p>
<p><strong>启示</strong>：本研究为使用大语言模型解决复杂的组合优化问题提供了新范式，表明通过精心设计的训练机制（试错、回溯），标准Transformer可以内化复杂的算法行为（如DPLL）。它强调了在推理任务中，数据生成（如模拟搜索轨迹）和损失函数设计（如多目标损失、基于解长度的损失）与模型架构同等重要。这项工作为开发更高效、更通用的神经推理机指明了方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对大型语言模型难以解决组合优化问题（如数独）的不足，提出了一种高效的试错学习框架。该方法结合对数独规则的模仿学习与显式深度优先搜索策略，通过有根据的猜测和回溯进行探索，并采用深度-1猜测以最小化猜测次数。实验表明，仅使用普通GPT-2模型，该框架在数独任务上达到了99%的准确率，且绝大多数谜题仅需至多一次猜测即可解决，性能优于先前神经符号方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.22023" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>