<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>ScaleADFG: Affordance-based Dexterous Functional Grasping via Scalable Dataset - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>ScaleADFG: Affordance-based Dexterous Functional Grasping via Scalable Dataset</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2511.09602" target="_blank" rel="noreferrer">2511.09602</a></span>
        <span>作者: Wang, Sizhe, Yang, Yifan, Luo, Yongkang, Li, Daheng, Wei, Wei, Zhang, Yan, Hu, Peiying, Fu, Yunjin, Duan, Haonan, Sun, Jia, Wang, Peng</span>
        <span>日期: 2025/11/12</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>灵巧的功能性工具抓取对于机器人有效操作工具至关重要。然而，现有方法在高效构建大规模数据集和确保对日常物体尺度的泛化能力方面面临重大挑战。这些挑战主要源于机器人手与人类手之间的尺寸不匹配，以及真实世界中物体尺度的多样性。当前主流方法严重依赖人类手部演示，并通过重定向或接触图对齐迁移到机器人手，这导致数据集受限于人类手部尺寸和运动学偏差，倾向于抓取更大物体，且功能性抓取精度不足。此外，对现有物体数据集或手动3D扫描的依赖进一步限制了可扩展性和多样性。</p>
<p>本文针对上述痛点，提出了基于可操作性（Affordance）的新视角，旨在摆脱对人类演示的依赖，通过关联手部与物体的可操作性部件（功能部件和抓握部件）来合成抓取。本文的核心思路是：利用预训练基础模型自动化构建大规模、多尺度的灵巧功能抓取数据集，并在此基础上训练一个轻量级的单阶段抓取生成网络，以实现对多样物体形状和尺度的强适应性及零样本泛化。</p>
<h2 id="方法详解">方法详解</h2>
<p>ScaleADFG框架包含一个全自动的数据集构建流程和一个轻量级的抓取生成网络，其整体流程如图2所示。</p>
<p><img src="https://arxiv.org/html/2511.09602v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：ScaleADFG框架概览。左侧为大规模ScaleADFG-Dataset的构建流程，包括从互联网图像自动生成3D物体、利用密集特征对应进行可操作性检索，以及基于轴对齐初始化的优化式功能抓取合成。右侧为基于条件变分自编码器（CVAE）的轻量级ScaleADFG-Net，用于预测不同形状和尺度物体的抓取。手和物体的可操作性部件用相同颜色标示其对应关系。</p>
</blockquote>
<p><strong>1. 大规模数据集构建 (ScaleADFG-Dataset)</strong><br>该流程包含三个核心模块：</p>
<ul>
<li><strong>3D资产生成</strong>：通过网络搜索收集大量2D图像，使用Grounded SAM 2进行分割，并利用多个预训练生成模型（InstantMesh, TripoSR, TRELLIS）生成3D网格。通过人工快速筛选、文件大小过滤以及后续基于抓取质量指标的过滤，保留高质量网格，即使存在异常结构（如不完整网格、额外部件）也予以保留以增强数据复杂性。</li>
<li><strong>可操作性检索</strong>：为每个物体类别手动标注一个随机模板物体的可操作性部件（功能部件和抓握部件）。利用预训练模型PTv3-object（源自SAMPart3D，特征蒸馏自DINOv2）提取物体点云特征。通过密集特征匹配，将模板的部件标签传播到同类别其他实例上，实现了轻量级且可靠的自动化标注。</li>
<li><strong>灵巧功能抓取优化</strong>：基于可操作性策略合成抓取，通过优化使手部和物体对应的可操作性部件相互靠近，同时保证力闭合稳定性和物理合理性（避免穿透）。一个关键创新是处理物体尺度变化，为每个类别定义了从<code>S_low</code>到<code>S_high</code>的尺度范围（基于物体定向包围盒的最大范围），并采样15个尺度进行抓取合成。对于极端小尺度物体，方法通过改变手势而非微调手指构型来适应。</li>
</ul>
<p><strong>2. 轴对齐初始化</strong><br>优化性能高度依赖初始化质量。本文提出一种轴对齐初始化策略以提升功能性抓取合成效果，如图3所示。</p>
<p><img src="https://arxiv.org/html/2511.09602v1/x3.png" alt="轴对齐初始化"></p>
<blockquote>
<p><strong>图3</strong>：轴对齐初始化示意图。(a)物体和(b)手部各关联两种轴，同色轴线表示抓握部件与功能部件之间的对齐关系。(c)展示了初始化结果示例。</p>
</blockquote>
<p>为手部和物体分别定义两种轴：<strong>抓握到功能轴</strong>（<code>GF_i</code>，连接抓握中心和功能接触区域）和<strong>力施加轴</strong>（<code>FA_i</code>，与功能接触面法向等相关）。初始化分两步：首先精确对齐手与物体的主轴（<code>GF_i</code>），然后在垂直于主轴的平面对齐副轴（<code>FA_i</code>）以确保正确的施力方向。随后进行平移使手部与物体无穿透接触，并以手指微屈内收的姿态初始化关节角度。</p>
<p><strong>3. 基于可操作性的优化损失</strong><br>给定物体点云<code>P_O</code>及其功能部件<code>A_OF</code>和抓握部件<code>A_OG</code>，优化目标是找到最优抓取配置<code>G*</code>，总损失为加权和：<br><code>L_total = λ_F * L_F + λ_G * L_G + λ_FC * L_FC + λ_IP * L_IP + λ_SP * L_SP</code></p>
<ul>
<li><code>L_F</code>（功能部件距离损失）：鼓励手部功能锚点<code>A_HF</code>靠近物体功能部件<code>A_OF</code>，使用Chamfer距离。</li>
<li><code>L_G</code>（抓握部件距离损失）：鼓励手部抓握锚点<code>A_HG</code>靠近物体抓握部件<code>A_OG</code>。</li>
<li><code>L_FC</code>（力闭合损失）：基于[force_closure2022zhusongchun]的公式，促进抓取稳定性。</li>
<li><code>L_IP</code>（手-物体穿透损失）：最小化手部网格与物体之间的穿透深度（基于符号距离场SDF）。</li>
<li><code>L_SP</code>（手自穿透损失）：最小化手部不同部件（如手指间）的穿透。</li>
</ul>
<p>优化后，使用严格指标（<code>d_G≤0.02m, d_F≤0.002m, d_IP≤0.002m, d_SP≤0.002m</code>）过滤，并经过仿真环境精炼，仅保留成功的抓取。该方法收敛快（&lt;200步），合成效率高（平均&lt;0.2秒/抓取）。</p>
<p><strong>4. 抓取预测网络 (ScaleADFG-Net)</strong><br>网络采用轻量级CVAE架构。编码器输入物体点云及其从PTv3-object提取的特征的前三个主成分，输出潜变量分布的均值μ和方差Σ。解码器从潜空间采样并预测抓取配置（手部姿态和关节角度），通过可微分前向运动学得到手部点云。训练时使用两个损失：</p>
<ul>
<li><code>L_Rec</code>（重建损失）：最小化预测手部点云<code>P^_H</code>与真实点云<code>P_H</code>之间的Chamfer距离。该损失同时约束了关节角、旋转和平移。</li>
<li><code>L_KLD</code>（KL散度损失）：正则化潜空间使其逼近标准高斯分布<code>N(0, I)</code>，以促进泛化能力。<br>推理时，丢弃编码器，直接从<code>N(0, I)</code>采样潜变量，使网络能为新物体和新尺度生成多样化的功能抓取。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在仿真环境IsaacSim和真实机器人（Shadow Hand和Allegro Hand）上进行实验。使用了五个物体类别：电钻、手电筒、订书机、喷壶和乳液瓶。ScaleADFG-Dataset每个类别包含超过1000个独特形状，每个形状有15个尺度变体，过滤后为每只灵巧手提供超过60,000个抓取。</p>
<p><strong>基线方法</strong>：对比了DexGraspNet（通用抓取）、ContactGrasp（基于接触图的功能抓取）、DexFG（基于接触图迁移的多手功能抓取）以及直接使用数据集抓取（Ours w/o Net）和仅用单一尺度训练（Ours w/o Scale）的变体。</p>
<p><strong>关键定量结果</strong>：</p>
<ul>
<li><strong>数据集质量</strong>：如表II所示，人类研究评估表明，数据集中抓取的平均稳定率达91.6%，平均功能率达81.2%。可操作性标注的准确率（功能部件91.12%，抓握部件87.69%）也验证了自动标注的有效性。</li>
<li><strong>仿真抓取成功率</strong>：如图4所示，在五个类别的多尺度物体上，ScaleADFG-Net的平均成功率最高（Shadow Hand: 80.7%, Allegro Hand: 75.5%），显著优于基线方法，尤其在较小尺度物体上优势明显。消融实验表明，多尺度训练（Ours w/o Scale）对性能提升至关重要。</li>
</ul>
<p><img src="https://arxiv.org/html/2511.09602v1/x4.png" alt="仿真抓取成功率对比"></p>
<blockquote>
<p><strong>图4</strong>：在五个物体类别不同尺度下的仿真抓取成功率对比。ScaleADFG-Net（橙色）在两只手上的平均成功率均最高，尤其在较小尺度（S1-S5）上显著优于基线方法。</p>
</blockquote>
<ul>
<li><strong>真实世界零样本转移</strong>：如图5所示，在未见过的真实物体上，ScaleADFG-Net取得了最高的平均成功率（Shadow Hand: 86.7%, Allegro Hand: 83.3%），证明了其强大的零样本泛化能力。</li>
</ul>
<p><img src="https://arxiv.org/html/2511.09602v1/x5.png" alt="真实世界抓取成功率"></p>
<blockquote>
<p><strong>图5</strong>：真实世界零样本抓取成功率。ScaleADFG-Net在两只手上对五个类别的真实物体均取得了最高的平均成功率。</p>
</blockquote>
<p><strong>消融实验分析</strong>：</p>
<ul>
<li><strong>多尺度训练的重要性</strong>：图4中“Ours w/o Scale”（仅用单一尺度训练）的性能显著下降，证明了数据集中尺度多样性对于网络适应不同尺寸物体的关键作用。</li>
<li><strong>初始化方法的贡献</strong>：如图6所示，与随机初始化相比，本文提出的轴对齐初始化将优化成功率（合成高质量抓取的比例）从约50%提升至80%以上，并大幅减少优化所需迭代步数。</li>
</ul>
<p><img src="https://arxiv.org/html/2511.09602v1/x6.png" alt="初始化方法消融"></p>
<blockquote>
<p><strong>图6</strong>：初始化方法消融实验。轴对齐初始化相比随机初始化，显著提高了优化成功率和收敛速度。</p>
</blockquote>
<p><strong>定性结果</strong>：</p>
<ul>
<li><strong>尺度与形状适应性</strong>：图1展示了网络对不同尺度和形状物体的抓取预测，体现了良好的适应性。</li>
<li><strong>抓取多样性</strong>：图7展示了对于同一物体，通过从潜空间不同采样生成的多样化且均具功能性的抓取配置。</li>
</ul>
<p><img src="https://arxiv.org/html/2511.09602v1/x7.png" alt="抓取多样性"></p>
<blockquote>
<p><strong>图7</strong>：抓取多样性展示。对于同一物体（喷壶），通过从潜空间采样不同的噪声向量，网络可以生成多种不同的功能性抓取配置。</p>
</blockquote>
<ul>
<li><strong>真实机器人抓取</strong>：图8和图9展示了真实机器人平台成功执行零样本功能抓取和后续操作（如按压、触发）的序列。</li>
</ul>
<p><img src="https://arxiv.org/html/2511.09602v1/x8.png" alt="真实机器人抓取序列1"></p>
<blockquote>
<p><strong>图8</strong>：真实Shadow Hand抓取和使用电钻的序列。机器人成功抓取并触发了电钻开关。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2511.09602v1/x9.png" alt="真实机器人抓取序列2"></p>
<blockquote>
<p><strong>图9</strong>：真实Allegro Hand抓取和使用订书机、手电筒的序列。机器人成功执行了按压订书机和打开手电筒的功能操作。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>提出了ScaleADFG框架</strong>：包含一个利用预训练基础模型（用于分割、重建和感知）实现全自动、可扩展抓取数据集构建的流程，以及一个轻量级CVAE抓取生成网络。</li>
<li><strong>构建了大规模多尺度灵巧功能抓取数据集</strong>：基于可操作性合成算法，摆脱了对人类演示的依赖，包含了丰富的物体形状和尺度变体（每类&gt;1000形状，每形状15尺度），支持多款机器人手。</li>
<li><strong>设计了高效的抓取合成与预测方法</strong>：提出了轴对齐初始化策略显著提升优化效率；网络采用极简的损失设计（仅重建损失和KL散度），实现了跨类别的统一建模和出色的零样本真实世界转移能力。</li>
</ol>
<p><strong>局限性</strong>：<br>论文提到，当前方法在极端小尺度物体上仍面临挑战，且对于功能部件定义更复杂的物体（如需要多个特定手指协同操作的物体），其功能性的实现可能受限。</p>
<p><strong>启示</strong>：<br>本研究证明了基于可操作性的方法在构建大规模抓取数据和实现泛化方面的巨大潜力。未来工作可探索：1) 将可操作性概念扩展到更复杂的工具和任务；2) 结合大语言模型（LLM）等更高层语义理解来定义和推理可操作性；3) 进一步探索网络架构以提高对复杂几何和功能的推理能力。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对灵巧功能抓取中数据集构建效率低、对日常物体尺度泛化能力差的核心问题，提出ScaleADFG框架。其关键技术包括全自动数据集构建管道，利用基于可供性的算法合成多尺度抓取配置，支持灵活的对象-手尺寸比例，构建了包含五类物体、每类超千形状、各15尺度变体的大规模数据集；以及轻量级单阶段抓取生成网络，采用简单损失设计无需后细化。实验表明，该框架显著增强了对多尺度物体的适应性，提升了抓取稳定性、多样性和泛化能力，并实现了有效的零样本迁移到真实物体。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2511.09602" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>