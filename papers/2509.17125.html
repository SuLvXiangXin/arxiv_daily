<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Imagine2Act: Leveraging Object-Action Motion Consistency from Imagined Goals for Robotic Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Imagine2Act: Leveraging Object-Action Motion Consistency from Imagined Goals for Robotic Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.17125" target="_blank" rel="noreferrer">2509.17125</a></span>
        <span>作者: Hao Dong Team</span>
        <span>日期: 2025-09-21</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>关系性物体重排任务要求机器人具备精确的语义和几何推理能力。当前主流方法主要有两类：一类是基于预收集演示的三维模仿学习方法，这类方法直接将RGB-D观测映射到机器人动作，但未能显式地对物体间复杂的几何约束进行推理；另一类是利用生成模型产生目标状态观测以捕获语义和几何知识的方法，但这些方法未能显式地将预测的物体变换与预测的机器人动作耦合起来，导致因生成噪声而产生误差。</p>
<p>本文针对现有方法在几何约束推理与动作生成脱节这一具体痛点，提出了通过“想象”目标并学习“物体-动作运动一致性”的新视角。核心思路是：首先利用强大的基础模型生成一个编码了语义和几何约束的“想象”目标点云，作为策略的额外条件输入；进而设计一种物体-动作一致性学习策略，显式地将预测的末端执行器运动与生成的物体变换对齐，从而利用几何先验并避免误差累积。</p>
<h2 id="方法详解">方法详解</h2>
<p>Imagine2Act的整体框架是一个三维模仿学习流程，其核心在于一个离线的语义几何约束生成模块和一个在线训练时使用的物体-动作一致性学习策略。</p>
<p><img src="https://arxiv.org/html/2509.17125v1/x2.png" alt="方法总览"></p>
<blockquote>
<p><strong>图2</strong>：Imagine2Act方法总览。在执行前，语义几何约束生成模块基于初始观测生成想象的点云目标。在训练时，该想象点云作为策略的额外输入。此外，通过引入物体-动作一致性学习，计算初始与想象物体位姿间的变换，该变换作为辅助先验输入并贡献一个损失项，以加强物体变换与末端执行器运动间的强相关性。</p>
</blockquote>
<p><strong>整体流程</strong>：给定初始RGB-D观测 <code>S_0</code> 和语言指令 <code>L</code>，方法首先运行<strong>语义几何约束生成模块</strong>，离线生成一个想象的目标点云 <code>P_G</code> 及其对应的RGB-D观测 <code>S_G</code>。在策略训练时，当前观测 <code>S_t</code> 与想象目标观测 <code>S_G</code> 一同作为视觉输入。同时，从 <code>S_0</code> 和 <code>S_G</code> 中计算出动作物体 <code>O_m</code> 的SE(3)变换 <code>T_obj</code>，编码为<strong>变换令牌</strong>注入策略。策略模型（一个基于扩散的模型）综合视觉令牌、语言令牌、历史动作令牌和变换令牌，预测末端执行器的动作序列。训练目标除了标准的扩散去噪损失，还增加了<strong>软位姿一致性损失</strong>，以对齐预测动作与物体变换 <code>T_obj</code>。</p>
<p><strong>核心模块一：语义几何约束生成</strong>。该模块旨在为零样本泛化提供鲁棒的物体关系先验。具体分为两步：1) <strong>生成目标图像</strong>：利用图像编辑模型（如GPT-Image-1），以初始观测 <code>S_0</code> 和指令 <code>L</code> 为条件，生成一张描绘任务完成场景的想象图像，并保持与初始观测相同的相机视角。2) <strong>重建目标点云</strong>：使用分割模型（如Grounded-SAM）从想象图像中分割出前景物体（动作物体 <code>O_m</code> 和锚定物体 <code>O_s</code>）。背景点云 <code>P_back</code> 直接从初始观测中提取。前景物体则通过三维重建模型（如TripoSR）得到其点云 <code>P_fore</code>。为了将重建的前景点云与真实场景对齐，利用位姿估计算法（如FoundationPose）从初始观测中估计锚定物体 <code>O_s</code> 的6D位姿 <code>T_anchor^pose</code>，并手动设定一个缩放因子 <code>s</code> 构成缩放矩阵 <code>T_anchor^scale</code>。最终，想象目标点云通过公式 <code>P_G = P_back ∪ (T_anchor^pose · T_anchor^scale · P_fore)</code> 组装而成，再被反投影为RGB-D图像 <code>S_G</code> 供策略使用。</p>
<p><strong>核心模块二：物体-动作一致性学习</strong>。该策略旨在显式利用物体运动与末端执行器动作间的强相关性，同时避免生成噪声导致的误差传播。包含两个部分：1) <strong>编码变换令牌</strong>：对从 <code>S_0</code> 和 <code>S_G</code> 中提取的动作物体点云使用刚性配准算法（如Kabsch算法）计算其SE(3)变换 <code>T_obj</code>。将旋转矩阵 <code>R_obj</code> 和平移向量 <code>p_obj</code> 展平后，通过MLP编码为一个单独的变换令牌 <code>τ_T</code>，与其它令牌拼接后输入扩散Transformer。2) <strong>软位姿一致性损失</strong>：该损失仅在机器人已抓取物体后的操纵阶段施加。计算预测动作产生的相对变换 <code>T_act</code> 与物体变换 <code>T_obj</code> 之间的旋转偏差（测地距离θ）和平移偏差（欧氏距离d）。不同于严格的L2损失，本文设计了一个基于阈值的柔性损失：<code>L_soft = E[σ(k_r·(θ-τ_r)) + σ(k_t·(d-τ_t))]</code>，其中σ为sigmoid函数，<code>τ_r≈0.1</code>弧度、<code>τ_t=0.01</code>米为容忍阈值。这意味着只有当预测动作与物体变换的偏差超过阈值时才会产生显著的惩罚，从而允许微小偏差并提高对估计错误的鲁棒性。</p>
<p><strong>最终目标函数</strong>为：<code>L = L_diff + λ_pose * L_soft</code>，其中 <code>L_diff</code> 为标准扩散去噪损失。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在仿真环境RLBench和真实世界进行了评估。RLBench中选取了7个需要高精度操作的关系性物体重排任务（如Put-Plate, Stack-Cups等），采用单视角RGB-D输入，每个任务使用100条演示训练，在25次试验上评估成功率。对比的基线方法包括：3D Diffuser Actor (3DDA)、Imagine Policy 和 3D-LOTUS。</p>
<p><strong>关键实验结果</strong>：</p>
<p><img src="https://arxiv.org/html/2509.17125v1/x1.png" alt="RLBench实验结果表"></p>
<blockquote>
<p><strong>表I</strong>：在RLBench上7个关系物体重排任务的评估结果（成功率）。Imagine2Act平均成功率为0.79，优于所有基线方法。与3DDA和3D-LOTUS相比，分别有0.12和0.10的绝对提升；与同样生成目标的Imagine Policy相比，提升幅度达0.45。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.17125v1/x3.png" alt="实验可视化"></p>
<blockquote>
<p><strong>图3</strong>：RLBench实验可视化。展示了6个关系物体重排任务和2个关节物体操纵任务的初始观测、想象目标点云及执行结果。直观展示了想象目标如何提供几何约束引导。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.17125v1/x4.png" alt="真实世界实验可视化"></p>
<blockquote>
<p><strong>图4</strong>：真实世界实验可视化。展示了初始观测、用黄色箭头标示的所需轨迹、在真实场景中渲染的想象目标点云以及最终操作结果。</p>
</blockquote>
<p><strong>真实世界实验</strong>：在6个高精度重排任务上，Imagine2Act相比3DDA基线，平均成功率从43%提升至68%，绝对提升达25%。</p>
<p><strong>消融实验</strong>：</p>
<p><img src="https://arxiv.org/html/2509.17125v1/x2.png" alt="消融研究表"></p>
<blockquote>
<p><strong>表II</strong>：Imagine2Act的消融研究。Ex0（无想象）作为基础线；Ex1（使用真实目标）提供了性能上界；Ex2（仅使用想象点云）带来初步提升；Ex3（增加变换令牌）和Ex4（增加软位姿损失）进一步改善性能；Ex5（完整方法）达到最佳效果0.79。</p>
</blockquote>
<p>消融实验表明：1) <strong>想象目标生成模块（Ex2）</strong>：仅将其作为额外策略输入，平均成功率从0.67（Ex0）提升至0.72。2) <strong>变换令牌（Ex3）</strong>：在Ex2基础上加入变换令牌，性能提升至0.76。3) <strong>软位姿一致性损失（Ex4）</strong>：在Ex2基础上加入该损失，性能提升至0.75。4) <strong>完整方法（Ex5）</strong>：结合所有组件，达到最优性能0.79。此外，Ex1（使用真实目标）的结果0.74表明，本文生成的想象目标可以很好地逼近拥有完美目标监督的效果。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1) 设计了一个基于强大开源模型的想象目标点云生成模块，能在零样本条件下为策略学习提供鲁棒的语义和几何物体约束。2) 提出了一种物体-动作一致性学习策略，通过注入变换令牌和软位姿一致性损失，显式对齐预测的末端执行器运动与生成的物体变换，有效利用了几何先验并避免了误差累积。3) 在仿真和真实世界的高精度操作任务上均显著超越了之前的先进方法。</p>
<p><strong>局限性</strong>：论文提到的方法依赖于外部基础模型（图像编辑、分割、3D重建），这些模型的性能和误差会直接影响想象目标的生成质量。此外，整个生成流程涉及多个步骤，可能带来较高的计算成本（尽管是在执行前离线完成）。</p>
<p><strong>后续启示</strong>：本文展示了如何将基础模型的强语义、几何先验知识与机器人动作生成进行“紧耦合”式结合的有效范式。未来研究可探索更高效的端到端目标生成方式，或将此一致性学习思想扩展到更复杂的多步、动态任务中。同时，如何降低对多个外部模型的依赖，构建更自洽的系统，也是一个值得探索的方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>Imagine2Act论文针对机器人操作中的关系物体重排任务，解决了现有方法难以耦合物体变换与动作预测、导致生成噪声误差的核心问题。该框架提出3D模仿学习方法，首先生成基于语言指令的想象目标图像并重建3D点云以提供语义和几何先验；进而通过物体-动作一致性策略与软姿态监督，显式对齐预测的末端执行器运动与物体变换。实验在模拟和真实世界中进行，结果表明Imagine2Act优于先前的最优策略。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.17125" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>