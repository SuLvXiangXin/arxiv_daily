<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.09229" target="_blank" rel="noreferrer">2510.09229</a></span>
        <span>作者: Pai Zheng Team</span>
        <span>日期: 2025-10-10</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人遥操作已成为执行复杂、接触丰富操作任务的关键技术，旨在弥合人类灵巧性与机器人精度之间的差距。尽管模仿学习已展现出利用人类演示训练机器人的潜力，但现有遥操作系统在此类场景下面临显著挑战。首先，缺乏视觉以外的多模态反馈（如力和触觉），限制了操作者感知和调整实时力交互的能力，而这对于涉及精细或动态接触的任务至关重要。其次，人与机器人操作器之间的结构差异，以及映射延迟，引入了“具身鸿沟”，使精确控制变得复杂。这些限制导致数据收集效率低下，灵巧操作任务性能不佳。</p>
<p>本文针对上述痛点，提出了一个集成了空间力矩（力-扭矩）反馈与具备指尖霍尔传感器校准功能的触觉手套的新型、低成本、可穿戴遥操作系统——Glovity。其核心思路是通过提供直观的力矩和触觉反馈来克服接触丰富任务中的关键挑战，同时通过精确的映射来缩小具身鸿沟。</p>
<h2 id="方法详解">方法详解</h2>
<p>Glovity系统的整体设计旨在为灵巧操作提供丰富、直观的反馈和优异的映射性能，同时确保低成本、易于复现和组装。系统主要由两个核心模块组成：空间力矩反馈系统和触觉手套。</p>
<p><img src="https://arxiv.org/html/2510.09229v1/figures/wrench.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：力矩反馈系统的结构和四种基本反馈模式示意图。(A) 沿x轴施加的力，引发垂直运动模式。(B) 沿y轴施加的力，驱动水平运动。(C) 沿z轴施加的力，引发前后运动。(D) 绕z轴的扭矩，产生旋转响应。</p>
</blockquote>
<p><strong>1. 空间力矩反馈系统</strong><br>该系统旨在以紧凑、符合人体工程学的设计提供直观的力矩反馈。硬件上，它采用四个高扭矩、快速响应的XL330伺服电机，通过双连杆机构将旋转运动转换为安装在手掌上的固定器的线性位移和旋转。该固定器通过TPU打印的连杆连接，在保持有效力反馈的同时，最大限度地减少对手腕运动的限制。四个伺服电机成对排列在前臂远端的上方和下方，相邻对呈90度角正交放置（如图1所示），以实现紧凑的多方向反馈并优化佩戴舒适性。</p>
<p>其核心是力矩反馈映射算法。该算法根据安装在机器人末端执行器上的力-扭矩传感器获取的实时6维力-扭矩数据，控制伺服电机旋转到相应位置。对于每个伺服电机 i，其目标角度 θ_i 由初始角度和各个力/扭矩分量（f_x, f_y, f_z, τ_z）的贡献加权求和得到。关键创新在于引入了动态系数 c_j_i，该系数根据扭矩-力比值（τ_x/f_y 和 τ_y/f_x）动态调整 f_y 和 f_x 分量的贡献，旨在模拟接触点离手腕远近不同造成的感官差异。算法还采用了动态时间窗滤波来增强稳定性。</p>
<p><strong>2. 触觉手套</strong><br>触觉手套提供了一个低成本、用户友好的灵巧遥操作解决方案。硬件上，它采用了类似乐高积木的模块化组装设计，包含六个IMU模块（五个在指尖，一个在手背）、一个安装在拇指指腹的霍尔传感器（与食指上的磁铁配对）、五个偏心转子电机（ERM）及其驱动、以及一个微控制器。</p>
<p><img src="https://arxiv.org/html/2510.09229v1/figures/teleoperate_pickdog.png" alt="方法框架"></p>
<blockquote>
<p><strong>图6</strong>：触觉手套在抓取玩具狗任务中的用户研究场景。</p>
</blockquote>
<p>其核心算法包括重定向和校准。对于食指到小指，采用融合加速度计和陀螺仪数据的互补滤波器来计算手指弯曲角度，以确保在不同姿势下的鲁棒性。对于拇指，则采用相对角速度法，并辅以<strong>霍尔传感器辅助的指尖校准</strong>。这是该模块的关键创新：霍尔传感器读数随拇指和食指尖接近而增加。系统预设了两个阈值：较低阈值触发校准，较高阈值指示指尖接触。在两个阈值之间，通过线性插值和平滑滤波计算过渡角度，确保灵巧手的指尖姿态与操作者手势匹配。这种基于阈值的方法能够适应不同的用户手型和环境噪声，从而实现薄物体的高效抓取。</p>
<p>此外，系统还兼容Vive Tracker进行高精度手部姿态跟踪，并通过逆运动学实现对手部姿势的低延迟重定向。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验平台采用配备FT300s力-扭矩传感器的UR5e机械臂和Inspire Hand RH56灵巧手。用户研究招募了10名无专业遥操作经验的参与者。</p>
<p><strong>1. 力矩反馈用户研究</strong><br>包含感知实验、遥操作实验和动态案例研究。<br><em>感知实验</em>：测试参与者在不依赖视觉的情况下，识别力方向、力施加区域（8个区域）以及区分力施加于指尖附近还是手腕附近的能力。</p>
<p><img src="https://arxiv.org/html/2510.09229v1/figures/perception.png" alt="感知实验区域"></p>
<blockquote>
<p><strong>图2</strong>：感知实验的力施加区域。蓝色区域对应Level 2的八个不同区域，橙色区域对应Level 3的两个区域。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.09229v1/figures/perceptiontable.png" alt="感知实验结果"></p>
<blockquote>
<p><strong>图3</strong>：三个实验级别的成功率，平均成功率分别为93%、81%和35%。结果表明，系统在识别力方向和大致区域上效果良好，但精确区分指尖与手腕附近的力仍有困难。</p>
</blockquote>
<p><em>遥操作实验</em>：参与者执行翻书任务，比较有/无力矩反馈下的表现。</p>
<p><img src="https://arxiv.org/html/2510.09229v1/figures/teleop_flip.jpg" alt="翻书任务"></p>
<blockquote>
<p>**图4(a)**：翻书任务的遥操作实验场景。</p>
</blockquote>
<p>结果如表I所示，力矩反馈将成功率从48%（24/50）显著提升至78%（39/50），并将平均任务完成时间从17.7秒缩短至11.8秒，减少了约25%。失败案例分析表明，无反馈时更容易因施力过大或滑动而失败。</p>
<p><em>案例研究</em>：操作者仅凭力矩反馈（无视觉）操控机械手悬吊鼠标进行摆动。结果表明，操作者可以成功摆动并调节摆动半径和速度，证明了系统在支持高动态任务方面的潜力。</p>
<p><img src="https://arxiv.org/html/2510.09229v1/figures/mouse2.jpg" alt="动态摆动"></p>
<blockquote>
<p><strong>图5</strong>：动态鼠标摆动案例研究场景。</p>
</blockquote>
<p><strong>2. 触觉手套用户研究</strong><br>参与者执行抓取玩具狗和信封并放入盒子的任务，与AnyTeleop（视觉方法）和Vrtrix手套（商业手套）进行对比。</p>
<p><img src="https://arxiv.org/html/2510.09229v1/figures/evelop.png" alt="信封抓取"></p>
<blockquote>
<p><strong>图7</strong>：抓取信封任务的用户研究场景。</p>
</blockquote>
<p>结果如表II所示。在抓取玩具狗任务中，三种方法性能相当。但在抓取薄信封任务中，Glovity在保持高成功率（82%）的同时，平均完成时间（5.9秒）远短于Vrtrix手套（18.4秒），也略短于AnyTeleop（9.3秒）。Vrtrix手套成功率（34%）大幅下降，主要因其无法精确定位指尖捏合；AnyTeleop则因延迟和捏合检测不稳定导致操作时间延长。</p>
<p><strong>3. 模仿学习实验</strong><br>基于IDP3框架，将RGB图像（经R3M编码）、6维力矩数据以及机器人姿态共同作为观测，训练扩散策略（DP-R3M）。</p>
<p><img src="https://arxiv.org/html/2510.09229v1/figures/IL.png" alt="模仿学习数据流"></p>
<blockquote>
<p><strong>图10</strong>：模仿学习实验中的数据流。</p>
</blockquote>
<p><em>翻书任务</em>：收集30条演示，训练有/无力矩观测的策略。</p>
<p><img src="https://arxiv.org/html/2510.09229v1/figures/bookflip.png" alt="模仿学习翻书"></p>
<blockquote>
<p><strong>图8</strong>：模仿学习翻书任务。机器人需根据接触力判断翻页时机。</p>
</blockquote>
<p>加入力矩数据的策略成功率达到80%（16/20），而无力矩的策略成功率仅为45%（9/20）。消融实验表明，力矩数据对于策略学习动态调整摩擦力和时机至关重要。</p>
<p><em>交接任务</em>：机器人抓取玩具狗并移动到指定位置，需在感知到接收者施加拉力后才释放。</p>
<p><img src="https://arxiv.org/html/2510.09229v1/figures/handover.png" alt="模仿学习交接"></p>
<blockquote>
<p><strong>图9</strong>：模仿学习交接任务。机器人需在感知到来自接收者的力后才释放物体。</p>
</blockquote>
<p>加入力矩数据的策略成功率为75%（15/20），能够可靠地等待人力干预。而无力矩的策略则会过早释放物体。但论文也指出，加入力矩数据后，由于扩散模型的迭代推理过程放大了力传感器读数中的噪声，机器人运动出现了轻微抖动。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>可穿戴空间力矩反馈系统</strong>：设计了一种低成本、紧凑的穿戴式设备，能提供实时、多维的力-扭矩反馈，在接触丰富任务中实现直观的操作调整。</li>
<li><strong>带指尖霍尔校准的触觉手套</strong>：提出了一种集成线性霍尔传感器的触觉手套，通过阈值校准方法显著提高了薄物体抓取的精度。</li>
<li><strong>用于模仿学习的高效演示数据</strong>：展示了Glovity收集高质量演示数据的能力，并将力矩信号融入基于扩散的模仿学习策略，在新型接触丰富任务中实现了鲁棒性能。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ol>
<li>力矩反馈系统在区分手掌上靠近指尖与靠近手腕的施力区域时效果不佳（成功率仅35%）。</li>
<li>在模仿学习任务中，引入力矩观测会导致策略输出的机器人动作产生轻微抖动，可能与扩散模型迭代推理放大传感器噪声有关。</li>
</ol>
<p><strong>启示</strong>：</p>
<ol>
<li><strong>低成本硬件的潜力</strong>：通过巧妙的结构和算法设计，低成本、开源硬件方案同样能在关键性能上媲美甚至超越部分商业系统，降低了灵巧操作研究的门槛。</li>
<li><strong>多模态数据的重要性</strong>：实验证明，力矩反馈不仅能提升遥操作效率，其对应的传感器数据作为观测输入，能极大增强模仿学习策略在接触丰富、需力感知的任务中的适应性和成功率。</li>
<li><strong>硬件与算法协同优化</strong>：Glovity的成功体现了为特定问题（如指尖校准）定制硬件解决方案（霍尔传感器配对）的价值。未来研究可继续探索硬件感知与高级学习算法的深度结合，以解决更复杂的操作问题。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出Glovity，一种低成本可穿戴遥操作系统，旨在解决接触丰富操作任务中缺乏实时力触觉反馈及人机结构差异导致的控制难题。核心方法包括：可穿戴空间力矩反馈装置提供直观力/扭矩反馈；集成指尖霍尔传感器的触觉手套实现精确抓取校准；将力矩信号融入扩散模仿学习（DP-R3M）生成高质量演示数据。实验表明：力矩反馈使书本翻页成功率从48%提升至78%，耗时降低25%；指尖校准显著提高薄物体抓取成功率；结合力矩信号的模仿学习在新接触任务（如翻页、交接）中取得高成功率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.09229" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>