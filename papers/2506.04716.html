<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Learning dissection trajectories from expert surgical videos via imitation learning with equivariant diffusion - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Learning dissection trajectories from expert surgical videos via imitation learning with equivariant diffusion</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.04716" target="_blank" rel="noreferrer">2506.04716</a></span>
        <span>作者: Qi Dou Team</span>
        <span>日期: 2025-06-05</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在机器人学和AI领域，模仿学习已被证明是从专家示范中学习复杂技能的有效途径。然而，在应用于从手术视频中学习解剖轨迹预测这一具体任务时，现有方法面临诸多挑战。首先，未来的解剖轨迹具有固有的不确定性，导致基于确定性映射的显式策略（如行为克隆）倾向于平均所有可能的路径，产生不准确的预测。其次，基于能量模型（EBM）的隐式策略虽然能更好地捕捉多模态分布，但存在训练效率低下（依赖于朗之万动力学）、对数据分布敏感以及性能不稳定等问题。此外，手术场景（如内镜视图）中存在的几何对称性（如平面旋转）未被现有方法明确利用，限制了模型在不同手术情境下的泛化能力。</p>
<p>本文针对从内镜黏膜下剥离术（ESD）专家视频中预测解剖轨迹这一具体任务，提出了一种新的视角：将隐式策略学习与扩散模型及等变表示相结合。核心思路是：1）使用无条件扩散模型来高效地建模复杂的联合状态-动作分布，以捕捉轨迹的不确定性；2）在扩散模型中显式地嵌入旋转等变性，使模型能够泛化到输入状态的几何对称变换；3）设计一种前向扩散引导的动作推理策略，以从训练好的隐式策略中进行条件采样。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的方法名为 iDPOE（Implicit Diffusion Policy with Equivariant Representations for Imitation Learning），旨在从专家视频示范中学习解剖轨迹预测的隐式策略。整体流程包括隐式策略建模与训练，以及基于前向扩散引导的推理两个主要部分。</p>
<p><img src="https://arxiv.org/html/2506.04716v1/x2.png" alt="方法总览"></p>
<blockquote>
<p><strong>图2</strong>：iDPOE方法总览。(a) 展示了隐式策略的建模及其训练过程。我们训练一个带有等变表示的扩散模型来近似联合状态-动作分布。(b) 描绘了使用前向扩散引导进行轨迹预测的推理循环。</p>
</blockquote>
<p><strong>问题定义与隐式策略建模</strong>：任务被形式化为一个模仿学习问题。输入状态 <code>s</code> 是一段长度为 <code>L</code> 的视频帧序列，输出动作 <code>a</code> 是未来 <code>N</code> 步在图像空间上的二维坐标序列，即解剖轨迹。与学习显式映射 <code>a = F_θ(s)</code> 不同，iDPOE 将策略定义为对联合状态-动作密度函数 <code>p_θ(s, a)</code> 的最大化：<code>arg max_{a∈A} p_θ(s, a)</code>。通过最小化学习策略 <code>π_θ(a|s)</code> 与专家示范分布之间的KL散度（等价于最大化联合分布的对数似然）来进行训练。</p>
<p><strong>基于扩散模型的隐式策略学习</strong>：为了高效近似复杂的联合分布，iDPOE 采用无条件扩散模型作为隐式策略。该模型包含一个确定性的前向扩散过程（逐步向数据 <code>x_0 = (s, a)</code> 添加高斯噪声）和一个可学习的反向去噪过程。训练目标简化为一个噪声预测问题，其损失函数结合了对状态噪声和动作噪声的预测误差：<br><code>ℒ_noise(θ) = E_ε,t,x_0[(1-γ)‖ε^a_θ(x_t, t) - ε^a‖ + γ‖ε^s_θ(x_t, t) - ε^s‖]</code><br>其中 <code>γ</code> 是一个权衡权重。网络采用 U-Net 结构处理视频帧特征，并通过 MLP 嵌入层整合轨迹坐标信息，在瓶颈处通过一个 MLP 分支预测轨迹噪声。</p>
<p><strong>状态空间的等变学习</strong>：为了使模型能够泛化到输入状态的几何对称变换（如旋转），iDPOE 将等变性嵌入到扩散模型中。具体地，考虑图像平面上的旋转群 <code>G ⊆ SO(2)</code>，例如离散循环子群 <code>C_n</code>。通过使用等变卷积层构建网络，确保每一层的变换对于群 <code>G</code> 中的操作是等变的。这意味着当输入状态（视频帧）经历旋转 <code>g ∈ G</code> 时，网络预测的轨迹噪声也会发生相应的协同变换，从而使学习到的策略对旋转具有泛化能力。</p>
<p><strong>前向扩散引导的动作推理</strong>：训练得到一个无条件扩散模型（即联合分布 <code>p_θ(s, a)</code>）后，需要从中进行条件采样以得到给定状态 <code>s</code> 下的最优动作 <code>a</code>。直接使用 classifier-free guidance 在视频等高维状态上计算代价高昂。因此，iDPOE 提出了一种前向扩散引导的策略：首先对目标状态 <code>s</code> 进行前向扩散得到带噪声的状态 <code>s_t</code>，然后利用训练好的扩散模型从噪声中联合去噪，恢复出清晰的状态-动作对 <code>(s_0, a_0)</code>。由于模型在训练时学习了 <code>s</code> 和 <code>a</code> 的联合分布，在给定 <code>s_t</code> 的条件下，去噪过程会倾向于生成与 <code>s</code> 一致的动作 <code>a</code>。通过多次迭代此过程，可以获得最终的轨迹预测。</p>
<p><strong>创新点总结</strong>：1) <strong>隐式扩散策略</strong>：用扩散模型替代传统的EBM来学习隐式策略，实现了更高效、稳定的训练，并能更好地建模高维复杂分布。2) <strong>等变表示集成</strong>：在扩散模型中显式嵌入旋转等变性，使模型能自动捕捉和泛化手术场景中的几何对称性，这是现有手术模仿学习方法未充分探索的。3) <strong>前向扩散引导推理</strong>：提出了一种新颖的、无需分类器的条件采样策略，适用于从联合分布模型中高效地进行状态条件化的动作生成。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>数据集与实验设置</strong>：研究使用了一个自行收集的 ESD 手术视频数据集，包含近 2000 个标注了解剖轨迹的视频片段。输入视频帧被调整为 128×128 分辨率，使用连续 5 帧（L=5）来预测未来 10 步（N=10）的轨迹坐标。</p>
<p><strong>对比方法</strong>：与多种先进的模仿学习方法进行了比较，包括：1) <strong>显式策略方法</strong>：Behavior Cloning (BC), Transformer BC；2) <strong>隐式策略方法</strong>：Implicit Behavior Cloning (iBC)，以及两种基于扩散的变体 Diffusion Policy (DP) 和 DDPM-iBC。</p>
<p><strong>评价指标</strong>：主要使用<strong>位置误差</strong>（Prediction Error），即预测轨迹点与真实标注点之间的平均欧氏距离（以像素为单位）。还使用了<strong>动态时间规整</strong>（DTW）距离来评估整个轨迹形状的相似性。</p>
<p><img src="https://arxiv.org/html/2506.04716v1/x3.png" alt="定量结果"></p>
<blockquote>
<p><strong>图3</strong>：不同方法在ESD数据集上的轨迹预测误差（位置误差）和DTW距离对比。iDPOE在所有指标上均取得了最佳性能。</p>
</blockquote>
<p><strong>关键实验结果</strong>：如图3所示，iDPOE 在位置误差和DTW距离上均显著优于所有基线方法。具体而言，iDPOE 的位置误差比次优方法（DP）降低了约 **11.8%**，比原始的隐式方法 iBC 降低了约 **33.7%**。这证明了扩散模型在建模手术轨迹分布上的优势，以及引入等变性的有效性。</p>
<p><img src="https://arxiv.org/html/2506.04716v1/x4.png" alt="消融实验"></p>
<blockquote>
<p><strong>图4</strong>：消融研究结果。从左至右分别评估了：不同隐式策略学习框架（EBM vs. Diffusion）、是否加入等变性（Equivariance）、以及不同推理策略（Classifier-free Guidance vs. 提出的 Forward-diffusion Guidance）的影响。</p>
</blockquote>
<p><strong>消融实验</strong>：图4的消融实验清晰地展示了每个核心组件的贡献：</p>
<ol>
<li><strong>扩散模型 vs. EBM</strong>：使用扩散模型（iDPOE w/o Equiv.）替代 iBC 中的EBM，将误差从 9.82 像素降低到 7.67 像素，证明了扩散模型在效率和稳定性上的优势。</li>
<li><strong>等变性的作用</strong>：在扩散模型基础上加入等变性（iDPOE），误差进一步从 7.67 像素降低到 <strong>6.76 像素</strong>，验证了等变学习对提升泛化能力和预测准确性的关键作用。</li>
<li><strong>推理策略比较</strong>：与使用 classifier-free guidance 的推理方式相比，本文提出的前向扩散引导策略将误差从 7.35 像素降低到 6.76 像素，显示了其在处理高维状态条件采样时的有效性。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.04716v1/x5.png" alt="泛化能力"></p>
<blockquote>
<p><strong>图5</strong>：在旋转增强测试集上的泛化性能。iDPOE 在输入图像发生旋转时，预测误差保持稳定且最低，而其他方法（尤其是非等变方法）的误差显著上升。</p>
</blockquote>
<p><strong>泛化能力分析</strong>：图5测试了模型对输入图像旋转的泛化能力。iDPOE 由于集成了等变性，在不同角度的旋转测试中，预测误差保持稳定且最低。相比之下，其他所有方法（包括未使用等变的扩散模型DP）在输入旋转后误差都大幅增加，这凸显了显式建模几何对称性对于手术场景下鲁棒泛化的重要性。</p>
<p><img src="https://arxiv.org/html/2506.04716v1/x6.png" alt="定性结果"></p>
<blockquote>
<p><strong>图6</strong>：轨迹预测的定性对比。iDPOE 预测的轨迹（红色）与真实轨迹（绿色）最为吻合，且能捕捉到合理的多模态可能性（如图中右下角案例所示的分叉预测），而其他方法预测的轨迹可能偏离较大或过于模糊。</p>
</blockquote>
<p><strong>定性结果</strong>：图6展示了不同方法的预测轨迹可视化。iDPOE 的预测结果与真实轨迹的贴合度最高。特别是在复杂场景下，iDPOE 能够产生合理且多样的轨迹假设（如图中右下案例，预测了两种可能的分支），这得益于其强大的分布建模能力。</p>
<p><img src="https://arxiv.org/html/2506.04716v1/extracted/6514772/Figures/fig_7_R1.png" alt="推理策略分析"></p>
<blockquote>
<p><strong>图7</strong>：前向扩散引导推理过程的迭代可视化。随着去噪迭代次数（Step k）增加，初始的随机噪声轨迹逐渐收敛到与输入状态一致的最优轨迹。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>提出了首个用于手术解剖轨迹预测的隐式扩散策略框架（iDPOE）</strong>，通过扩散模型高效、稳健地学习专家示范中复杂的联合状态-动作分布，解决了传统隐式方法训练慢、不稳定的问题。</li>
<li><strong>将几何等变性显式集成到手术模仿学习中</strong>，使模型能够自动捕捉和泛化内镜视图中的旋转对称性，显著提升了模型在多样手术场景下的泛化能力和预测精度。</li>
<li><strong>设计了一种前向扩散引导的动作推理策略</strong>，实现了从无条件训练的联合扩散模型中高效、准确地进行状态条件化的轨迹采样，避免了在高维状态上使用分类器引导的高计算成本。</li>
</ol>
<p><strong>局限性</strong>：论文提到，尽管在二维图像平面上实现了旋转等变性，但真实手术场景可能涉及更复杂的3D几何变换。此外，扩散模型的采样过程仍涉及多步迭代，在追求极低延迟的实时应用场景中可能存在挑战。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>探索更广泛的对称性</strong>：未来工作可以探索将其他类型的对称性（如尺度、平移或更复杂的3D手术空间变换）纳入等变学习框架。</li>
<li><strong>与其他模态结合</strong>：可以结合术前CT/MRI影像、术中力反馈或其他传感器信息，以提供更全面的上下文，进一步提升轨迹预测的准确性和安全性。</li>
<li><strong>应用于其他手术任务</strong>：该框架可扩展至其他需要从视觉示范中学习复杂、不确定轨迹的手术或机器人操作任务，如缝合、打结等。</li>
<li><strong>优化推理效率</strong>：研究更快的扩散模型采样技术（如蒸馏）或更高效的等变网络结构，以满足实时手术辅助系统的需求。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文研究内镜黏膜下剥离术视频中的解剖轨迹预测问题，旨在通过模仿学习提升手术技能训练效果。针对轨迹预测中的不确定性、几何对称性及泛化性挑战，提出iDPOE方法：通过联合状态-动作分布隐式建模专家行为，引入扩散模型提升策略学习的训练与采样效率，并融合等变表示增强对几何对称性的泛化能力。在包含近2000个片段的ESD视频数据集上验证，该方法在轨迹预测任务中优于现有显式与隐式先进方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.04716" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>