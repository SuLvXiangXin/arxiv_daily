<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Phantom Menace: Exploring and Enhancing the Robustness of VLA Models Against Physical Sensor Attacks - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Phantom Menace: Exploring and Enhancing the Robustness of VLA Models Against Physical Sensor Attacks</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2511.10008" target="_blank" rel="noreferrer">2511.10008</a></span>
        <span>作者: Lu, Xuancun, Chen, Jiaxiang, Xiao, Shilin, Jin, Zizhi, Chen, Zhangrui, Yu, Hanwen, Qian, Bohan, Zhou, Ruochen, Ji, Xiaoyu, Xu, Wenyuan</span>
        <span>日期: 2025/11/13</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-行动（VLA）模型通过整合视觉、听觉等多模态传感器输入，实现了从感知到行动的端到端映射，正在机器人、自动驾驶等领域快速部署。然而，现有关于VLA安全性的研究主要集中于数字领域的攻击，例如针对图像输入的对抗补丁攻击（RoboticAttack）、针对文本模态的LLM越狱攻击（Robotgcg）或后门攻击（BadVLA）。这些方法虽然有效，但未能充分反映物理世界交互中攻击的独特性，例如攻击者直接向摄像头或麦克风注入物理信号（如激光、超声波、电磁干扰）。鉴于VLA系统严重依赖传感器输入，其在物理传感器攻击下的鲁棒性成为一个关键且未被充分探索的痛点。</p>
<p>本文首次对VLA模型面临的物理传感器攻击进行了系统性研究，旨在量化此类攻击的影响并探索防御方法。核心思路是提出一个“Real-Sim-Real”框架，自动模拟基于物理原理的传感器攻击向量，在大规模仿真环境中评估VLA模型的脆弱性，并通过真实机器人实验进行验证，最终提出一种基于对抗训练的防御策略以增强模型鲁棒性。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的“Real-Sim-Real”框架旨在系统且真实地评估和增强VLA模型对物理传感器攻击的鲁棒性。整体流程分为三个阶段：1）从真实世界的物理攻击中提取攻击模式；2）在仿真环境中基于物理原理进行高保真数字模拟并开展大规模评估；3）利用仿真中搜索到的最优攻击参数，在真实机器人系统上进行验证，并实施防御。</p>
<p><img src="https://arxiv.org/html/2511.10008v2/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：“Real-Sim-Real”框架概览。展示了从物理世界攻击到数字模拟，再回到真实世界验证与防御的完整流程。攻击者向摄像头和麦克风注入恶意物理信号（如激光、超声波），框架旨在评估其影响并提升VLA模型的鲁棒性。</p>
</blockquote>
<p>核心模块是八种物理传感器攻击的模拟与一种防御策略：</p>
<ol>
<li><strong>攻击模拟</strong>：论文选取了八种来自顶级安全会议的典型物理传感器攻击进行模拟，包括六种摄像头攻击和两种麦克风攻击。<ul>
<li><strong>麦克风攻击</strong>：<ul>
<li><strong>语音拒绝服务（Voice DoS）</strong>：通过注入高强度超声波使麦克风 transducer 或放大器饱和。模拟方法是将真实录制到的恶意噪声信号叠加到原始音频指令上。</li>
<li><strong>语音欺骗（Voice Spoofing）</strong>：通过调制激光或超声波向麦克风注入特定的恶意语音指令。模拟方法是将生成的恶意语音信号作为后缀附加到原始语音信号后。</li>
</ul>
</li>
<li><strong>摄像头攻击</strong>：<ul>
<li><strong>激光致盲（Laser Blinding）</strong>：模拟高功率激光使摄像头感光元件饱和。方法是将记录的激光攻击模式线性叠加到原始图像上，通过调整权重控制强度。</li>
<li><strong>光投影（Light Projection）</strong>：模拟通过投影仪向环境或镜头投射伪造图像。方法是将记录的投影攻击模式叠加到原始图像上，并调整权重和位置。</li>
<li><strong>激光色条（Laser Color Strip）</strong>：利用摄像头CMOS传感器的滚动快门效应，通过开关调制激光注入彩色条纹。采用原攻击论文的方法进行模拟，通过改变RGB颜色百分比和权重调整强度。</li>
<li><strong>电磁色条与电磁截断（EM Color Strip &amp; EM Truncation）</strong>：模拟电磁干扰（EMI）导致图像传输错误。通过控制紫色条纹的位置、宽度、数量以及图像的截断位置来模拟不同强度。</li>
<li><strong>超声模糊（Ultrasound Blur）</strong>：模拟超声波引起摄像头防抖模块（IMU）共振，导致算法误补偿而产生图像模糊。模拟三种模糊模式（线性、径向、旋转），并通过调整模糊幅度控制强度。</li>
</ul>
</li>
</ul>
</li>
<li><strong>防御策略</strong>：提出一种基于对抗训练的防御方法。首先在无攻击的干净数据集上训练VLA模型，然后以一定比例混入包含各种传感器攻击的数据集进行对抗训练，旨在使模型对分布外的物理扰动具有鲁棒性，同时保持其在干净数据上的性能。</li>
</ol>
<p><img src="https://arxiv.org/html/2511.10008v2/x2.png" alt="VLA架构"></p>
<blockquote>
<p><strong>图2</strong>：VLA模型架构与流程。VLA模型由视觉语言模型（VLM）和动作解码器组成。VLM通过视觉编码器和文本编码器处理图像和文本（来自语音识别），生成多模态嵌入，再由LLM主干生成动作令牌。动作解码器（如直接解码、MLP映射、扩散解码或流匹配解码）将这些令牌转换为具体的机器人动作。</p>
</blockquote>
<p>本文的创新点具体体现在：1) <strong>研究视角创新</strong>：首次系统性地将物理传感器攻击引入VLA模型的安全性评估，关注分布外（Out-of-Distribution）鲁棒性，而非此前工作关注的数字攻击或光照、模糊等分布内扰动；2) <strong>评估框架创新</strong>：提出“Real-Sim-Real”框架，弥合了纯数字仿真与高成本物理实验之间的鸿沟，实现了高效、可扩展的大规模评估；3) <strong>防御方法创新</strong>：针对物理传感器攻击这种新型威胁，验证了对抗训练作为一种有效防御策略的可行性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>仿真平台与数据集</strong>：使用Libero视觉语言机器人仿真器及其四个数据集：Libero-Spatial（空间配置变化）、Libero-Object（物体识别与操纵）、Libero-Goal（目标指令变化）、Libero-Long（长时程规划）。</li>
<li><strong>评估模型</strong>：选择了四种代表性的VLA模型：OpenVLA、OpenVLA-OFT、π0和π0-fast。</li>
<li><strong>对比基线</strong>：以各模型在无攻击（Baseline）下的任务成功率（TSR）为基准，对比其在八种攻击、三种强度（弱、中、强）下的性能。</li>
<li><strong>攻击参数</strong>：如表1所示，为每种攻击的三种强度设定了具体参数（如叠加权重、条纹数量、截断比例、模糊标准差）。</li>
<li><strong>真实实验</strong>：使用搭载两个摄像头和一个麦克风的Franka Panda机械臂作为目标系统，验证仿真中找到的最优攻击参数。</li>
</ul>
<p><img src="https://arxiv.org/html/2511.10008v2/x3.png" alt="攻击示例"></p>
<blockquote>
<p><strong>图3</strong>：八种传感器攻击的模拟示例。包括六种摄像头攻击（激光致盲、光投影、激光色条、电磁色条、电磁截断、超声模糊）和两种麦克风攻击（语音DoS、语音欺骗）。每种攻击从左至右强度递增（弱、中、强）。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>物理传感器攻击对VLA模型有效</strong>：如表2所示，所有VLA模型在传感器攻击下均表现出脆弱性。在强攻击或长时程任务（Libero-Long）中，模型性能常发生灾难性下降。例如，OpenVLA在强激光致盲攻击下，在所有数据集上的TSR均降至0%；而相对鲁棒的OpenVLA-OFT在强超声模糊攻击下的Libero-Object任务TSR也从98.4%骤降至9.4%。</li>
<li><strong>攻击影响具有差异性</strong>：<ul>
<li><strong>攻击类型</strong>：激光致盲、电磁截断、超声模糊等破坏关键视觉特征的攻击影响最严重；而光投影、激光色条等注入扰动的攻击影响相对较小。</li>
<li><strong>任务类型</strong>：需要理解多变指令的Libero-Goal数据集对语音DoS攻击最敏感（指令被淹没）；而场景-指令对应的数据集（如Spatial）中，模型可从视觉上下文推断指令，受语音DoS影响较小。</li>
<li><strong>模型架构</strong>：不同VLA模型对同类攻击的鲁棒性差异显著。例如，对于语音欺骗攻击，OpenVLA-OFT的TSR暴跌至接近0%，而π0-fast则保持了较高性能。</li>
</ul>
</li>
<li><strong>对抗训练防御有效</strong>：如表3所示，经过对抗训练（AT）后，VLA模型在面对中等强度攻击时，TSR普遍得到提升或下降幅度减小，同时其在干净数据集（AT Baseline）上的性能基本得以维持。这证明了该防御策略能在增强分布外鲁棒性的同时，不牺牲模型原有性能。</li>
</ol>
<p><img src="https://arxiv.org/html/2511.10008v2/x4.png" alt="真实实验设置"></p>
<blockquote>
<p><strong>图4</strong>：真实世界实验设置。攻击目标是一个配备腕部摄像头、全局摄像头和麦克风的Franka Panda机械臂。攻击设备包括EMI平台、投影平台、激光平台和超声波平台。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2511.10008v2/x5.png" alt="真实攻击后果"></p>
<blockquote>
<p><strong>图5</strong>：真实世界攻击后果示例。展示了在物理传感器攻击下，VLA机器人系统执行任务失败的情况，直观验证了仿真评估发现的漏洞在现实世界中确实存在。</p>
</blockquote>
<p><strong>消融实验总结</strong>：论文通过设置弱、中、强三种攻击强度（见表1及图3），系统性地消融分析了攻击强度对模型性能的影响。结果（表2）清晰表明，随着攻击强度增加，所有模型的TSR普遍呈下降趋势，尤其是在强攻击下性能崩溃最为严重，这量化了攻击强度与危害程度之间的正相关关系。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>漏洞验证</strong>：首次通过系统性的仿真与真实实验，证实了VLA模型在面对物理传感器攻击时存在严重的安全漏洞，其在真实部署中可能因此产生错误行为。</li>
<li><strong>评估框架</strong>：提出了创新的“Real-Sim-Real”框架，为高效、大规模地评估VLA模型对物理传感器攻击的鲁棒性提供了标准化工具，架起了数字仿真与物理实验之间的桥梁。</li>
<li><strong>防御策略</strong>：提出并验证了一种基于对抗训练的防御方法，能够有效提升VLA模型对分布外物理扰动的鲁棒性，且不损害其正常性能。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，其仿真虽然基于高保真物理原理，但与真实物理世界之间仍可能存在差距。此外，所提出的对抗训练防御的有效性可能依赖于特定的攻击集和训练数据比例，其普适性和对未知攻击的泛化能力有待进一步研究。</p>
<p><strong>研究启示</strong>：</p>
<ol>
<li><strong>标准化需求</strong>：这项工作凸显了为VLA模型建立针对物理传感器攻击的标准化鲁棒性基准的迫切性，以指导更安全的模型开发与评估。</li>
<li><strong>跨模态防御</strong>：攻击的影响因任务和模态交互方式而异，启示后续研究需要开发更细粒度的、考虑跨模态依赖关系的防御机制。</li>
<li><strong>传感器安全</strong>：除了在算法层面提升鲁棒性，也需从硬件和传感器设计层面考虑如何抵御物理信号注入攻击，形成端到端的防御体系。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对视觉-语言-动作（VLA）模型在物理传感器攻击下的脆弱性展开研究。提出了“Real-Sim-Real”框架，能自动模拟针对摄像头（六种）和麦克风（两种）的物理攻击向量，并在真实机器人系统上验证。通过大规模评估，揭示了VLA模型在不同任务和架构下的显著漏洞。进一步提出了一种基于对抗训练的防御方法，能在保持模型性能的同时，有效增强其对传感器攻击引发的分布外物理扰动的鲁棒性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2511.10008" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>