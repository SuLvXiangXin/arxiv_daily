<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Seeing, Saying, Solving: An LLM-to-TL Framework for Cooperative Robots - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Seeing, Saying, Solving: An LLM-to-TL Framework for Cooperative Robots</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.13376" target="_blank" rel="noreferrer">2505.13376</a></span>
        <span>作者: Choe, Dan BW, Sangeetha, Sundhar Vinodh, Emanuel, Steven, Chiu, Chih-Yuan, Coogan, Samuel, Kousik, Shreyas</span>
        <span>日期: 2025/05/19</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在多机器人系统（如仓库）中，异构机器人团队需要协作以解决不可预见的冲突。当前，视觉语言模型（VLM）凭借其场景理解和异常检测能力，为冲突检测提供了潜在解决方案。然而，VLM生成的计划无法提供安全性保证，这在人机共享的安全关键环境中是主要问题。另一方面，形式化方法（如信号时序逻辑STL）能够为机器人计划提供满足约束的保证，但如何将这些方法与基础模型的推理能力无缝集成，以实现安全的多智能体协调，仍然是一个开放性问题。</p>
<p>现有工作要么使用基础模型进行冲突检测和推理但不提供形式化保证，要么将VLM用于单智能体的时空导航命令落地。本文针对“如何将形式化方法与基础模型推理集成，以实现安全、无缝的多智能体协作”这一具体痛点，提出了一种新的视角：让机器人通过自然语言（利用大语言模型LLM）进行求助与提供帮助的通信，同时利用STL对帮助计划进行形式化验证，以保证安全性和可行性。本文的核心思路是：提出一个去中心化的“LLM到TL（时序逻辑）”框架，使机器人能够通过自然语言通信请求和提供帮助，并利用STL语法约束和求解来保证帮助计划的安全性与最优性，从而最小化对系统整体任务时间的影响。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的框架是一个去中心化的多机器人协作流程。整体流程始于一个机器人（<strong>请求者</strong>）检测到自身无法解决的冲突。框架包含以下几个核心阶段：1) 请求者生成并广播自然语言求助请求；2) 潜在帮助者机器人评估请求并生成包含能力与时间影响的帮助提议；3) 帮助者将自然语言提议转换为STL规范并求解最优路径；4) 请求者选择总体时间成本最低的帮助者并确认。</p>
<p><img src="%E5%9B%BE%E7%89%87URL%E6%9C%AA%E5%9C%A8%E6%8F%90%E4%BE%9B%E5%86%85%E5%AE%B9%E4%B8%AD%E7%9B%B4%E6%8E%A5%E7%BB%99%E5%87%BA%EF%BC%8C%E8%AE%BA%E6%96%87%E4%B8%AD%E5%BA%94%E4%B8%BALABEL:fig:overall_framework" alt="方法框架图"></p>
<blockquote>
<p><strong>图1</strong>：方法整体框架。左侧展示了请求者机器人利用VLM检测冲突，并通过LLM生成求助请求；右侧展示了帮助者机器人接收请求，通过LLM生成帮助提议，利用BNF语法约束将其转换为STL规范，并通过求解混合整数线性规划（MILP）得到最优路径，最后将包含时间成本的提议回复给请求者。</p>
</blockquote>
<p>核心模块一：<strong>自然语言通信协议</strong>。该模块利用LLM实现机器人间的三种消息交互。首先，请求者机器人根据冲突描述 $(m^{\mathrm{\textnormal{c}}}, x^{\mathrm{\textnormal{c}}}, \tau^{\mathrm{\textnormal{c}}})$ 和自身能力 $c_i$，在提示 $p^{\mathrm{\textnormal{c}}}$ 下通过自然语言推理（NLR）生成广播求助请求 $m_{i\to\mathcal{H}<em>i}^{\mathrm{\textnormal{r}}}$，其中使用约束生成确保包含冲突位置和请求者能力信息。其次，每个潜在帮助者机器人 $j$ 根据收到的求助请求、自身位置 $x_j$ 和能力 $c_j$，在提示 $p^{\mathrm{\textnormal{h}}}$ 下生成发送给请求者的帮助提议 $m</em>{j\to i}^{\mathrm{\textnormal{o}}}$，该提议包含其提供帮助所需时间 $\tau^{\mathrm{\textnormal{h}}}_j$ 以及相较于原任务的额外时间 $\tau^{\mathrm{\textnormal{new}}}_j$。最后，请求者选择总成本 $(\tau^{\mathrm{\textnormal{h}}}_j+\tau^{\mathrm{\textnormal{new}}}_j)$ 最小的帮助者 $j^\star$，并向其发送“接受”消息，向其他帮助者发送“拒绝”消息。</p>
<p>核心模块二：<strong>自然语言到时序逻辑（NL-to-STL）的转换</strong>。此模块旨在将帮助者生成的自然语言帮助提议 $m_{j\to i}^{\mathrm{\textnormal{o}}}$ 转换为可执行的STL规范 $\varphi_j^{\mathrm{\textnormal{h}}}$。创新点在于使用巴科斯-诺尔范式（BNF）语法来约束LLM的输出。通过定义一个包含STL一元/二元时序/布尔运算符、允许的谓词以及时序逻辑关系文本表示的BNF语法，并将其作为提示 $p^{\mathrm{\textnormal{STL}}}$ 的一部分和生成时的约束，可以保证LLM输出的STL公式在语法上是有效的，从而能够直接输入给STL求解器。转换过程表示为：$\varphi_j^{\mathrm{\textnormal{h}}} \leftarrow \operatorname{NLR}(m_{j\to i}^{\mathrm{\textnormal{o}}}, x^{\mathrm{\textnormal{c}}} \mid p^{\mathrm{\textnormal{STL}}}, \operatorname{BNF})$。</p>
<p>核心模块三：<strong>最优路径求解</strong>。该模块为帮助者机器人生成既能完成原任务又能提供帮助的最优路径。假设帮助者机器人 $j$ 已有原任务STL规范 $\varphi_j^{\mathrm{\textnormal{orig}}}$ 及其对应最优路径 $X_j^{\mathrm{\textnormal{orig}}}$（通过最小化曼哈顿距离 $D(X)$ 和完工时间 $T(\varphi_j^{\mathrm{\textnormal{orig}}})$ 得到）。在获得帮助任务STL规范 $\varphi_j^{\mathrm{\textnormal{h}}}$ 后，机器人需要求解一个新的路径 $X_j^{\mathrm{\textnormal{new}}}$，其对应的新规范为 $\varphi_j^{\mathrm{\textnormal{new}}} = \Diamond\varphi_{j}^{\mathrm{\textnormal{h}}} \land \Diamond\varphi^{\mathrm{\textnormal{orig}}}_{j} \land \Box\varphi^{\mathrm{\textnormal{g}}}$（即最终要满足帮助任务和原任务，并始终满足全局约束）。优化目标是最小化路径距离、新任务完工时间以及帮助任务本身的持续时间 $T(\varphi^{\mathrm{\textnormal{h}}}_j)$（此项是为了最小化请求者的等待时间）。公式(4)和(5)被表述为混合整数线性规划（MILP）问题并使用Gurobi求解。最终，帮助者计算出 $\tau^{\mathrm{\textnormal{h}}}_j = T(\varphi^{\mathrm{\textnormal{h}}}_j)$ 和 $\tau^{\mathrm{\textnormal{new}}}_j = T(\varphi^{\mathrm{\textnormal{new}}}_j) - T(\varphi^{\mathrm{\textnormal{orig}}}_j)$ 并放入帮助提议中。</p>
<p><img src="https://arxiv.org/html/2505.13376v1/extracted/6439812/figures/example_path.png" alt="路径示例"></p>
<blockquote>
<p><strong>图1</strong>：重新配置路径的示例。帮助者在11个时间步后到达帮助地点，使原始路径延长了4个时间步，总成本 $\tau^{\mathrm{\textnormal{h}}}_j+\tau^{\mathrm{\textnormal{new}}}_j = 15$ 个时间步。</p>
</blockquote>
<p>与现有方法相比，本文的创新点具体体现在：1) 提出了一个完整的、去中心化的、结合LLM自然语言交互与STL形式化验证的机器人协作框架；2) 使用BNF语法约束LLM输出，<strong>保证</strong>了从自然语言到STL转换的语法有效性，这是实现形式化验证的前提；3) 在路径求解中同时优化系统总时间影响和请求者等待时间，并通过通信协议实现了基于全局成本评估的帮助者选择。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验平台与数据集</strong>：实验在仿真中进行。使用了两个主要实验：1) NL到TL转换实验，使用[wang2021learning]提出的包含7500个自然语言与线性时序逻辑（LTL）对的数据集（导航任务上下文），评估模型为Gemma 3 27B LLM（使用llama.cpp库进行BNF约束生成）。2) 案例研究：模拟仓库场景，一个移动机器人被托盘阻挡，向多个叉车机器人求助。</p>
<p><strong>对比的Baseline方法</strong>：在实验1中，对比了以下方法变体：Gemma (F+P+C，即本文方法：少量示例+语法提示+语法约束)、Gemma (F+P：仅提示语法)、Gemma (F：仅少量示例)、以及GPT-4 (F+P)和GPT-4 (F)基线（来自[chen2023nl2tl]）。在实验2中，比较了请求者选择帮助者的不同策略：本文的“最小总时间影响”策略与“选择最近的帮助者”启发式策略。</p>
<p><strong>关键实验结果</strong>：<br>实验1（NL到TL转换）结果总结于表I。本文方法（Gemma F+P+C）在5个和20个少量示例下，均实现了<strong>100%的公式有效性</strong>，验证了BNF约束生成的保证作用。在翻译准确率方面，使用20个示例时，本文方法达到76.73% ± 2.93%，虽然低于同模型下未加约束的变体（89.73%）和GPT-4 F+P（92.73%），但这是在<strong>使用小得多的、可部署在机器人上的LLM（Gemma 3）且保证100%语法有效性</strong>的前提下取得的。结果表明，约束生成虽然保证了有效性，但可能在一定程度上限制了LLM的灵活性，影响了准确率。</p>
<p>实验2（仓库案例研究）的关键结果以箱线图展示。实验模拟了不同数量的初始叉车任务（1-4个）和不同帮助者选择策略。</p>
<p><img src="https://arxiv.org/html/2505.13376v1/extracted/6439812/figures/box_plot.png" alt="箱线图结果"></p>
<blockquote>
<p><strong>图2</strong>：不同帮助者选择策略下，系统总时间增加量的箱线图。结果表明，与简单的“选择最近机器人”启发式方法相比，本文提出的“最小化总时间影响”策略能够显著降低系统总体的时间成本。</p>
</blockquote>
<p><strong>消融实验总结</strong>：实验1本身就是一个系统的消融研究，如表I所示。它分离并评估了少量示例提示（F）、在提示中包含BNF语法（P）以及使用BNF语法约束生成（C）每个组件的贡献。核心结论是：<strong>组件C（语法约束）是实现100%语法有效性的关键</strong>；组件P（语法提示）能显著提升翻译准确率；而当同时使用P和C时，约束生成（C）可能会对仅使用提示（P）已达到的高准确率产生一定的限制。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：1) 提出了一种将自然语言任务描述转换为时序逻辑规范的方法，该方法利用BNF语法约束LLM输出，<strong>保证了生成的时序逻辑公式的语法有效性</strong>。2) 通过将STL求解与LLM推理结合，为LLM智能体赋予了空间和时间推理能力，从而向实现形式化方法的保证迈出了一步。3) 提出了一个完整的、去中心化的LLM-to-TL框架，并在仿真实验中验证了其相较于简单启发式方法在最小化系统总时间影响方面的有效性。</p>
<p>论文自身提到的局限性：在NL到TL的转换实验中，虽然约束生成保证了100%的有效性，但同时也可能降低了翻译的准确率（对比Gemma F+P与Gemma F+P+C的结果）。作者指出，解决此问题是当前研究的一个方向，例如提出新的约束解码算法。</p>
<p>对后续研究的启示：本文为融合基础模型的灵活性与形式化方法的严谨性提供了一个可行的框架范式。后续工作可以探索更高效的约束解码算法以平衡有效性与准确性；可以将框架扩展到连续空间或更复杂的动态环境；此外，如何将VLM更深度地集成到冲突检测与场景理解的闭环中，也是一个值得深入的方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对异构机器人团队在动态仓库环境中协作时，因冲突导致效率低下且需人工干预的问题，提出了一种去中心化的协作框架。其核心是“Seeing, Saying, Solving”流程：机器人首先利用视觉语言模型（VLM）检测冲突，通过大型语言模型（LLM）生成自然语言求助请求；潜在帮助者则通过一个基于信号时序逻辑（STL）的LLM进行推理，该LLM使用巴科斯-诺尔范式（BNF）语法确保从自然语言到STL的语法正确转换，并最终将问题转化为混合整数线性规划（MILP）求解。实验表明，请求机器人通过综合评估多个帮助提议（而非仅选择最近机器人），能有效最小化对系统整体任务时间的负面影响。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.13376" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>