<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>LaST $_{0}$ : Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>LaST $_{0}$ : Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.05248" target="_blank" rel="noreferrer">2601.05248</a></span>
        <span>作者: Shanghang Zhang Team</span>
        <span>日期: 2026-01-08</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作模型通过整合预训练视觉语言模型的语义理解能力与机器人策略的低级控制能力，展现出强大的泛化性能。该领域的主流方法主要分为两类：一是受大语言模型中思维链启发，显式生成语言推理轨迹或功能表示以增强操作稳定性和可解释性；二是通过预测未来状态来捕获环境动态。然而，这些显式推理方法面临两个关键局限性：首先，自回归生成范式会带来不可避免的计算开销，导致显著的推理延迟，限制了模型实现实时响应的能力，并削弱了闭环操作所需的时间一致性；其次，显式推理通常局限于语言空间，形成了一个表示瓶颈，难以忠实捕捉难以言表的物理属性（如精细的几何结构、动态物理交互）。</p>
<p>本文针对上述痛点，提出了在紧凑的潜在空间中进行推理的新视角。具体而言，本文提出了LaST₀框架，旨在通过一种潜在的时空思维链，实现高效的“先推理后行动”行为。其核心思路是：构建一个令牌高效的潜在CoT空间，自回归地建模未来的视觉动态、3D结构信息和机器人本体感知状态，并通过一个双系统架构（混合专家设计）来协调低频的潜在推理与高频的动作生成，从而在捕获难以言表的细粒度物理和机器人动态的同时，实现实时机器人操控。</p>
<h2 id="方法详解">方法详解</h2>
<p>LaST₀的整体框架是一个统一的VLA模型，采用双系统架构，通过混合专家方案实现。如图2所示，模型包含两个通过共享自注意力机制交互的专家：一个运行在低频的“慢推理专家”负责构建潜在时空CoT；一个运行在高频的“快行动专家”负责基于高频观测和周期性更新的潜在表示生成动作。</p>
<p><img src="https://arxiv.org/html/2601.05248v2/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：LaST₀框架总览。a) 提出的具有双系统架构的统一VLA模型，通过混合专家方案实现，包含慢推理专家和快行动专家。b) 设计的时空潜在空间，其中预训练的模态特定编码器从未来的RGB图像、点云和机器人状态中提取特征，作为监督推理专家的真实潜在CoT目标。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>视觉编码器</strong>：使用SigLIP-Large从输入的RGB观测中提取语义特征。</li>
<li><strong>点云编码器（仅训练时使用）</strong>：使用预训练的Uni3D编码器从未来点云中提取3D几何特征，作为潜在CoT的监督目标，推理时不使用。</li>
<li><strong>混合专家LLM骨干网络</strong>：以DeepSeek-LLM 1.5B为基础，将其24层解码器架构转化为MoT架构。两个专家共享全局自注意力上下文，但拥有各自的任务特定参数集（如前馈网络、注意力投影、层归一化）。</li>
<li><strong>MLP组件</strong>：包括用于对齐点云特征的3D投影器，以及用于流匹配策略的时序MLP、加噪动作MLP和投影器MLP。</li>
<li><strong>潜在时空思维链构建</strong>：这是方法的核心创新。对于未来H个时间步，模型从三个模态构建紧凑的潜在表示：使用SigLIP编码的未来RGB帧视觉潜在<code>z_k^v</code>、使用Uni3D编码的未来点云几何潜在<code>z_k^p</code>、以及通过动作标记器转换的未来机器人状态本体感知潜在<code>z_k^s</code>。每个模态的特征图通过平均池化压缩为单个令牌。这些令牌按时间顺序交错排列，形成真实潜在序列<code>Z_GT</code>，以保留因果物理依赖关系并鼓励跨模态耦合动态学习。推理时，慢推理专家自回归地生成这些潜在嵌入。</li>
<li><strong>双系统协调机制</strong>：如图3所示，引入异步频率机制。慢推理专家仅在稀疏的关键帧（<code>t mod κ = 0</code>）被激活进行潜在CoT推理；快行动专家则在每个控制时间步都运行，并以前一次推理输出的潜在表示和当前高频观测为条件生成动作。这种设计使得高频动作生成能够利用低频推理捕获的时空依赖关系。</li>
</ol>
<p><img src="https://arxiv.org/html/2601.05248v2/x3.png" alt="异步频率协调"></p>
<blockquote>
<p><strong>图3</strong>：双系统协调示意图。推理专家执行低频潜在CoT推理以捕获时空依赖性，而快行动专家则基于高频观测和周期性更新的潜在知识生成动作。</p>
</blockquote>
<p><strong>与现有方法的创新点</strong>：</p>
<ul>
<li><strong>潜在推理空间</strong>：不同于显式生成语言或图像，LaST₀在紧凑的潜在空间中进行推理，该空间联合编码了语义意图、几何结构和机器人状态，能更高效、更丰富地表示难以言表的物理动态。</li>
<li><strong>异步频率协调</strong>：通过MoT架构和异步更新策略，创新地将低频、深度的规划推理与高频、响应的动作控制解耦并协调，在保持高性能的同时大幅提升了推理速度。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准/数据集</strong>：在模拟环境中使用RLBench的10个任务进行评估；在真实世界中评估了10个复杂任务，涵盖桌面单/双臂、移动和灵巧手操作。</li>
<li><strong>实验平台</strong>：模拟实验在CoppeliaSim中进行，使用Franka Panda机械臂；训练使用8张NVIDIA A800 GPU。</li>
<li><strong>对比的基线方法</strong>：OpenVLA、SpatialVLA、CogACT、CoT-VLA、π₀.₅、HybridVLA。</li>
</ul>
<p><strong>关键实验结果</strong>：<br>在RLBench模拟实验中，LaST₀取得了平均82%的成功率，显著优于其他基线。</p>
<p><img src="https://arxiv.org/html/2601.05248v2/x1.png" alt="实验结果表"></p>
<blockquote>
<p><strong>表1</strong>：LaST₀与基线方法在RLBench上的对比结果。LaST₀取得了最高的平均成功率（82%），并且在10个任务中的7个上表现最佳。其推理速度达到15.4 Hz，远超显式CoT方法（CoT-VLA的1.1 Hz）。</p>
</blockquote>
<p>在真实世界任务中，LaST₀在桌面、移动和灵巧手操作三个场景下的平均成功率分别比之前的SOTA VLA方法提高了13%、14%和14%。同时，推理速度比之前的显式CoT VLA方法提升了14倍。</p>
<p><strong>定性分析</strong>：<br><img src="https://arxiv.org/html/2601.05248v2/x4.png" alt="注意力热力图"></p>
<blockquote>
<p><strong>图4</strong>：最后一层的注意力热力图可视化对比。与无CoT的变体以及显式CoT方法（CoT-VLA）相比，LaST₀（带LaST CoT）对操作物体和机器人表现出高度集中的注意力模式，显示了其优越的时空理解能力。</p>
</blockquote>
<p><strong>消融实验总结</strong>：<br><img src="https://arxiv.org/html/2601.05248v2/x5.png" alt="消融实验"></p>
<blockquote>
<p><strong>图5</strong>：LaST₀关键设计选择的消融研究结果。a) 每个潜在模态（图像、点云、机器人状态）都对性能有贡献，组合使用效果最佳。b) 为每个潜在模态分配1个令牌是效率与性能的最佳平衡点。c) 潜在推理覆盖4个未来关键帧时性能最佳。d) 在训练中混合使用不同的快慢操作频率（如1:4）能使模型在推理时更鲁棒。</p>
</blockquote>
<p>消融实验验证了各核心组件的贡献：</p>
<ol>
<li><strong>多模态潜在表示</strong>：图像、点云和机器人状态每个模态单独使用都能提供较强的性能基础，三者结合带来额外增益。</li>
<li><strong>令牌效率</strong>：每个模态使用1个令牌是计算开销与表示能力的最佳权衡。</li>
<li><strong>时间覆盖范围</strong>：潜在推理覆盖未来4个关键帧时性能达到峰值。</li>
<li><strong>混合频率训练</strong>：在监督微调阶段用随机的快慢操作比例训练动作专家，提高了模型在部署时对不同推理更新频率的适应性和鲁棒性。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了LaST₀，一个通过<strong>潜在时空思维链</strong>实现高效“先推理后行动”的统一VLA模型，能够在紧凑的潜在空间中捕获难以言表的细粒度物理和机器人动态。</li>
<li>设计了一种<strong>双系统VLA架构</strong>（通过混合专家实现），协调低频潜在推理与高频动作生成，实现了实时机器人操控。</li>
<li>在广泛的模拟和真实世界机器人任务上验证了方法的有效性，在显著提升性能（平均成功率最高提升21%）的同时，实现了比显式CoT方法快14倍的推理速度。</li>
</ol>
<p><strong>局限性</strong>：<br>论文提到，点云编码器（Uni3D）仅在训练时用于提供监督信号，在推理时并不使用。这暗示了模型在部署时依赖于2D视觉输入来隐式地推理3D几何，可能在某些对精确3D感知要求极高的任务中存在挑战。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>潜在推理的扩展</strong>：LaST₀展示了在非语言潜在空间中进行推理的有效性，未来可以探索更丰富或更结构化的潜在表示（如物理启发的表示）来进一步提升物理交互的理解和预测。</li>
<li><strong>高效架构探索</strong>：混合专家与异步频率协调的设计为构建兼具深度规划和实时响应能力的具身智能体提供了有价值的架构范式，可被应用于其他需要分层决策的控制问题。</li>
<li><strong>训练策略</strong>：混合操作频率的训练策略表明，让模型在训练阶段适应不同的决策节奏，可以增强其在部署时的灵活性和鲁棒性，这一思路可推广至其他动态系统。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人视觉-语言-动作模型中显式推理导致的高延迟和语言表示瓶颈问题，提出LaST0框架。其核心是潜在时空思维链，在隐式空间建模未来视觉动态、3D结构及本体状态，并采用混合Transformer的双系统架构，协调低频推理与高频动作生成。在10个真实世界任务中，LaST0相比先前方法将平均成功率提升13%、14%和14%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.05248" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>