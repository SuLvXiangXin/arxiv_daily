<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.20085" target="_blank" rel="noreferrer">2508.20085</a></span>
        <span>作者: Huazhe Xu Team</span>
        <span>日期: 2025-08-31</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>目前，利用人类运动数据赋予机器人灵巧操作技能是一个有前景的范式。主流方法包括从视频中提取人类手部轨迹并应用于机器人，但主要针对简单的平行夹爪，难以泛化到具有高维复杂动作空间的灵巧手。另一些方法使用运动学重定向生成类人运动，但忽略了手与物体交互的物理建模，导致无法产生物理上可行的机器人动作。近期工作开始使用强化学习在运动学参考轨迹引导下探索可行策略，但通常依赖有限的人类数据源，且缺乏向物理世界迁移的方案，或严重依赖显式的物体和机器人状态信息，无法实现端到端的视觉学习，限制了策略在不同场景下的适应性。此外，现有方法缺乏在非结构化环境中的自主移动操作能力。</p>
<p>本文针对上述痛点，提出了HERMES框架，旨在解决将多源人类手部运动转化为物理可行的移动双臂灵巧操作策略，并实现端到端的视觉模拟到现实迁移。其核心思路是：<strong>利用单次人类演示，通过统一的强化学习奖励设计和轨迹增强，学习泛化的操作策略；采用基于深度图像的通用数据增强和DAgger蒸馏实现端到端视觉迁移；并集成导航基础模型与闭环PnP定位，实现精确的视觉目标对准，从而桥接自主导航与灵巧操作。</strong></p>
<h2 id="方法详解">方法详解</h2>
<p>HERMES的整体框架是一个四阶段流程，旨在通过模拟到现实迁移实现移动双臂灵巧操作。</p>
<p><img src="https://arxiv.org/html/2508.20085v3/x3.png" alt="方法整体流程"></p>
<blockquote>
<p><strong>图3</strong>：HERMES的主要流程。包含四个阶段：1）从多源获取单次人类演示；2）训练基于状态的RL教师策略，并用DAgger蒸馏为基于视觉的学生策略；3）使用ViNT进行长距离导航，随后通过闭环PnP精细调整机器人位姿以实现精确对准；4）在现实世界零样本部署学生策略。</p>
</blockquote>
<p><strong>阶段一：获取单次人类运动数据</strong>。系统支持三种数据源：1）<strong>模拟遥操作</strong>：使用Apple Vision Pro以75Hz频率捕捉操作者手部和手臂运动，直接控制模拟中的机器人。2）<strong>动作捕捉数据</strong>：从OakInk2等公开数据集中获取。3）<strong>从原始视频中提取</strong>：利用WiLoR检测手部并获取2D/3D关键点，通过PnP算法估计手腕在相机坐标系中的空间平移，并通过拟合平面获得手掌方向；同时使用FoundationPose估计物体位姿，并结合ARCode扫描重建物体网格。为了从单次演示中获得泛化能力，对参考轨迹进行增强，随机化物体在预设范围内的位置和朝向。获取数据后，首先使用DexPilot将人类手部姿态重定向到机器人手部配置，作为强化学习的初始化。</p>
<p><strong>阶段二：基于强化学习的策略学习</strong>。任务被定义为目标条件强化学习问题。核心创新在于<strong>通用化的奖励设计</strong>，避免了复杂的、任务特定的奖励工程。奖励由三部分组成：</p>
<ol>
<li><strong>对象中心距离链</strong>：建模手与物体之间动态空间关系的关键。如图6所示，以双手指尖、手掌以及物体碰撞网格中心的坐标为关键点，计算这些关键点与物体中心之间向量的时间变化，并与参考轨迹对齐。该奖励仅在指尖和手掌与物体之间的接触点数量超过阈值时才被激活，确保策略关注物理上合理的手物交互。</li>
<li><strong>物体轨迹跟踪</strong>：鼓励策略使被操作物体的位姿（位置和朝向）与参考轨迹对齐。</li>
<li><strong>功率惩罚</strong>：惩罚手部关节的力与速度乘积，以平滑策略执行，减少抖动。<br>此外，采用<strong>残差动作学习</strong>策略：对于手臂，动作分解为由人类轨迹提供的粗略动作和由网络预测的精细调整残差；对于手部，由于重定向不准确，完全由网络输出建模与物体的交互行为。训练使用DrM（一种具有休眠比率机制的离策略方法）或PPO算法在MuJoCo/MJX仿真中进行。</li>
</ol>
<p><img src="https://arxiv.org/html/2508.20085v3/x6.png" alt="对象中心距离链"></p>
<blockquote>
<p><strong>图6</strong>：对象中心距离链奖励项。通过跟踪物体中心与双手各指尖及手掌之间形成的向量的时间变化来计算。</p>
</blockquote>
<p><strong>阶段三：模拟到现实视觉迁移</strong>。为了将依赖特权状态信息的教师策略迁移到仅使用视觉输入的现实世界，采用DAgger进行蒸馏，得到基于视觉的学生策略。关键创新在于<strong>使用深度图像作为视觉输入</strong>，并提出了一种通用的、面向操作的以物体为中心的深度图像增强方法。具体包括：裁剪超过阈值距离的深度值；对真实深度图像中因边缘捕捉失败缺失的值用最大深度填充；在仿真深度图像中添加高斯噪声和模糊来模拟真实世界的边缘噪声。这种方法无需针对特定相机进行复杂的噪声建模，即可实现仿真与真实观测之间强语义对齐。</p>
<p><img src="https://arxiv.org/html/2508.20085v3/x7.png" alt="深度图像可视化对比"></p>
<blockquote>
<p><strong>图7</strong>：深度图像可视化。展示了两个不同任务下，经过预处理后仿真与真实世界深度图的对比。手和物体的深度表征表现出强烈的语义对应性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.20085v3/x8.png" alt="深度强度分布对比"></p>
<blockquote>
<p><strong>图8</strong>：深度强度分布。仿真与真实世界图像的深度值分布模式具有显著相似性。</p>
</blockquote>
<p><strong>阶段四：移动操作集成</strong>。为了在非结构化环境中实现长距离操作，在基于RGB的通用导航基础模型ViNT之上，开发了一个RGB-D模块用于精确局部定位。该模块将任务建模为透视n点问题，并通过迭代求解实现闭环PnP定位，确保机器人在导航终点与操作所需的视觉目标精确对准，从而无缝衔接导航与操作策略。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：硬件平台为集成X1移动底盘、两个6自由度Galaxea A1手臂和两个OYMotion 6自由度灵巧手的移动双臂机器人，使用RealSense L515采集RGB-D观测。仿真基于MuJoCo和MJX平台构建了高保真模型。评估了涵盖<strong>开瓶盖、倒水、插拔充电头、开关抽屉、操作游戏手柄、双手持物移动</strong>等多种复杂双臂灵巧操作任务。</p>
<p><strong>对比方法</strong>：与多个基线进行比较，包括：1) <strong>BC</strong>：行为克隆。2) <strong>BC+Aug</strong>：使用增强轨迹的行为克隆。3) **RL (State)**：仅使用上述通用奖励进行强化学习（无人类参考）。4) **RL (Ref)**：在人类参考轨迹引导下进行强化学习。5) <strong>VAT-Mart</strong>：一种先进的双臂操作框架。</p>
<p><strong>关键结果</strong>：</p>
<ul>
<li><strong>模拟性能</strong>：在多个任务上，HERMES（RL (Ref)）取得了最高的平均成功率（86.7%），显著优于BC、BC+Aug和无参考的RL (State)基线。例如，在“开瓶盖”任务上，HERMES成功率达93.3%，而BC+Aug为73.3%，RL (State)为60%。</li>
<li><strong>模拟到现实迁移</strong>：经过蒸馏的视觉策略能够成功迁移到真实机器人。如图11所示，策略在真实世界中完成了倒水、开瓶盖等任务。</li>
<li><strong>导航与定位</strong>：集成ViNT和闭环PnP后，机器人能够在室内外环境中长距离导航（最远20米）并精确定位到目标物体前，如图12所示，定位误差在厘米级。</li>
<li><strong>从视频数据学习</strong>：仅使用从单个人类演示视频中提取的手物轨迹，HERMES训练出的策略也能在仿真和现实中成功执行任务（如倒水），证明了其处理多源数据的能力。</li>
<li><strong>泛化能力</strong>：策略能够泛化到未经训练的新物体（如不同形状的瓶子）、新的物体初始位置以及动态干扰（如被推动的瓶子）。</li>
</ul>
<p><img src="https://arxiv.org/html/2508.20085v3/x9.png" alt="模拟实验结果对比"></p>
<blockquote>
<p><strong>图9</strong>：模拟实验结果。HERMES (RL (Ref)) 在多个任务上的平均成功率最高。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.20085v3/x11.png" alt="真实世界操作结果"></p>
<blockquote>
<p><strong>图11</strong>：真实世界操作结果。展示了从视频学习倒水、开瓶盖等任务的成功执行。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.20085v3/x12.png" alt="导航与定位结果"></p>
<blockquote>
<p><strong>图12</strong>：导航与定位结果。机器人成功进行长距离导航，并通过PnP实现厘米级精度的最终定位。</p>
</blockquote>
<p><strong>消融实验</strong>：</p>
<ul>
<li><strong>奖励组件</strong>：移除“对象中心距离链”奖励会导致性能大幅下降（成功率从86.7%降至53.3%），证明了建模手物交互的重要性。</li>
<li><strong>数据增强</strong>：在BC中，使用轨迹增强（BC+Aug）比原始BC性能更好，但仍不及结合了增强和强化学习的HERMES。</li>
<li><strong>视觉输入模态</strong>：对比了RGB、RGB-D和仅深度（D）输入。仅使用深度图像的学生策略性能与使用RGB-D相当，且优于仅RGB，证明了深度信息对于跨域迁移的有效性。</li>
<li><strong>残差动作设计</strong>：对手臂使用残差动作学习比直接预测完整动作或仅使用参考动作效果更好。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>统一的多源人类运动学习框架</strong>：首次系统整合了模拟遥操作、动捕数据和原始视频作为人类演示来源，并通过单次演示结合轨迹增强与通用奖励的强化学习，获得泛化的双臂灵巧操作策略。</li>
<li><strong>端到端的深度视觉模拟到现实迁移</strong>：提出了一种通用的、以物体为中心的深度图像预处理与增强方法，结合DAgger蒸馏，实现了无需显式状态估计的、强健的视觉策略跨域迁移。</li>
<li><strong>移动灵巧操作系统集成</strong>：将通用视觉导航模型与闭环PnP精确定位相结合，使灵巧操作策略具备了在非结构化室内外环境中自主移动并执行长距离任务的能力。</li>
</ol>
<p><strong>局限性</strong>：论文提到，方法目前依赖于高质量仿真进行训练；视觉策略依赖于深度相机，在透明或反光物体上可能面临挑战；导航部分依赖于现有的基础模型ViNT。</p>
<p><strong>启示</strong>：HERMES展示了利用丰富但异构的人类数据驱动机器人复杂技能学习的可行路径。其通用奖励设计和基于深度图像的迁移方法为减少仿真依赖和领域随机化工程提供了新思路。将基础模型（导航）与经典几何视觉（PnP）及学习策略（操作）模块化结合，为构建能在复杂环境中执行长视距任务的机器人系统提供了有效的架构参考。未来工作可探索减少对仿真的依赖，以及处理更复杂视觉场景和动态环境。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出HERMES框架，旨在解决将多源人类手部运动数据转化为配备灵巧手的移动机器人可行行为这一核心挑战。关键技术包括：1）统一的强化学习方法，将异构人手运动转化为物理合理的机器人动作；2）基于深度图像的端到端sim2real迁移方法，以提升泛化能力；3）结合闭环PnP定位的导航基础模型，实现自主导航与灵巧操作的衔接。实验表明，该框架能在多样化的真实场景中成功执行复杂的移动双手灵巧操作任务。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.20085" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>