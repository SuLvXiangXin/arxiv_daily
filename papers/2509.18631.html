<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.18631" target="_blank" rel="noreferrer">2509.18631</a></span>
        <span>作者: Danfei Xu Team</span>
        <span>日期: 2025-09-23</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人操作领域的行为克隆方法因其简单有效而备受关注，但其性能严重依赖于大规模、多样化的专家示范数据。在真实世界中收集此类数据成本高昂且耗时。随着物理仿真器、程序化场景生成和运动合成技术的进步，利用仿真数据成为一种可扩展的低成本替代方案。然而，由于视觉外观、传感器噪声和动作动力学等方面的差异，将仅在仿真中训练的策略转移到真实世界面临显著的仿真到真实领域差距的挑战。</p>
<p>现有方法试图弥合这一差距：领域随机化和数据增强需要精心调参；领域适应技术试图在像素级或特征级对齐分布，但许多特征级方法仅对齐观测的边际分布（如MMD），这可能不足以保留跨领域的动作相关信息。最近，仿真与真实协同训练（即在混合数据上训练单一策略）显示出简单而有效的优势，但此类方法通常缺乏对跨领域特征空间对齐的显式约束，可能阻碍最优的迁移和泛化。</p>
<p>本文针对协同训练缺乏显式特征对齐这一具体痛点，提出了一个新的视角：对齐跨领域的观测及其对应动作（或任务相关状态）的联合分布，能为学习可迁移特征提供更丰富的信号。本文的核心思路是：在协同训练框架中嵌入最优传输（OT）损失，以学习一个领域不变且任务相关的特征空间，并扩展为不平衡最优传输（UOT）以处理仿真数据丰富而真实数据稀缺的失衡问题。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出一个统一的仿真-真实协同训练框架，旨在联合学习一个视觉特征编码器 <code>f_φ</code> 和一个策略 <code>π_θ</code>。整体目标是利用丰富的仿真示范 <code>D_src</code> 和有限的真实示范 <code>D_tgt</code>，训练一个在真实世界中表现良好且能泛化到仅仿真见过场景的策略。</p>
<p><img src="https://arxiv.org/html/2509.18631v3/x2.png" alt="方法概述"></p>
<blockquote>
<p><strong>图2</strong>：方法整体框架。通过行为克隆损失在混合的仿真与真实数据上训练策略 <code>π_θ</code> 和编码器 <code>f_φ</code>。同时，引入不平衡最优传输（UOT）损失作为正则项，促使编码器学习对齐跨领域的联合（特征，本体感知）分布，从而得到一个领域不变且任务相关的潜在空间 <code>Z</code>。</p>
</blockquote>
<p>核心模块是<strong>基于不平衡最优传输（UOT）的特征对齐损失</strong>和<strong>时序感知采样策略</strong>。</p>
<ol>
<li><strong>最优传输用于动作感知的特征对齐</strong>：本文的核心创新是使用OT对齐联合分布 <code>P_src(f_φ(o_src), a_src)</code> 和 <code>P_tgt(f_φ(o_tgt), a_tgt)</code>，而非仅对齐观测的边际分布。这鼓励编码器学习一个潜在空间，其中对动作预测至关重要的几何关系在不同领域间保持一致。在实际实现中，由于动作表示可能存在域间差异，采用更一致的本体感知信息 <code>x</code>（如末端执行器位姿）替代动作 <code>a</code>，构建联合 <code>(f_φ(o), x)</code> 分布进行对齐。地面代价 <code>c</code> 结合了潜在空间距离 <code>d_Z</code> 和本体感知空间距离 <code>d_X</code>。</li>
<li><strong>不平衡最优传输（UOT）</strong>：标准OT要求严格的质量守恒约束，这在数据量 <code>(|D_src| ≫ |D_tgt|)</code> 且状态空间仅部分重叠的仿真-真实场景中会导致扭曲或虚假对齐。UOT通过引入KL散度惩罚项来松弛边际约束，允许部分质量传输，从而能选择性地对齐分布中最相似的部分，忽略不匹配的部分。UOT损失 <code>L_UOT</code> 包含传输代价、熵正则项以及对偏离均匀边际分布的惩罚。</li>
<li><strong>时序感知采样策略</strong>：在基于迷你批次的OT/UOT训练中，随机采样可能导致批次内的源和目标样本处于任务的不同阶段，产生噪声较大的传输计划。为提高对齐效率，本文提出一种两阶段采样策略：首先，使用动态时间规整（DTW）计算仿真与真实轨迹在本体感知序列上的相似性，并依此加权采样一对相似轨迹；然后，从这对轨迹中采样具体的状态转换元组来构建迷你批次。这增加了批次内状态对的可对应性，使UOT优化能更专注于对齐相关状态下的视觉特征。</li>
</ol>
<p>与现有协同训练方法相比，创新点在于引入了<strong>显式的、基于联合分布对齐的特征空间约束</strong>。通过UOT损失和时序采样，框架能够<strong>鲁棒地处理数据失衡和部分状态重叠</strong>，从而更有效地利用海量仿真数据提升真实策略的泛化性能。</p>
<p>最终，整体训练目标为联合损失：<code>L(f_φ, π_θ) = L_BC(f_φ, π_θ) + λ * L_UOT(f_φ)</code>，其中 <code>L_BC</code> 是标准的基于均方误差的行为克隆损失，<code>λ</code> 是平衡超参数。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在6个具有挑战性的桌面操作任务上进行评估：Lift（抓取抬起）、BoxInBin（盒子放入箱子）、Stack（堆叠）、Square（方形排列）、MugHang（杯子挂架）、Drawer（开抽屉）。实验平台包括真实世界的Franka Emika Panda机械臂（使用RealSense D435相机）以及仿真环境（使用Robomimic和MimicGen）。观测模态涵盖图像和点云。</p>
<p><img src="https://arxiv.org/html/2509.18631v3/x3.png" alt="评估任务套件"></p>
<blockquote>
<p><strong>图3</strong>：评估任务套件。顶部为真实世界任务，底部为对应的仿真任务，用于验证仿真到真实的迁移效果。</p>
</blockquote>
<p><strong>对比方法</strong>：对比了多种基线方法，包括：仅用仿真数据训练（SimOnly）、仅用真实数据训练（RealOnly）、简单的仿真-真实协同训练（CoTrain）、领域随机化（DR）、特征级对齐方法（如MMD），以及领域随机化与协同训练的结合（DR+CoTrain）。</p>
<p><img src="https://arxiv.org/html/2509.18631v3/x4.png" alt="真实世界性能对比"></p>
<blockquote>
<p><strong>图4</strong>：在6个真实世界任务上的平均成功率对比。本文方法（Ours）相比简单的协同训练（CoTrain）平均提升约30%，并且显著优于所有其他基线方法。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>真实世界性能提升</strong>：在6个真实任务上，本文方法相比简单的协同训练基线（CoTrain）平均成功率提升了约30%（例如，从<del>40%提升至</del>70%），并且显著优于所有其他基线（图4）。</li>
<li><strong>泛化到仅仿真见过的场景</strong>：在“Sim-only Generalization”实验中，策略在训练时仅见过某个物体（如蓝色方块）的仿真数据，而未见其真实数据。测试时在真实世界中操作该物体，本文方法成功率达65%，而协同训练基线为0%，证明了其卓越的泛化能力（图5）。</li>
<li><strong>仿真到仿真迁移</strong>：在具有视觉干扰的仿真环境中测试，本文方法同样优于基线，表明其学习的特征对视觉变化具有鲁棒性（图6）。</li>
<li><strong>多模态适用性</strong>：方法在图像和点云两种观测模态下均有效，在点云模态上同样展现出对协同训练基线的显著提升（图7）。</li>
<li><strong>数据规模扩展</strong>：增加仿真数据量能持续提升在真实世界和仿真仅见场景下的泛化性能（图8）。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.18631v3/x9.png" alt="消融研究"></p>
<blockquote>
<p><strong>图9</strong>：消融实验。在Lift任务上，移除UOT损失（w/o UOT）或使用时序采样（w/o Temp. Sampling）均会导致性能下降，验证了这两个核心组件的必要性。</p>
</blockquote>
<p><strong>消融实验</strong>：消融研究（图9）证实了UOT损失和时序感知采样策略的关键作用。移除任一组件，性能都会下降。UOT处理数据失衡的作用至关重要，而时序采样则提升了迷你批次对齐的质量。</p>
<p><img src="https://arxiv.org/html/2509.18631v3/x10.png" alt="定性结果"></p>
<blockquote>
<p><strong>图10</strong>：真实世界任务成功的定性示例。本文方法能够成功完成复杂的操作序列。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.18631v3/x11.png" alt="特征空间可视化"></p>
<blockquote>
<p><strong>图11</strong>：特征空间t-SNE可视化。本文方法学到的特征空间中，仿真和真实数据点根据其语义（任务阶段）而非领域进行聚类，显示了良好的领域不变性和任务相关性。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个新颖的仿真-真实协同训练框架，通过最优传输显式学习领域不变且任务相关的潜在特征空间，显著提升了利用丰富仿真数据增强真实策略性能的能力。</li>
<li>引入了不平衡最优传输（UOT）损失和时序感知采样策略，有效解决了仿真与真实数据间的严重失衡问题，并提升了迷你批次训练中的对齐质量。</li>
<li>在多种操作任务、观测模态（图像、点云）以及仿真到仿真、仿真到真实的迁移场景中进行了全面实验验证，证明了方法的有效性、泛化性和优于现有基线的性能（最高达30%的平均成功率提升）。</li>
</ol>
<p><strong>局限性</strong>：论文提到，当前工作主要关注视觉领域差距，并假设准静态操作下动态差距是次要的。对于动态特性差异显著的任务，可能需要额外的处理。</p>
<p><strong>后续研究启示</strong>：</p>
<ol>
<li><strong>对齐目标扩展</strong>：可以探索将更丰富的任务相关信息（如物体姿态、接触力）纳入联合分布对齐。</li>
<li><strong>处理动态差距</strong>：将方法扩展到需要显式处理动力学差异的非准静态任务或动态环境中。</li>
<li><strong>理论分析</strong>：对UOT在数据失衡和部分重叠的模仿学习问题中的性质进行更深入的理论分析。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对仿真到现实策略迁移中的领域差距问题，提出了一种统一的仿真与现实协同训练框架。其核心是学习一个领域不变的任务特征空间，关键技术是采用最优传输（OT）损失来对齐跨领域的观测-动作联合分布，并扩展为非平衡OT以处理数据量不平衡问题。实验表明，该方法能有效利用大量仿真数据，在真实机器人操作任务中实现高达30%的成功率提升，并能泛化至仅仿真见过的场景。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.18631" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>