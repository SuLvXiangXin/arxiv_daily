<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Behavior Foundation Model for Humanoid Robots - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Behavior Foundation Model for Humanoid Robots</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.13780" target="_blank" rel="noreferrer">2509.13780</a></span>
        <span>作者: Zeng, Weishuai, Lu, Shunlin, Yin, Kangning, Niu, Xiaojie, Dai, Minyue, Wang, Jingbo, Pang, Jiangmiao</span>
        <span>日期: 2025/09/17</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人的全身控制（WBC）在技能多样性方面取得了显著进展，能够实现运动、遥操作和运动跟踪等多种应用。然而，现有的WBC框架在很大程度上仍然是任务特定的，严重依赖劳动密集型的奖励工程，并且在跨任务和技能上的泛化能力有限。这些限制阻碍了它们对任意控制模式的响应，并限制了在复杂现实场景中的部署。本文认为，现有方法局限性的根源在于缺乏跨不同任务的统一表述。通过重新审视现有WBC系统，本文发现了一个贯穿不同任务的共同目标：生成引导机器人达到期望目标状态的适当行为。基于此洞察，本文提出了行为基础模型（BFM），这是一种在大规模行为数据集上预训练的生成模型，旨在捕获人形机器人广泛、可重用的行为知识。本文的核心思路是将行为与控制模式解耦，将范式从孤立的任务学习转向整体的行为学习，并通过预训练的BFM实现对任意控制模式的灵活操作以及无需从头训练即可高效获取新行为的能力。</p>
<h2 id="方法详解">方法详解</h2>
<p>BFM的实现分为三个阶段：代理训练、BFM预训练和BFM应用。</p>
<p><img src="https://arxiv.org/html/2509.13780v1/x1.png" alt="BFM实现概述"></p>
<blockquote>
<p><strong>图1</strong>：BFM实现概述。(a) 将人体运动数据集重定向到人形机器人用于代理训练。(b) 通过运动模仿训练代理，其在模拟器中可以访问所有信息。(c) 一种行为可以通过多种控制模式来指定，从抽象的文本指令到具体的全身关节位置，产生不同的目标状态。我们将不同控制模式的激活简化为对统一控制接口应用掩码。(d) 我们使用CVAE对BFM建模，并采用DAgger框架进行BFM预训练，提供了一个结构化的潜在空间来编码广泛的行为知识。</p>
</blockquote>
<p><strong>1. 代理训练：</strong> 首先，利用公开的AMASS人体运动数据集，通过两阶段重定向方法将其适配到目标人形机器人。然后，在模拟器中以运动模仿为任务，训练一个拥有“特权信息”（如完整参考姿态、速度等）的代理策略。该代理策略的输入是特权本体感知状态和源自参考运动的目标状态，输出是关节目标位置。训练采用PPO算法，奖励函数由任务奖励（模仿精度）、正则化项和惩罚项加权构成，并应用了课程学习、领域随机化、参考状态初始化（RSI）、早期终止以及困难负样本挖掘等策略来提升训练效果和数据集覆盖度。</p>
<p><strong>2. BFM预训练：</strong> 目标是学习演示行为的底层分布 (P(\tau))。BFM被建模为一个以真实世界可观测状态为条件的生成模型。</p>
<ul>
<li><strong>状态设计：</strong> 真实世界本体感知状态 (s_t^{p,real}) 包含过去25步的关节位置、关节速度、根角速度、投影重力以及上一时刻动作。</li>
<li><strong>控制接口与掩码策略：</strong> 设计了一个统一的控制接口，包含根控制、运动学位置控制和关节角度控制。通过对此接口元素应用伯努利采样的二进制掩码，可以灵活激活任意的低层级控制模式（如仅速度命令、仅关节角度等）。训练初期采用掩码课程（冷启动），采样概率从1.0逐渐衰减至0.5，以确保稳定。</li>
<li><strong>CVAE建模：</strong> 采用条件变分自编码器来建模策略 (\pi_\theta(a_t | s_t^{p,real}, s_t^{g,real}))。编码器接收特权状态和当前掩码，输出一个均值和方差，作为对先验分布的残差。先验网络接收真实状态和目标状态。解码器接收真实本体感知状态和潜在变量 (z)，输出动作分布（假设固定方差）。这种设计鼓励潜在空间编码更多与行为本身而非具体目标相关的知识。</li>
<li><strong>在线蒸馏：</strong> 采用DAgger框架进行在线训练。在模拟中执行当前BFM策略产生轨迹，同时计算对应的特权状态，并查询代理策略获得参考动作 (\hat{a_t})。BFM的损失函数为：(L = L_{DAgger} + \lambda_{KL} L_{KL})，其中 (L_{DAgger} = ||\hat{a_t} - a_t||<em>2^2) 是动作重建损失，(L</em>{KL}) 是潜在变量后验分布与先验分布之间的KL散度。</li>
</ul>
<p><strong>3. 创新点：</strong> 与HOVER等现有方法相比，BFM的主要创新在于：1) 提出了统一的行为学习范式，而非多任务学习；2) 采用了更简单的直接伯努利采样掩码策略来支持任意控制模式，而非两阶段固定优先级掩码；3) 系统性地利用CVAE构建了结构化的潜在空间，并分析了其在行为组合与调制中的应用潜力；4) 通过残差学习实现高效的新行为获取。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在模拟环境和真实人形机器人平台（Unitree H1）上进行。使用了AMASS数据集及其子集进行训练和测试。对比的基线方法包括：任务专家策略（为VR遥操作或运动跟踪单独训练）、HOVER（当前最先进的多模态控制方法）以及从零开始强化学习训练的BFM。</p>
<p><strong>关键实验结果：</strong></p>
<ol>
<li><strong>VR遥操作与运动跟踪（表III）：</strong> 在AMASS测试集上，BFM在VR遥操作任务中取得了最佳的整体性能（Empjpe: 0.2235, Empkpe: 63.1388）。在运动跟踪任务中，BFM与任务专家策略性能相当，部分指标更优（如Empkpe: 61.1236 vs 73.6332），并且显著优于HOVER和从零训练的BFM。这证明了BFM在两种截然不同的控制模式下的有效泛化能力。</li>
<li><strong>运动任务（表IV）：</strong> 在运动（如前进、后退、侧移）任务中，BFM在成功率和命令跟踪误差方面均优于或与HOVER相当，显著优于从零训练的BFM，证明了其对抽象速度命令的响应能力。</li>
<li><strong>行为调制：</strong> 通过线性插值潜在空间中的向量，BFM可以在两种行为（如行走和挥手）之间进行平滑插值，生成复合行为（边走路边挥手），且无需额外训练。表III下方展示了在运动跟踪任务中引入风格化潜在变量（λ=0.5, 1.0, 1.5）进行调制的效果，部分指标相比基础BFM有进一步提升。</li>
<li><strong>真实机器人部署：</strong> 论文展示了BFM在真实Unitree H1机器人上成功完成VR遥操作、运动跟踪和以速度命令运动等多种任务，验证了其从模拟到现实的转移能力。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.13780v1/x2.png" alt="真实世界实验结果"></p>
<blockquote>
<p><strong>图2</strong>：真实世界实验结果。BFM部署在Unitree H1人形机器人上，成功完成了VR遥操作、运动跟踪和运动（速度命令控制）任务，展示了其处理多种控制模式的泛化能力和鲁棒性。</p>
</blockquote>
<p><strong>消融实验贡献：</strong> 论文通过对比实验验证了各组件的重要性。使用CVAE相较于直接输出动作的MLP策略，能学习到更结构化、可解释的潜在空间，从而支持行为调制。在线蒸馏框架和掩码策略对于从代理策略中有效学习并实现多模态控制至关重要。从零开始训练BFM（不利用预训练行为知识）性能极差，凸显了大规模行为预训练的价值。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献：</strong></p>
<ol>
<li><strong>范式转变：</strong> 提出了人形机器人的行为基础模型（BFM），将控制研究的焦点从整体的任务学习转向统一的行为学习。</li>
<li><strong>框架设计：</strong> 设计了一个集成掩码在线蒸馏和CVAE的框架，能够直接由多样化的WBC任务引导，并可通过残差学习高效获取新行为而无需从头训练。</li>
<li><strong>全面验证：</strong> 在模拟和真实机器人上的大量实验验证了BFM的表达能力和有效性，突显了其作为开发通用人形机器人基础模型的潜力。</li>
</ol>
<p><strong>局限性：</strong></p>
<ol>
<li>BFM的性能依赖于代理策略所提供的“行为数据”的质量和多样性。</li>
<li>当前工作专注于低层级的运动控制，与更高层次的规划或推理模块的结合是未来方向。</li>
<li>实时性方面，BFM需要处理过去25帧的历史信息，对计算效率有一定要求。</li>
</ol>
<p><strong>对后续研究的启示：</strong><br>BFM为构建通用人形机器人控制器提供了一个有前景的架构。其“行为”与“控制模式”解耦的思想可扩展到更广泛的任务定义中。结构化的潜在空间为行为编辑、组合和基于语义的检索打开了新的大门。未来的工作可以探索如何融入更丰富的感知模态（如视觉），以及如何与大型语言模型等高层级推理模型相结合，以实现真正自主、通用的人形机器人智能体。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人全身控制框架任务特定、泛化能力差的问题，提出行为基础模型。该模型基于大规模行为数据预训练，采用掩码在线蒸馏框架与条件变分自编码器整合，建模行为分布以实现跨任意控制模式的灵活操作。实验表明，BFM在仿真与实体平台上能稳健泛化至多样任务，并快速适应新行为，为通用人形控制奠定了基础。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.13780" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>