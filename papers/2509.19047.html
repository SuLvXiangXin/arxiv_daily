<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>ManipForce: Force-Guided Policy Learning with Frequency-Aware Representation for Contact-Rich Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>ManipForce: Force-Guided Policy Learning with Frequency-Aware Representation for Contact-Rich Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.19047" target="_blank" rel="noreferrer">2509.19047</a></span>
        <span>作者: Kyoobin Lee Team</span>
        <span>日期: 2025-09-23</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>目前，模仿学习在灵巧和接触丰富的操作任务中展现出巨大潜力，但主流方法主要依赖纯视觉演示，忽略了人类在操作中自然感知和利用的丰富力/力矩信息。现有的一些手持数据收集系统（如UMI）简化了演示收集，但未捕获F/T数据；而结合视觉与F/T数据的方法（如依赖点云的方法）则存在设置复杂、难以感知小物体和精细间隙、以及将高频力信号下采样至图像帧率导致丢失关键动态信息等局限性。</p>
<p>本文针对接触丰富操作任务（如精密装配）中精确交互力控制的需求，提出了一个双重解决方案：一个能够捕获高频力信号与RGB数据的自然人手演示收集系统，以及一个能够有效处理异步、异构多模态信号进行策略学习的新模型。本文的核心思路是：通过手持系统ManipForce收集包含高频F/T和RGB的自然人演示数据，并设计频率感知多模态Transformer模型FMT，利用频率和模态感知的嵌入以及双向交叉注意力，学习融合异步视觉与力信号的鲁棒策略。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文框架包含两个核心组件：数据收集系统ManipForce和策略学习模型FMT。ManipForce负责在自然人手持演示过程中，同步采集高频（200 Hz）力/力矩信号和RGB图像（30 Hz）以及精确的末端位姿。FMT则基于这些异步多模态数据，通过频率感知表示学习和交叉注意力融合，训练出一个扩散策略网络，最终输出控制机器人的动作序列。</p>
<p><img src="https://arxiv.org/html/2509.19047v1/figures/model.jpg" alt="方法框架"></p>
<blockquote>
<p><strong>图4</strong>：FMT模型整体架构。异步的RGB（30 Hz）和F/T（200 Hz）信号通过频率感知多模态嵌入进行编码，经由双向交叉注意力模块融合，最后输入到Transformer扩散策略网络中生成用于精确、接触丰富操作任务的鲁棒动作。</p>
</blockquote>
<p><strong>核心模块1: ManipForce数据收集系统</strong><br>该系统（结构见图3）旨在实现直观、精确、稳定的人手演示数据收集。其核心是一个集成了平行夹爪、线性导轨和触发锁定机制的手持夹持器，所有组件安装在F/T传感器之后，以捕获完整的交互力。系统使用双RGB手眼相机（Intel RealSense D455和D405）以减少遮挡。为解决SLAM在近表面跟踪精度下降的问题，采用外部Azure Kinect传感器检测3D ArUco标记来估计手腕位姿，精度达亚毫米级。末端执行器动作被计算为连续帧之间的6自由度位姿差。F/T传感器（AIDIN AFT200）以200Hz记录数据，并利用相机IMU数据进行重力补偿，以隔离真实的接触力（补偿效果验证见图3）。</p>
<p><img src="https://arxiv.org/html/2509.19047v1/figures/figure3.jpg" alt="系统结构"></p>
<blockquote>
<p><strong>图2</strong>：ManipForce系统结构。包括双RGB相机、腕部安装的F/T传感器和ArUco标记跟踪。带有触发锁定和线性导轨的齿条-齿轮夹持器支持精确、稳定的人体演示。</p>
</blockquote>
<p><strong>核心模块2: 频率感知多模态Transformer</strong><br>FMT基于Transformer扩散策略架构扩展而来，包含四个关键部分：</p>
<ol>
<li><strong>RGB-力标记化</strong>：双相机RGB图像经预处理后，使用DINOv2-B编码器提取视觉表示；F/T信号则通过1D CNN编码器提取特征。为处理异步输入，采用基于时间戳的窗口对齐方法，将30Hz的视觉帧与200Hz以上的对应F/T样本在连续图像帧定义的时间边界内对齐。</li>
<li><strong>频率感知多模态嵌入</strong>：引入三种可学习的位置嵌入来统一处理编码后的模态：（i）用于视觉令牌的<strong>空间嵌入</strong>；（ii）用于捕获不同采样率模态间时间戳关系的<strong>频率感知嵌入</strong>；（iii）标识令牌来源的<strong>模态嵌入</strong>。这些嵌入被加到视觉和F/T令牌上，使Transformer能够对异构多模态序列中每个令牌的空间、频率和模态特定上下文进行建模。</li>
<li><strong>双向交叉注意力</strong>：该模块促进模态间的信息交换。视觉令牌关注F/T令牌以纳入接触动态，F/T令牌关注视觉特征以理解空间上下文。通过交叉注意力计算，分别得到增强后的视觉令牌和F/T令牌，随后将它们拼接并通过全连接层和层归一化，形成统一的多模态观测表示。</li>
<li><strong>Transformer扩散策略</strong>：统一的多模态观测令牌作为条件输入，用于动作生成。在去噪的每一步，带噪声的动作嵌入通过交叉注意力关注多模态观测特征，同时对先前的动作令牌保持因果自注意力。噪声预测网络通过迭代去噪步骤生成动作序列。</li>
</ol>
<p><strong>创新点</strong>：与现有方法（如简单特征拼接或仅低频率跨模态交互）相比，FMT的创新在于：（1）专门设计了可学习的频率感知嵌入，显式地处理视觉与力信号间的异步和采样率不匹配问题；（2）采用双向交叉注意力进行动态的、细粒度的跨模态特征融合，而非静态或单向融合。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在6个真实世界的接触丰富操作任务上评估（任务示例见图5），包括齿轮装配、LAN插头插入、翻盒子、打开盖子、电池拆卸和电池插入。使用7自由度Franka Panda机器人，配备与ManipForce相同的腕部F/T传感器。每个任务收集约100条演示轨迹进行训练，并在随机初始位姿下进行20次试验评估。</p>
<p><img src="https://arxiv.org/html/2509.19047v1/figures/figure2.jpg" alt="评估任务"></p>
<blockquote>
<p><strong>图1</strong>：评估中使用的六个接触丰富操作任务：齿轮装配、LAN插头插入、翻盒子、打开盖子、电池拆卸和电池插入。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.19047v1/figures/figure6.jpg" alt="策略执行示例"></p>
<blockquote>
<p><strong>图5</strong>：提出的FMT在六个接触丰富操作任务上的策略执行示例。每个序列展示了训练后的策略利用融合的RGB-F/T反馈执行各任务关键阶段。</p>
</blockquote>
<p><strong>基线对比</strong>：与基于相同Transformer扩散策略架构但仅使用RGB输入的基线模型进行比较。</p>
<p><strong>关键实验结果</strong>：<br>如表1所示，FMT在所有六个任务上的成功率均显著高于RGB-only基线，平均成功率达到**83%<strong>，而RGB-only基线仅为</strong>22%**。在需要精细力控的任务（如齿轮装配、电池插入）或依赖瞬态力信号的任务（如打开盖子）上提升尤为显著。</p>
<p><strong>消融实验</strong>：<br>如图7所示，通过移除FMT的核心模块进行消融研究：</p>
<ul>
<li><strong>低频率F/T（30 Hz）</strong>：将力信号下采样至30Hz，性能显著下降，尤其在依赖高频力峰值的“打开盖子”任务中。</li>
<li><strong>无频率感知多模态嵌入</strong>：移除统一的频率和模态嵌入，性能普遍下降，在“齿轮装配”任务中影响最大，表明其对异步多模态对齐至关重要。</li>
<li><strong>无交叉注意力</strong>：禁用双向跨模态注意力，性能也出现下滑，表明动态特征融合对提升策略鲁棒性有贡献。<br>实验表明，高频力感知、模态-频率嵌入和双向交叉注意力三者共同作用，缺一不可。</li>
</ul>
<p><img src="https://arxiv.org/html/2509.19047v1/figures/ablation_comparison.png" alt="消融实验"></p>
<blockquote>
<p><strong>图6</strong>：在三个代表性任务（齿轮装配、翻盒子、打开盖子）上的消融研究。对比了完整的FMT模型与低频率F/T输入、无位置嵌入和无交叉注意力的变体。</p>
</blockquote>
<p><strong>采样频率分析</strong>：<br>如图8所示，在齿轮装配任务中，F/T采样频率从30Hz提升至200Hz时，策略成功率从<strong>0.40</strong>单调增长至<strong>0.95</strong>，证实了更高频的力信号能带来性能增益，因为其能捕获更精细的接触动态和瞬态事件。</p>
<p><img src="https://arxiv.org/html/2509.19047v1/figures/ft_frequency_performance.jpg" alt="采样频率影响"></p>
<blockquote>
<p><strong>图7</strong>：齿轮装配任务在不同F/T采样频率下的成功率，表明性能随频率提高而提升。</p>
</blockquote>
<p><strong>数据收集效率分析</strong>：<br>如图9所示，对比直接人手演示、ManipForce系统和遥操作系统Gello在“翻盒子”和“电池拆卸”任务上的数据收集时间。ManipForce的效率接近直接人手操作，而遥操作则耗时显著更长，且缺乏触觉反馈难以施加精确的交互力。</p>
<p><img src="https://arxiv.org/html/2509.19047v1/figures/figure9.jpg" alt="数据收集效率"></p>
<blockquote>
<p><strong>图8</strong>：人手演示、我们的ManipForce和基于遥操作的Gello之间的数据收集效率比较，显示ManipForce在保持接触和精确力控方面接近人手速度，而遥操作则较慢。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>ManipForce</strong>，一个集成了双RGB手眼相机和腕部F/T传感器的便携式数据收集系统，能够在自然人手持演示中捕获高质量、高频的多模态数据，并可直接迁移至机器人执行。</li>
<li>提出了<strong>频率感知多模态Transformer</strong>，通过可学习的频率-模态嵌入和双向交叉注意力，有效融合了异步、异构的视觉与高频力信号，实现了针对接触丰富操作的鲁棒策略学习。</li>
<li>在六项多样化的真实机器人操作任务上进行了全面实验验证，证明了所提系统与方法的有效性，平均成功率大幅超越纯视觉基线，并通过详实的消融和频率分析揭示了各组件的作用。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，当前研究展示了在多样化接触任务上的强大性能，但未来计划将框架扩展到需要更复杂夹持器行为、更长任务序列和更灵巧的操作任务中，以进一步增强其在复杂现实场景中的通用性和可扩展性。</p>
<p><strong>启示</strong>：本研究强调了在接触丰富操作中，<strong>高频力感知</strong>与<strong>视觉信息</strong>同等重要。它为解决多模态传感器（尤其是不同采样率的传感器）的异步融合问题提供了一个新颖的、基于嵌入学习和注意力机制的范式。这为未来开发更通用、更鲁棒的多模态模仿学习系统，特别是在精密装配、灵巧操作等需要精细物理交互的领域，提供了重要的技术思路和实验基础。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对接触式操作任务中现有模仿学习方法缺乏力感知信息的问题，提出ManipForce手持系统与频率感知多模态变换器（FMT）。ManipForce采集高频力-扭矩与RGB数据；FMT通过频率与模态感知嵌入编码异步信号，并利用双向交叉注意力在扩散策略中融合多模态信息。在齿轮装配等六项真实任务中，基于ManipForce演示训练的FMT平均成功率达83%，显著优于仅使用RGB的基线，验证了高频力数据与跨模态融合对提升策略精度与稳定性的关键作用。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.19047" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>