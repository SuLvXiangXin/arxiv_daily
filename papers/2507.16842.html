<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.16842" target="_blank" rel="noreferrer">2507.16842</a></span>
        <span>作者: Charlie C. L. Wang Team</span>
        <span>日期: 2025-07-19</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>冗余软体机械臂因其固有的柔顺性和高自由度，在安全交互和灵活任务执行方面具有优势。然而，其运动学控制面临三大关键挑战：1）<strong>未知负载</strong>导致被动变形，使得驱动-构型映射高度非线性和负载敏感，基于模型的运动学方法因假设均匀对称结构而在变化负载下产生显著误差，而数据驱动方法需要大量训练数据且泛化能力有限；2）<strong>执行器饱和</strong>，由于冗余软体机械臂存在多对一的驱动-状态映射，基于梯度优化的方法容易陷入局部最优且难以进行零空间调节，滑模控制则存在抖振效应且缺乏轨迹级优化；3）<strong>受限空间操作</strong>，传统将任务空间约束纳入优化的方法往往导致过于保守、不精确的解，并增加计算复杂度。</p>
<p>本文针对上述痛点，提出了一种<strong>传感器空间模仿学习运动控制（SS-ILKC）</strong>框架。其核心思路是：利用集成在机械臂上的弹簧传感器直接感知其几何状态（弹簧长度），将控制目标定义在传感器空间而非对负载敏感的驱动空间；通过<strong>双学习策略</strong>——在仿真中使用强化学习训练开放空间策略，结合生成对抗模仿学习从稀疏专家演示中学习受限空间策略；并引入<strong>预处理的仿真到现实（S2R）迁移机制</strong>来弥合仿真与现实差距，实现控制策略的零样本现实部署。</p>
<h2 id="方法详解">方法详解</h2>
<p>SS-ILKC框架旨在学习一个传感器空间控制策略，该策略以初始传感器状态和任务目标（末端执行器6D位姿）为输入，输出参考传感器信号，随后由一个PID控制器进行实时跟踪，以驱动机械臂。</p>
<p><img src="https://arxiv.org/html/2507.16842v1/extracted/6636773/fig/Main_Loop.jpg" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：SS-ILKC框架总览。(a) 基于传感器空间的控制回路：策略根据初始传感器状态和任务目标生成参考传感器信号，由PID控制器跟踪。(b) 整体学习框架：结合仿真（用于开放空间）和物理演示（用于受限空间，即模仿学习）来学习控制策略。</p>
</blockquote>
<p>整体框架包含三个核心模块：</p>
<ol>
<li><strong>仿真环境与S2R迁移</strong>：在MuJoCo中构建高保真仿真环境，使用肌腱模拟气动腔室，并建模弹簧传感器。为了解决仿真与现实间的运动学差异，论文提出了一种<strong>预处理的S2R机制</strong>。该方法并非在策略训练后进行微调，而是预先训练一个轻量级神经网络，将仿真的末端执行器位姿映射到现实位姿。通过离线优化，该机制能准确估计执行器饱和极限等物理参数，从而在校正后的仿真环境中进行策略训练，实现零样本部署。</li>
<li><strong>多目标传感器空间强化学习</strong>：在经S2R校正的仿真环境中，采用基于强化学习的框架训练开放空间控制策略。其创新在于：a) <strong>传感器空间控制</strong>：状态和动作均基于弹簧长度，确保了策略的负载无关性，同时将驱动约束明确纳入优化过程；b) <strong>多目标学习</strong>：使策略能够泛化到整个工作空间，建立从多样初始构型到任意目标位姿的鲁棒映射。</li>
<li><strong>GAIL模仿学习模块</strong>：对于复杂的受限空间操作，设计奖励函数困难且难以在仿真中精确复现环境交互。因此，引入生成对抗模仿学习（GAIL），使智能体能够从稀疏的专家演示（在现实受限空间中采集的离散样本位姿）中有效学习控制策略。GAIL模块通过一个判别器来区分策略生成的状态-动作对与专家演示数据，并以此生成奖励信号来指导策略优化。</li>
</ol>
<p>与现有方法相比，本文的创新点具体体现在：1) 将控制问题定义在负载无关的传感器空间；2) 采用预处理而非后处理的S2R迁移，避免在线适应需求；3) 结合仿真RL与演示GAIL的双学习策略，分别高效处理开放空间和受限空间问题。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验平台与数据集</strong>：使用一个三模块、九腔室（9自由度）的气动软体机械臂，每个模块集成三个弹簧传感器。基准任务包括：1) <strong>圆形路径跟踪任务</strong>（开放空间）；2) <strong>T型管道内的拾放操作任务</strong>（受限空间）。</p>
<p><strong>对比方法</strong>：与多种基线方法对比，包括PID控制、LQR控制、基于优化的方法（Meng et al., 2024）、先前的传感器空间控制（SSC）以及纯仿真训练的RL策略（无S2R）。</p>
<p><img src="https://arxiv.org/html/2507.16842v1/extracted/6636773/fig/Circle_analysis.jpg" alt="路径跟踪误差对比"></p>
<blockquote>
<p><strong>图11</strong>：不同方法在圆形路径跟踪任务中的误差对比。SS-ILKC（橙色）的平均误差（1.7 mm）和最大误差（4.1 mm）均显著低于其他方法。</p>
</blockquote>
<p><strong>关键定量结果</strong>：</p>
<ol>
<li><strong>路径跟踪任务</strong>：SS-ILKC实现了<strong>1.7 mm的平均跟踪误差和4.1 mm的最大误差</strong>，性能优于所有基线方法。在末端负载0-200克变化时，SS-ILKC的误差保持稳定（~1.7 mm），而其他方法误差显著增加（例如，基于优化的方法误差从2.1 mm增至5.8 mm），证明了其负载无关的鲁棒性。</li>
<li><strong>受限空间拾放任务</strong>：SS-ILKC在T型管道内的成功率高达**93.3%**，而纯仿真RL策略、SSC和基于优化的方法的成功率分别为26.7%、60%和73.3%。SS-ILKC在存在未知负载（0-200g）时，成功率仍保持在86.7%。</li>
</ol>
<p><img src="https://arxiv.org/html/2507.16842v1/extracted/6636773/fig/cirlce_different_weight.jpg" alt="不同负载下跟踪误差"></p>
<blockquote>
<p><strong>图12</strong>：不同末端负载下各方法的路径跟踪误差。SS-ILKC（橙色）在不同负载下误差保持稳定，而其他方法误差随负载增加而显著上升。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.16842v1/extracted/6636773/fig/pick_place_blk_new.jpg" alt="拾放任务成功率"></p>
<blockquote>
<p><strong>图13</strong>：T型管道内拾放任务的成功率对比。SS-ILKC成功率（93.3%）远高于其他方法。</p>
</blockquote>
<p><strong>消融实验</strong>：</p>
<ul>
<li><strong>移除S2R模块</strong>：使用未校正仿真训练的RL策略，在现实世界中性能严重下降（路径跟踪误差增至5.2 mm，拾放成功率降至26.7%），验证了预处理S2R机制的必要性。</li>
<li><strong>移除GAIL模块</strong>（仅用仿真RL训练受限空间任务）：策略无法学习到有效的避障和导航行为，在拾放任务中成功率很低，证明了从专家演示中学习的价值。</li>
</ul>
<p><img src="https://arxiv.org/html/2507.16842v1/extracted/6636773/fig/Failure.jpg" alt="失败案例分析"></p>
<blockquote>
<p><strong>图14</strong>：基线方法在受限空间任务中的典型失败案例。(a)纯仿真RL策略导致碰撞；(b)SSC方法因不当的零空间调节导致执行器饱和。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.16842v1/extracted/6636773/fig/pick_place_white.jpg" alt="定性结果展示"></p>
<blockquote>
<p><strong>图15</strong>：SS-ILKC在T型管道内执行拾放任务的连续动作序列定性展示。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个新颖的<strong>传感器空间学习框架（SS-ILKC）</strong>，通过结合仿真强化学习和物理演示模仿学习，实现了对高冗余软体机械臂在未知负载、执行器饱和及受限空间下的鲁棒运动学控制。</li>
<li>设计了一种<strong>预处理的仿真到现实（S2R）迁移机制</strong>，通过前校准而非后微调的方式，准确表征执行器饱和极限并校正仿真模型，实现了策略的零样本现实部署。</li>
<li>开发了<strong>基于GAIL的演示学习模块</strong>，使智能体能从稀疏的专家演示中有效学习复杂受限空间下的控制策略，弥补了纯仿真训练的不足。</li>
</ol>
<p><strong>局限性</strong>：论文提到，当前方法主要针对准静态任务。对于涉及快速动态或极端负载（可能导致传感器非线性或失效）的场景，其性能可能需要进一步验证和增强。</p>
<p><strong>后续研究启示</strong>：本文的工作表明，将<strong>几何传感</strong>、<strong>预处理仿真校正</strong>和<strong>混合学习范式</strong>（仿真RL+演示IL）相结合，是解决软体机器人现实部署中建模不准、泛化不足等挑战的有效途径。未来可探索将该框架扩展到更复杂的动态任务、多机械臂协作，或集成其他模态的感知信息（如触觉）以进一步增强在完全未知环境中的操作能力。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对冗余软体机械臂在未知外部载荷和受限环境下运动学控制困难的问题，提出一种传感器空间模仿学习运动学控制（SS-ILKC）框架。该方法采用双学习策略：基于强化学习的多目标传感器空间控制处理开放空间；生成对抗模仿学习从稀疏专家演示中学习受限空间策略。通过预处理仿真到现实迁移机制，实现零样本真实部署。实验表明，该方法能有效控制气动软体机械臂，在未知载荷的受限环境中完成精确路径跟踪与物体操作。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.16842" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>