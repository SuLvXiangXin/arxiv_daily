<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>SDCD: Structure-Disrupted Contrastive Decoding for Mitigating Hallucinations in Large Vision-Language Models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Computer Vision and Pattern Recognition (cs.CV)</span>
      <h1>SDCD: Structure-Disrupted Contrastive Decoding for Mitigating Hallucinations in Large Vision-Language Models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.03500" target="_blank" rel="noreferrer">2601.03500</a></span>
        <span>作者: Xia, Yuxuan, Wang, Siheng, Li, Peng</span>
        <span>日期: 2026/01/07</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，大视觉语言模型在物体幻觉缓解方面的研究主要集中于减轻语言先验或高层统计偏差。然而，这些方法往往忽略了视觉编码过程的内部复杂性。本文指出，视觉编码器在弱结构监督下固有的“Bag-of-Patches”行为导致了视觉统计偏差，模型倾向于依赖单个图像块内的局部纹理特征，而非整体的几何结构。这种偏差会引发虚假的视觉置信度，从而导致幻觉。本文针对这一由视觉编码内部机制引发的具体痛点，提出了从“结构敏感性差异”入手的新视角。其核心思路是：通过引入一个结构被打乱的“负视图”，与原始视图进行对比解码，惩罚那些在结构缺失条件下仍保持高置信度的令牌，从而抑制纹理驱动的幻觉。</p>
<h2 id="方法详解">方法详解</h2>
<p>SDCD是一个无需训练的推理时校准策略。其整体流程是：给定输入图像和文本查询，模型同时处理原始图像视图 $V$ 和一个通过打乱图像块得到的结构破坏视图 $V&#39;$，然后对两个视图下的输出logits进行对比校准，得到最终的解码分布。</p>
<p><img src="https://arxiv.org/html/2601.03500v1/figures/sdcd_overview.jpg" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：SDCD方法整体框架。给定文本输入 $x$，模型通过联合利用原始视图 $V$ 和打乱视图 $V&#39;$ 进行对比解码。通过抑制纹理驱动的偏差，SDCD在生成过程中有效消除幻觉物体。</p>
</blockquote>
<p>核心模块是结构破坏视图的构建与对比校准机制。首先，给定输入图像 $I$ 和打乱块大小 $S$，将图像重塑为 $N$ 个块的序列 $V = {v_1, v_2, \dots, v_N}$。然后通过一个随机排列函数 $\pi(\cdot)$ 打乱块索引，生成结构破坏视图 $V&#39; = {v_{\pi(1)}, v_{\pi(2)}, \dots, v_{\pi(N)}}$。此操作切断了块间的几何依赖和空间关联，但完全保留了所有局部纹理特征和物体语义。</p>
<p>该方法的关键创新在于利用了论文发现的“结构敏感性差异”。对于真实存在的物体，其对应令牌的生成置信度对结构破坏高度敏感，在 $V&#39;$ 下会显著下降（结构惩罚）。而对于潜在的幻觉物体，其对应令牌的置信度在结构破坏后可能维持甚至升高（纹理释放）。SDCD利用 $V&#39;$ 作为负约束来刻画和抑制这种诱导幻觉的误导性纹理线索。</p>
<p>最终的对比解码分布定义为：<br>$$ p_{\text{SDCD}}(y_{t} \mid V, V&#39;, x) = \operatorname{softmax}\big((1+\alpha),\operatorname{logit}<em>{\theta}(y</em>{t} \mid V, x) - \alpha,\operatorname{logit}<em>{\theta}(y</em>{t} \mid V&#39;, x)\big) $$<br>其中 $\alpha \geq 0$ 是对比超参数，控制对纹理偏差的惩罚强度。该公式构成了一个结构感知的纠正机制：对于真实物体令牌，其 $V&#39;$ 下的logit降低，对比校准主要保留并强化原始视图的结构一致性证据；对于幻觉物体令牌，其 $V&#39;$ 下的高logit会被直接抑制。</p>
<p><img src="https://arxiv.org/html/2601.03500v1/figures/ViT_BoP.png" alt="ViT与CLIP的Bag-of-Patches行为定量分析"></p>
<blockquote>
<p><strong>图2</strong>：Bag-of-Patches行为的定量分析。(a) ViT-B/16在ImageNet验证集子集上，在不同打乱粒度下的Top-1准确率。(b) CLIP-ViT-L/14的图像-文本检索性能（R@1和R@5）。尽管结构被严重破坏，两种模型都保持了强大的语义性能，揭示了其纹理鲁棒性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.03500v1/figures/CLIP_BoP.png" alt="结构敏感性差异图示"></p>
<blockquote>
<p><strong>图3</strong>：LVLM解码中结构敏感性差异的图示。分析了在原始视图($V$)和打乱视图($V&#39;$)下“Yes”和“No”令牌的logit动态。(a) 对于真实答案为“No”的情况（潜在幻觉），错误“Yes”令牌的置信度在$V&#39;$下常常增加，表明当全局结构被移除时，决策由纹理主导。(b) 对于真实答案为“Yes”的情况（真实物体），正确“Yes”令牌的置信度在$V&#39;$下急剧下降，揭示了对全局几何结构的强依赖。这种不对称响应刻画了真实物体与幻觉物体之间的结构敏感性差异。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p>实验使用了多个基准：POPE（用于判别性幻觉评估）、MME（评估整体多模态能力，特别是其幻觉子集）、以及CHAIR（评估开放式生成中的幻觉）。对比的基线方法包括：常规解码（Regular Decoding）、基于视觉不确定性的对比解码VCD、以及基于先验的推理干预PAI。测试的LVLM基础模型包括LLaVA-1.5、Qwen2.5-VL-7B-Instruct（MLP投影器架构）和Qwen-VL（基于Resampler的压缩架构）。</p>
<p>在POPE基准上，对于MLP投影器架构的模型，SDCD在大多数设置下优于常规解码和VCD。例如，LLaVA-1.5在MSCOCO的Random设置下，SDCD准确率达到85.90%，超过常规解码（82.93%）和VCD（84.87%）。Qwen2.5-VL在SDCD下将Recall从64.53%提升至72.07%，同时保持高精度，F1分数达到83.38%，有效纠正了模型的过度拒绝倾向。对于Resampler投影器的Qwen-VL，SDCD与VCD在不同设置下优势互补，SDCD在A-OKVQA (Random)和GQA (Popular)等更具挑战性的设置中取得了最高的F1分数。</p>
<p>在MME基准上（使用LLaVA-1.5），SDCD在存在性、计数、位置等结构敏感类别上取得了最显著的提升，获得了最高的总体感知分数（1348.35），并且在认知任务上也显示出显著优势（338.93），表明强化结构一致性有助于高层推理。</p>
<p>在CHAIR基准上（使用LLaVA-1.5），SDCD在抑制幻觉方面表现最佳，句子级幻觉率($\text{CHAIR}<em>{S}$)和实例级幻觉率($\text{CHAIR}</em>{I}$)分别降至18.6和6.4，显著低于常规解码、VCD和PAI。</p>
<p>消融实验（论文附录）表明，打乱块大小 $S$ 和对比强度 $\alpha$ 需要合理设置。过细的打乱（$S$ 太小）可能无法充分破坏结构，过粗的打乱（$S$ 太大）可能损害局部语义；适中的 $\alpha$（如2.0）能在抑制幻觉和保持正常生成之间取得最佳平衡。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）揭示了LVLM物体幻觉与视觉编码器“Bag-of-Patches”行为导致的视觉统计偏差之间的紧密关联；2）发现了真实物体与幻觉物体令牌之间的“结构敏感性差异”；3）基于此提出了无需训练的SDCD方法，通过结构破坏的对比解码有效抑制纹理驱动的幻觉。</p>
<p>论文提到的局限性包括：对于使用重采样器（Resampler）投影器的模型（如Qwen-VL），由于跨注意力机制会聚合视觉信息，部分削弱了结构扰动的信号，因此SDCD的改进效果相对MLP架构模型有所减弱。此外，生成结构破坏视图并进行额外的前向传播会带来一定的计算开销。</p>
<p>这项工作对后续研究的启示在于：缓解幻觉需要深入理解视觉编码的内部机制及其向语言生成空间的渗透。未来的工作可以探索更高效的结构破坏方式，或设计能够显式增强视觉编码器结构感知能力的训练方法，从根本上纠正“Bag-of-Patches”行为。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对大型视觉语言模型（LVLMs）中普遍存在的物体幻觉问题，指出其根源在于视觉编码器固有的“Bag-of-Patches”行为导致的视觉统计偏差，即模型过度依赖局部纹理特征而忽视整体几何结构。为解决此问题，作者提出了一种无需训练的方法——结构破坏对比解码（SDCD）。该方法通过引入打乱的结构破坏视图，对输出概率分布进行对比校准，惩罚在结构缺失情况下仍保持高置信度的文本标记，从而抑制纹理驱动的偏差。实验表明，SDCD能在多个基准测试上显著减轻幻觉，并提升模型的整体多模态能力。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.03500" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>