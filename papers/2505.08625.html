<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Beyond Predefined Actions: Integrating Behavior Trees and Dynamic Movement Primitives for Robot Learning from Demonstration - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Beyond Predefined Actions: Integrating Behavior Trees and Dynamic Movement Primitives for Robot Learning from Demonstration</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.08625" target="_blank" rel="noreferrer">2505.08625</a></span>
        <span>作者: Domínguez, David Cáceres, Schaffernicht, Erik, Stoyanov, Todor</span>
        <span>日期: 2025/05/13</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在机器人示教学习领域，可解释的策略表示对于确保人类操作者能够理解、分析和调试学习到的行为至关重要。行为树作为一种层次化结构，提供了表示和编排机器人决策过程的直观框架，已有工作展示了从示教中学习行为树结构的能力。然而，现有方法需要以预定义动作集合形式存在的任务特定专家知识，这需要手动设计，不仅耗时，而且限制了可组合行为的范围。另一方面，动态运动原语作为从示教中学习轨迹的灵活框架，被探索用于设计行为树的底层动作基元，但这些方法需要手动设计行为树结构并手动集成预定义动作，通常还需要在执行过程中调整动作参数。因此，当前从示教中学习行为树的方法是不完整的：要么在动作已手动定义时学习行为树结构，要么在行为树结构固定时学习动作参数。</p>
<p>本文针对行为树需要预定义动作、动态运动原语缺乏高层任务逻辑这两个关键局限性，提出将动态运动原语控制器集成到行为树框架中的新视角，从单次示教中联合学习行为树结构和动态运动原语动作，从而消除对预定义动作的需求。本文的核心思路是：利用行为树作为组合结构，动态运动原语作为底层动作生成器，从示教中同时学习高层任务结构和相关的底层动作，并通过行为树节点的前后条件来监督执行，从而创建能够处理不同情况和意外事件的复杂自适应行为。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的方法旨在从人类示教中学习一个完整的行为树策略，无需手动标记或预定义行为树动作。整体流程分为三个阶段，如图3所示。</p>
<p><img src="https://arxiv.org/html/2505.08625v1/x2.png" alt="方法流程图"></p>
<blockquote>
<p><strong>图3</strong>：所提方法流程图。(1) 数据收集阶段收集示教数据 T，将轨迹 t_i 与状态变量 c_i 关联。(2) DMP学习阶段递归地将分割后的轨迹拟合为DMPs π^dmp_{i,j}(θ_{i,j})，并通过DTW进行评估。(3) BT学习阶段使用CART训练一个决策树，并使用RE:BT-Espresso将其转换为行为树策略 π^bt。</p>
</blockquote>
<p><strong>1. 整体框架与目标</strong>：给定包含示教轨迹 t_i 和关联状态变量 c_i 的数据集 T = {(t_i, c_i)}^N_{i=1}，目标是学习一个上层行为树策略 π^bt 和一组下层动态运动原语控制策略 π^dmp_{i,j}(θ_{i,j})，使得 π^bt: (c_i, s_bt) → π^dmp_{i,j}(θ_{i,j})。其中 s_bt 代表由当前tick位置决定的行为树策略 π^bt 的当前执行状态。每个动态运动原语策略被封装在一个行为树动作节点内。两种策略并发运行但频率不同，动态运动原语策略 π^dmp_{i,j}(θ_{i,j}) 控制机器人的底层轨迹 τ_{i,j}。上层行为树策略 π^bt 从数据集 D = {(π^dmp_{i,j}, c_i)}^N_{i=1} 中使用RE:BT-Espresso算法学习。</p>
<p><strong>2. 核心模块详解</strong>：</p>
<ul>
<li><strong>数据收集</strong>：收集示教数据集 T，每个示教包含观察到的轨迹 t_i 和关联的状态变量 c_i。状态 c_i 可以包括环境变量（如物体姿态、传感器读数）或工程条件（如夹爪状态）。如果在示教过程中工程条件发生变化，则会记录新的轨迹 (t_{i+1}, c_{i+1}) 并添加到 T 中。将 c_i 与每个 t_i 关联，确保了每个学习到的 π^dmp 与后续将在 π^bt 中使用的 c_i 子集相一致，从而实现状态间轨迹的连续性，并允许识别来自相似示教、属于同一 π^dmp 的不同 t_i。</li>
<li><strong>动态运动原语学习与轨迹分割</strong>：学习动态运动原语涉及多个参数 θ（例如基函数数量、基函数宽度、典范系统常数）。因此，对 π^dmp_i(θ_i) 中的 θ_i 执行网格搜索，选择最能拟合 t_i 的最优参数配置。为了确定哪个 π^dmp_i(θ_i) 最匹配示教轨迹 t_i，使用FastDTW算法计算示教轨迹 t_i 与动态运动原语生成的轨迹 τ_i 之间的动态时间规整距离 DTW(t_i, τ_i)。随后基于适应度阈值 ϵ 进行评估：若 DTW(t_i, τ_i) ≤ ϵ，则认为 π^dmp_i(θ_i) 学习成功，轨迹 t_i 用该动态运动原语标记；若 DTW(t_i, τ_i) &gt; ϵ，则认为学习不成功，并将 t_i 对半分割，然后为每个分段 t_{i,j} 执行网格搜索以找到最佳的 π^dmp_{i,j}(θ_{i,j})。如图4所示，此分割过程递归进行，直到所有分段满足 DTW(t_{i,j}, τ_{i,j}) ≤ ϵ 并被动态运动原语标记，最终产生数据集 D。</li>
</ul>
<p><img src="https://arxiv.org/html/2505.08625v1/x3.png" alt="递归分割策略"></p>
<blockquote>
<p><strong>图4</strong>：t_i 的递归分割策略：如果 DTW(t_{i,j}, τ_{i,j}) &gt; ϵ，则将其分割为 t_{i,j}。当 DTW ≤ ϵ 时，有效分段（绿色）链接到DMP，并继续处理 t_{i,j+1}。</p>
</blockquote>
<ul>
<li><strong>行为树学习</strong>：使用从动态运动原语学习阶段得到的数据集 D，采用CART算法训练一个决策树。然后，应用RE:BT-Espresso算法将生成的决策树转换为行为树策略 π^bt。RE:BT-Espresso通过消除逻辑冗余来增强所学行为树的可解释性。</li>
</ul>
<p><strong>3. 创新点</strong>：与现有方法相比，本文的核心创新在于<strong>联合且自动地</strong>从原始示教数据中学习高层行为树逻辑和底层动态运动原语动作，完全摒弃了对预定义动作库或手动设计树结构的依赖。通过动态时间规整距离指导的递归轨迹分割，方法能自动将连续示教分解为适合动态运动原语建模的片段，并以此为“动作”标签来驱动行为树结构的学习。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验使用Franka Emika Panda机械臂，装备一个铲子，执行任务：舀起一个网球并将其放入指定的站点中。评估了两种任务变体：(1) 两个目标站点（左或右），(2) 三个目标站点（左、中或右）。实验平台为ROS。</p>
<p><strong>对比方法</strong>：</p>
<ol>
<li><strong>纯动态运动原语</strong>：使用单个动态运动原语复制整个示教轨迹。</li>
<li><strong>带有预定义动作的行为树</strong>：使用RE:BT-Espresso从包含预定义原子动作（如 <code>move_to_ball</code>, <code>scoop_ball</code>, <code>move_to_bin_left</code>）的标记数据集中学习行为树。</li>
<li><strong>本文方法</strong>：结合动态运动原语和行为树，从示教中联合学习。</li>
</ol>
<p><strong>关键实验结果</strong>：</p>
<ul>
<li><strong>任务完成率</strong>：在两个站点的任务中，纯动态运动原语方法成功率为40%，预定义动作行为树为60%，而本文方法达到**100%<strong>。在三个站点的任务中，本文方法成功率为</strong>90%**，显著高于对比方法。</li>
<li><strong>轨迹误差</strong>：本文方法生成的轨迹与示教轨迹之间的动态时间规整距离中位数最低，表明其复现示教运动的能力更强。</li>
<li><strong>策略复杂性</strong>：本文方法学习到的行为树节点数少于使用预定义原子动作的行为树，表明其通过动态运动原语封装更复杂的运动，从而产生了更紧凑、更易解释的策略。</li>
</ul>
<p><img src="https://arxiv.org/html/2505.08625v1/extracted/6435635/fig/dist-2.png" alt="两站点任务结果"></p>
<blockquote>
<p><strong>图8</strong>：两站点任务中，各方法任务完成成功率对比。本文方法（BT with DMPs）达到100%成功率。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2505.08625v1/extracted/6435635/fig/dist-3.png" alt="三站点任务结果"></p>
<blockquote>
<p><strong>图9</strong>：三站点任务中，各方法任务完成成功率对比。本文方法（BT with DMPs）达到90%成功率。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2505.08625v1/extracted/6435635/fig/dist-4.png" alt="轨迹误差对比"></p>
<blockquote>
<p><strong>图10</strong>：各方法生成的轨迹与原始示教轨迹之间的DTW距离中位数对比。本文方法（BT with DMPs）的误差中位数最低。</p>
</blockquote>
<p><strong>消融实验分析</strong>：实验验证了递归分割阈值 ϵ 的影响。结果表明，ϵ 值需要仔细选择：过小会导致过度分割和过多的动态运动原语；过大会导致欠拟合，动态运动原语无法准确捕捉轨迹形状。选择一个合适的 ϵ 对于在运动保真度和行为树复杂性之间取得平衡至关重要。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一种新颖的框架，将动态运动原语与行为树无缝集成，能够从单次人类示教中<strong>联合学习</strong>高层任务逻辑和底层连续动作，无需任何预定义的动作集。</li>
<li>引入了一种基于动态时间规整距离的<strong>递归轨迹分割算法</strong>，自动将演示分解为可由动态运动原语有效表示的子单元，从而自动生成用于行为树学习所需的带标签数据。</li>
<li>所生成的策略兼具<strong>可解释性</strong>（得益于行为树的模块化结构）、<strong>灵活性</strong>（动态运动原语适应新目标）和<strong>动作表达的丰富性</strong>（动态运动原语能够封装复杂的连续运动）。</li>
</ol>
<p><strong>局限性</strong>：论文提到，该方法依赖于状态变量 c_i 在示教过程中被观察并记录变化。对于更隐晦或难以感知的状态变化，可能需要更高级的环境感知或分割技术。此外，动态运动原语参数的调整（如基函数数量）会影响学习效果，需要一定的经验或自动调优。</p>
<p><strong>后续研究启示</strong>：这项工作为从演示中学习分层、可解释的策略开辟了道路。未来的方向可能包括：探索更鲁棒或自动化的轨迹分割标准；将方法扩展到动态环境或需要在线适应的情况；研究如何将强化学习与该方法结合，以进一步优化学习到的动态运动原语参数或行为树逻辑；以及将该框架应用于更复杂的多步骤任务和不同的机器人形态。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人示教学习中，可解释策略（行为树BT）与灵活动作生成（动态运动原语DMP）难以协同的问题，提出一种集成方法。核心方案是将DMP封装为BT的动作节点，利用节点的前后条件监督执行，从而能够从单次演示中**自动学习BT的整体结构及其底层的DMP动作参数**，无需预定义动作库。该方法在机械臂铲球任务中得到验证，实现了高层任务逻辑与底层运动技能的统一学习，提升了策略的可解释性、模块化程度和适应性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.08625" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>