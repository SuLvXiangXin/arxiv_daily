<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2511.03181" target="_blank" rel="noreferrer">2511.03181</a></span>
        <span>作者: Kensuke Harada Team</span>
        <span>日期: 2025-11-05</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人操作可变形物体（如纸张）在物流和辅助机器人等领域至关重要。然而，在诸如电子商务履行流水线的最终礼品包装环节，这一涉及折叠、塞入和粘贴的多步骤过程仍然严重依赖人工。当前主流方法存在关键局限性：纯强化学习方法样本效率低下；基于目标的条件策略在材料非线性变形等未来状态不确定时会失效；而基于示范的方法则需要难以收集的大规模数据集，且难以捕获精细的力控轮廓，通常依赖于硬件特定的遥操作设置。</p>
<p>本文针对长时程、接触丰富的可变形物体操作任务中，高层任务序列规划与低层精细力控制难以统一集成的痛点，提出了一个结合高层语言引导规划、统一策略学习和低层力适应的新视角。本文的核心思路是：通过大语言模型进行高层任务分解与协作规划，利用引入子任务标识符的Transformer模型从人类示范中学习一个覆盖全过程的统一策略，并通过一个残差强化学习模块对动作进行基于导纳控制的实时精细化调整，从而实现鲁棒、精确的纸张包裹。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架旨在从多模态观察历史中生成机器人控制动作。输入包括多视角RGB图像、机器人状态（末端执行器位姿、夹爪开合度）、六维力/扭矩传感器读数以及当前子任务上下文嵌入。输出是末端执行器的笛卡尔空间平移、6D旋转表示和夹爪开合度命令。</p>
<p><img src="https://arxiv.org/html/2511.03181v1/Figs/BK.png" alt="方法框架总览"></p>
<blockquote>
<p><strong>图2</strong>：提出的框架概览：系统输入为自然语言任务描述、多视角RGB观测、机器人本体感知和力/扭矩数据。START模型使用统一策略预测高层动作。并行地，基于语言的任务规划器与人类伙伴同步协作，而残差RL模块学习用于精确动作柔顺执行的导纳控制参数。</p>
</blockquote>
<p>框架包含三个核心模块：</p>
<ol>
<li><p><strong>LLM任务规划器</strong>：该模块接收用户的自然语言指令，通过两个并行的微调LLM进行处理。GPT-4o生成用于条件化START模型的子任务ID序列，提供任务阶段的高层语义信息。GPT-3.5则将同一指令分解为可映射到机器人原语的底层步骤。这些步骤随后通过Codex转换为可执行的机器人代码（如<code>move_to</code>, <code>open_gripper</code>）。<br><img src="https://arxiv.org/html/2511.03181v1/Figs/code_jp.jpg" alt="任务规划流程"></p>
<blockquote>
<p><strong>图3</strong>：基于LLM的任务规划器框架：首先使用GPT将任务描述分解为步骤，然后使用Codex通过将步骤与预定义原语及学习模型生成的坐标结合，生成可执行的机器人命令。同时，它也生成子任务ID。</p>
</blockquote>
</li>
<li><p><strong>子任务感知机器人Transformer模型</strong>：本文提出了START模型，作为对ACT模型的改进。其关键创新在于引入了可学习的子任务ID机制。模型输入包括通过ResNet-18提取的视觉特征、机器人状态、力/扭矩读数以及由CLIP文本编码器生成的子任务嵌入。输出为机器人动作和一个用于隐式切换运动模式的转移标志。子任务ID通过CLIP嵌入注入Transformer编码器，使单个统一策略能根据当前任务阶段（如“拾取”与“压痕”）调整运动模式，从而捕获长时程任务的时序上下文。<br><img src="https://arxiv.org/html/2511.03181v1/Figs/start.png" alt="START模型架构"></p>
<blockquote>
<p><strong>图4</strong>：使用改进的任务感知START模型在真实机器人上学习模仿任务的框架。</p>
</blockquote>
</li>
<li><p><strong>用于导纳参数适应的残差RL</strong>：为解决纯位置控制在接触动态变化时的不足，该模块使用Soft Actor-Critic算法学习一个残差策略。其状态输入包括相对于START预测期望路径点的位置误差、当前工具速度、测量接触力和上一时刻的期望接触力。策略输出一个残差动作向量，包含位置修正量以及自适应的比例和微分增益。更新的导纳控制命令据此计算，实现对接触力的柔顺调节。奖励函数旨在鼓励精确轨迹跟踪、平滑的力调节并惩罚不稳定行为。</p>
</li>
</ol>
<p>与现有方法相比，创新点具体体现在：1) 通过子任务ID机制，使单个Transformer模型能够统一学习长时程任务的所有阶段，避免了为每个子任务训练独立模型；2) 通过残差RL模块进行实时的导纳参数自适应，实现了对纸张刚度变化和接触不确定性的精细力控制，这是纯模仿学习或位置控制难以达到的。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验使用UR3e机械臂搭配Robotiq Hand-E夹爪和力扭矩传感器，以及两个Intel RealSense D435相机提供多视角视觉感知。</p>
<p><img src="https://arxiv.org/html/2511.03181v1/Figs/hardware_setup_jp.jpg" alt="硬件实验平台"></p>
<blockquote>
<p><strong>图5</strong>：实验硬件设置，包括带有Robotiq Hand-E夹爪的UR3e机械臂。两个Intel RealSense D435相机提供多视角RGB感知。</p>
</blockquote>
<p>任务涉及使用标准工业纸盒和白纸进行礼品包装。数据集包含5个可重复子任务的250条专家示范，通过VR遥操作系统收集。<br><img src="https://arxiv.org/html/2511.03181v1/Figs/subtask.png" alt="子任务分解"></p>
<blockquote>
<p><strong>图6</strong>：定义纸张包裹策略的五个可重复子任务和三个核心动作[通过推动折叠、沿着盒子压痕、压折边缘]。</p>
</blockquote>
<p><strong>关键定量结果</strong>：在150次整体任务执行中，取得了97.3%的成功率。各子任务成功率在93.33%到100%之间。为了量化包裹质量，论文提出了纸张完整性分数，通过视觉管道评估撕裂、皱纹和边缘变形。在10次试验中，平均PIS达到0.962，表明纸张保存完好。</p>
<p><strong>消融实验总结</strong>：</p>
<ul>
<li><strong>高层规划器</strong>：微调的LLM规划器任务成功率达90%，而零样本基线完全失败（1%），证明了任务特定微调对生成逻辑正确、可执行计划的重要性。</li>
<li><strong>中层执行器</strong>：从START中移除子任务ID导致长时程任务成功率骤降至35%；移除力/扭矩数据输入导致平均施加力增加115%；用手动启发式替换学习的转移标志使成功率下降30%。这证明了子任务ID、力感知和自动转移对鲁棒执行都至关重要。</li>
<li><strong>低层校正器</strong>：移除RL导纳控制器后，任务成功率从97%降至90%，平均PIS从0.96降至0.89。这凸显了力适应对接触丰富任务的必要性。<br><img src="https://arxiv.org/html/2511.03181v1/Figs/ft.jpg" alt="力曲线对比"><blockquote>
<p><strong>图7</strong>：压痕过程中的力曲线对比。RL精炼的动作紧密跟踪理想地面真值，而原始的START输出则存在过冲或过低的问题，展示了精确且安全的力控制。</p>
</blockquote>
</li>
</ul>
<p><strong>与模块化策略对比</strong>：将统一策略与为每个子任务训练独立策略的模块化基线对比。在存在感知变化（相机偏移）的情况下，统一策略的成功率为97%，而模块化策略降至73%，证明了统一策略在长时程任务中具有更好的泛化鲁棒性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出了一个集成了LLM任务规划、统一Transformer策略学习和残差力控制的混合学习框架，用于解决长时程可变形物体操作任务；2) 设计了子任务感知机器人Transformer模型，通过引入子任务ID使单个模型能够掌握复杂任务的完整时序上下文；3) 开发了一个约束残差强化学习模块，实现了基于导纳控制的实时精细力调节，显著提升了接触任务的执行安全性与精度。</p>
<p>论文提到的局限性包括使用的是单臂系统，因此在折叠过程中需要使用胶带辅助固定纸张边缘，未来可扩展至双臂系统以实现完全自主的双手包裹。</p>
<p>本工作对后续研究的启示在于：展示了如何通过语义子任务分解与标识来桥接高层任务规划与低层连续控制，为其他复杂长时程操作任务提供了可借鉴的框架。同时，将语言模型与机器人技能学习结合，为实现更自然、灵活的人机协作开辟了途径。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人协作包装纸张时，因纸张形变难以预测且需自适应力控制而导致的协调难题，提出了一种学习框架。该框架整合大型语言模型（LLM）进行高级任务规划，并采用混合模仿学习（IL）与强化学习（RL）的低级策略，其核心是能学习统一策略的Sub-task Aware Robotic Transformer（START）。通过引入子任务ID来显式标记时间，模型能捕捉长距离依赖关系，学习子目标而非简单复制动作序列。实验表明，该框架在真实包装任务中取得了97%的成功率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2511.03181" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>