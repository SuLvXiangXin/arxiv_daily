<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.01939" target="_blank" rel="noreferrer">2602.01939</a></span>
        <span>作者: Qiang Nie Team</span>
        <span>日期: 2026-02-02</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>随着人形机器人的快速发展，操作研究重点正从工业场景的协作机器人转向通用应用的人形机器人。这一转变伴随着主摄像头相对于机械臂安装位置的变化：从安装在操作空间侧面转向安装在机器人头部。这种变化带来了基础不变性的灵活性，但也产生了副作用——视觉遮挡问题（主视角更频繁地被遮挡）。近期研究通过基于高自由度主动颈部的主动视觉来应对此问题。本文认为视觉遮挡问题的本质是缺乏对完成任务有用的信息。为了在观察不足的情况下执行操作任务，人类可以主动运用感官，例如移动头部或伸手触摸物体。受此启发，本文将视觉遮挡问题扩展为一个更广泛、更根本的问题，即探索性与专注性操作问题。EFM问题的核心是主动寻求信息，以完成需要探索或专注的挑战性操作任务。本文的核心思路是提出EFM问题并建立EFM-10基准测试，同时提出一种利用非操作臂提供手眼主动视觉、操作臂提供力感知的双臂主动感知策略来应对该问题。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的整体策略是双臂主动感知。其核心思想是利用非操作臂（如果可用）为正在进行的任务提供手眼主动视觉，并利用操作臂在接触过程中提供力感知。该策略的动机在于，大多数现有人形机器人不具备近期主动视觉研究中所采用的6/7自由度主动颈部，但拥有两条并不总是同时操作的手臂，可以更高效地利用它们。BAP策略与基于颈部的主动视觉完全兼容，未来可结合两者以最大化利用所有可用摄像头，并在双臂都忙碌时实现主动感知。</p>
<p><img src="https://arxiv.org/html/2602.01939v1/x1.png" alt="BAPData数据集示例"></p>
<blockquote>
<p><strong>图1</strong>：为EFM-10中10个任务收集的BAPData数据集示意图。左侧为左腕部视角图像，中间为主视角图像，右侧为右腕部视角图像，按时间顺序展示每个示例。</p>
</blockquote>
<p>BAP策略的具体实施体现在数据收集和策略学习两个阶段。在数据收集阶段，作者使用真实世界双臂机器人，基于BAP策略记录专家演示，构建了名为BAPData的数据集。该数据集包含1810条轨迹，覆盖EFM-10中的所有任务。数据模态包括来自头部（主视角）和两个腕部（主动视角）的视觉观察，以及来自操作臂末端执行器的6维力/扭矩传感数据。在策略学习阶段，采用模仿学习的方式，利用收集到的多模态数据（主视角、主动视角、力/扭矩、本体感知、动作指令）训练端到端的操作策略。实验发现了一个微妙但重要的技术细节：当手持物体进行精细操作时，在主动视角中捕捉操作末端执行器比仅捕捉手持物体更好，因为后者无法提供关于操作末端执行器应如何调整姿态的直接线索。</p>
<p>与现有方法相比，BAP的创新点在于：1) 不依赖高自由度主动颈部，而是利用机器人已有的双臂架构实现主动感知，对现有人形机器人平台更具普适性；2) 将主动视觉与力感知在双臂框架下协同使用，分别由非操作臂和操作臂承担，以同时应对探索性任务中的视觉信息缺失和专注性任务中的精细接触控制需求。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验使用了作者新建立的EFM-10基准测试，该基准包含10个需要探索或专注的挑战性任务，分为4类：语义探索任务、涉及视觉遮挡的探索任务、需要专注的精细任务、以及同时需要探索和专注的复杂任务。实验平台为真实世界双臂机器人。</p>
<p>对比的基线方法包括：1) <strong>仅主视角</strong>：仅使用头部固定主视角图像和本体感知数据。2) <strong>主视角+力感知</strong>：在主视角基础上增加操作臂的力/扭矩数据。3) <strong>主视角+主动视觉</strong>：在主视角基础上增加非操作臂腕部摄像头提供的主动视角图像。4) <strong>BAP（完整）</strong>：同时使用主视角、主动视觉和力感知。</p>
<p><img src="https://arxiv.org/html/2602.01939v1/x2.png" alt="任务成功率对比"></p>
<blockquote>
<p><strong>图2</strong>：不同策略在EFM-10各任务上的成功率对比。BAP（完整）策略在绝大多数任务上取得了最高成功率。</p>
</blockquote>
<p>关键实验结果总结如下：在EFM-10的所有10个任务上，完整的BAP策略（结合主视角、主动视觉和力感知）取得了最佳的整体性能。具体而言，与非操作臂提供的主动视觉相比，仅使用主视角的策略在所有任务上的成功率都显著更低。例如，在“Cable-Match”任务中，BAP完整策略的成功率达到80%，而仅主视角策略的成功率仅为20%。力感知的加入对涉及精细操作的任务（如“Light-Plug”、“Nail-Knock”）带来了显著提升。主动视觉则对所有类型的任务都有普遍助益，尤其是在涉及视觉遮挡（如“Cup-Hang”）或需要近距离观察（如“Charger-Plug”）的任务中。</p>
<p><img src="https://arxiv.org/html/2602.01939v1/x3.png" alt="消融研究"></p>
<blockquote>
<p><strong>图3</strong>：在“Charger-Plug”任务上的消融研究，展示了不同感知模态组合对任务成功率的影响。</p>
</blockquote>
<p>消融实验明确了每个组件的贡献：1) <strong>主动视觉</strong>：通过提供无遮挡或更集中的视角，普遍提升了所有任务的成功率，是应对探索性任务和视觉遮挡的关键。2) <strong>力感知</strong>：专门提升了涉及接触和精细操作任务（如插入、敲击）的性能，实现了神经力顺应控制。实验还验证了在主动视角中捕捉末端执行器对于精细操作的重要性。</p>
<p><img src="https://arxiv.org/html/2602.01939v1/x4.png" alt="定性结果"></p>
<blockquote>
<p><strong>图4</strong>：BAP策略在“Cable-Match”任务中的定性结果序列，展示了机器人如何先探索端口颜色，再执行插入操作。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.01939v1/x5.png" alt="注意力可视化"></p>
<blockquote>
<p><strong>图5</strong>：策略网络在处理“Charger-Plug”任务时对主视角和主动视角的注意力可视化。在探索阶段（定位端口），注意力集中在主视角；在执行精细插入阶段，注意力转移到主动视角。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) 提出了探索性与专注性操作这一新问题，并构建了包含10个任务的综合性基准测试EFM-10，为未来研究奠定了基础。2) 提出了双臂主动感知策略，该策略不依赖主动颈部，利用非操作臂提供主动视觉，操作臂提供力感知，并基于此收集了BAPData数据集。3) 通过模仿学习实验，验证了BAP策略的有效性，并揭示了在精细操作中主动视角应捕捉末端执行器而非仅手持物体的重要技术细节。</p>
<p>论文提到的局限性包括：BAP策略假设至少有一条手臂可用于提供主动视觉，当双臂都忙于操作时，该策略需要与基于颈部的主动视觉结合，而后者是未来的研究方向。</p>
<p>对后续研究的启示：EFM-10基准和BAP策略为研究如何在信息不完备情况下通过主动感知完成复杂操作任务提供了新的问题定义、评估标准和初始解决方案。这项工作鼓励社区关注超越简单拾放的操作任务，向需要主动信息收集和精细控制的更通用、更复杂的人形机器人操作迈进。将BAP与颈部主动视觉结合，以及探索更高级的主动感知规划算法，是未来有前景的方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人操作中因视觉遮挡导致信息缺失的问题，提出了探索与聚焦操作这一新问题。为此，作者建立了包含10个任务的EFM-10基准，并设计了一种双主动感知策略，即利用一只手臂提供主动视觉，另一只手臂在操作时提供力觉。基于该策略收集了BAPData数据集，并通过模仿学习验证了其有效性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.01939" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>