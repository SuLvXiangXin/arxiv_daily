<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.24055" target="_blank" rel="noreferrer">2510.24055</a></span>
        <span>作者: Jiashuo Bai Team</span>
        <span>日期: 2025-10-28</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>目前，模仿学习是机器人获取操作技能的有效范式，主流方法如基于Transformer的动作分块（ACT）和基于扩散的策略（DP）在单任务基准上表现出色。然而，在多任务场景中，这些方法面临两大关键局限性：一是“相似输入、不同输出”的感知模糊性，即视觉上相似的场景可能对应完全不同的用户意图，迫使网络平均矛盾的动作；二是任务冲突，即当单一策略网络学习多样化任务时，不同任务的梯度更新在网络的共享组件中相互干扰，导致负迁移。现有的大型视觉-语言-动作（VLA）模型虽展现出潜力，但其庞大的参数量和较高的延迟使其难以应用于实时机器人系统。因此，本文针对多任务模仿学习中的感知模糊性和任务冲突这两个具体痛点，提出了一种结合语义对齐和专家专业化的新视角。本文的核心思路是：设计一个轻量级的语言条件视觉表示（LCVR）模块，通过语言指令对视觉特征进行语义对齐以解决感知模糊性；并提出一个语言条件专家混合密度策略（LMoE-DP），利用稀疏的专家混合（MoE）架构来专门处理不同的多模态动作分布，以缓解任务冲突。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的框架包含三个核心组件：用于生成语义接地状态表示的LCVR模块、用于解决任务冲突的稀疏MoE架构LMoE-DP策略，以及用于稳定训练和确保专家有效专业化的FAMO梯度调制算法。</p>
<p><img src="https://arxiv.org/html/2510.24055v1/image/LCVR.jpg" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：LCVR模块架构。从高分辨率图像中提取九个局部和一个全局图像块，通过一个共享的、预训练且冻结的CLIP ViT-B/16编码器进行编码。得到的图像块标记通过交叉注意力（全局特征作为查询Q，局部特征作为键K/值V）融合，合成统一的视觉特征。该特征随后与语言指令的嵌入向量拼接，并由一个轻量级Transformer处理，最终生成用于下游LMoE-DP策略的语言条件表示 z_LCVR。</p>
</blockquote>
<p><strong>语言条件视觉表示（LCVR）模块</strong>：该模块旨在生成语义接地且空间准确的状态表示。其输入为高分辨率图像 I (480x640x3) 和语言指令。首先，采用多尺度编码策略：使用冻结的预训练CLIP编码器，从图像中提取一个全局特征 f_global 和九个局部块特征 {f_local^i}，以保留整体上下文和高保真细节。然后，通过交叉注意力机制将局部特征（作为键/值）与全局特征（作为查询）融合，聚焦于任务相关细节，得到统一的视觉表示 f_vision。接着，将语言指令进行标记化并投影为嵌入序列 f_lang，与 f_vision 拼接。最后，一个轻量级Transformer编码器（采用了分组查询注意力GQA、RMSNorm和旋转位置嵌入RoPE以提高效率）对拼接后的特征进行深度集成，输出最终的语言条件状态表示 z_LCVR。</p>
<p><img src="https://arxiv.org/html/2510.24055v1/image/L-MOE-DP.jpg" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：LMoE-DP架构概述。该策略是一个条件扩散模型。一个以语言-视觉特征 z_LCVR、机器人本体状态和扩散时间步 k 为条件的Transformer主干网络，处理带噪声的动作序列 A^k，生成特征表示 X_feat。一个序列级门控网络使用Top-2策略（训练时）或Top-1策略（推理时）将该表示路由到一组专门的MDN专家库。每个激活的MDN专家参数化一个高斯混合模型来预测噪声 ε_pred，由DDIM调度器用于迭代计算更干净的动作 A^{k-1}。</p>
</blockquote>
<p><strong>语言条件专家混合密度策略（LMoE-DP）</strong>：这是一个基于条件扩散模型的策略网络，旨在解决策略网络内部的任务冲突并显式建模多模态动作分布。其输入包括：来自LCVR模块的 z_LCVR、机器人本体状态 p_proprio（如关节角度）、扩散时间步 k 和带噪声的动作轨迹 A^k。这些输入被拼接成综合状态表示 s，并输入到一个Transformer主干网络 F_T 中，生成丰富的特征序列 X_feat。<br>该策略的核心创新在于用稀疏MoE架构替换了单一回归头，其中每个专家实现为一个混合密度网络（MDN）。具体流程如下：</p>
<ol>
<li><strong>序列级门控与稀疏路由</strong>：门控网络 G 首先对特征序列 X_feat 进行平均池化，得到序列级特征 x_seq，然后计算 N_e 个专家的路由概率 g。<strong>训练时</strong>采用软性Top-2策略，即选择两个概率最高的专家，并根据其归一化权重 g_i‘ 结合其输出计算总损失。<strong>推理时</strong>采用硬性Top-1策略，选择概率最高的单个专家 i* 来生成整个动作轨迹，确保一致性。</li>
<li><strong>混合密度预测与参数化</strong>：每个MDN专家 E_i 接收 X_feat，并行输出所有时间步的高斯混合模型（GMM）参数，包括混合系数 π、均值 μ 和对数标准差 σ^。训练损失是目标噪声序列 ε 在Top-2专家组合下的联合密度的负对数似然。推理时，首先固定选择专家 i<em>，然后对每个时间步 t 选择该专家内混合系数最高的GMM分量 m</em>，取其均值作为预测噪声 ε_pred,t，最后通过DDIM调度器迭代去噪得到最终动作序列 A^0。</li>
<li><strong>辅助损失与梯度调制</strong>：为了防止专家崩溃并促进负载均衡，引入了加权辅助损失 L_aux，包含负载均衡项和重要性项。更重要的是，为了缓解共享主干网络 F_T 因不同专家产生的冲突梯度而导致的负迁移，采用了快速自适应多任务优化（FAMO）算法。FAMO为每个活跃专家的损失计算关于共享参数的梯度 g_i，然后通过求解一个最小范数优化问题得到一组非负系数 α_i，最终将调制后的梯度 g_FAMO = Σ α_i g_i 与门控网络混合损失梯度相结合，用于更新共享参数，从而确保更新沿着帕累托有效的下降方向，最小化梯度冲突。</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在一个配备6自由度Realman机械臂、EG2-4C2夹爪和顶置Intel RealSense D435i相机的真实机器人平台上进行（如图3）。评估使用了包含5个代表性操作任务的数据集，每个任务有多个变体（如图5）。成功标准是在60秒内抓取正确物体并放入目标区域。性能以成功率衡量。</p>
<p><img src="https://arxiv.org/html/2510.24055v1/image/setup.jpg" alt="实验平台"></p>
<blockquote>
<p><strong>图3</strong>：真实世界实验平台，展示了机器人臂、夹爪和顶置相机。</p>
</blockquote>
<p><strong>LCVR有效性评估</strong>：为了评估LCVR解决感知模糊性的能力，在四个具有高度视觉相似性的操作任务上（如图4）进行了测试。将LCVR集成到ACT和DP基线中，替换其标准ResNet-18视觉编码器。</p>
<p><img src="https://arxiv.org/html/2510.24055v1/image/LCVRexperiment.jpg" alt="评估任务"></p>
<blockquote>
<p><strong>图4</strong>：用于评估的四个操作任务示意图，红色圆圈指示目标物体。</p>
</blockquote>
<p>表I结果显示，LCVR带来了显著的性能提升。ACT的平均成功率从26.25%提升至60.00%，DP从32.50%提升至57.50%。这证实了LCVR通过细粒度视觉表示和语言条件有效缓解了感知模糊性。</p>
<p><strong>LMoE-DP任务专业化评估</strong>：在五个多任务类别（共9个变体，如图5）上，将LMoE-DP与先进的Σ-agent基线进行对比。</p>
<p><img src="https://arxiv.org/html/2510.24055v1/image/Nine3.jpg" alt="任务变体"></p>
<blockquote>
<p><strong>图5</strong>：用于评估的5个任务及其9个变体的示意图，包括每个任务使用的具体语言模板。</p>
</blockquote>
<p>表II结果显示，LMoE-DP以79%的平均成功率显著优于Σ-agent的58%，实现了21%的绝对提升。在动作分布独特的任务（如“挂杯子”、“放物品进桶”）上提升尤为明显（+30%， +35%），表明MoE架构成功地将这些独特技能分配给专门专家，隔离了冲突梯度。</p>
<p><strong>专家与组件数量网格搜索</strong>：为了平衡专家数量（N_e）和每个专家的MDN组件数量（M），进行了网格搜索（表III）。结果表明，性能最佳的配置是 N_e=4, M=5（成功率92%）。过少（M=1）无法建模多模态，过多（M=9）则导致过参数化和优化不稳定。专家数量太少（N_e=1）导致性能差，太多（N_e=5）则可能使每个专家数据不足。这证实了适度的专家数量（3-4）配合适度的MDN复杂度（3-5个分量）是最有效的。</p>
<p><strong>梯度调制消融实验</strong>：通过比较使用和不使用FAMO梯度调制的训练动态，评估其对稳定性的影响。</p>
<p><img src="https://arxiv.org/html/2510.24055v1/image/famo.jpg" alt="训练动态"></p>
<blockquote>
<p><strong>图6</strong>：使用和不使用FAMO的训练动态比较。FAMO改善了梯度对齐，平衡了专家利用率，稳定了门控分布，表现为更低的负载方差、更平滑的Top-1概率、降低的验证负对数似然（Val-NLL）以及更高的梯度余弦相似度。</p>
</blockquote>
<p>图6显示，FAMO显著提高了训练稳定性：梯度余弦相似度更高（表明梯度冲突减少），专家负载方差更低，门控网络的Top-1专家概率曲线更平滑，验证负对数似然（Val-NLL）也更低。这直接回答了研究问题Q3，表明梯度调制对于实现稳定的专家专业化和高效的多任务学习至关重要。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) 设计了轻量级、即插即用的LCVR模块，通过语义对齐高效解决多任务操作中的感知模糊性；2) 提出了LMoE-DP策略，利用稀疏MoE架构和MDN专家来缓解任务冲突并建模复杂的多模态动作分布；3) 引入了FAMO梯度调制，有效稳定了MoE模型的训练，促进了专家间的平衡专业化。<br>论文自身提到的局限性主要在于超参数（专家数量N_e和MDN组件数M）需要根据具体任务和数据量进行仔细调整，网格搜索表明过高的参数会导致性能下降和优化不稳定。<br>本文对后续研究的启示在于：将语义接地表示与模块化、专业化的策略架构相结合，是构建高效、鲁棒的多任务机器人系统的有前途方向。未来的工作可以探索如何使专家选择和组件数量的配置更加自适应，或者将类似原理扩展到更广泛的机器人学习范式中。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对多任务机器人模仿学习中的感知模糊性与任务冲突问题，提出了一种结合**语言条件视觉表示模块**和**语言条件专家混合密度策略**的框架。前者通过语言指令对齐视觉特征以区分相似任务；后者采用稀疏专家架构，让不同专家专精于多模态动作分布，并通过梯度调制稳定训练。在真实机器人基准测试中，该框架将ACT与DP的成功率分别提升33.75%和25%，整体平均成功率达到79%，优于先进基线21%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.24055" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>