<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Geometric Visual Servo Via Optimal Transport - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Geometric Visual Servo Via Optimal Transport</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.02768" target="_blank" rel="noreferrer">2506.02768</a></span>
        <span>作者: Ashutosh Tiwari Team</span>
        <span>日期: 2025-06-03</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>视觉伺服控制是机器人领域的关键技术，通过跟踪图像特征生成误差信号来控制机器人运动。传统方法主要分为两类：基于位姿的视觉伺服（PBVS）和基于图像的视觉伺服（IBVS）。PBVS将特征映射到位姿空间计算误差，而IBVS直接跟踪图像特征。然而，这两种方法均存在局限性：PBVS依赖于精确的位姿估计，对传感器噪声敏感；IBVS则通常需要手工设计和调校特征提取方法，缺乏通用性，且难以处理复杂的几何形状。此外，现有方法通常将位姿误差和图像特征误差分开处理，未能提供一个统一的框架。</p>
<p>本文针对上述痛点，提出了一个新的视角：将相机获取的深度图（点云）视为定义在三维特殊欧几里得群SE(3)上的概率测度。通过最优传输理论，计算当前深度图与目标深度图之间的Wasserstein距离，该距离在几何上等价于SE(3)上的测地线距离。基于此，本文开发了一个几何控制器，将经典的PD控制与重力补偿相结合，并通过在SE(3)群上的测地线流进行误差最小化，从而实现了位姿与图像特征误差的统一处理。核心思路是：在SE(3)李群上建立端口哈密顿动力学模型，并将深度图表述为概率测度，利用最优传输距离定义控制误差，从而设计出同时适用于PBVS和IBVS的几何视觉伺服控制器。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的控制架构整体流程如下图所示。其核心在于将视觉伺服问题重新表述为在SE(3)李群上概率测度的最优传输问题，并基于端口哈密顿动力学设计控制器。</p>
<p><img src="https://arxiv.org/html/2506.02768v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：本文提出的几何视觉伺服控制架构。红色部分（最优传输图T*的计算）在控制循环初始化时离线执行，使用初始深度图和目标位姿。蓝色部分（扰动校正输入u_DC的计算）在线运行，利用当前相机深度图和预计算的传输图生成控制信号。绿色部分（基于无源性的位姿控制输入）提供几何位姿控制。最终控制输入是两者的结合。</p>
</blockquote>
<p><strong>整体框架与输入输出</strong>：</p>
<ol>
<li><strong>初始化（离线）</strong>：输入为机械臂初始位姿对应的深度图（概率测度μ0）和目标位姿对应的深度图（概率测度μ1）。通过求解不平衡最优传输问题，计算从μ0到μ1的最优传输映射T*。</li>
<li><strong>在线控制</strong>：在每个时间步，输入为当前相机实时获取的深度图（概率测度μt）以及预计算的最优传输映射T*。控制器输出为机械臂关节的扭矩控制输入u。该输入由两部分组成：基于端口哈密顿动力学的几何位姿控制输入（用于稳定系统动力学）和基于最优传输的扰动校正输入（用于将当前深度图向目标深度图传输）。</li>
</ol>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>系统动力学建模（端口哈密顿形式）</strong>：论文在SE(3)李群上推导了机械臂的端口哈密顿动力学。这种形式将系统的几何特性（如旋转和平移）自然地嵌入到动力学方程中，并提供了能量守恒的物理解释。动力学状态包括位姿g ∈ SE(3)和动量p。通过设计无源性的控制律（类似PD控制加重力补偿），可以保证系统的稳定性，为后续基于视觉的误差校正提供基础。</li>
<li><strong>视觉特征作为概率测度</strong>：将RGB-D相机产生的深度图（点云）解释为定义在SE(3)任务空间上的概率测度μ。这意味着每个三维点不仅包含空间位置信息，其分布本身也被赋予了概率权重。这种表述方式使得可以使用概率度量工具（如Wasserstein距离）来量化两个点云之间的差异。</li>
<li><strong>基于最优传输的误差生成与控制</strong>：这是方法的核心创新点。最优传输理论用于计算两个概率测度μ（当前）和ν（目标）之间的“距离”。本文采用Wasserstein距离，其几何意义对应于SE(3)流形上的测地线距离。控制器利用离线计算的最优传输映射T*，结合当前深度图μt，生成一个“扰动校正”输入u_DC。这个输入的作用是沿着最小能量路径（即测地线）推动当前深度图向目标深度图演化，其本质是在任务空间注入能量以最小化Wasserstein误差。</li>
</ol>
<p><strong>创新点</strong>：</p>
<ul>
<li><strong>统一的几何框架</strong>：在SE(3)李群上统一处理位姿（PBVS）和图像特征（IBVS），避免了传统方法二选一的局限。</li>
<li><strong>概率特征表述</strong>：将深度图视为概率测度，无需手工设计或调校具体的图像特征（如角点、矩），方法更具通用性。</li>
<li><strong>最优传输作为误差度量</strong>：利用Wasserstein距离作为控制误差，该距离具有坚实的几何和概率基础，能够自然地处理点云的整体形状和分布差异，而不仅仅是单个点的匹配。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>平台</strong>：在配备有Robotiq 2F-85夹持器和Intel RealSense D435i深度相机的UR5机械臂上进行真实世界实验。</li>
<li><strong>任务与数据集</strong>：使用一个具有方形孔洞的木板作为目标物体。定义了多个不同的初始机械臂位姿（初始深度图μ0）和一个固定的目标位姿（目标深度图μ1），以测试方法的泛化能力。目标是将相机移动到使当前看到的孔洞深度图与存储的目标深度图对齐的位置。</li>
<li><strong>对比基线</strong>：论文主要展示了所提出方法自身的性能，并未与其他传统的PBVS或IBVS方法进行数值对比，而是通过在不同初始条件下成功完成任务来证明其有效性和泛化性。</li>
</ul>
<p><strong>关键实验结果</strong>：<br>论文通过一系列图表展示了控制过程。首先展示了目标物体（方形孔板）和从初始位姿、中间位姿到最终位姿的深度图序列，直观显示了深度图向目标对齐的过程。</p>
<p><img src="https://arxiv.org/html/2506.02768v1/extracted/6508162/images/square_hole.png" alt="目标物体"></p>
<blockquote>
<p><strong>图3</strong>：实验使用的目标物体——带有方形孔洞的木板。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.02768v1/extracted/6508162/images/frame_0.png" alt="深度图序列"></p>
<blockquote>
<p><strong>图4</strong>：初始时刻（t=0）的深度图。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.02768v1/extracted/6508162/images/frame_25.png" alt="深度图序列"></p>
<blockquote>
<p><strong>图5</strong>：控制过程25%时刻的深度图。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.02768v1/extracted/6508162/images/frame_50.png" alt="深度图序列"></p>
<blockquote>
<p><strong>图6</strong>：控制过程50%时刻的深度图。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.02768v1/extracted/6508162/images/frame_75.png" alt="深度图序列"></p>
<blockquote>
<p><strong>图7</strong>：控制过程75%时刻的深度图。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.02768v1/extracted/6508162/images/frame_100.png" alt="深度图序列"></p>
<blockquote>
<p><strong>图8</strong>：最终时刻（t=100）的深度图，已与目标深度图对齐。</p>
</blockquote>
<p>关键的定量结果如下：位置误差范数最终收敛到接近零（约0.0025米），旋转误差（通过对数映射计算）也成功收敛。控制输入扭矩在整个过程中保持平滑，系统动能逐渐衰减至零，表明系统稳定。</p>
<p><img src="https://arxiv.org/html/2506.02768v1/extracted/6508162/images/geodesic.png" alt="位姿误差"></p>
<blockquote>
<p><strong>图9</strong>：机械臂末端执行器在任务空间中的运动轨迹（测地线）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.02768v1/extracted/6508162/images/pos_error.png" alt="位置误差"></p>
<blockquote>
<p><strong>图10</strong>：位置误差‖p‖随时间的变化。误差成功收敛到接近零（约0.0025米）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.02768v1/extracted/6508162/images/rot_error.png" alt="旋转误差"></p>
<blockquote>
<p><strong>图11</strong>：旋转误差（通过李代数坐标表示）随时间的变化。误差成功收敛到零。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.02768v1/extracted/6508162/images/input.png" alt="控制输入"></p>
<blockquote>
<p><strong>图12</strong>：六个关节的控制输入扭矩（u）随时间的变化。输入平滑无抖振。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.02768v1/extracted/6508162/images/kinetic.png" alt="动能"></p>
<blockquote>
<p><strong>图13</strong>：系统动能随时间的变化。动能最终衰减至零，表明系统达到稳定静止状态。</p>
</blockquote>
<p><strong>消融实验分析</strong>：<br>论文虽未进行严格的模块消融实验，但其架构本身揭示了组件的必要性。整体控制输入u由基于动力学的位姿控制（绿色部分）和基于最优传输的视觉伺服控制（蓝色部分）叠加而成。前者保证了系统的动力学稳定和无源性，后者提供了驱动系统向视觉目标运动的具体误差信号。两者缺一不可：若无几何位姿控制，系统可能不稳定；若无最优传输校正，则无法实现基于深度图的视觉伺服任务。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>提出了一个统一的几何视觉伺服框架</strong>：在SE(3)李群上，通过端口哈密顿动力学将机器人控制与基于最优传输的视觉误差生成相结合，同时解决了PBVS和IBVS问题。</li>
<li><strong>将视觉特征表述为概率测度</strong>：将深度图建模为SE(3)上的概率测度，从而可以利用最优传输理论来定义和最小化当前与目标视觉场景之间的“距离”。</li>
<li><strong>设计了基于最优传输的控制器</strong>：利用Wasserstein距离及其对应的测地线流，生成控制信号以最小化视觉误差，为视觉伺服提供了一种新的、基于几何和概率的误差驱动方法。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到，计算初始最优传输映射T*可能需要相当的计算成本，尽管这是在离线阶段完成的。此外，当前方法假设目标深度图是静态的，并未考虑动态目标跟踪的场景。</p>
<p><strong>后续研究启示</strong>：</p>
<ol>
<li><strong>扩展到更广泛的系统</strong>：该方法框架不局限于机械臂，可应用于任何使用视觉反馈的自主系统（如无人机、移动机器人）。</li>
<li><strong>处理动态目标</strong>：未来的工作可以探索如何将框架扩展到跟踪运动目标，这可能涉及在线更新最优传输映射或预测目标运动。</li>
<li><strong>与机器学习结合</strong>：为了降低最优传输的在线计算复杂度，可以探索使用神经网络来近似传输映射或直接生成控制策略。</li>
<li><strong>探索不同的概率表示</strong>：可以研究除深度图点云之外的其他视觉特征（如语义分割图）的概率测度表示，以完成更复杂的任务。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人视觉伺服控制中忽略概率特征、依赖手动特征提取的问题，提出一种基于最优传输的几何控制律。方法将相机输入建模为3维特殊欧几里得群上的概率测度，利用Wasserstein距离类比几何测地线，结合经典PD控制与重力补偿，通过测地线流最小化误差，实现姿态与图像视觉伺服的统一。实验通过测试案例验证了该方法对不同初始位置的泛化能力。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.02768" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>