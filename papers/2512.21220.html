<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Artificial Intelligence (cs.AI)</span>
      <h1>RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.21220" target="_blank" rel="noreferrer">2512.21220</a></span>
        <span>作者: Wang, Le, Ying, Zonghao, Yang, Xiao, Zou, Quanchen, Yin, Zhenfei, Li, Tianlin, Yang, Jian, Yang, Yaodong, Liu, Aishan, Liu, Xianglong</span>
        <span>日期: 2025/12/24</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，由视觉语言模型驱动的具身智能体在执行复杂任务方面表现出色，但其容易受到恶意危险指令的攻击，从而执行可能造成实际物理伤害的不安全行为。运行时安全护栏通过在任务执行过程中拦截危险动作，提供了一种灵活且轻量化的安全解决方案。然而，现有防御方法通常依赖于预定义的静态规则过滤器或手工设计的安全对齐提示，难以有效应对动态、时间依赖且上下文丰富的环境中出现的隐式风险。具体而言，它们难以处理两类风险：<strong>上下文风险</strong>（一个看似良性的动作因特定上下文而变得危险，例如“打开微波炉”在内部有金属餐具时是危险的）和<strong>时序风险</strong>（危险源于一段时间内不安全的动作序列，例如“长时间让热炉灶开着而不关闭”）。</p>
<p>本文针对上述现有方法在动态、复杂场景下识别隐式风险的局限性，提出了一种基于可执行安全逻辑的混合推理运行时护栏新视角。核心思路是设计一个结合<strong>前向预测推理</strong>和<strong>后向反思推理</strong>的双向安全逻辑验证框架，并利用一个<strong>混合长短安全记忆</strong>来存储和检索安全知识，从而生成可解释、可执行的代码化安全逻辑，以主动防御上下文和时序风险。</p>
<h2 id="方法详解">方法详解</h2>
<p>RoboSafe的整体框架是一个运行时护栏系统，它将具身智能体视为黑盒，在智能体输出每个动作 <code>a_t</code> 前进行安全验证。其核心是引入一个<strong>护栏VLM</strong>，该模型与一个<strong>混合长短安全记忆</strong>交互，执行双向推理。长期记忆 <code>M^L</code> 存储结构化的终身安全经验，短期记忆 <code>M^S</code> 存储当前指令 <code>T</code> 下的近期轨迹 <code>τ</code>。</p>
<p><img src="https://arxiv.org/html/2512.21220v2/x2.png" alt="方法框架总览"></p>
<blockquote>
<p><strong>图2</strong>：RoboSafe整体运行时护栏框架。框架集成了前向预测推理（用于预防上下文风险）和后向反思推理（用于缓解时序风险），确保在动态、时间依赖场景下的防御有效性。</p>
</blockquote>
<p><strong>前向预测推理模块</strong>旨在预防上下文风险。其流程如下：</p>
<ol>
<li><strong>安全知识生成与记忆构建</strong>：从安全基准（如SafeAgentBench）的训练集中，利用大语言模型自动生成结构化的种子安全知识。采用<strong>知识解耦机制</strong>，将复杂物理场景分解为两种互补形式：① 高级可读的安全推理演示 <code>ρ_t</code>，指导护栏VLM进行情境化推理；② 为 <code>ρ_t</code> 定制的低级可执行逻辑谓词集合 <code>Φ_t</code>（例如 <code>observation[held_object] not in [Knife, Fork, Hammer]</code>）。这些知识连同观察 <code>o_t</code>、动作 <code>a_t</code> 等构成初始记忆条目存入 <code>M^L</code>。</li>
<li><strong>多粒度安全知识检索</strong>：在每个时间步 <code>t</code>，护栏VLM首先从当前RGB场景 <code>I</code> 中提取并总结所有可见物体及其安全相关属性，形成多模态观察 <code>o_t</code>。然后，它使用<strong>多粒度上下文检索策略</strong>，结合粗粒度的上下文（<code>o_t</code>, <code>T</code>, <code>M^S</code>）和细粒度的动作 <code>a_t</code> 作为查询，通过文本编码器计算与 <code>M^L</code> 中每个条目的相关性得分 <code>S(m_i^L)</code>（公式4）。该得分综合考虑了动作级和上下文级语义相似度，并引入了标签平衡权重 <code>ω(y_i)</code> 来缓解 <code>M^L</code> 中“良性”样本占主导的偏差。最终检索出最相关的 <code>k</code> 个安全经验子集 <code>M_t^L</code>。</li>
<li><strong>上下文逻辑验证</strong>：利用检索到的 <code>M_t^L</code> 中的高级推理演示 <code>ρ_t</code> 来指导对当前情境的风险评估，并生成对应的可验证低级逻辑谓词集 <code>Φ_t(M_t^L)</code>。<strong>上下文逻辑</strong> <code>L_t^f(·)</code> 定义为这些谓词的逻辑或（公式6）。如果任何谓词被触发（返回1），则逻辑验证为真，护栏将执行 <code>block</code> 动作以阻止 <code>a_t</code>。验证后，若生成的安全逻辑无误且可执行，则将当前经验（包括 <code>o_t</code>, <code>a_t</code>, <code>ρ_t</code>, <code>T</code>, <code>Φ_t</code>, <code>M^S</code>）更新到长期记忆 <code>M^L</code> 中，实现安全知识的自主积累。</li>
</ol>
<p><strong>后向反思推理模块</strong>专门用于缓解时序风险。其流程如下：</p>
<ol>
<li><strong>时序谓词分类</strong>：为确保可验证性，将复杂时序安全需求分类为三种可验证的时序谓词：<strong>前提谓词</strong> <code>ψ^p</code>（强制严格的顺序依赖，如必须先“从微波炉中取出叉子”才能“打开微波炉”）、<strong>义务谓词</strong> <code>ψ^o</code>（确保危险触发动作后，在指定步数内必须跟随安全纠正动作，如“打开炉灶”后需在两步内“关闭炉灶”）和<strong>邻接谓词</strong> <code>ψ^a</code>（确保响应动作必须紧接在触发动作之后，不允许中间状态）。</li>
<li><strong>时序谓词推断</strong>：任务开始时，护栏VLM根据指令 <code>T</code> 推断其安全相关的顺序依赖关系，并按照上述三类谓词，将其分解为一组初始的时序谓词实例集合 <code>Ψ</code>。每个谓词 <code>ψ</code> 由其类型、触发动作、响应动作和允许响应动作的最大步数窗口参数化。</li>
<li><strong>时序逻辑验证</strong>：在执行每个动作 <code>a_t</code> 前，动态确定当前活跃的时序谓词子集 <code>Ψ_t ⊆ Ψ</code>（即触发动作与 <code>a_t</code> 匹配的谓词）。<strong>时序逻辑</strong> <code>L_t^b(·)</code> 定义为 <code>Ψ_t</code> 中所有谓词在短期记忆 <code>M^S</code>（存储了过往轨迹）上的逻辑或（公式8）。如果任何谓词被验证为违规（返回1），护栏将触发 <code>replan</code> 动作。该动作会主动将一个包含“响应动作”的纠正动作序列插入原始执行计划，引导智能体暂时偏离当前轨迹以消除时序危险，之后恢复原始执行上下文。</li>
</ol>
<p>整个护栏的决策基于公式2：若前向或后向逻辑任一为真，则执行相应的安全动作（<code>block</code> 或 <code>replan</code>）。Python解释器被用作轻量级验证器来执行生成的安全逻辑代码。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在AI2-THOR模拟器中进行，评估了三种代表性的具身智能体：ReAct、ProgPrompt和Reflexion（均基于GPT-4o）。主要使用SafeAgentBench数据集，包含详细的不安全指令集（评估上下文风险）、长视野不安全指令集（评估时序风险）和安全指令集（评估对正常任务性能的影响）。对比基线包括：ThinkSafe（基于模型的模块）、Poex（基于提示的策略）、AgentSpec（基于领域特定语言的框架）以及GuardAgent（通用安全框架）。评估指标包括准确拒绝率（ARR，越高越好）、执行成功率（ESR，对危险任务越低越好）和安全规划率（SPR，越高越好）。RoboSafe使用Gemini-2.5-flash作为护栏VLM。</p>
<p><strong>主要结果</strong>：</p>
<ul>
<li><strong>对上下文风险的防御</strong>（表1）：无防御的原始智能体ARR极低（平均2.33%），ESR极高（平均84.11%），极易受攻击。RoboSafe在所有智能体上均取得最高ARR（最高达92.33%，平均89.89%）和最低的危险ESR（最低至3.00%，平均4.78%），防御能力显著优于所有基线。</li>
</ul>
<p><img src="https://arxiv.org/html/2512.21220v2/x3.png" alt="上下文风险防御结果"></p>
<blockquote>
<p><strong>图3</strong>：在详细上下文不安全指令集上的防御结果对比。RoboSafe（橙色）在准确拒绝率（ARR）上远超其他基线，并能将危险动作的执行成功率（ESR）抑制到极低水平。</p>
</blockquote>
<ul>
<li><strong>对时序风险的防御</strong>（表2）：在长视野时序不安全指令集上，原始智能体的安全规划率（SPR）很低（平均10.00%）。RoboSafe显著提升了SPR（最高达40.00%，平均36.67%），并能成功执行这些安全计划（ESR平均32.00%），远优于其他基线方法，后者在识别复杂时序依赖方面表现不佳。</li>
</ul>
<p><img src="https://arxiv.org/html/2512.21220v2/x4.png" alt="时序风险防御结果"></p>
<blockquote>
<p><strong>图4</strong>：在长视野时序不安全指令集上的防御结果对比。RoboSafe（橙色）在安全规划率（SPR）和安全计划执行成功率（ESR）上均大幅领先，证明了其处理时序风险的有效性。</p>
</blockquote>
<ul>
<li><strong>对正常任务性能的影响</strong>：在安全指令集上，应用RoboSafe后，各智能体的任务执行成功率（ESR）与原始性能相比下降甚微（平均仅-2.11%），表明其安全防御几乎没有牺牲智能体的原有任务能力。</li>
</ul>
<p><img src="https://arxiv.org/html/2512.21220v2/x5.png" alt="正常任务性能影响"></p>
<blockquote>
<p><strong>图5</strong>：在安全指令集上的任务性能评估。RoboSafe（橙色）在提供强力安全防护的同时，保持了与原始智能体（蓝色）接近的任务执行成功率。</p>
</blockquote>
<p><strong>消融实验</strong>：<br>研究通过消融实验验证了各个核心组件的贡献。</p>
<p><img src="https://arxiv.org/html/2512.21220v2/x11.png" alt="组件消融实验（上下文风险）"></p>
<blockquote>
<p><strong>图11</strong>：针对上下文风险防御的组件消融研究。移除前向推理模块导致ARR大幅下降，证明了该模块对上下文风险防御的关键作用；移除后向推理模块影响较小。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.21220v2/x12.png" alt="组件消融实验（时序风险）"></p>
<blockquote>
<p><strong>图12</strong>：针对时序风险防御的组件消融研究。移除后向推理模块导致SPR急剧下降，证明了该模块对时序风险防御不可或缺；移除前向推理模块也有一定影响，表明两者存在协同。</p>
</blockquote>
<p>结果表明：<strong>前向预测推理模块</strong>对于防御上下文风险至关重要，移除它会导致ARR大幅下降；<strong>后向反思推理模块</strong>对于防御时序风险不可或缺，移除它会导致SPR急剧下降；<strong>多粒度检索机制</strong>和<strong>知识解耦机制</strong>也都是有效的设计。完整模型结合了所有组件，取得了最佳性能。</p>
<p>此外，论文还展示了RoboSafe在物理机器人手臂上的实际应用案例（图13），并进行了针对越狱攻击的鲁棒性测试，进一步证实了其实用性和有效性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）提出了<strong>RoboSafe</strong>，一个基于可执行安全逻辑的、新颖的具身智能体运行时护栏框架；2）设计了<strong>双向混合推理机制</strong>（前向预测推理和后向反思推理），结合混合长短安全记忆，能有效识别和防御动态环境中的上下文与时序两类隐式风险；3）通过大量模拟和真实机器人实验证明，该框架能<strong>显著降低危险动作发生率（-36.8%）</strong>，同时几乎不影响原始任务性能。</p>
<p>论文提到的局限性包括：安全知识的自动生成依赖于初始种子示例和LLM的能力；运行时进行双向推理可能引入一定的延迟。</p>
<p>这项工作对后续研究的启示在于：<strong>混合推理</strong>（结合前向预测与后向反思）和<strong>可验证的安全逻辑</strong>（将高级推理与低级可执行代码解耦）是构建更安全、更可靠具身智能系统的有效途径。未来的工作可以探索更高效的知识记忆与检索机制，以及将此类安全框架扩展到更广泛的开放世界场景中。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出RoboSafe，旨在解决具身智能体在动态、时间依赖和上下文丰富环境中执行任务时，易受危险指令触发不安全行为的问题。现有静态规则或提示级防御难以应对隐式风险。RoboSafe采用基于谓词的可执行安全逻辑，通过混合长短安全记忆集成两个互补推理：后向反思推理持续回顾短期轨迹以推断时间安全谓词并触发重规划；前向预测推理利用长期记忆和多模态观察预测上下文风险。实验表明，与领先基线相比，RoboSafe将风险发生率降低36.8%，同时保持接近原始的任务性能。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.21220" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>