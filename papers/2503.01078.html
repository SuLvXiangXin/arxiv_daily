<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>KineSoft: Learning Proprioceptive Manipulation Policies with Soft Robot Hands - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>KineSoft: Learning Proprioceptive Manipulation Policies with Soft Robot Hands</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2503.01078" target="_blank" rel="noreferrer">2503.01078</a></span>
        <span>作者: Yoo, Uksang, Francis, Jonathan, Oh, Jean, Ichnowski, Jeffrey</span>
        <span>日期: 2025/03/03</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，欠驱动软体机器人手因其材料柔顺性，在安全性和对不确定几何形状的适应性方面优于刚性系统。然而，赋予软体手机器人手灵巧的操作技能仍然是一个挑战。现有方法主要依赖需要专家操作的手工设计动作原语，限制了系统的适应性。虽然模仿学习在教授复杂操作技能方面显示出潜力，但将其应用于软体机器人面临独特的挑战：为刚性关节机器人设计的示教收集方法（如遥操作）不适用于具有近乎无限自由度的欠驱动软体末端执行器；刚性机器人常用的状态表示（如刚体变换位姿）无法有效描述连续变形的结构。这些限制阻碍了模仿学习在软体机器人操作中的应用。</p>
<p>本文针对上述痛点，提出了一个新的视角：软体机器人固有的柔顺性不应仅仅被视为控制挑战，更应被转化为技能教学的优势。与刚性机器人不同，软体手可以被人类演示者轻松物理变形到期望的姿势，而不会违反机械限制，这使得通过直接动觉示教收集演示成为可能。本文的核心思路是提出KineSoft框架，利用软体手的自然柔顺性进行动觉示教，通过本体感知反馈学习基于形状的模仿策略，从而实现灵巧的手内操作。</p>
<h2 id="方法详解">方法详解</h2>
<p>KineSoft框架采用分层方法，弥合动觉示教与自主执行之间的差距。整体流程如下：首先，人类演示者物理操纵集成了应变传感器的软体手（MOE平台）执行任务，系统同步记录传感器读数（应变）和外部视觉观测（RGB-D点云）。其次，一个形状估计模型将应变传感器读数映射为软体手指网格顶点的位移，从而提供高保真度的本体感知形状状态。接着，一个基于扩散模型的模仿策略，以当前的形状状态和视觉观测为输入，预测未来一段时间内期望的形状变化轨迹和末端执行器位姿变化。最后，一个形状条件控制器将预测的期望形状轨迹与当前估计的形状进行比较，计算出误差并将其投影到驱动方向上，生成伺服电机指令以跟踪形状轨迹，从而执行操作任务。</p>
<p><img src="https://arxiv.org/html/2503.01078v2/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：KineSoft框架概述。包含三个关键组件：1）用于高保真形状估计的本体感知模型；2）基于扩散的模仿学习，用于预测形状和末端执行器位姿的变化；3）形状条件控制器，使软体手能够跟踪给定的形状轨迹。</p>
</blockquote>
<p><strong>核心模块1：传感器化MOE软体末端执行器</strong>。平台基于MOE软体机器人，每个手指由两个伺服电机通过四根肌腱驱动。创新之处在于将低成本导电弹性橡胶作为传感器嵌入每个手指的硅胶弹性体中，传感器位于肌腱之间。每个手指集成四个传感器，整个三指手共12个传感器，以约400Hz的频率提供电阻读数，构成传感器测量空间 <strong>S</strong>，用于估计真实的变形状态空间 <strong>M</strong>。</p>
<p><strong>核心模块2：形状估计模型</strong>。该模型将应变传感器读数 <strong>R</strong> ∈ ℝ^12 映射到MOE手指的网格顶点位移。模型学习一个函数 f，该函数以传感器输入和未变形的网格为条件，预测每个顶点的变形：f(<strong>R</strong>, {<strong>V</strong>_j,0}) = {Δ<strong>V</strong>_j}。采用基于FoldingNet的架构实现。对于每个手指j，编码器 h_enc 将其四个电阻值 <strong>R</strong>_j 转换为潜在代码 <strong>z</strong>_j ∈ ℝ^128。解码器 h_dec 则结合每个顶点的初始位置 <strong>v</strong>_j,0^i 和 <strong>z</strong>_j 来预测其位移 Δ<strong>v</strong>_j,i。模型在模拟的变形数据集上进行训练。</p>
<p><img src="https://arxiv.org/html/2503.01078v2/x2.png" alt="本体感知网络"></p>
<blockquote>
<p><strong>图2</strong>：本体感知网络。A：用于软体手指网格形状估计的网络架构。B：域对齐迭代的结果，损失在200次迭代后收敛。</p>
</blockquote>
<p><strong>核心模块3：仿真到现实的域对齐</strong>。为了弥合仿真与真实世界部署之间的差距，引入了一个校准程序来对齐物理实验的传感器读数与仿真变形模型。目标是优化一组每传感器一个的校正因子 κ_i，通过最小化无监督倒角距离（Unsupervised Chamfer Distance, UCD）来实现。UCD损失计算观测到的软体手指表面3D点云与形状估计模型预测的表面点云之间的差异，确保基于电阻测量估计的内部变形能产生与外部几何观测一致的表面网格。</p>
<p><strong>核心模块4：形状条件控制器</strong>。该控制器利用MOE手指的实时本体感知网格状态估计来执行期望的形状轨迹。对于每个手指j，控制器将当前估计的顶点位置 <strong>V</strong>_t 与策略轨迹生成的期望目标位置 <strong>V</strong>_t^D 进行比较。每个手指由一对拮抗肌腱驱动。伺服调整量 δu_j,t 通过将形状误差投影到这些驱动方向上来计算：δu_j,t = k_p Σ_n <strong>e</strong>_j,t^n · [<strong>d</strong>_2j, <strong>d</strong>_2j+1]^T，其中 <strong>e</strong>_j,t = <strong>V</strong>_t,j^D - <strong>V</strong>_t,j。控制器以100Hz频率运行，实现响应式形状轨迹跟踪。</p>
<p><strong>核心模块5：模仿策略</strong>。策略以形状估计模型提供的顶点位置 <strong>V</strong>_t（本体感知）和腕戴RGB-D相机捕获的工作空间点云 <strong>P</strong>_t（外部感知）作为输入。训练一个扩散策略来模仿操作技能。策略预测动作 a_t = {Δ<strong>V</strong>_t, Δ<strong>p</strong><em>t}，耦合了表面变形和末端执行器运动。状态 s_t 结合了本体感知和外部感知信息，并分别通过MLP编码器（h_shape）和DP3编码器（h_pc）进行处理。扩散策略通过学习去噪网络 μ_θ，通过反向过程 a</em>{t-1} = μ_θ(a_t, s_t, t) + σ_t <strong>z</strong> 来学习去噪顶点级动作轨迹。</p>
<p>与现有方法相比，KineSoft的主要创新点在于：1) 将软体手的柔顺性转化为可直接进行物理示教的优势；2) 提出了一个完整的、基于高维网格形状表示的模仿学习框架，将本体感知形状估计、扩散策略和形状跟踪控制器无缝集成；3) 开发了仿真到现实的域对齐方法，使在仿真数据上训练的模型能有效应用于真实机器人。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在真实的MOE软体机器人平台上进行，使用了三指配置。评估了六项手内操作任务，涉及刚性和可变形物体：瓶盖拧开、瓶盖拧紧、插头插入、插头拔出、纸巾折叠和纸巾展开。对比的基线方法是“应变基线策略”，该策略直接以原始应变传感器读数作为策略输入，而不是KineSoft使用的估计网格形状。</p>
<p><img src="https://arxiv.org/html/2503.01078v2/x4.png" alt="任务成功率对比"></p>
<blockquote>
<p><strong>图4</strong>：六项操作任务的定量结果。KineSoft在所有任务上都显著优于应变基线策略。</p>
</blockquote>
<p>关键实验结果：KineSoft在六项任务中均取得了显著更高的成功率。具体而言，在瓶盖拧开任务中，KineSoft成功率达到80%（±7.1%），而应变基线策略仅为20%（±8.2%）；在插头插入任务中，KineSoft为83.3%（±8.8%），基线为36.7%（±10.2%）；在纸巾折叠任务中，KineSoft为76.7%（±8.8%），基线为13.3%（±7.1%）。这证明了基于形状表示的策略相对于原始传感器输入的有效性。</p>
<p><img src="https://arxiv.org/html/2503.01078v2/x5.png" alt="消融实验"></p>
<blockquote>
<p><strong>图5</strong>：消融研究。评估了不同状态表示对策略性能的影响：仅视觉（V）、仅应变（S）、仅形状（Sh）以及完整状态（V+Sh）。完整状态（V+Sh）取得了最佳性能。</p>
</blockquote>
<p>消融实验总结了每个组件的贡献：实验比较了不同状态输入对策略性能的影响。仅使用视觉（V）或仅使用应变（S）的性能都较差。仅使用估计的形状（Sh）已经能取得不错的效果，但结合视觉和形状（V+Sh）的完整状态输入能获得最佳性能，凸显了本体感知与外部感知互补的重要性。</p>
<p><img src="https://arxiv.org/html/2503.01078v2/x6.png" alt="形状估计与跟踪精度"></p>
<blockquote>
<p><strong>图6</strong>：形状估计与跟踪精度。左：形状估计模型在真实数据上的定性结果（绿色为预测网格，红色为真实扫描）。右：形状条件控制器跟踪正弦波形状命令的精度。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2503.01078v2/x7.png" alt="模仿策略生成的轨迹"></p>
<blockquote>
<p><strong>图7</strong>：模仿策略生成的形状轨迹可视化。展示了在瓶盖拧开任务中，策略预测的未来形状序列（蓝色到红色）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2503.01078v2/x8.png" alt="真实机器人执行序列"></p>
<blockquote>
<p><strong>图8</strong>：真实机器人执行序列。展示了KineSoft在瓶盖拧开、插头插入和纸巾折叠任务中的执行过程。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2503.01078v2/x9.png" alt="域对齐效果"></p>
<blockquote>
<p><strong>图9</strong>：域对齐对形状估计的影响。经过域对齐后，预测网格（绿色）与观测点云（红色）更加吻合。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：1) 提出了KineSoft，首个有效利用软体机器人被动柔顺性进行动觉示教并使其获得灵巧手内操作技能的框架；2) 开发了一种先进的、基于应变传感并与软体手集成的本体感知形状估计方法，能够在接触丰富的任务中精确跟踪手指变形；3) 引入了形状条件控制器和仿真到现实的域对齐方法，实现了对生成变形轨迹的精确跟踪和模型的有效部署。</p>
<p>论文自身提到的局限性包括：该方法仍然需要人类演示来收集数据；外部感知（RGB-D相机）对于需要物体重定位的任务是必要的；目前框架主要针对已知的、传感器化的软体手设计。</p>
<p>本工作对后续研究的启示在于：它展示了将软体机器人的“弱点”（高维、难以建模的变形）转化为教学“优势”的新范式。未来的工作可以探索更少依赖示教的方法（如无监督或强化学习），将框架扩展到更多样化的软体结构，以及研究如何将学习到的技能组合或泛化到新物体和新任务上。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对软体机器人手缺乏有效灵巧操作技能学习方法的问题，提出KineSoft框架。该框架利用软体手的自然顺应性，通过本体感觉演示进行学习。其关键技术包括：基于本体感觉的形状估计模型、用于预测动作的扩散模仿学习策略，以及能精确跟踪形状轨迹的控制器。在物理实验中，KineSoft在六项手内操作任务上均优于基于应变的基线方法，证明了其优越性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2503.01078" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>