<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.23016" target="_blank" rel="noreferrer">2510.23016</a></span>
        <span>作者: Fei Chen Team</span>
        <span>日期: 2025-10-27</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，扩散模型在机器人双手技能学习中展现出巨大潜力，已成为该领域的主流方法之一。然而，现有方法主要专注于从专家演示中模仿低层级的轨迹模式，而忽略了专家任务认知中固有的高层级姿势特征。在姿势依赖的操作任务中，任务成功与否关键取决于能否达到适当的手臂构型以满足特定方向的力和速度要求，现有方法的这一局限性降低了其在姿势依赖操作中的有效性。</p>
<p>本文针对现有扩散策略在双手操作中缺乏姿势感知能力这一具体痛点，提出了将可操作性学习融入双手轨迹扩散过程的新视角。其核心思路是：首先从专家演示中提取双手可操作性特征，利用基于黎曼几何的概率模型进行编码，然后将这些编码后的姿势特征融入条件扩散过程，以引导生成与任务兼容的双手运动序列。</p>
<h2 id="方法详解">方法详解</h2>
<p>ManiDP的整体流程包含两个关键步骤：1) 双手可操作性学习，在SPD流形上使用GMM和GMR学习并复现专家BMEs；2) 可操作性引导的扩散采样，通过最小化当前BMEs与复现的专家BMEs之间的SPD目标，迭代优化生成的双手轨迹。</p>
<p><img src="https://arxiv.org/html/2510.23016v1/figs/fig2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：ManiDP方法总览。(a) 与仅关注轨迹模仿的典型扩散策略不同，ManiDP将BMEs学习融入技能扩散过程以优化双臂构型，从而增强与姿势依赖任务需求的兼容性。(b) ManiDP通过两个关键步骤学习BMEs特征与机器人轨迹的联合分布：双手可操作性学习与可操作性引导的扩散采样。</p>
</blockquote>
<p>核心模块一：双手可操作性表示。针对不同的双臂协调模式，定义了两种可操作性表示。对于对称任务，系统作为统一整体运作，采用<strong>双手绝对可操作性</strong>（BAM）来表征姿势变化。对于非对称任务，需要捕捉双臂间的相对运动和动态协调，因此引入了基于相对雅可比矩阵的<strong>双手相对可操作性</strong>（BRM）表示。BMEs被表示为一个3×3的对称正定矩阵，表征双臂的平移可操作性椭球。</p>
<p>核心模块二：基于SPD流形的可操作性学习。由于BMEs是SPD矩阵，在SPD流形上形成测地线，其内在几何结构需要专门的学习模型。ManiDP采用<strong>SPD-GMM</strong>结合<strong>SPD-GMR</strong>来编码和检索BMEs特征。SPD-GMM将传统高斯混合模型扩展到SPD流形上，使用黎曼对数映射、指数映射和平行传输等操作进行参数估计。随后，利用时间驱动的SPD-GMR，基于学习到的SPD高斯分量，条件生成所需的BMEs轮廓。</p>
<p><img src="https://arxiv.org/html/2510.23016v1/figs/fig3.png" alt="BMEs在SPD流形上的可视化"></p>
<blockquote>
<p><strong>图3</strong>：BMEs在SPD流形𝒮⁺⁺²上的可视化。BMEs在锥形的𝒮⁺⁺²上遵循一条测地线路径（绿色曲线），与欧几里得路径（红色虚线）形成对比。每个测地点代表一个具有关联切空间的双手可操作性矩阵。</p>
</blockquote>
<p>核心模块三：可操作性引导的扩散采样。ManiDP的核心思想是利用复现的专家BMEs来引导基于扩散的双手轨迹采样过程。该方法将目标分布建模为原始扩散模型生成的动作概率分布与达到期望BMEs的概率分布的乘积。可操作性目标函数𝒢ℬ基于SPD对数映射距离设计，用于衡量当前动作计算出的BMEs与复现的专家BMEs在SPD流形上的距离。在采样过程中，通过泰勒展开近似可操作性目标的梯度，并利用该梯度修正原始扩散过程的均值，从而在每一步去噪中引导生成的动作朝向满足姿势需求的方向优化。</p>
<p>与现有方法相比，ManiDP的创新点具体体现在：1）首次系统分析了适用于不同双臂协调模式（对称/非对称）的双手可操作性表示；2）将基于SPD流形的可操作性学习模型与扩散策略相结合；3）在扩散采样过程中引入了可操作性目标引导，使生成的动作不仅在轨迹层面合理，而且在姿势层面与任务要求兼容。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验使用了DOBOT X-Trainer双臂机器人系统，包含两个6自由度机械臂和1自由度夹爪，通过三个Intel RealSense D405相机捕获RGB图像。在六个真实世界双手任务上进行了评估，这些任务分为对称任务（如挂毛巾、举箱子）和非对称任务（如擦盘子、拔插头）。</p>
<p>对比的基线方法包括：1) <strong>DP</strong>：原始扩散策略；2) <strong>ACT</strong>：作为条件VAE训练的动作分块Transformer；3) <strong>GMM-GMR</strong>：在欧几里得空间学习的经典方法。</p>
<p>关键实验结果如下：<br>在可操作性学习准确性上，ManiDP在对称和非对称任务中均取得了最高的可操作性复现准确率，平均MRA比基线高出0.31。</p>
<p><img src="https://arxiv.org/html/2510.23016v1/figs/fig6.png" alt="塔悬挂任务在SPD流形上的BMEs学习结果"></p>
<blockquote>
<p><strong>图4</strong>：塔悬挂任务在SPD流形上的BMEs学习结果。通过考虑BMEs的内在黎曼性质，ManiDP可以在锥形SPD流形内生成几何上合理的BMEs序列。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2510.23016v1/figs/fig5.png" alt="塔悬挂任务在时域上的BMEs学习结果"></p>
<blockquote>
<p><strong>图5</strong>：塔悬挂任务在时域上的BMEs学习结果。结果表明，ManiDP可以捕捉专家BMEs的关键状态，然后在每个时间步准确地复现它们。</p>
</blockquote>
<p>在真实机器人实验中，ManiDP在六个任务上的平均操作成功率达到了85.00%，相比ACT、DP和GMM-GMR分别提升了39.33%、39.33%和96.67%。在任务兼容性指数上，ManiDP平均达到0.92，相比ACT和DP分别提升了0.41和0.39。</p>
<p><img src="https://arxiv.org/html/2510.23016v1/figs/fig7.png" alt="真实机器人实验定性结果"></p>
<blockquote>
<p><strong>图6</strong>：真实机器人实验定性结果。与DP基线相比，ManiDP可以调整双臂姿势以最小化最终BMEs与期望BMEs之间的差异。这增强了沿任务相关方向的速度控制和力施加，从而提高了操作性能。</p>
</blockquote>
<p>消融实验（体现在与GMM-GMR基线的对比）表明，ManiDP中基于SPD流形的可操作性学习模块是性能提升的关键，因为它显式地考虑了BMEs的几何属性，能够生成几何上合理的BMEs序列。同时，可操作性引导的扩散采样过程有效缩小了生成姿势与期望姿势之间的BMEs差距。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) 提出了ManiDP，一种将可操作性学习融入双手轨迹扩散的新策略，能够生成既合理又与任务兼容的双臂动作；2) 系统分析了不同双臂协调模式下的双手可操作性表示；3) 在六个真实世界双手任务上进行了全面评估，证明了ManiDP在平均操作成功率和任务兼容性上的显著提升。</p>
<p>论文自身提到的局限性在于，方法依赖于专家演示的质量来学习可操作性特征，对于未见过或高度变化的姿势需求，其泛化能力有待进一步验证。</p>
<p>这项工作对后续研究的启示在于：强调了将姿势相关的机器人先验知识（如可操作性）整合到基于学习的策略中的重要性，为实现类人的适应性和灵巧性提供了新思路。未来工作可以探索如何在线适应或优化可操作性目标，或者将其与其他形式的任务约束（如力/触觉反馈）相结合。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对现有机器人双手操作技能学习方法忽略姿态依赖任务特征的问题，提出ManiDP方法。该方法从专家示范中提取双手可操作性，利用黎曼概率模型编码姿态特征，并通过条件扩散过程生成任务兼容的运动序列。在六项真实任务实验中，相比基线方法，平均操作成功率提升39.33%，任务兼容性提高0.45。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.23016" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>