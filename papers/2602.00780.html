<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Environment-Aware Adaptive Pruning with Interleaved Inference Orchestration for Vision-Language-Action Models - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Artificial Intelligence (cs.AI)</span>
      <h1>Environment-Aware Adaptive Pruning with Interleaved Inference Orchestration for Vision-Language-Action Models</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.00780" target="_blank" rel="noreferrer">2602.00780</a></span>
        <span>作者: Huang, Yuting, Ding, Leilei, Tang, Zhipeng, Zhu, Zenghuan, Deng, Jiajun, Lin, Xinrui, Liu, Shuo, Ren, Haojie, Ji, Jianmin, Zhang, Yanyong</span>
        <span>日期: 2026/01/31</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作（VLA）模型在具身智能领域展现出巨大潜力，但其庞大的参数量导致显著的推理延迟，阻碍了实时控制。为加速推理，参数稀疏化（剪枝）是一种有效途径。然而，在VLA模型执行过程中，环境是动态演变的，导致最优的稀疏化模式也随之变化。现有方法存在关键局限性：静态剪枝方法（如RLRC、GLUESTICK）基于固定校准数据剪枝，缺乏对动态环境的适应性；而固定间隔的动态层剪枝方法（如MoLe-VLA、DeeR-VLA）虽然具备任务依赖性，但粒度粗糙（层级别），且依赖额外的路由网络，带来高昂的重训练和运行时开销。本文针对动态环境下最优剪枝模式自适应变化这一具体痛点，提出了首个训练免费、即插即用、细粒度的自适应剪枝框架。其核心思路是：通过一个轻量级的环境感知模块动态预测稀疏模式变化，并利用VLA推理过程中固有的计算（FLOPs）气泡，以非阻塞的并行编排方式执行剪枝计算，从而在几乎不影响延迟的前提下实现模型自适应加速。</p>
<h2 id="方法详解">方法详解</h2>
<p>EcoVLA框架包含两个核心组件：环境感知自适应剪枝（EAP）和交错推理编排（I2O）。</p>
<p><img src="https://arxiv.org/html/2602.00780v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：EcoVLA的整体流程。(a) 环境感知自适应剪枝（EAP）：一个轻量级方法，通过感知实时环境动态来识别稀疏模式变化。考虑到物理环境中VLA执行的时间一致性，EAP将瞬时特征与历史特征融合以联合计算稀疏模式。(b) 交错推理编排（I2O）：利用VLA推理中固有的FLOPs气泡，采用非阻塞并行范式将稀疏模式计算交错编排进去。</p>
</blockquote>
<p><strong>环境感知自适应剪枝（EAP）</strong>：该模块旨在根据环境变化动态更新剪枝模式。首先，一个<strong>轻量级环境感知稀疏变化预测器</strong>负责判断何时需要更新剪枝模式。它计算当前帧与上一帧视觉特征（来自VLA视觉编码器）的平均token-wise余弦相似度。为了适应开放世界中动态变化的特征分布，论文引入了<strong>时序上下文条件化的稀疏触发机制</strong>：维护一个最近T帧相似度的滑动窗口，当当前相似度低于该窗口的p分位数时，则触发稀疏模式更新。此机制具有自调节性，在快速运动时抑制过度更新以保证稳定，在稳定阶段则能敏感检测细微变化。</p>
<p><img src="https://arxiv.org/html/2602.00780v1/x3.png" alt="剪枝触发"></p>
<blockquote>
<p><strong>图3</strong>：环境感知稀疏变化预测器的触发机制示意图。基于时序上下文的动态决策准则能自适应环境变化。</p>
</blockquote>
<p>触发更新后，执行<strong>时序一致性剪枝</strong>来计算新的稀疏模式。在触发更新的第t帧，进行一次密集推理以获取各层的中间激活。对于每个结构化的通道k，计算其瞬时特征（即该通道激活的L2范数平方）。考虑到VLA执行的物理环境具有时间连续性，论文将瞬时特征与历史特征进行聚合，得到融合特征。历史特征通过指数移动平均进行更新，以保持时间一致性。最终，第k个通道的重要性得分由其对应的最终权重矩阵（如MLP中的<code>W_down</code>或注意力中的<code>W_O</code>）的列向量L2范数平方与融合特征的乘积决定。重要性低的通道将被剪枝。</p>
<p><strong>交错推理编排（I2O）</strong>：该模块旨在隐藏EAP带来的计算开销。论文首先分析了VLA推理的<strong>计算气泡</strong>：1) <strong>VLM骨干阶段</strong>：以大规模GEMM为主，计算强度高，GPU张量核心接近饱和，但内存带宽有剩余；2) <strong>动作专家阶段</strong>：计算量轻，在批大小为1的流式控制下，GPU张量核心利用率严重不足。I2O的核心思想是将稀疏模式计算（为下一帧t+1准备）与当前帧t的主推理流解耦，并调度到一个并行的剪枝流中。具体而言，在VLM骨干阶段，剪枝流并行地缓存所需的中间激活；当推理进入动作专家阶段时，I2O将稀疏模式计算交错插入到该阶段的FLOPs气泡中，充分利用空闲的张量核心。这种编排方式避免了严重的GPU资源竞争，使得剪枝开销δ极小，几乎不影响总推理延迟<code>T_infer</code>。</p>
<p><img src="https://arxiv.org/html/2602.00780v1/x4.png" alt="计算气泡利用"></p>
<blockquote>
<p><strong>图4</strong>：I2O如何利用VLA推理管道中的FLOPs气泡来隐藏剪枝开销。将剪枝计算与主推理流并行执行。</p>
</blockquote>
<p><strong>硬件高效实现</strong>：为提升实际加速效果，论文进行了底层优化。对于稀疏推理，实现了<strong>稀疏线性变换Triton内核</strong>以避免索引开销，采用<strong>内存合并</strong>存储（如列优先格式）提升访问效率，并开发了<strong>高性能融合内核</strong>将MLP中的多个操作合并，减少内核启动和内存流量。对于密集的稀疏模式计算，采用了<strong>免分配缓存</strong>（预计算权重范数、预分配静态缓冲区）和<strong>批量度量计算</strong>（跨层融合内核）来减少内存操作和启动开销。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：论文在两个机器人操作仿真基准（LIBERO和SIMPLER）上评估了EcoVLA，使用了三个不同的VLA模型：OpenVLA-OFT、π_0.5和CogACT。对比的基线方法包括：原始模型（Vanilla）、令牌剪枝方法FastV、KV缓存方法VLA-Cache以及静态结构化剪枝方法Wanda。</p>
<p><strong>关键实验结果</strong>：<br>在OpenVLA-OFT（LIBERO）上，在25%剪枝率下，EcoVLA取得了96.8%的平均成功率（仅比原始模型下降0.4%），同时实现了1.26倍加速。在40%剪枝率下，仍保持94.0%的成功率和1.41倍加速，显著优于静态剪枝方法Wanda（88.8%成功率，1.35倍加速）。更重要的是，EcoVLA能与现有加速方法正交组合：与FastV（50%令牌剪枝率）结合后，加速比从1.21倍提升至2.18倍，并且恢复了FastV单独使用造成的性能下降，将成功率差距从2.3%缩小到仅0.5%。</p>
<p><img src="https://arxiv.org/html/2602.00780v1/x5.png" alt="表1结果"></p>
<blockquote>
<p><strong>表1</strong>：EcoVLA在OpenVLA-OFT (LIBERO) 上的性能。展示了在不同剪枝率下，EcoVLA在成功率和加速比方面均优于静态剪枝基线Wanda，并且能与令牌剪枝（FastV）和KV缓存（VLA-Cache）有效结合，实现更高的加速。</p>
</blockquote>
<p>在π_0.5（LIBERO）和CogACT（SIMPLER）模型上的实验进一步验证了EcoVLA的通用性。对于π_0.5，在25%和37.5%剪枝率下分别实现了1.31倍和1.46倍加速，成功率下降极小（0.2%和1.9%）。对于CogACT，在40%剪枝率下实现了1.57倍加速，同时成功率略有提升（从73.3%到73.6%）。</p>
<p><img src="https://arxiv.org/html/2602.00780v1/x6.png" alt="表2与表3结果"></p>
<blockquote>
<p><strong>表2与表3</strong>：EcoVLA在π_0.5 (LIBERO) 和 CogACT (SIMPLER) 上的性能。结果表明EcoVLA在不同VLA模型和任务基准上均能有效工作，在保持高成功率的同时显著降低计算量（FLOPs）和延迟。</p>
</blockquote>
<p><strong>消融实验</strong>：<br>论文通过消融实验验证了各组件贡献。移除环境感知预测器（使用固定间隔更新）或时序一致性（仅用瞬时特征）都会导致性能下降，尤其是在长序列任务（LIBERO-Long）上。移除I2O（即串行执行剪枝）会带来显著的额外延迟，破坏了实时性。同时，论文展示了在真实Kinova Gen3机器人上的部署结果，验证了其在实际场景中的加速能力。</p>
<p><img src="https://arxiv.org/html/2602.00780v1/x7.png" alt="消融实验"></p>
<blockquote>
<p><strong>图6</strong>：消融研究。(a) 在LIBERO-Long任务上，移除环境感知预测器（Env.-Aware）或时序一致性（Temp. Consistency）均会导致成功率下降。(b) 移除I2O（串行执行）会引入明显的额外延迟，而I2O能几乎完全隐藏该开销。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1) 提出了首个训练免费、即插即用的VLA模型自适应剪枝框架EcoVLA，能够根据环境动态调整细粒度剪枝模式。2) 设计了环境感知的稀疏变化预测器和基于时序一致性的剪枝算法，实现了对动态环境的稳健适应。3) 提出了交错推理编排（I2O）范式，通过利用VLA推理中的计算气泡并行执行剪枝计算，几乎完全隐藏了自适应带来的开销。</p>
<p><strong>局限性</strong>：论文自身提到，EcoVLA目前依赖于VLM骨干的标准化结构（如Transformer块），对于非标准架构可能需要调整。此外，方法需要一个小的校准数据集来初始化历史特征。</p>
<p><strong>后续启示</strong>：EcoVLA展示了在流式、单样本推理场景下，通过细粒度自适应和硬件感知的并行编排来优化模型效率的可行性。这种“感知环境-动态调整-并行隐藏开销”的思路可推广至其他对延迟敏感的序列模型（如视频理解模型）的加速。其与令牌剪枝等输入侧优化方法的正交性也为构建多层次、协同的VLA加速系统提供了可能。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对视觉-语言-动作模型推理延迟高、静态剪枝无法适应环境动态变化的问题，提出EcoVLA框架。其核心包含**环境感知自适应剪枝**，根据环境时序一致性动态更新通道稀疏模式；以及**交错推理编排**，利用推理间隙并行执行剪枝以规避延迟。该方法无需训练，可与其他加速技术正交结合。实验表明，EcoVLA最高实现**1.60倍加速且成功率仅降0.4%**；与令牌剪枝结合后加速比达**2.18倍，性能仅降0.5%**，并在真实机器人上验证有效。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.00780" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>