<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Latent Action Diffusion for Cross-Embodiment Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Latent Action Diffusion for Cross-Embodiment Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.14608" target="_blank" rel="noreferrer">2506.14608</a></span>
        <span>作者: Robert K. Katzschmann Team</span>
        <span>日期: 2025-06-17</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人端到端学习是迈向通用机器人的一条有前景的路径，但其发展受限于数据稀缺性以及不同机器人具身（Embodiment）之间动作空间的异质性。具体而言，不同末端执行器（如灵巧手、平行夹爪）的多样化动作空间（维度、表示形式不同）为跨具身学习和技能迁移设置了障碍。目前主流方法主要采取两种策略：一是仅使用共享相同动作空间的数据进行预训练或协同训练，这限制了可利用的数据多样性；二是利用人类操作数据集进行预训练，但依赖于将人类动作空间显式地对齐到机器人动作空间。这些方法要么牺牲了动作空间的表达能力，要么依赖于固定的、单向的映射，难以统一高度多样化的末端执行器。本文针对“具身鸿沟”（Embodiment Gap）这一具体痛点，提出了一个新的视角：不直接处理显式动作空间，而是通过学习一个统一的、语义对齐的潜在动作空间来编码不同末端执行器的动作。本文的核心思路是：首先通过对比学习构建一个跨末端执行器的语义对齐潜在动作空间，然后在该空间中训练一个具身无关的扩散策略，从而实现单策略控制多机器人并促进跨具身技能正向迁移。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的跨具身策略学习框架包含两个核心部分：1) 学习潜在动作空间；2) 训练潜在策略。整体流程聚焦于统一不同末端执行器的动作空间，并将其视为一个多模态表示学习问题。</p>
<p><img src="https://arxiv.org/html/2506.14608v3/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：学习跨具身潜在动作空间的三阶段流程。<strong>阶段1</strong>：通过将人手姿态重定向到不同机器人末端执行器，生成对齐的末端执行器姿态。<strong>阶段2</strong>：使用对比损失训练具身特定的编码器，将这些动作投影到一个共享的潜在空间中。<strong>阶段3</strong>：训练解码器从潜在空间重建原始姿态，并微调编码器以提高重建质量。</p>
</blockquote>
<p><strong>1. 创建对齐的动作对</strong>：为了进行多模态表示学习，需要成对的、跨模态对应的数据。本文利用从人手到机器人末端执行器的重定向函数作为对齐先验。具体而言，给定一个人手姿态 (x_i^H)，通过重定向函数 (f_H^{R_j}) 生成对应的机器人末端执行器姿态，从而构成数据元组 (\mathbf{x}_i=(x_i^H, f_H^{R_1}(x_i^H), \dots, f_H^{R_M}(x_i^H)))。对于灵巧手（如Faive手、mimic手），重定向通过最小化人手与机器人手之间关键向量（从手掌到指尖以及指尖间的向量）的平方差来实现（公式2）。对于平行夹爪，则通过计算所有源自拇指的关键向量的最小值并归一化来得到夹爪宽度（公式3）。</p>
<p><strong>2. 对比潜在空间学习</strong>：目标是学习一个共享的潜在动作空间，要求既能精确重建末端执行器姿态，又能保持训练数据中存在的跨模态对齐结构。学习分为两步：<br>    *   <strong>第一步（编码器对齐）</strong>：使用通过重定向生成的对齐姿态批次，训练多个模态特定编码器 (q_m)，将各模态动作 (x_m) 投影到共享潜在空间。采用基于批次的成对InfoNCE损失（公式4）来确保潜在空间内的对齐，即鼓励来自同一数据元组（对应同一人手姿态）的不同模态潜在表示彼此接近。<br>    *   <strong>第二步（解码器重建与微调）</strong>：训练模态特定解码器 (p_m) 从潜在表示重建原始动作。同时，以较低的学习率微调编码器。总损失是重建损失 (\mathcal{L}<em>{\text{recon}})（公式5）和对比损失 (\mathcal{L}</em>{\text{contrastive}}) 的加权和（公式6），超参数 (\lambda) 用于权衡对齐与重建。编码器和解码器均由多层感知机实现。</p>
<p><strong>3. 策略学习</strong>：在学到潜在动作空间后，采用扩散策略将跨数据集的共享观测映射到潜在空间中的末端执行器动作以及机器人手臂的非潜在手腕姿态。编码器和解码器在策略学习期间被冻结，扩散目标应用于去噪后的潜在末端执行器动作和手腕姿态。推理时，使用合适的具身特定解码器将潜在策略的输出解码为具体的末端执行器姿态。论文在两种扩散策略实现（基于Transformer和基于U-Net）上验证了方法。在协同训练不同大小的数据集时，通过为每个数据集分配归一化权重并据此采样子批次，然后将动作投影到共享潜在空间并归一化，最后拼接成一个批次进行训练。</p>
<p><img src="https://arxiv.org/html/2506.14608v3/x2.png" alt="潜在空间定性评估"></p>
<blockquote>
<p><strong>图2</strong>：联合潜在动作空间的定性评估。将归一化的夹爪宽度编码，并通过跨模态重建解码为人手姿态（左侧彩色线条）和Faive手姿态（右侧灰色模型）。这展示了潜在空间实现了双向、任意的模态间转换，克服了传统重定向方法只能单向映射的局限。</p>
</blockquote>
<p><strong>创新点</strong>：与现有工作相比，本文的创新点在于将重定向不作为策略学习的直接固定动作映射，而是作为构建统一潜在动作空间的强归纳偏置。这种方法避免了约束动作空间的局限性，也避免了刚性单向映射的不足，从而能够统一包括灵巧手在内的、高度多样化的末端执行器。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>Benchmark/任务</strong>：三个真实世界操作任务：1) <strong>方块堆叠</strong>（使用mimic手和Franka夹爪）；2) <strong>方块抓放</strong>（使用mimic手和Franka夹爪，且mimic手有腕部相机，夹爪没有，构成非对称观测）；3) <strong>毛绒玩具抓放</strong>（使用Faive手和Franka夹爪）。</li>
<li><strong>数据集</strong>：为每个任务和每个末端执行器收集了100或200条演示数据。</li>
<li><strong>对比方法</strong>：在相同数据量下，将本文提出的<strong>跨具身潜在扩散策略</strong>（在来自所有末端执行器的数据上协同训练）与<strong>单具身扩散策略</strong>（仅在单个末端执行器数据上训练）进行对比。</li>
<li><strong>评估指标</strong>：任务成功率（分阶段或整体）。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>消融实验（对比动作模型）</strong>：如表III所示，温度退火和编码器微调对学习高质量的潜在空间至关重要。完整流程（含温度退火和微调）在自重建和跨重建损失上均优于去除任一或两个组件的变体，其中微调的影响最为显著。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.14608v3/x3.png" alt="成功率对比"></p>
<blockquote>
<p><strong>图3</strong>：三个不同任务的成功率对比，比较了单具身扩散策略与在每个任务中利用两个具身数据协同训练的跨具身潜在扩散策略。结果显示，在大多数情况下，跨具身策略带来了显著的性能提升，最高达25.3%。</p>
</blockquote>
<ol start="2">
<li><p><strong>主要性能对比</strong>：</p>
<ul>
<li><strong>方块堆叠任务</strong>：跨具身协同训练带来了最显著的技能迁移。在“抓取方块”阶段，mimic手的成功率绝对提升了25.3%，Franka夹爪提升了13%。更重要的是，在后续更需精细操作的“堆叠方块”和“放入盒子”阶段，Franka夹爪的性能分别显著提升了13%和11%，表明夹爪从灵巧手数据中学习了更精细的操作策略。</li>
<li><strong>方块抓放任务</strong>（存在非对称观测）：协同训练对传感器更丰富的具身（mimic手）仍有收益，其成功率提升了13%。但Franka夹爪的性能下降，作者归因于策略变得依赖仅mimic手可用的腕部相机视图。</li>
<li><strong>毛绒玩具抓放任务</strong>：跨具身策略显著优于单具身版本，Faive手成功率提升10%，Franka夹爪提升7.5%。</li>
</ul>
</li>
<li><p><strong>多机器人控制展示</strong>：如图4所示，单个跨具身扩散策略可以同时控制实验设置中不同的机器人（mimic手、Faive手、Franka夹爪）执行抓放任务，验证了多机器人控制能力。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2506.14608v3/x4.png" alt="多机器人控制展示"></p>
<blockquote>
<p><strong>图4</strong>：两个抓放任务在不同设置下的跨具身策略执行过程。每个设置中的机器人（左：mimic手；中：mimic手与Franka夹爪；右：Faive手与Franka夹爪）均由同一个跨具身扩散策略控制，展示了多机器人控制能力。</p>
</blockquote>
<p><strong>消融实验总结</strong>：温度退火和编码器微调是构建高质量（对齐且可重建）潜在动作空间的关键组件，两者缺一都会导致自重建和跨重建损失显著上升。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个通用框架，利用对比学习将多样化的末端执行器动作空间统一到单个语义对齐的潜在空间中，从而支持跨多样化机器人具身的下游学习。</li>
<li>展示了将扩散策略分解为潜在的、具身无关的策略和具身特定的动作解码器，能够实现对形态差异显著的机器人的多机器人控制。</li>
<li>在真实世界实验中证明了跨具身协同训练能带来显著的性能增益（成功率最高提升25.3%，平均提升13.4%），实现了跨大具身鸿沟的技能正向迁移。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ol>
<li><strong>非对称观测</strong>：当不同具身拥有不同的传感器模态时，策略难以在所有具身上保持一致的性能。</li>
<li><strong>潜在空间正则化</strong>：学习的潜在空间没有显式正则化，可能导致非平滑区域，给下游策略建模带来困难。</li>
<li><strong>数据集规模不平衡</strong>：当将大规模数据集（如BridgeV2, DexYCB）加入协同训练时，收益有限。在数据量严重不平衡且观测空间差异巨大的情况下进行技能迁移仍具挑战。</li>
</ol>
<p><strong>对后续研究的启示</strong>：<br>本文通过将跨具身学习构建为多模态表示学习问题，为统一异构动作空间提供了一条新路径。未来的工作可以沿着以下几个方向展开：1) 探索视觉编码器自适应或学习观测对齐以解决非对称观测问题；2) 在潜在空间中引入VAE式先验或时间对比损失来增强平滑性和规律性；3) 开发更复杂的数据集权重采样策略和视觉表示学习方法，以处理大规模、不平衡且视觉差异大的跨具身数据集，进一步提升技能迁移的鲁棒性和泛化能力。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文解决机器人操作中因不同末端执行器（如人手、仿生手、平行夹爪）动作空间异构导致的跨形态技能迁移难题。提出**潜在动作扩散**方法，通过对比学习编码器构建**语义对齐的潜在动作空间**，将异构动作统一编码；并采用**形态无关的潜在策略**与**形态特定的解码器**进行协同训练。实验表明，该方法使用单一策略控制多机器人，在跨形态操作任务中成功率最高提升**25.3%**，实现了有效的技能迁移。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.14608" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>