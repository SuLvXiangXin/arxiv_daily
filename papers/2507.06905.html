<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.06905" target="_blank" rel="noreferrer">2507.06905</a></span>
        <span>作者: Sun, Wandong, Feng, Luying, Cao, Baoshi, Liu, Yang, Jin, Yaochu, Xie, Zongwu</span>
        <span>日期: 2025/07/09</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人移动操作（Loco-Manipulation）旨在整合机器人的移动能力与上半身的跟踪操控能力。目前主流方法采用分层架构，将控制分解为孤立的上半身（操作）和下半身（移动）策略。这种分解虽然降低了训练复杂度，但本质上限制了子系统间的协调，与人表现出的统一全身控制相矛盾。现有方法在设计上还面临命令空间选择、统一与解耦控制架构、以及运动捕捉与程序化训练数据之间的权衡等关键挑战。</p>
<p>本文针对现有解耦方法协调性不足、统一方法训练困难等痛点，提出了一个全新的视角：一个单一的统一策略能够实现人形机器人移动操作在跟踪精度、大工作空间和鲁棒性上的结合。本文的核心思路是提出统一移动操作控制器（ULC），这是一个单策略框架，以端到端的方式同时跟踪根速度、根高度、躯干旋转和双臂关节位置，证明统一控制在不牺牲性能的情况下是可行的。</p>
<h2 id="方法详解">方法详解</h2>
<p>ULC框架旨在通过一个端到端的强化学习策略，统一控制人形机器人的全身运动，以跟踪程序化生成的命令。其核心思想是通过一系列关键技术解决统一控制中的多任务学习、部署现实的命令生成以及负载下的平衡与泛化等挑战。</p>
<p><img src="https://arxiv.org/html/2507.06905v1/extracted/6609234/imgs/method.png" alt="方法框架"></p>
<blockquote>
<p><strong>图3</strong>：ULC方法整体框架。左侧展示了策略的训练过程，包括基于课程学习的序列技能获取、命令多项式插值、随机延迟释放和负载随机化。右侧展示了策略的部署过程，接收高层命令并输出关节动作。</p>
</blockquote>
<p><strong>整体流程与输入输出</strong>：策略的训练基于大规模并行强化学习。输入是机器人的本体感知状态观测（如关节位置/速度、基座角速度、重力投影等）以及当前时间步的目标命令。策略输出是机器人所有关节的动作（位置控制）。训练过程中，命令通过程序化方式生成，并应用了多种技术来提升学习效果和策略鲁棒性。</p>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>序列技能获取</strong>：采用渐进式课程学习，将复杂的控制任务分解为按顺序学习的技能序列。例如，首先学习跟踪根速度和高度（移动），然后加入躯干旋转，最后再加入双臂位置跟踪。只有当当前技能掌握后（达到特定成功率），才开始训练下一个技能，这确保了系统性能力探索并避免了灾难性遗忘。</li>
<li><strong>残差动作建模</strong>：为了提高双臂末端执行器的跟踪精度，对双臂关节采用了残差动作建模。策略输出一个基础动作，然后加上一个残差调整项，这使得策略能够进行更精细的控制调整，特别是在处理外部负载和精确操作时。</li>
<li><strong>命令多项式插值与随机延迟释放</strong>：为了生成平滑且贴近部署现实的命令轨迹，结合了固定间隔随机采样和五阶多项式插值来生成平滑的命令过渡。此外，引入了随机延迟释放机制，模拟实际部署中命令可能被缓冲或延迟发布的情况，从而增强策略对命令时序变化的鲁棒性。</li>
<li><strong>负载随机化与重心跟踪</strong>：为了泛化到不同的外部负载，在训练期间随机化末端执行器的负载质量。更重要的是，为了在负载下保持全身稳定性，引入了重心跟踪奖励。该奖励通过计算包含负载质量分布的机器人重心，并鼓励其在XY平面上的投影保持在双脚定义的支撑多边形内，为策略优化平衡提供了明确的梯度信号。</li>
</ol>
<p><strong>创新点</strong>：与现有解耦或部分统一的方法相比，ULC的主要创新在于其彻底的端到端统一控制架构，并配套了一系列解决该架构下特有挑战的训练技术。它放弃了依赖运动捕捉数据，完全通过程序化命令和精心设计的训练机制（序列技能、残差动作、命令平滑与扰动、显式平衡奖励）来学习一个高性能的全身协调策略。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在仿真环境（Isaac Gym）和真实的Unitree G1人形机器人（带3自由度腰部）平台上进行验证。</p>
<p><strong>对比的基线方法</strong>包括：HOMIE（解耦，RL腿+PD臂）、FALCON（解耦，多RL策略）、JAEGER（解耦，双层级）、AMO（解耦，RL躯干+PD臂）、SoFTA（解耦，双频代理）以及R2S2（统一，技能库）。</p>
<p><img src="https://arxiv.org/html/2507.06905v1/x4.png" alt="跟踪误差对比"></p>
<blockquote>
<p><strong>图4</strong>：各方法在双臂关节位置跟踪上的均方根误差（RMSE）对比。ULC在左臂、右臂及双臂平均误差上均显著低于其他基线方法，展示了最高的跟踪精度。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.06905v1/x5.png" alt="工作空间覆盖对比"></p>
<blockquote>
<p><strong>图5</strong>：各方法达到的双臂末端执行器工作空间覆盖范围（以点云表示）。ULC（紫色）覆盖的空间体积最大，表明其能够实现更大范围的操作。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.06905v1/extracted/6609234/imgs/tele.png" alt="真实机器人任务序列"></p>
<blockquote>
<p><strong>图6</strong>：真实机器人上执行的复杂移动操作任务序列，包括从桌上取面包放入冰箱、推车、铲沙、搬箱、捡玩偶放沙发、坐着弹尤克里里等，展示了ULC协调的全身控制能力。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ul>
<li><strong>跟踪精度</strong>：在双臂关节位置跟踪任务中，ULC的均方根误差（RMSE）最低，比最好的基线（FALCON）在平均误差上降低了约26.7%（仿真）。</li>
<li><strong>工作空间覆盖</strong>：ULC实现了最大的双臂工作空间覆盖体积，比次优方法（AMO）增大了约22.5%。</li>
<li><strong>负载操作</strong>：在末端负载（1kg）条件下，ULC仍能保持高精度的双臂跟踪和身体平衡，而基线方法如HOMIE的跟踪误差显著增大。</li>
<li><strong>真实世界验证</strong>：在Unitree G1机器人上成功完成了包括拾放、推车、铲沙、弹奏乐器在内的十多项复杂移动操作任务，证明了其sim-to-real的有效性。</li>
</ul>
<p><img src="https://arxiv.org/html/2507.06905v1/x8.png" alt="消融实验"></p>
<blockquote>
<p><strong>图8</strong>：消融实验结果显示，移除序列技能获取（w/o Seq.）、残差动作（w/o Res.）、重心跟踪奖励（w/o CoM）或随机延迟（w/o Delay）都会导致性能下降，验证了各组件的重要性。</p>
</blockquote>
<p><strong>消融实验总结</strong>：消融研究表明，每个提出的技术组件都对最终性能有贡献。移除序列技能获取会导致学习不稳定或某些技能无法掌握；移除残差动作会降低双臂跟踪精度；移除重心跟踪奖励会影响负载下的平衡稳定性；移除随机延迟释放会降低对命令时序变化的鲁棒性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>统一控制框架</strong>：证明了单一端到端策略能够有效协调人形机器人全身进行移动操作，在跟踪精度、工作空间和鲁棒性上优于解耦方法。</li>
<li><strong>关键技术集</strong>：提出并验证了一系列关键技术，包括序列技能获取、残差动作建模、命令多项式插值与随机延迟、负载随机化与显式重心跟踪，这些技术有效解决了统一控制中的多任务学习、精细调整、命令平滑与鲁棒性以及负载平衡等挑战。</li>
<li><strong>高性能验证</strong>：在仿真和真实机器人上进行了广泛实验，展示了ULC在多种复杂移动操作任务中的卓越性能，包括高精度跟踪、大范围工作空间以及在负载下的稳定操作。</li>
</ol>
<p><strong>局限性</strong>：论文提到，当前的ULC控制器专注于低级运动控制，缺乏与感知模块（如视觉）的直接集成，其命令空间虽然覆盖广泛，但仍由高层规划器或人工指定。</p>
<p><strong>对后续研究的启示</strong>：ULC的成功表明，通过精心设计的训练机制，统一全身控制并非不可逾越。这鼓励后续研究探索更紧密的感知-动作闭环，将类似统一控制框架与视觉、语言等高层理解模块结合，以实现完全自主的复杂移动操作。同时，其训练技术（如序列技能、显式平衡奖励）可为其他需要精细协调和多任务学习的机器人控制问题提供参考。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人运动操作中现有分层控制方法协调性差的问题，提出统一精细控制器ULC。该框架采用单一策略，以端到端方式同步跟踪根速度、高度、躯干旋转及双臂关节位姿。关键技术包括：序列技能获取、残差动作建模、命令多项式插值、随机延迟释放、负载随机化及重心跟踪。在Unitree G1机器人上的实验表明，ULC相比基线方法具有更优的跟踪性能、更大的工作空间覆盖范围，并能在外载下保持精确操作与全身协调。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.06905" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>