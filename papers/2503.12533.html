<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2503.12533" target="_blank" rel="noreferrer">2503.12533</a></span>
        <span>作者: Yuan, Haoqi, Bai, Yu, Fu, Yuhui, Zhou, Bohan, Feng, Yicheng, Xu, Xinrun, Zhan, Yi, Karlsson, Börje F., Lu, Zongqing</span>
        <span>日期: 2025/03/16</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前人形机器人研究在高层认知（利用基础模型，FM）和低层技能（如移动、操作）方面均取得了显著进展。主流方法尝试将FM与基于学习的机器人技能直接结合，以构建自主智能体。然而，将这种范式直接应用于人形机器人时，面临几个关键局限性：1) <strong>双足行走固有的不稳定性</strong>，使得机器人位置难以预测，需要频繁的闭环调整，而非执行开环命令序列；2) <strong>现有FM（如GPT-4o）的推理效率低且具身场景理解能力不足</strong>，导致智能体在长时程任务的导航与操作交替阶段反应迟钝、不够鲁棒；3) <strong>导航终止姿态可能不适合后续操作</strong>，即使成功抵达目标位置（如桌子旁），最终的站立姿态也可能无法为后续操作技能（如“抓取杯子”）提供合适的初始状态。</p>
<p>本文针对人形机器人智能体在长时程具身任务中决策效率低、鲁棒性差的痛点，提出了一个分层代理框架的新视角，并创新性地引入一个名为“连接器（Connector）”的中间模块来桥接高层规划与低层技能。本文的核心思路是：构建一个由基础模型（高层认知）、基于视觉语言模型（VLM）的连接器（中层协调）和模块化技能库（低层控制）组成的三层框架，通过连接器将FM的语言计划高效、可靠地转化为可执行的技能命令，并动态协调移动与操作，以提升任务成功率。</p>
<h2 id="方法详解">方法详解</h2>
<p>Being-0框架是一个分层代理系统，旨在通过自然语言指令控制配备灵巧手和主动视觉的全尺寸人形机器人完成复杂的现实世界任务。其整体工作流程为：用户输入语言指令（如“泡一杯咖啡”）→ <strong>基础模型（FM）</strong> 根据当前视觉观察进行推理、检测和规划，生成高层语言计划（如“找到桌子”）→ <strong>连接器（Connector）</strong> 接收FM的计划和实时视觉输入，利用其内部的轻量级VLM进行“接地技能规划”，将其转化为具体的、可执行的技能命令（如“向前走”或“转向桌子”）→ <strong>模块化技能库</strong> 执行连接器发出的技能命令，控制机器人身体（下半身移动、上半身及头部操作）。</p>
<p><img src="https://arxiv.org/html/2503.12533v2/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：Being-0框架概览。包含三个核心组件：(1) 用于高层任务规划和推理的基础模型（FM）；(2) 连接器，一个桥接FM与低层技能的视觉语言模型（VLM）；(3) 提供鲁棒移动和灵巧操作的模块化技能库。</p>
</blockquote>
<p><strong>核心模块一：模块化技能库</strong>。该库包含两类技能：1) <strong>基于摇杆命令的稳定移动技能</strong>：采用强化学习在仿真中训练一个以目标速度为条件的本体感知策略，通过域随机化和施加外力实现sim-to-real部署，控制频率50Hz。技能包括{无动作、直行、后退、左转、右转、左侧移、右侧移、倾斜头部、转动头部}。2) <strong>操作技能</strong>：使用Apple VisionPro进行遥操作，采集包含双目图像、上半身及颈部关节位置与动作的高质量、类人操作轨迹。采用ACT（一种基于Transformer的行为克隆方法）为每个与语言描述（如“grasp_bottle”）关联的操作技能训练一个策略，预测未来动作序列，控制频率10Hz。新增一个技能仅需50-150条轨迹和不到1小时的遥操作。</p>
<p><strong>核心模块二：基础模型（FM）</strong>。采用GPT-4o作为高层规划器，其功能包括：1) <strong>推理</strong>：根据图像观察和指令生成描述，理解任务及当前执行阶段；2) <strong>检测</strong>：评估近期执行技能的成功与否，识别失败和异常；3) <strong>规划</strong>：基于推理和检测结果，从技能库中选择下一个要执行的技能。</p>
<p><strong>核心模块三：连接器（Connector）</strong>。这是本文的核心创新点，旨在解决FM直接控制时的效率、鲁棒性和协调性问题。连接器核心是一个轻量级VLM（基于VideoLLaMA2架构），通过在多任务（图像描述、技能预测、目标检测）上使用标注了语言描述、技能、目标标签和边界框的第一人称导航图像数据集进行训练而获得。其主要作用体现在：</p>
<ol>
<li><strong>接地技能规划</strong>：将FM的语言计划与实时视觉观察结合，转化为可执行的技能命令。例如，当FM计划“抓取杯子”但机器人离桌子尚远时，VLM会将其解释为长期目标，并输出可行技能“move_towards(table)”。</li>
<li><strong>基于视觉导航的移动技能调用</strong>：当目标物体在视野内时，利用VLM的目标检测能力和双目图像合成深度估计物体相对位置，并选择最合适的移动技能靠近目标；若目标不可见，则触发结合移动和主动相机运动的探索例程。</li>
<li><strong>协调导航与操作</strong>：为了解决导航终止姿态可能不适合操作的问题，VLM在导航过程中不仅预测物体边界框，还预测机器人相对于物体的最佳对齐方向。如果当前朝向有偏差，则触发一个结合头部旋转和向前移动的复合技能，使机器人沿弧形路径调整姿态，确保抵达适合操作的优化位置。</li>
</ol>
<p>与现有方法相比，创新点具体体现在：1) 提出了专为人形机器人设计的、包含连接器模块的分层代理框架；2) 连接器作为一个经过具身知识蒸馏的轻量级VLM，实现了高层语言计划到低层技能的高效、可靠转换与动态协调，这是此前工作所不具备的。</p>
<p><img src="https://arxiv.org/html/2503.12533v2/x2.png" alt="任务执行流程"></p>
<blockquote>
<p><strong>图2</strong>：Being-0执行“泡一杯咖啡”任务的工作流程。图片按时间顺序排列，黄框图像为FM的决策点。黄色对话框显示FM的计划，绿色框显示连接器的决策，蓝色框表示从模块化技能库调用的技能。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：使用Unitree H1-2人形机器人，配备两个Inspire灵巧手、用于颈部运动的Dynamixel电机和用于主动视觉的ZED-mini相机。所有模块（除FM在云端外）均部署在机载NVIDIA Jetson AGX设备上。实验环境为一个20m×20m的大型办公室场景。技能库包含多种日常操作任务。评估了包括Fetch-bottle、Deliver-basket、Prepare-coffee、Make-coffee、Deliver-coffee在内的多个长时程任务。</p>
<p><strong>对比方法</strong>：主要对比了<strong>使用连接器的Being-0</strong>与<strong>不使用连接器的基线</strong>（即FM直接调用技能库）。此外，还进行了关于连接器中姿态调整方法和主动视觉的消融实验。</p>
<p><strong>关键实验结果</strong>：<br>长时程任务完成率（表1）：连接器的引入带来了显著性能提升。例如，Fetch-bottle任务完成率从0.00提升至0.90；Deliver-basket从0.00提升至0.80；Prepare-coffee从0.00提升至0.75；Deliver-coffee从0.33提升至0.87。平均完成率达到84.4%。</p>
<p><img src="https://arxiv.org/html/2503.12533v2/x3.png" alt="导航错误案例"></p>
<blockquote>
<p><strong>图3</strong>：FM（GPT-4o）在视觉导航中产生错误计划的定性示例。FM错误地估计了目标（桌子）的方向和距离，导致规划了“直行”技能，而实际上需要“右转”。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2503.12533v2/x5.png" alt="操作失败案例"></p>
<blockquote>
<p><strong>图5</strong>：没有连接器协调时，导航终止姿态不适合后续操作的失败案例。机器人成功导航到桌子，但最终站立位置（左图）不适合抓取杯子，导致操作失败。右图展示了经过连接器调整后的合适姿态。</p>
</blockquote>
<p><strong>消融实验总结</strong>：</p>
<ol>
<li><strong>姿态调整（表2）</strong>：在“导航后操作”的两阶段任务中，评估姿态调整方法对操作成功率的影响。对于抓取任务（Grasp-bottle, Grasp-coffee），使用调整后成功率显著提升（例如Grasp-coffee从1/5提升至4/5）。这证实了调整方法能有效优化导航终止状态。</li>
<li><strong>主动视觉（表3）</strong>：比较了主动相机与固定相机的配置。在导航和操作任务中，使用主动相机的Being-0成功率均为5/5。而固定相机在不同俯仰角下均存在缺陷：角度小(0.3)时虽能导航但无法操作（视野看不到桌面）；角度大(0.9)时利于操作但阻碍导航（视野看不到前方）。主动视觉通过动态调整视角解决了这一矛盾。</li>
<li><strong>效率提升</strong>：得益于轻量级VLM的机载部署，Being-0在导航方面的效率相比完全基于FM的代理提升了4.2倍。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个面向人形机器人的分层代理框架（Being-0），其各层（FM云端、连接器与技能库机载）被优化部署，实现了长时程具身任务的高效执行。</li>
<li>创新性地引入了一个基于VLM的连接器模块，有效桥接了FM的语言规划与低层技能执行，增强了具身决策能力，并协调了移动与操作技能。</li>
<li>实现了对配备多指灵巧手和主动相机的全尺寸人形机器人的控制，在复杂室内环境中成功完成了需要挑战性导航和操作子任务的长期程任务。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，连接器需要特定标注数据（第一人称导航图像与技能标注）进行训练；模块化技能库的扩展虽较高效，但仍需为每个新技能收集遥操作数据并进行训练；系统性能仍部分依赖于云端FM的能力与延迟。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>轻量化决策模块</strong>：连接器的成功表明，将FM的通用知识蒸馏到轻量级、专用于具身任务的机载模型，是平衡性能与效率的有效途径。</li>
<li><strong>主动感知的重要性</strong>：实验证明了主动视觉对于同时满足导航（看前方）和操作（看目标）需求的关键作用，这为复杂具身系统的传感器配置提供了指导。</li>
<li><strong>技能泛化与组合</strong>：当前技能是模块化且相对独立的。未来研究可探索如何使技能更具泛化能力，或如何动态组合基础技能以应对更广泛、未见过的新任务。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出人形机器人智能体框架Being-0，旨在解决复杂长时程现实任务中，直接结合高层认知模型与低层技能导致的鲁棒性差、效率低的问题。其核心采用三层架构：基础模型进行高层任务规划与推理；轻量视觉语言模型作为连接器，将语言计划转为可执行技能指令；模块化技能库提供稳健运动与灵巧操作。实验表明，该框架在大型室内环境中能有效完成需复杂导航与操作的长期任务，且除基础模型外均可部署于低成本机载设备，实现全尺寸人形机器人的实时控制。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2503.12533" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>