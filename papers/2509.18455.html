<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.18455" target="_blank" rel="noreferrer">2509.18455</a></span>
        <span>作者: Daniel Seita Team</span>
        <span>日期: 2025-09-22</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，机器人非抓取操作（如推、拉）的研究大多依赖于平行夹爪或杆、铲等简单末端执行器。这些方法虽然有效，但在处理几何形状复杂、尺寸过大或易倾倒的物体时，其接触模式和支持稳定性有限。相比之下，多指灵巧手提供了更丰富的接触模式和操作多样性，能够通过多个接触点稳定支撑物体，从而弥补了非抓取操作动力学建模的困难。然而，由于灵巧手与物体关系建模复杂、富含接触的运动规划困难，利用高自由度灵巧手进行非抓取操作的研究相对较少。</p>
<p>本文针对这一具体痛点，提出了一种新的视角：将灵巧手非抓取推拉问题重新定义为合成和学习能够导致有效操作的接触前灵巧手姿态。其核心思路是构建一个可扩展的管道，通过接触引导的优化和物理仿真验证生成大规模手部姿态数据集，并训练一个基于物体几何条件的扩散模型来预测可行的姿态，最终结合运动规划在现实世界中执行。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的方法名为“几何感知灵巧推拉”（GD2P），整体流程分为三步：1）生成用于推拉的大规模灵巧手姿态数据集；2）使用该数据训练一个基于物体几何条件生成手部姿态的扩散模型；3）在部署时，使用扩散模型生成候选姿态，并通过运动规划验证和选择最佳姿态执行。</p>
<p><img src="https://arxiv.org/html/2509.18455v2/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：GD2P方法整体框架。左侧为离线阶段：通过大规模数据生成管道产生手部姿态数据集，并用于训练扩散模型。右侧为在线执行阶段：给定物体，获取其基础点集表示并输入训练好的扩散模型以合成多样的浮动预接触手部姿态；随后在物理仿真中添加机械臂并进行运动规划，对可行姿态进行排序（如姿态“C”因机械臂与桌子不可避免的碰撞而被判定为不可行），选择性能最佳的姿态（如姿态“D”）在现实世界中执行。</p>
</blockquote>
<p><strong>1. 数据集生成</strong>：该方法从为灵巧抓取生成姿态的能量函数优化方法中获得灵感。首先在手掌和手指表面（指尖采用更密集的采样）定义一组候选接触点。然后通过优化算法最小化一个专门为推拉任务调整的能量函数来生成手部姿态。该能量函数在原有抓取相关项（力闭合估计器 $E_{fc}$、手到物体距离惩罚 $E_{dis}$、关节限制惩罚 $E_j$、穿透惩罚 $E_{pen}$）的基础上，引入了两个新项：$E_{dir}$ 鼓励手掌法向量 $v_{palm}$ 与推拉方向 $u_{dir}$ 对齐；$E_{arm}$ 通过惩罚手掌法向量向上的分量，鼓励生成对机械臂运动学更友好的姿态。通过随机重采样接触点索引和模拟退火等策略注入多样性。</p>
<p><img src="https://arxiv.org/html/2509.18455v2/x3.png" alt="手部姿态示例"></p>
<blockquote>
<p><strong>图2</strong>：通过优化能量函数（公式1）生成的推拉手部姿态示例。所有示例均已通过IsaacGym仿真验证，且预期的物体推动方向均为向右。这些数据点用于训练扩散模型。</p>
</blockquote>
<p>生成候选姿态后，使用GPU加速的物理仿真器IsaacGym进行验证。一次推/拉操作成功的标准是：执行20厘米平移后，物体中心在目标位置3厘米内，且物体姿态变化不超过45度。优化过程的成功率较低，因此对成功姿态添加轻微噪声以进行数据增强。最终构建了一个包含2300个物体、130万个成功手部姿态的数据集。</p>
<p><strong>2. 扩散模型训练</strong>：为了基于物体几何生成手部姿态，本文采用了条件U-Net架构的扩散模型，使用DDPM目标进行训练。前向过程对手部配置 $H$（包含关节角度和手腕位姿）逐步添加高斯噪声，反向过程则在物体几何条件的引导下迭代去噪以重建原始姿态。物体的观测表示采用基于物体点云 $P$ 的4096维基础点集（BPS）表示 $B$，它通过计算一组固定基础点到点云 $P$ 中各点的最短距离，将几何属性编码为固定长度的向量。</p>
<p><strong>3. 运动规划与评估</strong>：在线阶段，扩散模型生成候选手部姿态 $H = (\theta, T)$。随后，将机械臂纳入考虑，使用运动规划器（cuRobo）为每个姿态生成完整的机械臂运动轨迹，并丢弃不可行的轨迹。为了从可行轨迹中选择最佳执行方案，为每个关联的手部姿态设计了一个自定义分析评分 $V(H)$。</p>
<p><img src="https://arxiv.org/html/2509.18455v2/x4.png" alt="评分可视化"></p>
<blockquote>
<p><strong>图3</strong>：公式3中评分函数 $V(H)$ 的三个组成部分 $L_{goal}$、$L_{coll}$ 和 $L_{dir}$ 在三个仿真手部姿态上的可视化。姿态1在方向对齐上得分最高但会导致碰撞；姿态3在推动效果上得分较低；姿态2平衡了各项指标，因此被选中在现实世界执行。</p>
</blockquote>
<p>评分函数 $V(H) = \alpha L_{goal} + \beta L_{coll} + \gamma L_{dir}$，其中 $L_{goal}$ 衡量物体最终位置与目标位置的欧氏距离，$L_{coll}$ 指示执行过程中是否发生碰撞（发生为1，否则为0），$L_{dir}$ 鼓励手掌方向与推动方向对齐（即 $E_{dir}$ 项）。通过调整超参数 $\alpha, \beta, \gamma$ 来平衡各项。该方法可自然扩展到多步规划，例如在存在障碍物时，先用RRT*规划全局路径，再为每个路径点依次规划手部姿态。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在仿真（IsaacGym）和现实世界中进行。现实世界硬件平台为搭载16自由度Allegro手的Franka Panda机械臂，操作场景为桌面。测试物体包括3D打印物体和日常物体（如图5所示），均为训练集未见过的物体。对于日常物体，使用NeRFstudio、COLMAP和2D高斯泼溅等流程从现实世界重建点云和网格。</p>
<p><img src="https://arxiv.org/html/2509.18455v2/x5.png" alt="实验物体"></p>
<blockquote>
<p><strong>图4</strong>：现实世界实验中使用的物体，包括3D打印物体和日常物体。</p>
</blockquote>
<p><strong>基线方法</strong>：</p>
<ol>
<li><strong>预训练抓取姿态</strong>：使用基于NeRF的预训练抓取合成模型，测试抓取模型在非抓取任务上的泛化能力。</li>
<li><strong>最近邻（NN）</strong>：基于BPS表示找到最相似的训练集物体，并检索其关联的手部姿态，测试纯检索方法的泛化能力。</li>
<li><strong>GD2P（无排序）</strong>：GD2P的消融版本，随机执行一个可行姿态，测试评分排序机制的有效性。</li>
</ol>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><p><strong>仿真数据规模验证</strong>：在300个未见物体上测试不同训练数据比例下模型生成至少一个可行推动姿态的能力。如表I所示，使用100%数据（130万姿态）时，成功物体数量最高（169.33 ± 15.18），验证了大规模监督的有效性。</p>
</li>
<li><p><strong>现实世界性能对比</strong>：对每个物体测试三个方向，每个方向执行五次。成功率汇总如图6所示。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2509.18455v2/figures/bar_plot.png" alt="现实世界成功率"></p>
<blockquote>
<p><strong>图5</strong>：GD2P与基线方法在3D打印物体（左）和日常物体（右）上的推拉成功率对比。每个柱状图汇总了40次（左）和30次（右）试验的成功率。</p>
</blockquote>
<p>GD2P在两类物体上均优于或与其他方法持平。<strong>预训练抓取姿态</strong>基线由于手部姿态未考虑推动方向，物体易从手上滑落，且对某些几何形状不适用。<strong>最近邻</strong>基线因物体几何匹配粒度有限而表现不佳。<strong>GD2P（无排序）</strong> 因可能选择到易碰撞或方向不佳的姿态而成功率较低，这凸显了基于公式3的排序系统的重要性。</p>
<p><img src="https://arxiv.org/html/2509.18455v2/x6.png" alt="定性对比"></p>
<blockquote>
<p><strong>图6</strong>：GD2P与基线的定性对比示例。前两行显示GD2P（成功）和预训练抓取（失败）推动一个3D打印花瓶向前；后两行显示GD2P（成功）和最近邻（失败）将一个沙拉酱瓶向右推。</p>
</blockquote>
<ol start="3">
<li><strong>固定手部姿态案例研究</strong>：模仿先前使用铲子的工作，手动定义了一个手指平摊的“铲状”固定手部姿态。在对6个高度超过20厘米的物体进行测试时，成功率较低（18/60），表明简单策略对多样化物体支持不足。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.18455v2/x7.png" alt="固定姿态失败"></p>
<blockquote>
<p><strong>图7</strong>：使用固定手部姿态策略的典型失败案例，导致喷雾瓶倾倒。</p>
</blockquote>
<ol start="4">
<li><strong>多步操作演示</strong>：GD2P可作为可靠模块用于多步推动。如图9所示，机器人使用两个不同的手部姿态分步推动一个3D打印花瓶，展示了在路径不同阶段重新规划姿态的益处。</li>
</ol>
<p><img src="https://arxiv.org/html/2509.18455v2/x8.png" alt="多步规划"></p>
<blockquote>
<p><strong>图8</strong>：使用RRT*进行多步路径规划示例。第一列显示路径规划结果可视化，第二、三列显示沿路径推动物体时两个连续的手部姿态。</p>
</blockquote>
<ol start="5">
<li><strong>不同手型结构的适用性</strong>：将相同流程应用于16自由度的LEAP手（搭载xArm7机械臂），在相同14个物体上进行了测试，结果表明GD2P在不同手型结构上具有一致的性能和应用潜力。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个可扩展的管道，用于生成和筛选用于非抓取推拉的灵巧手部姿态数据集。</li>
<li>提出了一个基于物体几何条件、用于预测非抓取推拉手部姿态的扩散模型。</li>
<li>提出了一个结合运动规划在现实世界中执行这些姿态的框架，并通过840次现实世界试验证明GD2P优于其他方法。同时开源了包含2300个物体、130万个手部姿态的数据集和预训练模型。</li>
</ol>
<p><strong>局限性</strong>：论文提到，初步实验中一些生成的手部姿态仍会与物体发生碰撞，这促使了在运动规划评分中加入碰撞项。此外，仿真数据规模实验显示性能增长并非严格线性，表明在模型调优或数据策略方面仍有改进空间。</p>
<p><strong>启示</strong>：本研究展示了将大规模数据生成、生成式模型和传统运动规划相结合，解决灵巧手复杂接触任务（如非抓取操作）的有效路径。该方法不局限于特定手型，具有较好的泛化性。未来工作可探索更精细的动力学建模、闭环控制策略，以及将该框架扩展到更广泛的非抓取操作任务序列中。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文研究如何利用多指灵巧手进行几何感知的非抓取式推拉操作，以操纵难以直接抓取的物体。提出GD2P方法，其关键技术包括：通过接触引导采样生成多样化的预接触手部姿态，利用物理模拟进行筛选，并训练一个以物体几何为条件的扩散模型来预测可行姿态。实验在Allegro Hand上进行了840次真实世界测试，结果表明GD2P为训练灵巧非抓取操作策略提供了可扩展的途径，并成功迁移至LEAP Hand，证明了其对不同手部形态的适用性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.18455" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>