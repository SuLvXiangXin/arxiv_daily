<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>A multi-modal tactile fingertip design for robotic hands to enhance dexterous manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>A multi-modal tactile fingertip design for robotic hands to enhance dexterous manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.05382" target="_blank" rel="noreferrer">2510.05382</a></span>
        <span>作者: Xu, Zhuowei, Si, Zilin, Zhang, Kevin, Kroemer, Oliver, Temel, Zeynep</span>
        <span>日期: 2025/10/06</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人操作通常依赖视觉来感知环境、估计物体位姿并闭环控制。然而，当接触区域被机械臂本身或杂物遮挡时，视觉性能会显著下降。在灵巧手进行接触丰富的操作时，这种遮挡情况尤为常见。人类通过手部的触觉来补偿视觉遮挡，利用多种机械感受器感知压力、检测滑动并识别接触面属性。这启发了在机器人手上部署触觉传感。尽管已有多种触觉传感器被开发，但为机器人手设计和部署触觉传感器仍面临独特挑战：传感器需要足够紧凑以集成到手指中而不影响手部工作空间或灵活性；接触丰富的操作要求传感器测量稳定可靠；多模态触觉感知能捕捉更细微的接触信息；此外，传感器信号必须具有表现力且易于解读，以便有效控制高自由度手部系统并与视觉感知无缝集成。目前，基于视觉的传感器（如GelSight）通常体积较大且易受皮肤磨损影响，而基于流体的传感器（如BioTac）则成本高昂、制造复杂。本文针对这些痛点，提出了一种低成本、易制造、适应性强且紧凑的指尖设计，集成了多模态触觉传感器。核心思路是使用应变片传感器捕捉静态力，使用接触式麦克风传感器测量接触时的高频振动，模仿人类触觉的慢适应和快适应机械感受器，并将所有传感器内置在一个紧凑的指尖模块内，以提供可靠且富有表现力的触觉信息，增强在视觉遮挡下的灵巧操作能力。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的指尖设计（图1a）集成了功能结构（刚性指甲和软皮肤）以及两种触觉传感器（应变片和接触式麦克风），形成一个紧凑的指尖模块。选择这两种传感器是因为：i) 它们对两种互补的接触类型（静态力和振动触觉信息）敏感；ii) 它们扁平且尺寸小，易于集成到紧凑模块中；iii) 其传感器读数易于解读且可靠，适用于机器人手控制。</p>
<p><img src="https://arxiv.org/html/2510.05382v1/fig/teaser.jpg" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：提出的多模态触觉指尖设计。(a) 指尖结构包括刚性骨骼和指甲，并覆盖软皮肤，模仿人类指尖的机械结构。利用应变片传感器模仿慢适应机械感受器检测压力，利用接触式麦克风传感器模仿快适应机械感受器拾取接触振动。(b) 装备了该指尖的Delta手指。(c) 装备了四个触觉指尖的DeltaHand。(d)(e) 利用触觉传感器测量值在手控制回路中抓取软豆腐块和单块薯片而不损坏。</p>
</blockquote>
<p><strong>整体框架与制造</strong>：指尖结构由四个模块组成（图2）：1) 三角形底座，用于安装定制PCB并作为与机器人手指连接的结构接口；2) 半顺应方形棱柱，作为安装应变片传感器的刚性骨骼；3) 带刚性指甲的刚性盖，顶部安装接触式麦克风传感器以拾取来自指甲的振动；4) 软皮肤层，覆盖除指甲外的整个盖，以增加接触摩擦力并实现软接触，提高抓取稳定性。整体尺寸为1.9 cm × 1.9 cm × 2.7 cm。</p>
<p><img src="https://arxiv.org/html/2510.05382v1/fig/assemble-2.jpg" alt="制造流程"></p>
<blockquote>
<p><strong>图2</strong>：指尖的制造过程和最终原型。(a) 制造步骤：焊接连接器到PCB；用胶水将接触麦克风传感器粘在3D打印盖顶部；使用两个3D打印模具用硅胶为盖模制软皮肤；将四个应变片传感器粘在方形棱柱的四个侧面；将PCB用M2螺丝安装在指尖底座下方；用M2螺丝组装盖和棱柱；为盖穿上软皮肤。(b) 完全组装好的指尖原型。</p>
</blockquote>
<p>制造过程耗时约1小时（硅胶固化30分钟），总成本低于100美元，具有可扩展性和批量生产潜力。</p>
<p><strong>核心传感器模块</strong>：</p>
<ol>
<li><strong>应变片传感器</strong>：使用四个应变片传感器（BF120-3AA，4 mm × 6.8 mm）来估计施加在指尖侧面的2D法向力。它们被粘在方形棱柱的四个侧面。通过一个M2螺丝将盖刚性固定到棱柱顶部，并在所有侧面留下1 mm间隙，这使得棱柱在外部接触力下能自由弯曲，从而引起传感器应变变化。虽然四个正交排列的应变片理论上可以估计3D力，但本文仅校准和估计2D力以提高精度。</li>
<li><strong>接触式麦克风传感器</strong>：使用压电片接触麦克风传感器（直径10 mm）来感知动态接触事件（如建立/断开接触或滑动）产生的振动。该传感器刚性附着在指尖盖的顶部，靠近振动源（指甲）。当指甲与物体交互时，接触振动通过刚性盖传递，被传感器捕获并转换为电信号。</li>
</ol>
<p><strong>读出电路</strong>：定制PCB与指尖尺寸匹配，用于传感器数据读出。它将应变片和接触麦克风的信号输入，并通过统一输出端口输出。组合信号通过扁平柔性电缆传输到另一块定制PCB进行信号放大和模数转换（图3）。应变片信号通过惠斯通电桥和HX711模块（Arduino Uno）处理，接触麦克风信号通过前置放大器和改装后的Maono USB声卡处理。两者均通过USB传输到PC。应变片和接触麦克风的响应频率分别为15 Hz和44.1 kHz。</p>
<p><img src="https://arxiv.org/html/2510.05382v1/fig/circuit.jpg" alt="电路图"></p>
<blockquote>
<p><strong>图3</strong>：指尖的读出电路：接触麦克风传感器信号和应变片传感器信号通过指尖PCB收集，并由FFC电缆传输到另一块定制PCB。应变片测量值由HX711模块在Arduino Uno上放大和数字化，而振动触觉信号则由改装后的Maono USB声卡预放大和数字化。两者都通过USB传输到PC。</p>
</blockquote>
<p><strong>创新点</strong>：与现有多模态传感器（如体积大、易磨损的视觉传感器或成本高、制造复杂的流体传感器）相比，本文的创新点在于将两种成熟、低成本的单模态传感器（应变片和接触麦克风）巧妙地集成到一个紧凑、耐用、易于制造的指尖模块中。所有传感器内置，避免了直接磨损，并通过一次性校准即可提供可靠的多模态信号（力和振动），非常适合集成到多指机器人手中。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在DeltaHand上装备四个触觉指尖，并将其安装在Franka Emika Panda机械臂上。使用笛卡尔位置控制控制机械臂末端，使用关节位置控制控制DeltaHand。</p>
<p><strong>基准与对比方法</strong>：在三个任务中评估，并与视觉基线方法对比。视觉基线方法包括使用SAM2进行分割或使用GPT-5 VLA代理进行视觉问答。</p>
<p><strong>任务与关键结果</strong>：</p>
<ol>
<li><strong>基于指尖力控制的易碎物体捏取</strong>：使用指尖力估计进行闭环控制来抓取豆腐块和薯片。设定力阈值（豆腐0.5 N，薯片0.1 N）来引导捏取，并在提升过程中维持施加在物体上的力。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.05382v1/fig/pinching.jpg" alt="捏取实验"></p>
<blockquote>
<p><strong>图5</strong>：基于指尖应变片传感器的力控制来捏取和提升易碎物体（豆腐块和薯片）。设定力阈值引导捏取，并在提升过程中维持施加在物体上的力。</p>
</blockquote>
<p>两种控制器（力控和视觉基线）对两种物体各进行25次测试，均达到100%成功率。结果表明，触觉指尖提供了详细的接触信息，使简单的力阈值控制器能达到与视觉控制同等的效果。此外，触觉方法在CPU上以15 Hz运行，延迟低，而视觉方法需要GPU运行大型预训练模型（SAM2在RTX 2080上以2.5 Hz运行）。</p>
<ol start="2">
<li><strong>纸杯计数与拆解</strong>：任务涉及通过指甲滑过纸杯堆来计数杯缘数量，并利用振动触觉特征结合机器人Z轴运动来拆解指定数量的杯子。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.05382v1/fig/cups-sliding.jpg" alt="纸杯任务"></p>
<blockquote>
<p><strong>图6</strong>：纸杯计数与拆解流程。(a)-(e) 任务步骤。(f) 通过二值化原始振动触觉信号来定位滑过杯缘的时刻，并与机器人高度同步。(g) 视觉基线方法。(h) 结果显示振动触觉方法在视觉遮挡场景下优于视觉方法。</p>
</blockquote>
<p>进行了36次试验。振动触觉方法在计数和拆解上实现了完美性能（36/36）。视觉基线方法（使用GPT-5 VLA代理）虽然能较准确计数初始堆叠（35/36），但在滑动后（17/36）和提升后（11/36）的性能因遮挡而显著下降。这证明了在部分遮挡场景下，振动触觉感知能实现鲁棒的状态估计，并大幅优于视觉基线。</p>
<ol start="3">
<li><strong>通过摇晃检测隐藏物体材料</strong>：在视觉完全遮挡的情况下，机器人摇晃两个视觉相同的盒子（一个装螺丝，一个装橡皮筋），使用基于振动触觉的材料分类器识别盒内材料，并选择目标材料的盒子打开。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.05382v1/fig/shaking.jpg" alt="摇晃实验"></p>
<blockquote>
<p><strong>图7</strong>：遮挡下盒内物体材料检测及开盒的实验设置和流程。(a) 两个视觉相同的盒子。(b) 机器人依次抓取并摇晃盒子。(c) 摇晃期间收集的振动触觉读数用于预测隐藏材料类别。(d) 引导机器人选择包含目标材料类别的盒子并打开它。</p>
</blockquote>
<p>评估了26次试验，总体成功率达到94.64%（螺丝盒25/28，橡皮筋盒28/28）。这表明在完全视觉遮挡下，振动触觉检测可以可靠地推断盒内材料，并有效地为高层决策提供信息。</p>
<p><strong>传感器表征结果</strong>：<br><img src="https://arxiv.org/html/2510.05382v1/fig/cali-setup-and-result.jpg" alt="表征结果"></p>
<blockquote>
<p><strong>图4</strong>：触觉传感器表征设置与结果。(a) 应变片传感器表征设置。(b) 接触麦克风传感器表征设置。(c) 应变片测量值与真实力读数在0-5N范围内的线性对应关系。(d) 基于振动触觉测量的材料分类模型在测试集上的结果（混淆矩阵）。</p>
</blockquote>
<p>力估计方面，训练了一个多层感知机模型，在测试数据集上实现了约0.15 N²的均方误差，证明了从应变片测量值中准确估计力的能力。材料分类方面，使用振动触觉信号对七种材料进行分类，模型整体准确率达到95.49%，证明了其区分材料的能力。</p>
<p><strong>消融实验启示</strong>：在纸杯计数和通过主动触摸识别隐藏物体属性的任务中，研究表明，当视觉线索不足时，振动触觉信号能提供更细微、更直接的接触信息，只需轻量级的数据处理和机器学习即可用于提升任务性能。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>提出了一种适用于多指机器人手的多模态触觉指尖设计</strong>：该设计紧凑、低成本、易制造，集成了用于力感知的应变片传感器和用于振动感知的接触式麦克风传感器，所有传感器内置以避免直接磨损。</li>
<li><strong>对触觉传感器进行了系统表征</strong>：证明了该设计能提供富有表现力且可靠的传感器测量值，包括0-5 N范围内准确的2D平面力估计和高达95.49%准确率的材料分类能力。</li>
<li><strong>在具有不同视觉遮挡程度的三个操作任务中进行了评估</strong>：展示了不同的触觉模态如何灵活用于缓解视觉遮挡，例如实现易碎物体100%成功抓取、在遮挡下完美进行纸杯计数与拆解，以及在完全视觉遮挡下以高成功率推断隐藏物体材料以指导后续操作。</li>
</ol>
<p><strong>局限性</strong>：论文未明确提及自身局限性，但根据方法描述可推断，当前的力感知仅限于2D平面力估计，而未扩展至3D力/力矩。此外，材料的分类范围限于实验中使用的七种，泛化能力有待进一步验证。</p>
<p><strong>启示</strong>：这项工作表明，利用成熟、低成本的传感器进行巧妙集成，可以构建出实用且性能强大的机器人触觉感知模块。它强调了多模态触觉信息在补偿视觉感知不足方面的关键作用，特别是在接触丰富、遮挡严重的灵巧操作任务中。为后续研究提供了将触觉感知紧密集成到机器人控制回路和高层决策中的可行范例，并启发了在更复杂任务和动态环境中探索触觉与视觉融合的策略。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人手在灵巧操作中视觉遮挡导致性能下降、触觉传感因成本高和集成难而应用受限的问题，提出一种低成本、紧凑的多模态触觉指尖设计。关键技术方法包括集成应变计传感器测量静态力（0-5 N范围）和接触式麦克风传感器检测高频振动，传感器内部集成以减少磨损。核心实验结论显示，应变计提供可重复的2D力测量，接触式麦克风能区分材料属性；在视觉遮挡任务中，如精确计数和卸载纸杯堆叠，实现100%成功率，优于纯视觉方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.05382" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>