<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>TACT: Humanoid Whole-body Contact Manipulation through Deep Imitation Learning with Tactile Modality - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>TACT: Humanoid Whole-body Contact Manipulation through Deep Imitation Learning with Tactile Modality</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.15146" target="_blank" rel="noreferrer">2506.15146</a></span>
        <span>作者: Eiichi Yoshida Team</span>
        <span>日期: 2025-06-18</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前人形机器人的运动与操作大多局限于末端（如手和脚）的接触。相比之下，人类利用全身与环境及物体互动，以均匀分布负载并增强稳定性。实现此类行为需要先进的感知-运动映射能力，以感知全身接触并据此选择恰当动作。然而，传统的基于模型的人形机器人控制方法面临建模和计算成本的挑战，通常会将分布式触觉测量转换为低维数据（如接触面积），因此利用分布式触觉测量进行精细反馈仍是一个重大难题。现有基于优化的方法计算密集，难以生成时间上密集的姿势序列；而基于扭矩或准静态假设的控制方法则要求事先已知接触点，无法应用于接触点在运动过程中才确定的全身操作任务。</p>
<p>本文针对全身接触操作中感知精细接触并生成适应性动作这一具体痛点，提出了一种基于学习的新视角。核心思路是：通过在人形机器人上半身安装分布式触觉传感器，并采用基于人类遥操作数据的模仿学习，训练一个能够处理触觉、视觉和本体感觉多模态输入的Transformer策略，从而实现涉及丰富且精细接触的全身移动操作。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体控制系统采用双层架构，如图2所示，上层是基于学习的、具有触觉反馈的操作运动生成层，下层是基于模型的重定向和运动控制层。在训练数据收集阶段，人类操作员佩戴姿态追踪器进行现场演示；在策略部署阶段，学习到的策略根据传感器测量值推断出与训练阶段格式相同的运动指令。下层控制器保证机器人的物理约束，而上层控制器则生成需要复杂技能的全身接触运动。</p>
<p><img src="https://arxiv.org/html/2506.15146v1/extracted/6550917/figs/system3.jpg" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：用于触觉反馈全身接触操作的人形机器人控制系统。系统由两层组成：基于学习的操作控制上层和基于模型的重定向与运动控制下层。$c$是质心位置，$p$是脚或手臂的位姿，$q$是关节位置，$w$是接触力，$\tau$是触觉测量值，$I$是相机图像。符号的上标<code>cmd</code>和<code>msr</code>分别代表指令值和测量值。</p>
</blockquote>
<p><strong>下层：基于模型的重定向与运动控制</strong><br>该层核心是基于二次规划（QP）的逆运动学（IK）计算，实时计算质心、脚和手臂的目标位姿并输入IK。它包含两个主要部分（图3）：</p>
<ol>
<li><strong>基于LIPM的双足控制</strong>：使用线性倒立摆模型（LIPM）对双足动力学建模。通过离散预览控制求解优化问题（公式1），在LIPM动力学下跟踪由步态序列导出的参考零力矩点（ZMP）轨迹，以保持平衡。此外，基于LIPM发散分量（DCM）的误差进行反馈（公式2），并在外部扰动下进一步稳定直立姿势和行走。对于位置控制型机器人，通过阻尼控制计算脚底位姿（公式3），根据力矩误差比例分配接触点的速度。</li>
<li><strong>运动学重定向</strong>：为直观控制人形机器人上半身，实时测量并重定向人类操作员的上半身姿态。操作员在腰、肘、腕佩戴可测量3D位姿的追踪器。通过校准程序考虑操作员身体比例差异，计算机器人肘和腕相对于其腰部的目标位姿。使用一阶滞后系统更新IK目标位姿以控制跟踪响应性，时间常数约为0.16秒。此外，对选定身体部位实施了基于模型的导纳控制，以在接触时增强柔顺性。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.15146v1/extracted/6550917/figs/retarget-locomotion.jpg" alt="重定向与运动控制"></p>
<blockquote>
<p><strong>图3</strong>：重定向与运动控制。包含(A)基于LIPM的双足控制和(B)运动学重定向两部分。</p>
</blockquote>
<p><strong>上层：基于学习的操作控制（TACT策略）</strong><br>为处理高维分布式触觉测量（本研究中163个传感单元），本文扩展了用于机器人操作的高效模仿学习方法——动作分块Transformer（ACT），提出了触觉模态扩展的ACT（TACT）。</p>
<p><img src="https://arxiv.org/html/2506.15146v1/extracted/6550917/figs/act2.jpg" alt="TACT模型结构"></p>
<blockquote>
<p><strong>图4</strong>：TACT（触觉模态扩展ACT）的模型结构。TACT是一个基于CVAE的策略，以关节位置、图像和触觉测量作为输入。编码器编码感官输入和动作，条件块从当前观测中提取特征，解码器使用Transformer生成时间一致的动作序列。图中可视化了人形机器人实验中模型输入输出数据的示例。</p>
</blockquote>
<p>TACT模型基于条件变分自编码器（CVAE），由编码器、解码器和条件块组成。编码器和解码器使用Transformer实现，图像特征提取使用ResNet18。<strong>与ACT的关键区别在于包含了触觉测量</strong>：触觉数据被扁平化为一个1D向量（326个元素，对应163个传感单元的触觉和接近感强度），经过线性投影成为token，输入到编码器和条件块中。这使得Transformer能够学习触觉输入与其他模态之间的相关性，用于全身接触操作。</p>
<p>训练数据通过人类操作员经由重定向控制操作机器人执行全身接触操作获得。动作并非机器人的关节位置指令 $q^{cmd}$，而是人类手臂的位姿 $\hat{p}_{arm}^{cmd}$。这种设计保持了训练和部署之间输入输出结构的一致性，并避免了学习关节空间的反馈行为（如柔顺性），这部分由下层控制器单独处理。策略通过最小化潜在变量的KL散度和预测动作的误差作为标准CVAE进行训练。部署时，省略编码器块，解码器使用零潜在向量，根据输入条件块的传感器输入生成未来动作序列。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验平台与设置</strong>：</p>
<ul>
<li><strong>机器人平台</strong>：在川崎重工开发的全尺寸人形机器人RHP7 Kaleido的上半身（胸部、上臂、前臂、手腕）安装了Intouch Robotics的分布式触觉传感器e-skin，共11个贴片，163个传感单元。</li>
<li><strong>数据集与任务</strong>：训练数据集包含27个片段，人类操作员远程操作机器人抱起三种不同宽度（440毫米、270毫米、210毫米）的脆弱纸箱各9次。评估任务为机器人使用双臂抱起纸箱，该任务需要前臂和手腕表面的接触，并需精细控制接触力以避免压碎纸箱。</li>
<li><strong>对比基线</strong>：<ol>
<li><strong>Replay</strong>：随机选择并开环回放人类遥操作数据。</li>
<li><strong>TACT w/o vision</strong>：从TACT中移除视觉模态的策略。</li>
<li><strong>TACT w/o tactile</strong>：从TACT中移除触觉模态的策略（即原始ACT）。</li>
</ol>
</li>
</ul>
<p><img src="https://arxiv.org/html/2506.15146v1/extracted/6550917/figs/exp/medium_box_tactile.png" alt="策略部署与评估结果"></p>
<blockquote>
<p><strong>图5</strong>：TACT策略在抱起中等尺寸纸箱任务中的部署示例，展示了触觉传感的激活情况。</p>
</blockquote>
<p><strong>关键实验结果</strong>：<br>论文通过表格（表I）和文字总结了在三种尺寸纸箱上的成功率评估结果。TACT（所提方法）在抱起中等尺寸和大尺寸纸箱的所有试验中均取得成功，而基线策略则出现失败且成功率较低。</p>
<ul>
<li><strong>TACT w/o vision</strong> 倾向于压碎纸箱。</li>
<li><strong>TACT w/o tactile</strong> 在抱起中等尺寸纸箱时，由于手臂与纸箱之间存在微小间隙，倾向于掉落纸箱。</li>
<li><strong>Replay</strong> 由于开环回放，失败（掉落或压碎）随机发生。</li>
<li>对于训练数据中未见过的尺寸（介于大尺寸和小尺寸之间），TACT也显示出优势。然而，对于小尺寸纸箱，所有策略在将其抱起时均因未能保持接触而失败。作者认为这归因于训练数据中纸箱尺寸差异过大（小尺寸与大尺寸宽度相差两倍以上），导致策略对尺寸的泛化精度不足，并指出可通过增加训练数据片段和丰富尺寸多样性来缓解。</li>
</ul>
<p><strong>消融实验总结</strong>：<br>实验通过移除视觉或触觉模态的基线策略，明确了各输入模态的贡献。<strong>触觉模态对于精细接触力的调整和防止物体掉落至关重要</strong>；<strong>视觉模态则有助于避免因力过大而压碎物体</strong>。两者结合（TACT）才能实现鲁棒的、涉及丰富且精细接触的全身操作。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>将主流的机器人操作模仿学习方法ACT扩展至处理对接触密集型全身操作至关重要的触觉模态，提出了TACT。</li>
<li>将基于模型的重定向/运动控制与基于学习的操作运动生成相结合，构建了一个兼具可靠性（下层保证平衡与物理约束）和灵活性（上层处理复杂接触技能）的人形机器人控制系统。</li>
<li>在全尺寸人形机器人RHP7 Kaleido上进行了实验验证，首次实现了在使用覆盖上半身的触觉传感器、并采用基于Transformer策略的学习型操作控制下，完成全身接触移动操作任务。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ul>
<li>策略对训练数据中未充分覆盖的物体尺寸（如极小尺寸纸箱）泛化能力有限，表明需要更多样化和丰富的训练数据。</li>
<li>研究中部分增强接触柔顺性的控制（如手腕导纳控制）仅在仿真中验证，未在实物机器人上完全应用，暗示了模拟到实际转移的挑战或硬件设置限制。</li>
</ul>
<p><strong>对后续研究的启示</strong>：</p>
<ul>
<li>证明了Transformer架构能够有效融合高维触觉、视觉和本体感觉，为处理更复杂的多模态机器人感知与控制问题提供了可行路径。</li>
<li>分层控制架构（学习层处理高级技能，模型层保证底层安全与稳定）是协调复杂人形机器人任务的一种有效范式。</li>
<li>未来工作可探索如何更高效地收集多样化的演示数据，或结合强化学习来进一步提升策略的鲁棒性和泛化能力。</li>
</ul>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出TACT方法，解决人形机器人全身接触操作中运动生成计算成本高、广域接触感知难的挑战。核心技术为基于深度模仿学习的策略TACT，其以关节位置、视觉及分布式触觉测量为多模态输入，并与基于双足模型的重定向和步态控制集成。实验表明，融合视觉与触觉输入能有效提升机器人（RHP7 Kaleido）在执行广泛且精细接触操作时的鲁棒性，使其在保持平衡与行走的同时完成全身接触操作任务。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.15146" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>