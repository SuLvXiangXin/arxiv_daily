<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Data Retrieval with Importance Weights for Few-Shot Imitation Learning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Data Retrieval with Importance Weights for Few-Shot Imitation Learning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.01657" target="_blank" rel="noreferrer">2509.01657</a></span>
        <span>作者: Joey Hejna Team</span>
        <span>日期: 2025-09-01</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，大规模机器人数据集推动了模仿学习（IL）的进展，但从小规模、任务特定的数据集中学习对于在新环境和未见任务中部署仍然至关重要。小样本模仿学习的一种主流方法是基于检索的模仿学习，它从大型、广泛可用的先验数据集中提取相关样本，以增强有限的目标演示数据集。现有检索方法（如BehaviorRetrieval、FlowRetrieval、SAILOR）通常通过计算先验数据点在潜在空间中到目标数据点的最小距离（L2距离）来确定相关性。尽管这种方法在实践中取得了成功，但论文揭示了其两个关键局限性：第一，它依赖于高方差的最近邻估计，容易受到噪声影响；第二，它没有考虑检索时先验数据本身的分布，导致检索分布存在偏差。本文针对这些痛点，从概率视角（重要性采样）重新审视检索问题，提出了重要性加权检索（IWR）。其核心思路是：使用高斯核密度估计（KDE）平滑地估计目标数据分布和先验数据分布，并通过计算两者概率密度之比（重要性权重）来检索数据，从而同时降低方差并纠正分布偏差。</p>
<h2 id="方法详解">方法详解</h2>
<p>IWR的整体流程遵循基于检索的模仿学习范式，但在数据选择机制上进行了关键改进。其目标是在给定少量目标演示数据集 $\mathcal{D}<em>{\text{t}}$ 和大型先验数据集 $\mathcal{D}</em>{\text{prior}}$ 的情况下，检索出一个子集 $\mathcal{D}_{\text{ret}}$ 用于与目标数据共同训练策略（公式1）。IWR的创新在于用基于重要性权重的选择规则取代了传统的最近邻L2距离规则。</p>
<p><img src="https://arxiv.org/html/2509.01657v1/figures/main.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：IWR方法整体框架。包含三个主要步骤：(A) 学习一个潜在空间来编码状态-动作对；(B) 估计目标数据和先验数据的概率分布，并使用重要性权重进行数据检索；(C) 在目标数据和检索到的先验数据上共同训练策略。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><p><strong>表示学习</strong>：与许多现有检索方法相同，IWR首先需要一个编码器 $f_{\phi}$（例如来自VAE）将状态-动作对（或其序列）映射到低维潜在表示 $z$。IWR本身不规定特定的表示学习方法，可以与SAILOR（基于技能的表示）、FlowRetrieval（基于光流的VAE）或BehaviorRetrieval（基于状态-动作的VAE）等方法结合使用。</p>
</li>
<li><p><strong>改进的密度建模（平滑估计）</strong>：论文指出，传统的最近邻L2距离检索规则（公式2）等价于带宽 $h \rightarrow 0$ 时目标数据分布 $p_{\text{t}}$ 的高斯KDE估计的极限情况。这种极限估计方差高。IWR采用具有合理带宽参数（如基于Scott规则）的高斯KDE来平滑地估计分布。对于一个数据集 $\mathcal{D}$ 的嵌入表示，其KDE估计为（公式5）：<br>$p^{\text{KDE}}(z) = \frac{1}{|\mathcal{D}|} \sum_{z&#39; \in f_{\phi}(\mathcal{D})} \mathcal{N}(z; z&#39;, h^2\Sigma)$<br>其中 $\Sigma$ 是样本协方差矩阵。这通过考虑所有数据点而非仅最近邻来获得更低方差的估计。</p>
<p><img src="https://arxiv.org/html/2509.01657v1/figures/is_l2.png" alt="平滑效果示意图"></p>
<blockquote>
<p><strong>图2</strong>：一个玩具示例，说明IWR（高斯KDE）与L2距离检索的区别。在潜在空间中，L2距离会丢弃左侧点（靠近多个目标点）而检索右侧点（仅靠近单个目标点）。IWR由于平滑效应并利用多个目标点进行估计，正确地检索了更相关的左侧点。</p>
</blockquote>
</li>
<li><p><strong>重要性加权</strong>：这是IWR的核心创新。检索的最终目标是利用来自 $p_{\text{prior}}$ 的样本来近似在目标分布 $p_{\text{t}}$ 下的期望损失。根据重要性采样原理，这需要对来自 $p_{\text{prior}}$ 的样本赋予重要性权重 $p_{\text{t}} / p_{\text{prior}}$（公式6）。IWR使用上述高斯KDE分别估计 $p_{\text{t}}^{\text{KDE}}$ 和 $p_{\text{prior}}^{\text{KDE}}$，然后计算重要性权重 $p_{\text{t}}^{\text{KDE}} / p_{\text{prior}}^{\text{KDE}}$。通过优先选择重要性权重高的先验数据点，IWR旨在使检索数据分布 $p_{\text{ret}}$ 更接近 $p_{\text{t}}$，从而纠正传统方法中 $p_{\text{ret}} \propto p_{\text{t}} \cdot p_{\text{prior}}$ 的偏差。</p>
</li>
<li><p><strong>数据检索与策略学习</strong>：基于估计的重要性权重对 $\mathcal{D}<em>{\text{prior}}$ 中的数据点进行排序或设定阈值（例如 $p</em>{\text{t}}^{\text{KDE}} / p_{\text{prior}}^{\text{KDE}} &gt; \eta$）来选择 $\mathcal{D}_{\text{ret}}$。随后，使用标准的行为克隆目标（公式1），以权重 $\alpha$ 混合目标数据和检索数据来训练策略（论文中使用Diffusion Policy）。</p>
</li>
</ol>
<p><strong>创新点总结</strong>：与现有方法相比，IWR的创新具体体现在：1) <strong>概率视角</strong>：将检索形式化为重要性采样问题，为启发式的距离度量提供了数学依据；2) <strong>平滑、低方差估计</strong>：用高斯KDE取代高方差的最近邻估计；3) <strong>偏差校正</strong>：通过显式建模并除以先验分布 $p_{\text{prior}}$，纠正了检索分布对先验数据分布的依赖偏差。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>Benchmark/数据集</strong>：<ul>
<li><strong>模拟任务</strong>：Robomimic中的Square Assembly任务；LIBERO基准测试中的5个LIBERO-10任务（Mug-Microwave, Mug-Mug, Mug-Pudding, Soup-Cheese, Soup-Sauce），使用LIBERO-90作为先验数据集。</li>
<li><strong>真实世界任务</strong>：基于Bridge V2数据集，评估3个未见任务：Corn（5个演示）、Carrot（10个演示）和长视野任务Eggplant（20个演示）。</li>
</ul>
</li>
<li><strong>实验平台</strong>：模拟环境及真实机器人（WidowX）。</li>
<li><strong>Baseline方法</strong>：行为克隆（BC，仅用目标数据）、Behavior Retrieval (BR)、Flow Retrieval (FR)、SAILOR (SR)。所有检索方法均使用相同比例的检索数据（Square: 30%, LIBERO: 2.5%），并共同训练Diffusion Policy。</li>
</ul>
<p><strong>关键实验结果</strong>：<br>论文中的表1汇总了主要结果。</p>
<p><img src="https://arxiv.org/html/2509.01657v1/x1.png" alt="结果表格"></p>
<blockquote>
<p><strong>表1</strong>：在模拟和真实任务上的成功率对比。IWR在绝大多数任务上超越了所有基线方法。在模拟的Square任务上，IWR成功率84%优于BR的69%；在LIBERO任务上，IWR相比BR有显著提升（例如Mug-Pudding: 87% vs. 81%）。在真实任务上提升更为显著，例如Carrot任务成功率从BR的8/20提升到IWR的14/20，长视野Eggplant任务的完全成功率从BR的3/20提升到IWR的11/20。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.01657v1/figures/tasks.png" alt="任务示意图"></p>
<blockquote>
<p><strong>图3</strong>：实验中使用的模拟环境（Robomimic Square, LIBERO任务）和真实世界Bridge任务（Corn, Carrot, Eggplant）的示意图。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.01657v1/x2.png" alt="检索分布分析"></p>
<blockquote>
<p><strong>图4</strong>：针对LIBERO中Mug-Pudding任务，对比BR和IWR检索数据分布的差异。左图按任务相关性分类显示，IWR检索到更高比例的“相关”任务（构成目标子任务）和更少的“有害”任务（无关）。右图按演示时间步分段显示，IWR检索的数据在时间分布上更均衡，而BR严重偏向初始阶段（约40%）。这验证了IWR能检索到更相关且跨任务阶段更多样的数据。</p>
</blockquote>
<p><strong>消融实验与组件贡献</strong>：<br>论文通过分析（如图4）间接说明了各组件贡献：1) <strong>平滑估计（KDE）</strong>：有助于检索靠近多个目标点的数据，并缓解对初始时间步的偏差。2) <strong>重要性加权（除以 $p_{\text{prior}}$）</strong>：有助于在存在相似但不相关对象的任务中，识别并降低对“常见但非目标”数据（如频繁出现在先验集中的对象或场景）的权重，从而提升检索任务的相关性。两者结合使得IWR能更准确、多样地检索到与目标任务相关的数据。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>理论框架</strong>：为基于检索的模仿学习提供了一个基于重要性采样的概率视角，揭示了传统最近邻距离检索规则是高方差、有偏差的分布估计极限情况。</li>
<li><strong>新方法</strong>：提出了重要性加权检索（IWR），通过高斯KDE平滑估计目标与先验分布，并利用其比率作为重要性权重进行检索，同时降低了方差并校正了偏差。</li>
<li><strong>有效性与通用性</strong>：实验表明，IWR能一致地提升多种现有检索方法（BR, FR, SR）的性能，在模拟和真实世界任务中均取得了更高的成功率，且方法改动小，易于集成。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到：1) 高斯KDE在高维潜在空间中可能效果不佳（因此IWR要求潜在维度足够小）。2) IWR使用的基于阈值的选择（而非严格的重要性重采样）仍然是一个有偏估计。</p>
<p><strong>后续研究启示</strong>：</p>
<ol>
<li>可以探索更高效、更适应高维数据的密度估计器来替代高斯KDE。</li>
<li>可以研究如何将严格的重要性采样或去偏技术更有效地集成到检索流程中。</li>
<li>此概率框架可扩展到其他需要从大数据集中选择相关子集的问题领域。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对少样本模仿学习中基于检索的方法存在的两个问题：依赖高方差的最近邻距离估计易受噪声影响，且忽略先验数据分布。提出重要性加权检索（IWR）方法，通过高斯核密度估计计算目标与先验数据分布的重要性权重，以平滑估计并减少偏差。在模拟环境和真实Bridge数据集上的评估表明，该方法仅需微小修改即可一致提升现有检索方法的性能。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.01657" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>