<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>In-between Motion Generation Based Multi-Style Quadruped Robot Locomotion - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>In-between Motion Generation Based Multi-Style Quadruped Robot Locomotion</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.23053" target="_blank" rel="noreferrer">2507.23053</a></span>
        <span>作者: Peng Lu Team</span>
        <span>日期: 2025-07-30</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>四足机器人的运动控制，特别是复杂动态步态，仍然是一个重大挑战。使用真实狗的运动捕捉数据进行模仿学习为实现自然运动提供了一条有希望的路径。然而，依赖此类数据给模仿学习带来了关键限制：数据采集需要专用设施，导致数据集稀缺、短暂且速度信息不完整。这种运动捕捉数据的稀缺性直接损害了策略性能，导致速度跟踪不佳和不稳定。现有方法如对抗运动先验（AMP）虽然代表了处理这些问题的基本进展，但运动捕捉数据缺乏这一核心挑战仍未得到充分探索。</p>
<p>为了克服数据稀缺的挑战，本文针对四足机器人配置，专门为模仿学习开发了一种中间运动生成算法。核心思路是提出一个基于中间运动生成的多风格四足机器人运动框架，利用生成的运动序列来多样化原始训练数据集，并通过基于生成数据的模仿学习来验证生成运动数据在增强控制器稳定性和提高速度跟踪性能方面的有效性。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的框架包含两个关键组件：一个运动生成器和一个控制策略。运动生成器合成的运动轨迹作为模仿学习的参考运动。仿真结果展示了策略学习到的行为，最终通过部署验证了框架向真实硬件的成功迁移。</p>
<p><img src="https://arxiv.org/html/2507.23053v2/x2.png" alt="框架总览"></p>
<blockquote>
<p><strong>图2</strong>：框架总览。该框架包含两个关键组件：运动生成器和控制策略。运动生成器生成的运动轨迹作为模仿学习的参考运动。仿真结果说明了策略学习到的行为。最后，部署展示了GALLOP运动成功转移到真实世界硬件。</p>
</blockquote>
<p><strong>运动生成器</strong>：该模块基于条件变分自编码器（CVAE），由三个网络组成：周期性自编码器（PAE）网络、条件混合专家（CMoEs）解码器网络和采样器网络。</p>
<ol>
<li><strong>数据格式化</strong>：为确保生成的运动符合真实机器人的物理约束，采用了差异化的数据格式化策略。机器人的状态 s 定义为：<code>s = {p_root, R_root, q}</code>，其中包含根关节在世界坐标系中的全局位置 <code>p_root</code> 和旋转方向 <code>R_root</code>，以及机器人的关节姿态 <code>q</code>。这比使用所有物理关节点的全局位置和速度更能满足机器人控制的基本要求。</li>
<li><strong>PAE网络</strong>：首先训练一个周期性自编码器（PAE）来生成多维相位流形。PAE将运动分解为周期性分量，获得编码的相位流形，这是训练运动生成器的关键元素。针对四足机器人，本文修改了PAE架构，用可直接获得的高精度关节角速度替换了原始PAE中需要状态估计的3D骨骼速度输入。</li>
<li><strong>CMoEs解码器</strong>：用于学习不同的局部风格运动，使网络能够为运动生成器生成指定风格的运动。网络使用当前帧 <code>s^t</code> 和下一帧 <code>s^{t+1}</code> 来生成潜变量 <code>z</code>。为了在训练中更好地强调运动风格表示，输入数据集通过训练好的PAE网络处理以生成相位流形 <code>P</code>。从 <code>P</code> 中提取的时间步 <code>t+1</code> 的相位值 <code>p^{t+1}</code> 作为门控网络的输入。门控网络的输出与当前状态 <code>s_t</code>、目标速度 <code>v^{t+1}</code> 和潜变量 <code>z</code> 拼接后，输入专家池网络以预测状态变化 <code>Δs^{t+1}</code>。</li>
<li><strong>损失函数</strong>：CMoEs网络的损失函数经过精心设计，包含多个部分：<ul>
<li>KL散度损失 <code>L_KL</code>：约束潜变量的分布。</li>
<li>足部打滑损失 <code>L_foot</code>：当脚部高度低于阈值δ时，惩罚其速度，以减少足部滑动。</li>
<li>位置损失 <code>L_pos</code>、关节旋转损失 <code>L_rot</code>、朝向损失 <code>L_ori</code>、根位置损失 <code>L_root_pos</code>：分别约束全局关节位置、关节旋转、根部旋转和根部位置。</li>
<li>关节限位损失 <code>L_joint_limit</code>：当预测运动超过硬件能力时施加惩罚。<br>总损失 <code>L</code> 是上述各项损失之和，实现了全局坐标要求和机器人特定控制要求的双重约束优化。</li>
</ul>
</li>
<li><strong>采样器网络</strong>：CMoEs网络可以根据状态 <code>s^t</code> 和速度 <code>v^{t+1}</code> 预测具有所需风格的 <code>ŝ^{t+1</code>，但其输出不一定能到达目标状态。采样器网络的目的就是解决这个问题。它以当前状态 <code>s^t</code>、目标状态 <code>s^T</code> 和当前状态 <code>s^t</code> 的相位向量 <code>p^t</code> 作为输入。编码器将输入信息转换为潜嵌入 <code>z_in</code>，然后由LSTM预测器结合 <code>s^t</code> 和 <code>s^T</code> 的信息预测 <code>s^{t+1</code> 的潜信息。最后，解码器根据预测的潜信息和代表风格的相位向量，预测下一帧的风格 <code>p^{t+1</code>、下一个潜变量 <code>z^{t+1</code> 和下一帧的速度 <code>v^{t+1</code>。采样器网络的输出将作为CMoEs解码器的输入来生成下一状态 <code>s^{t+1</code>。</li>
<li><strong>初始相位预测</strong>：在机器人系统上部署时，获取初始帧的相位向量是一个关键挑战。本文通过一个深度学习网络来预测初始相位向量。具体方法是：通过重复复制起始帧来构建帧序列，以提供卷积层所需的时序上下文，然后通过一个特定的神经网络架构（见表I）处理该序列来预测初始相位向量。</li>
</ol>
<p><strong>控制策略</strong>：该方法通过整合对抗模仿学习（AIL）与任务目标，来学习敏捷且可控的腿式运动策略。</p>
<ol>
<li><strong>问题建模</strong>：将腿式运动学习建模为一个马尔可夫决策过程（MDP）。</li>
<li><strong>观测空间</strong>：策略观测向量 <code>o_t</code> 集成了多模态状态信息，包括：12维关节位置 <code>q</code> 和速度 <code>q̇</code>、投影重力 <code>G_p</code>、基座角速度 <code>ω</code>、命令 <code>C</code>（包括基座速度命令和角速度命令）以及上一时刻的动作 <code>a_{t-1}</code>。仿真训练时加入了特权信息（基座线速度 <code>v_base</code>），真实世界部署时则排除。</li>
<li><strong>动作生成</strong>：策略输出关节位置增量 <code>Δq</code>，执行关节姿态 <code>q_exec</code> 通过将策略生成的增量叠加到预定义的默认配置 <code>q_default</code> 上得到。</li>
<li><strong>奖励函数</strong>：奖励函数由三部分组成：任务奖励 <code>r_t^T</code>（鼓励跟踪速度命令）、风格奖励 <code>r_t^S</code>（通过对抗训练从生成的运动数据中获得，鼓励产生自然、稳定的运动）和正则化奖励 <code>r_t^R</code>（惩罚过大扭矩、动作突变、关节加速度、扭矩超限，并鼓励适当的足部空中时间）。总奖励是各项的加权和。</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：运动生成和模仿学习策略训练在仿真环境（Isaac Gym）中进行。最终策略部署在真实的Unitree AlienGo四足机器人上。评估了四种不同的运动模式：奔跑（Gallop）、三足步态（Tripod）、小跑（Trotting）和溜蹄（Pacing）。基线对比方法为RSMT。</p>
<p><strong>运动生成结果</strong>：<br><img src="https://arxiv.org/html/2507.23053v2/x3.png" alt="运动生成实验结果"></p>
<blockquote>
<p><strong>图3</strong>：运动生成的实验结果。展示了在奔跑、三足步态、小跑和溜蹄四种不同运动模式下的中间帧生成过程。生成的序列保持了每种步态的基本特征。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.23053v2/x7.png" alt="运动生成定量对比"></p>
<blockquote>
<p><strong>图4</strong>：运动生成定量对比表。与RSMT方法相比，本文方法在测试集上，对于最后预测帧的全局位置L2范数以及整个运动片段的全局位置L2范数，在几乎所有步态上都表现更优，尤其是在奔跑（Gallop）步态上提升显著。</p>
</blockquote>
<p><strong>模仿学习结果</strong>：<br><img src="https://arxiv.org/html/2507.23053v2/x4.png" alt="模仿学习仿真结果"></p>
<blockquote>
<p><strong>图5</strong>：Isaac Gym中的多运动对抗模仿结果。展示了四种步态在一个完整运动周期内的模仿效果，特别是奔跑（需要空中阶段和精确着陆协调）和三足步态（要求保持左前脚抬起的同时维持连续稳定性）这两种动态挑战性步态的成功执行。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.23053v2/x5.png" alt="仿真速度跟踪性能"></p>
<blockquote>
<p><strong>图6</strong>：命令跟踪性能。第一行：步态相位分析。第二行：角速度（ω）跟踪性能（灰色为参考命令）。第三行：沿机器人X轴的平移速度（v_x）跟踪。底部：沿机器人Y轴的平移速度（v_y）跟踪。结果表明，在不同步态下，机器人能较好地跟踪速度命令。</p>
</blockquote>
<p><strong>真实世界部署结果</strong>：<br><img src="https://arxiv.org/html/2507.23053v2/x1.png" alt="真实世界部署结果"></p>
<blockquote>
<p><strong>图1</strong>：部署结果。基于生成的中间运动学习到的奔跑和三足步态运动。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.23053v2/x6.png" alt="真实世界实验数据"></p>
<blockquote>
<p><strong>图7</strong>：在Unitree AlienGo上真实世界实验期间收集的运动数据。第一行：奔跑步态分析，线条代表FL（左前）、FR（右前）、RL（左后）、RR（右后）脚的接触状态。第二行：小腿关节角度随时间变化。第三行：小腿关节扭矩随时间变化。数据证实了奔跑步态中存在明显的飞行阶段和关节的周期性变化，三足步态则保持了预期的接触模式。</p>
</blockquote>
<p>实验结果表明，本文提出的方法在运动生成精度上优于基线RSMT，尤其是在长序列生成中误差累积更少。基于生成运动数据训练的模仿学习策略，在仿真和真实世界中都能成功执行多种复杂动态步态，并表现出良好的速度命令跟踪能力和稳定性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个专为四足机器人配置设计的中间运动生成框架，通过生成多样化的、物理可行的运动序列，有效缓解了模仿学习中运动捕捉数据稀缺的问题。</li>
<li>设计了一套适应机器人物理约束的数据格式化方案和损失函数（包括关节限位损失、足部打滑损失等），确保生成的运动可以直接用于机器人模仿学习，无需运动重定向或运动学预处理。</li>
<li>引入了初始相位预测网络，解决了在真实机器人部署时，仅凭起始帧无法计算相位向量的难题，实现了从仿真到真实世界的无缝迁移。</li>
</ol>
<p><strong>局限性</strong>：论文自身未明确阐述局限性，但基于方法描述，其性能可能高度依赖于初始运动数据的质量和覆盖的步态风格范围。生成运动的动态可行性虽然在损失函数中有所约束，但可能仍需与物理仿真进一步结合进行验证。</p>
<p><strong>启示</strong>：本文的工作表明，通过数据生成来扩充稀缺的专家演示数据，是提升模仿学习策略性能的有效途径。将运动生成技术与模仿学习框架紧密结合，能够为机器人学习复杂、动态的运动技能提供一条可扩展的路径。该方法可扩展至其他形态的机器人（如双足、六足）以及其他需要时序运动数据的任务中。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对四足机器人因参考运动数据稀缺而难以实现多风格运动的问题，提出了一种基于中间运动生成的多风格运动控制框架。核心技术是采用CVAE运动生成器，在任意起止状态间合成符合物理约束与关节位相连续性的多步态运动序列。实验表明，基于生成数据训练的模仿策略显著提升了速度跟踪性能和控制器稳定性，并成功在真实机器人上实现了包括疾跑、三足、小跑和溜蹄在内的复杂运动。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.23053" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>