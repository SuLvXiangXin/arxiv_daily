<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.01924" target="_blank" rel="noreferrer">2512.01924</a></span>
        <span>作者: Shingo Murata Team</span>
        <span>日期: 2025-12-01</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前基于深度学习的机器人控制方法，特别是从演示中学习的方法，能够通过模仿专家数据生成多步动作序列，但在面对环境不确定性时泛化能力不足。相比之下，人类能够结合目标导向和探索性行动来适应不确定环境。深度主动推理是一个基于自由能原理的计算框架，理论上可以统一解释这两种行为。然而，传统的深度主动推理方法面临两大挑战：一是其性能严重依赖框架对环境动态的表征能力；二是在任务执行期间计算期望自由能以选择动作的计算成本极高，难以应用于真实机器人。</p>
<p>本文针对深度主动推理在环境表征能力和动作选择计算成本方面的关键局限性，提出了一种新的视角：通过引入具有时间分层结构的世界模型来提升对长期环境动态的表征，并通过学习离散的抽象动作来压缩动作空间，从而将连续动作序列的选择问题转化为对有限个抽象动作的评估问题。本文的核心思路是构建一个由世界模型、动作模型和抽象世界模型组成的框架，利用时间分层的状态表示和抽象化的动作，在保持探索能力的同时，实现计算可行的主动推理控制。</p>
<h2 id="方法详解">方法详解</h2>
<p>提出的框架基于深度主动推理，旨在同时实现目标达成和探索。该框架由三个核心组件构成：世界模型、动作模型和抽象世界模型。</p>
<p><img src="https://arxiv.org/html/2512.01924v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：提出的框架概览。框架包含世界模型、动作模型和抽象世界模型。关键变量包括：观测 <em>o_t</em> 和动作 <em>a_t</em> 由世界模型处理以推断分层隐藏状态 <em>z_t^s</em>, <em>z_t^f</em>。动作模型将动作序列压缩为抽象动作 <em>A_t</em>。抽象世界模型使用 <em>A_t</em> 来预测未来的慢确定性状态 <em>d_{t+h}^s</em>。</p>
</blockquote>
<p><strong>世界模型</strong>负责从机器人动作和观测数据中学习环境动态的隐藏状态表示。它包含一个动态模型、一个编码器和一个解码器。动态模型采用分层结构，包含慢和快两种时间尺度的隐藏状态 <em>z_t = {z_t^s, z_t^f}<em>，每种状态又包含确定性状态 <em>d</em> 和随机性状态 <em>s</em>。慢动态的更新频率较低，用于捕捉任务的高级进展（如物体位置）；快动态更新频率高，捕捉瞬时信息。这是通过为慢层和快层的循环神经网络设置不同的时间常数来实现的。世界模型通过最小化变分自由能 <em>ℱ(t)</em> 进行训练，</em>ℱ(t)</em> 被分解为慢层和快层的自由能之和，并减去一个基于慢状态重建观测的辅助对数似然项。</p>
<p><img src="https://arxiv.org/html/2512.01924v1/x2.png" alt="世界模型结构"></p>
<blockquote>
<p><strong>图2</strong>：世界模型结构。它由动态模型、编码器和解码器组成。动态模型具有两个不同的时间尺度（慢和快）。</p>
</blockquote>
<p><strong>动作模型</strong>用于将连续的动作序列压缩为离散的抽象动作表示。它由一个编码器 <em>ℰ_ϕ</em>、一个包含 <em>N_q=2</em> 层的残差向量量化器 <em>𝒬_ϕ</em> 和一个解码器 <em>𝒟_ϕ</em> 组成。编码器将长度为 <em>h</em> 的动作序列 <em>a_{t:t+h}</em> 嵌入为低维特征 <em>A_t</em>，量化器将其映射为有限码本中的离散代码之和 <em>Â_t</em>，解码器再将 <em>Â_t</em> 重建为动作序列 <em>â_{t:t+h}<em>。</em>Â_t</em> 即被视为代表该动作序列的抽象动作。模型通过最小化重建损失和承诺损失进行训练。</p>
<p><strong>抽象世界模型</strong> <em>𝒲_ψ</em> 学习当前世界模型状态 <em>z_t</em> 与抽象动作 <em>A_t</em> 到未来慢确定性状态 <em>d_{t+h}^s</em> 的映射关系。它是一个多层感知机，输入为 <em>z_t</em> 和所有可能的抽象动作 *{Â_n}<em>{n=1}^{K^{N_q}}*，输出对应的未来慢确定性状态预测 *{d̂</em>{t+h,n}^s}*。其训练目标是最小化预测状态与通过世界模型“潜在想象”得到的目标状态之间的均方误差。</p>
<p>与现有方法相比，创新点具体体现在：1) 引入了时间分层的世界模型，以更好地建模环境中的多时间尺度动态；2) 通过动作模型将连续动作空间离散化为有限的抽象动作，极大地缩小了策略搜索空间；3) 利用抽象世界模型直接预测抽象动作的长期（慢尺度）后果，避免了在连续动作空间上进行耗时的迭代展开预测。</p>
<p><img src="https://arxiv.org/html/2512.01924v1/x3.png" alt="动作选择流程"></p>
<blockquote>
<p><strong>图3</strong>：基于最小化EFE的动作选择流程。首先，为多个抽象动作预测未来状态。然后，为每个预测的未来状态计算EFE。最后，机器人执行从产生最低EFE的抽象动作重建出的动作序列。</p>
</blockquote>
<p><strong>动作选择流程</strong>如图3所示。在每一步，给定当前状态 <em>z_t</em>，框架使用抽象世界模型为所有可能的抽象动作 <em>{Â_n}</em> 预测 <em>h</em> 步后的慢确定性状态 *{d_{t+h,n}^s}*。基于这些预测，通过蒙特卡洛采样近似计算每个抽象动作对应的期望自由能 <em>𝒢(τ)<em>。</em>𝒢(τ)</em> 包含鼓励减少不确定性的认知价值和鼓励接近目标的外在价值。最终，选择使 <em>𝒢(τ)</em> 最小的抽象动作，经动作模型解码后得到实际执行的动作序列。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在一个真实机器人操控环境中进行，使用了一个6自由度机械臂和摄像头。环境包含盘子、锅、平底锅、锅盖以及蓝色和红色小球，小球的存在和位置引入了不确定性。训练数据通过遥操作收集，包含了8种预定义策略模式（如将球从盘子移到锅中）的两两组合演示。</p>
<p><strong>对比的Baseline</strong>：在计算效率评估中，对比了传统的深度主动推理方法，该方法需要利用世界模型通过顺序输入重建出的动作序列来迭代预测未来状态。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>抽象世界模型能力</strong>：如图5所示，所提出的框架（Ours）预测未来状态的计算时间约为0.5毫秒，而传统方法（Sequential）需要约100毫秒，速度提升了约200倍。定性实验表明，抽象世界模型能够根据不同的抽象动作产生不同的状态预测，并且预测结果与实际执行相应动作序列后的观测结果一致。</li>
</ol>
<p><img src="https://arxiv.org/html/2512.01924v1/x5.png" alt="计算时间对比"></p>
<blockquote>
<p><strong>图5</strong>：使用所提框架（Ours）与使用世界模型顺序预测（Sequential）的计算时间比较。所提框架通过抽象世界模型进行单步预测，速度显著更快。</p>
</blockquote>
<ol start="2">
<li><p><strong>目标达成性能</strong>：在球操控任务（140次试验）和锅盖操控任务（24次试验）中评估成功率。如图6a所示，在球操控任务中，成功率高达98.6%。在锅盖操控任务中，当目标明确时（如“打开锅盖”），成功率也为100%。</p>
</li>
<li><p><strong>环境探索能力</strong>：在存在不确定性的任务中（例如，指令为“移动蓝球”，但蓝球可能被锅盖遮住），机器人能够表现出探索行为。如图6b所示，当初始状态锅盖关闭且蓝球位置未知时，机器人首先执行了“打开锅盖”的抽象动作，在确认蓝球存在后，再执行“移动蓝球”的动作，成功完成了任务。这证明了框架能够自主切换探索和目标导向行为。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2512.01924v1/x6.png" alt="实验结果"></p>
<blockquote>
<p><strong>图6</strong>：(a) 球操控任务的成功率。(b) 在不确定性环境下的探索行为示例：机器人首先执行打开锅盖的探索动作以确认球的位置，然后执行移动球的目标导向动作。</p>
</blockquote>
<p><strong>消融实验</strong>：论文进行了组件贡献分析。结果显示，完整框架在所有指标上表现最佳。移除抽象世界模型（即使用顺序预测）会导致计算成本剧增。而世界模型中的时间分层结构和基于慢状态的观测预测辅助任务，对于学习有意义的层次化状态表示至关重要。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出了一个集成时间分层世界模型、动作模型和抽象世界模型的深度主动推理新框架，有效提升了环境动态表征能力；2) 通过动作抽象和抽象世界模型，将连续动作空间中的策略评估转化为对有限离散选项的评估，使基于期望自由能的实时动作选择在真实机器人上变得计算可行；3) 在真实机器人物体操控任务上验证了该框架不仅能高效完成多样化的目标导向任务，还能在环境不确定性下自主产生探索行为。</p>
<p>论文提到的局限性包括：抽象动作是基于训练数据学习得到的离散集合，这可能限制了其灵活性，对于未在演示中出现过的长时程行为组合，可能无法很好地表示。</p>
<p>这项工作对后续研究的启示是：在构建用于复杂动态环境控制的模型时，显式地建模时间分层结构和进行动作/状态转移的抽象，是平衡模型表达能力、计算效率和智能体行为多样性（探索与利用）的有效途径。将高层抽象规划与低层连续控制相结合，是实现类人适应能力的关键方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文解决真实世界机器人控制中目标导向与探索性动作的平衡问题。提出了一种新的深度主动推理框架，其核心包括：1）世界模型，在快慢双时间尺度编码环境动态；2）动作模型，通过向量量化将动作序列压缩为抽象动作；3）抽象世界模型，基于抽象动作预测未来慢状态，以实现低成本动作选择。在真实机器人物体操作任务上的实验表明，该框架在多种任务中取得高成功率，能在不确定环境下切换目标与探索行为，并显著提升了动作选择的计算效率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.01924" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>