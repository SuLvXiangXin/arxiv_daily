<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>LiPS: Large-Scale Humanoid Robot Reinforcement Learning with Parallel-Series Structures - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>LiPS: Large-Scale Humanoid Robot Reinforcement Learning with Parallel-Series Structures</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2503.08349" target="_blank" rel="noreferrer">2503.08349</a></span>
        <span>作者: Zhang, Qiang, Han, Gang, Sun, Jingkai, Zhao, Wen, Cao, Jiahang, Wang, Jiaxu, Cheng, Hao, Zhang, Lingfeng, Guo, Yijie, Xu, Renjing</span>
        <span>日期: 2025/03/11</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，基于强化学习的人形机器人控制算法取得了重大进展。这类算法通常依赖于GPU的大规模并行计算能力，在仿真环境中进行大量并行训练。NVIDIA的IsaacGym是主流的训练平台之一，它利用URDF模型文件格式描述机器人。URDF因其简单易用、在ROS生态中广泛应用而成为首选。然而，URDF在描述并联结构（如人形机器人常见的并联踝关节）时，仅保留了几何特性，而忽略了其动态特性，导致仿真精度较低。为了在GPU上实现大规模并行训练，现有方法通常在训练阶段采用开环拓扑结构，将并联结构转换为串联结构，直到sim2real（从仿真到现实）阶段才转换回真实的并联结构。这种做法主要受限于当前GPU物理引擎对多刚体闭环拓扑的支持能力有限。这种“先开环训练，后并联转换”的方式引入了显著的sim2real差距，并增加了模型部署时的转换难度。</p>
<p>本文针对上述痛点，提出了一种新的训练方法LiPS。其核心思路是：在仿真训练环境中，通过多刚体动力学建模来精确描述人形机器人（特别是其并联踝关节）的动态行为，从而在训练阶段就采用真实的并联-串联混合结构，显著降低sim2real差距和部署时结构转换的难度。</p>
<h2 id="方法详解">方法详解</h2>
<p>LiPS方法的整体框架是在IsaacGym等支持大规模并行训练的仿真环境中，对使用URDF描述的机器人模型进行增强。其核心在于，不直接使用URDF中简化的、仅具几何意义的并联关节描述，而是通过一个额外的动力学建模模块，实时计算并联结构（以踝关节为例）的真实驱动关节状态。该模块的输入是策略网络输出的期望踝关节姿态（俯仰和横滚角），输出是驱动该并联踝关节的两个主动关节的角度、角速度和角加速度。这些计算出的驱动状态随后被送入物理引擎，用于计算下一时刻的机器人状态，从而形成一个闭环。</p>
<p><img src="https://arxiv.org/html/2503.08349v1/extracted/6270856/Figure/p2s.png" alt="方法框架"></p>
<blockquote>
<p><strong>图4</strong>：LiPS方法整体框架（Pipeline）。左侧展示了使用传统URDF描述时，并联踝关节在训练中被简化为一个虚拟的球关节，忽略了内部连杆动力学。右侧展示了LiPS方法：在训练循环中，策略网络输出期望的踝关节姿态后，通过一个并联结构逆解算模块（Parallel Structure Solver）计算出驱动电机所需的真实关节角度、速度和加速度，再送入物理引擎进行仿真。这使训练直接在真实的并联-串联混合结构上进行。</p>
</blockquote>
<p>核心模块是并联踝关节的局部运动学与动力学建模。如图3所示，作者对闭环连杆并联踝关节进行了详细分析。给定脚板相对于小腿的期望姿态χ = [φ, θ]^T，通过运动学逆解可以计算出两个主动驱动臂的关节角度q1和q2。具体推导基于向量环方法，公式(1)-(7)描述了从末端姿态到驱动角度的映射关系，并需满足杆长和关节旋转范围的约束条件(8)。</p>
<p><img src="https://arxiv.org/html/2503.08349v1/extracted/6270856/Figure/IK.png" alt="踝关节建模示意图"></p>
<blockquote>
<p><strong>图3</strong>：并联踝关节动力学建模示意图。展示了小腿坐标系、脚板、两个主动驱动臂（长度L1）以及被动连杆（长度L2）的几何关系。通过已知的脚板末端姿态（φ, θ），可以逆向求解出两个驱动关节的角度q1和q2。</p>
</blockquote>
<p>在此基础上，进一步进行了速度和加速度的逆解分析。根据脚板末端的速度χ̇ = [φ̇, θ̇]^T和加速度χ̈ = [φ̈, θ̈]^T，利用公式(9)及后续推导，可以计算出驱动关节的角速度q̇1, q̇2和角加速度q̈1, q̈2。这些完整的动力学信息被用于仿真中的状态更新。</p>
<p>与现有方法相比，LiPS的核心创新点在于将精确的并联结构多刚体动力学建模直接嵌入到大规模并行强化学习训练流程中。它没有改变URDF的模型描述文件本身，而是通过一个外部求解器在仿真运行时动态地、精确地计算并联结构的真实动态响应，从而让策略网络在训练阶段就在与实物高度一致的动力学模型上进行学习，省去了后续复杂的结构转换步骤。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在NVIDIA IsaacGym仿真平台中进行，使用自定义构建的、具有复杂并联踝关节的人形机器人模型。训练任务为在平坦地形上学习稳健的行走步态。</p>
<p><strong>对比方法</strong>：主要的对比基线（Baseline）是使用标准URDF描述的传统方法，该方法在训练时将并联踝关节简化为一个虚拟的球关节（忽略内部连杆动力学）。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>训练性能与收敛速度</strong>：LiPS方法在训练成功率和收敛速度上均显著优于URDF基线。具体而言，LiPS达到了98.8%的训练成功率，而URDF基线仅为73.8%。LiPS方法收敛所需的训练时长也更短。</li>
</ol>
<p><img src="https://arxiv.org/html/2503.08349v1/extracted/6270856/Figure/fig10.png" alt="训练曲线对比"></p>
<blockquote>
<p><strong>图5</strong>：训练曲线对比图。（a）图显示LiPS方法（蓝线）的平均奖励随训练时长增长更快、最终值更高。（b）图显示LiPS的成功率（蓝线）最终稳定在接近100%，远高于URDF基线（橙线）。</p>
</blockquote>
<ol start="2">
<li><strong>Sim2Real迁移性能</strong>：将仿真中训练好的策略直接部署到物理机器人上。LiPS方法表现出更优越的sim2real迁移能力。使用URDF基线策略的机器人在真实行走中出现明显的步态不稳定和身体抖动；而使用LiPS策略的机器人步态更加平稳、自然，身体抖动显著减小，展示了更小的sim2real差距。</li>
</ol>
<p><img src="https://arxiv.org/html/2503.08349v1/extracted/6270856/Figure/para.png" alt="Sim2Real对比"></p>
<blockquote>
<p><strong>图6</strong>：Sim2Real迁移定性结果对比。上图是使用传统URDF方法训练后部署的机器人行走序列，可见明显的身体晃动和不稳定。下图是使用LiPS方法训练后部署的机器人行走序列，步态明显更稳定、流畅。</p>
</blockquote>
<p><strong>消融实验</strong>：论文通过实验验证了在训练中提供完整的动力学信息（位置、速度、加速度逆解）的重要性。仅使用位置逆解（即只提供关节角度）而不提供速度和加速度信息，会导致训练收敛变慢，且最终策略在sim2real时的稳健性下降。这表明精确的动力学建模对于学习高质量、可迁移的策略至关重要。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：</p>
<ol>
<li><strong>提出了LiPS训练方法</strong>：首次在大规模GPU并行强化学习训练中，成功集成了对复杂并联结构（以踝关节为例）的多刚体动力学精确建模，显著降低了使用URDF描述的人形机器人的sim2real差距和部署难度。</li>
<li><strong>提升了训练与部署效率</strong>：该方法不仅提高了仿真训练的成功率和收敛速度，而且由于训练模型与实物动力学一致，减少了部署时的计算负载和调整误差，提升了真实机器人的推理效率和运动性能。</li>
<li><strong>提供了可泛化的工具</strong>：LiPS方法不依赖于特定机器人模型，可以方便地迁移到其他采用URDF描述且包含并联结构的机器人上，为整个机器人社区进行复杂机器人的大规模强化学习训练提供了一个有效工具。</li>
</ol>
<p><strong>局限性</strong>：论文自身未明确阐述局限性，但基于方法描述，潜在的局限性可能包括：该方法需要对目标并联结构进行精确的动力学建模和逆解推导，对于极度复杂或新型的并联机构，建模复杂度会增加；此外，实时计算逆解可能带来轻微的计算开销，尽管在GPU并行环境下影响相对较小。</p>
<p><strong>对后续研究的启示</strong>：LiPS工作表明，将领域知识（如精确的机构动力学模型）与数据驱动的强化学习相结合，是解决sim2real难题的有效途径。这启发后续研究可以探索将更多真实世界的物理约束（如摩擦、柔性、执行器动力学等）以可计算的方式嵌入到并行训练框架中。此外，该方法为设计更复杂、高性能的仿生机器人机构提供了支持，因为可以在训练阶段就充分考虑并利用其复杂的力学特性。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人强化学习（RL）训练中，因物理引擎限制而被迫采用开环拓扑进行仿真训练，导致与实际机器人串并联结构存在“仿真到现实”（sim2real）差距的核心问题。提出了一种名为LiPS的新训练方法，其关键技术在于在仿真环境中融入多刚体动力学建模，以直接支持闭环拓扑的大规模并行训练。该方法旨在显著减小sim2real差距，并降低模型部署时向并联结构转换的难度。正文节选未提供具体的实验结论或性能提升数据。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2503.08349" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>