<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Learning Human-Like Badminton Skills for Humanoid Robots - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Learning Human-Like Badminton Skills for Humanoid Robots</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.08370" target="_blank" rel="noreferrer">2602.08370</a></span>
        <span>作者: Chen, Yeke, Dong, Shihao, Ji, Xiaoyu, Sun, Jingkai, Luo, Zeren, Zhao, Liu, Zhang, Jiahui, Li, Wanyue, Ma, Ji, Xu, Bowen, Han, Yimin, Zhao, Yudong, Lu, Peng</span>
        <span>日期: 2026/02/09</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，人形机器人领域在实现类人运动模仿方面已取得显著进展，例如通过基于跟踪的奖励或对抗运动先验（AMP）来复现复杂的运动技能。然而，这些方法主要侧重于运动学层面的模仿，与实现功能性的、物理感知的动态交互之间存在鸿沟。具体到羽毛球等高要求运动，现有方法面临三大局限：1）能够模仿类人运动，但缺乏与微小物体的精确交互能力；2）能够实现精确交互，但通常仅关注上肢灵巧性，缺乏全身爆发性协调；3）部分研究仅在仿真中验证了类人空中球类运动，但未在物理机器人形态上验证或实现向真实硬件的迁移。因此，在要求精确时机、准确性和敏捷性的羽毛球等运动中，实现多功能且类人的性能仍然是一个巨大的挑战。</p>
<p>本文针对“如何弥合运动学模仿与动态交互之间的差距”这一具体痛点，提出了“模仿到交互”的新视角。其核心思路是通过一个渐进式的四阶段强化学习框架，首先从人类数据中建立鲁棒的运动先验，然后将其提炼为基于模型的状态表示，并通过对抗先验稳定动力学，最终通过流形扩展策略将稀疏的专家演示泛化至密集的交互空间，从而将机器人从“模仿者”逐步演变为功能性的“击球手”。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的框架旨在通过渐进式的四阶段流程，使人形机器人掌握高动态的羽毛球技能。</p>
<p><img src="https://arxiv.org/html/2602.08370v1/figures_origin/pipeline.png" alt="方法框架总览"></p>
<blockquote>
<p><strong>图2</strong>：框架概述。流程通过四个阶段逐步将运动学模仿者转变为动态击球手：（阶段1）模仿：教师策略学习使用本体感知（蓝色）和模仿目标（绿色）观测来鲁棒地跟踪来自动捕数据的人类运动。（阶段2）蒸馏：通过DAgger将教师的能力提炼到学生策略中。学生策略在由本体感知、任务目标（黄色：目标击球/恢复状态）和击球时间（红色）组成的简化观测空间上运行，移除了对未来运动轨迹的依赖。（阶段3）稳定化：使用带有AMP判别器的RL对学生策略进行微调，以强制风格合理性（风格奖励），同时最小化跟踪误差，稳定运动防止漂移。（阶段4）交互：在最终的物理交互环境中，策略通过模拟羽毛球动力学进行精炼，泛化至密集的时空流形以实现精确、敏捷的击球。</p>
</blockquote>
<p><strong>第一阶段：运动学运动先验学习（教师）</strong>。此阶段目标是从动捕数据中学习一个鲁棒的教师策略。其观察空间包括本体感知、特权信息（如基座高度、速度、脚部接触状态）以及跟踪信息（未来H步内的根状态和关节角与当前状态的差值）。奖励函数由跟踪奖励和正则化奖励构成，其中跟踪奖励细分为根状态、关节角度、末端执行器（包括手、球拍、脚）姿态以及脚部接触节奏的跟踪。为提高鲁棒性，训练时采用了重度域随机化和随机外力扰动。训练后，教师策略被用于生成物理上可行的参考轨迹，并进一步微调以提高轨迹精度。</p>
<p><strong>第二阶段：目标条件蒸馏（学生）</strong>。此阶段将控制策略从纯跟踪转向面向任务的执行。使用DAgger将教师知识提炼到学生策略中。核心创新在于设计了一个基于模型的目标条件状态表示，包括：1）<strong>击球时间</strong>：指示距离击球时刻的剩余时间，用于划分准备阶段（TTH&gt;0）和恢复阶段（TTH&lt;0）；2）<strong>目标击球/恢复状态</strong>：当前状态与击球时刻或恢复时刻目标状态（球拍或根位姿）的相对差异。为处理组合状态空间巨大带来的分布外问题，采用了TTH裁剪至[-2,2]秒以及阶段依赖的掩码策略（准备阶段掩码恢复目标，恢复阶段掩码击球目标）。奖励函数也相应调整为阶段特异性：准备阶段鼓励准确跟踪球拍轨迹，并施加基于击球时间的指数衰减权重以强调接近击球的时刻；恢复阶段则专注于跟踪根位姿，无时间衰减。</p>
<p><strong>第三阶段：基于RL的运动稳定化</strong>。蒸馏阶段以全局姿态模仿为主，可能导致球拍跟踪精度次优。此阶段引入纯试错优化，利用对抗运动先验来将重点转向高精度球拍跟踪，同时保持运动风格。引入一个判别器网络来区分智能体生成的状态转移和真实运动数据。总奖励是任务奖励（沿用第二阶段的公式）和风格奖励的加权组合，风格奖励基于判别器输出，鼓励智能体生成与人类数据风格一致的运动。</p>
<p><strong>第四阶段：交互驱动精炼</strong>。此阶段引入羽毛球的物理模拟，使策略能与模拟的球互动，基于真实反馈精炼控制。<br><img src="https://arxiv.org/html/2602.08370v1/figures_origin/hits2.png" alt="击球目标流形扩展"></p>
<blockquote>
<p><strong>图3</strong>：击球目标的流形扩展。散点表示原始动捕数据集中离散的击球位置，颜色根据相对于机器人初始姿态的击球时间编码（蓝色时间短，红色时间长）。半透明的青色体积展示了通过交互驱动精炼阶段实现的扩展后的连续击球流形。该方法使机器人能够从这些稀疏的人类演示泛化到跨越不同时间范围的、密集的、可到达目标的体积区域。</p>
</blockquote>
<p>关键创新是<strong>流形扩展</strong>：由于原始动捕数据中击球点稀疏，通过预生成大量不同拦截高度和时间的羽毛球轨迹，围绕原始数据样本选择击球点，将离散点扩展为一个密集、近乎连续的可达目标流形。奖励设计也相应调整：击球跟踪奖励中的时间衰减权重被替换为仅在击球瞬间附近狭窄时间窗口内激活的稀疏指示函数，因为只有击球点是确切已知的。此外，引入了基于球被击打后行为的物理信息奖励，鼓励球落在对手场内并惩罚软弱回球。同时，通过随机化发球与下一次击球间的时间间隔（1-6秒），增强策略对不同节奏模式的适应性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：训练在NVIDIA Isaac Sim仿真环境中进行，物理引擎运行频率200Hz，策略运行频率50Hz。真实世界评估使用EngineAI PM01人形机器人，并采用光学动捕系统获取机器人和羽毛球的位姿信息，通过扩展卡尔曼滤波器估计球的状态并预测最佳击球点。训练中应用了广泛的域随机化以促进零样本仿真到现实的迁移。</p>
<p><strong>学习到的技能</strong>：在仿真中，无需修改核心流程，即成功训练人形机器人掌握了多种羽毛球技能，包括正手挑球、反手挑球和吊球。<br><img src="https://arxiv.org/html/2602.08370v1/figures_origin/sim_hits3.png" alt="多样化的羽毛球技能"></p>
<blockquote>
<p><strong>图4</strong>：通过所提框架学习到的多样化羽毛球技能。演示人形机器人掌握的不同击球技术的延时序列。(a) 反手挑球：机器人旋转躯干以产生“鞭打”力量进行交叉回球。(b) 正手挑球：机器人执行延伸弓步以触及远处目标并快速恢复平衡。(c) 吊球：机器人执行带有自然惯性随挥的过头顶击球。粉色圆点可视化羽毛球的历史轨迹。</p>
</blockquote>
<p><strong>真实世界部署</strong>：实现了人形机器人全身羽毛球技能的首次零样本仿真到现实迁移。<br><img src="https://arxiv.org/html/2602.08370v1/figures_origin/head2-3.png" alt="真实世界系统部署"></p>
<blockquote>
<p><strong>图1</strong>：系统的真实世界部署。我们提出了一个基于学习的框架，使人形机器人能够使用球拍进行敏捷的羽毛球拦截。快照展示了两种基本技能的零样本仿真到现实迁移：(a, b) 正手挑球和 (c, d) 反手挑球。蓝色圆圈高亮了球拍与羽毛球成功接触的时刻。尽管运动复杂，我们的策略在物理硬件上保持了鲁棒的平衡和跟踪精度。</p>
</blockquote>
<p><strong>关键结果</strong>：论文通过真实世界的快照（图1）和仿真中的技能展示（图4）定性验证了方法的有效性。机器人能够执行需要全身协调的敏捷击球动作，如反手挑球中的躯干旋转“鞭打”、正手挑球中的延伸弓步及快速平衡恢复，并在物理硬件上保持了鲁棒的平衡和跟踪精度，成功复制了人类运动员的动力优雅性和功能精确性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：1）提出了一个渐进式的“模仿到交互”学习框架，有效弥合了运动学模仿与动态交互之间的鸿沟，能够合成协调与风格上独具类人特点的敏捷、高速运动。2）设计了一种能保留人类数据中运动先验的专用状态表示（击球时间、目标击球/恢复状态），确保了从运动学跟踪到物理感知击球的稳定过渡。3）首次实现了全身羽毛球技能向人形机器人的零样本仿真到现实迁移，在物理世界中展示了鲁棒的击球能力和风格真实性。</p>
<p>论文自身提到的局限性包括：依赖高质量的人类运动捕捉数据，数据稀疏性可能限制技能多样性；机器人形态与人类形态的差异需要通过复杂的运动重定向来弥补。</p>
<p>这项工作对后续研究的启示在于：为机器人学习复杂动态交互任务提供了一条从模仿先验到物理精炼的可循路径；其基于模型的目标状态表示和流形扩展策略为解决稀疏演示下的泛化问题提供了新思路；成功的零样本迁移表明，通过精心设计的仿真训练和域随机化，将高度动态的全身技能部署到真实机器人上是可行的，鼓励在更复杂的运动场景中进行探索。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人难以在羽毛球等高要求运动中实现兼具功能性与人类风格自然流畅表现的核心问题，提出“模仿到交互”的渐进式强化学习框架。该方法从人类数据建立运动先验，提炼为紧凑的模型化状态表示，并通过对抗先验稳定动力学；为克服专家数据稀疏性，引入流形扩展策略将离散击球点泛化为密集交互空间。实验表明，该框架使机器人掌握了包括高远球、吊球在内的多种技能，并首次实现了人形机器人羽毛球技能的零仿真到现实迁移，在物理硬件上成功复现了人类运动员的动感优雅与击球精度。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.08370" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>