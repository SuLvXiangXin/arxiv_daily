<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.11498" target="_blank" rel="noreferrer">2507.11498</a></span>
        <span>作者: Shahid, Asad Ali, Braghin, Francesco, Roveda, Loris</span>
        <span>日期: 2025/07/15</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前人形机器人控制的主流方法是基于运动模仿的学习范式，策略被训练以复现来自人类动作捕捉数据或视频的重新定位参考轨迹。这类方法在获取移动操作技能方面表现出色，但它们受限于数据集中的演示动作，主要优化几秒钟的短时间视野，并且缺乏发现新颖、时间精确的接触序列的显式目标。在机器人音乐演奏领域，强化学习已被应用于类人灵巧手弹钢琴以及简化欠驱动双自由度击鼓臂，但尚未有研究探索如何应用强化学习来自主协调人形机器人的全身进行鼓乐演奏。</p>
<p>本文针对人形机器人执行鼓乐演奏这一过程驱动、长时程且对时序精度要求极高的具体痛点，提出了将鼓乐演奏重新表述为<strong>时序接触链的连续履行</strong>的新视角。核心思路是：将鼓谱转化为节奏接触链，并将长时程乐曲分解为固定长度的片段，使用单一策略并行训练所有片段，通过密集的接触事件奖励引导策略学习精确的节奏行为。</p>
<h2 id="方法详解">方法详解</h2>
<p>整体框架（Pipeline）从原始MIDI鼓轨开始，首先将每个音符起始映射到特定鼓，然后转换为一系列定时的“接触事件”，形成<strong>节奏接触链</strong>。该链被分割成固定长度的片段，每个片段对应歌曲的不同部分，用于并行训练。在每个时间步，智能体的状态结合了未来的L个接触目标、机器人的本体感知以及空间上下文（鼓槌和鼓的位置）。策略输出关节位置目标给比例-微分控制器以生成扭矩。</p>
<p><img src="https://arxiv.org/html/2507.11498v2/extracted/6627388/figures/main.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：Robot Drummer方法整体框架。左侧为原始MIDI鼓轨；顶部中心展示了MIDI音符到接触事件的映射，形成节奏接触链；底部中心展示了将接触链分割为固定长度片段用于并行训练；右侧展示了状态输入（接触目标、本体感知、空间信息）、策略网络和PD控制器的流程。</p>
</blockquote>
<p><strong>核心模块与技术细节：</strong></p>
<ol>
<li><strong>音乐表示与节奏接触链</strong>：使用MIDI作为音乐表示，提取鼓通道上的“音符开启”事件，并将每个唯一的MIDI音符音高映射到物理鼓（见图1配置）。随后，将鼓轨转换为<strong>节奏接触链</strong>，定义为𝒞 = {C₁, C₂, …, C_N}，其中每个接触步骤C_i = (D_i, t_i, S_i) 包含了在时间t_i需要击打的鼓组D_i、以及可用于执行接触的鼓槌S_i（左、右或两者）。这为策略提供了明确的时空目标。</li>
</ol>
<p><img src="https://arxiv.org/html/2507.11498v2/extracted/6627388/figures/drum_kit.png" alt="鼓组配置"></p>
<blockquote>
<p><strong>图1</strong>：用于训练和评估人形机器人鼓手的鼓组配置。包括一个军鼓、两个通通鼓、一个踩镲和两个吊镲。每个鼓被分配一个唯一的MIDI音符，建立了固定的音符-鼓映射。</p>
</blockquote>
<ol start="2">
<li><p><strong>时间分解</strong>：为解决长时程（数分钟）任务带来的奖励稀疏和探索困难问题，将完整的节奏接触链𝒞分割成M个固定长度的段𝒞^(m)，每段包含P = N/M个接触步骤。这使得单一长时程任务被转化为多个较短的并行训练段，显著提高了样本效率。</p>
</li>
<li><p><strong>策略训练与状态/动作设计</strong>：采用近端策略优化算法训练策略。状态s_t由三部分组成：本体感知（关节位置、速度、上一时刻动作）、空间信息（鼓和鼓槌的位置）以及<strong>接触目标</strong>（未来L步内目标击打鼓的一热编码）。动作a_t是15个关节的目标角度，通过PD控制器（公式4）转换为关节扭矩。接触目标状态作为离散的相位标记，告知策略在当前音乐时刻应该瞄准“哪个”鼓，提供了节奏进展的隐含目标信号。</p>
</li>
<li><p><strong>密集接触奖励函数</strong>：奖励设计基于一个核心假设：每个接触事件（正确、错误或错过）都为学习精细时序和协调提供了关键信息。总奖励r_t = r_t^contact + r_t^reg。接触奖励r_t^contact进一步分解为：正确击打奖励(+1.0)、错误击打惩罚(-0.5)、错过击打惩罚(-2.0)以及接近目标奖励（鼓励鼓槌在预期击打时刻靠近目标鼓）。正则化奖励包括动作变化率和关节加速度惩罚。</p>
</li>
</ol>
<p><strong>创新点</strong>：与现有运动模仿方法或简化击鼓臂的RL方法相比，本文的创新具体体现在：1) 提出了“节奏接触链”这一通用任务表述，将鼓乐明确为时序接触履行问题；2) 设计了<strong>时间分解</strong>策略，有效处理音乐表演的长时程特性；3) 设计了<strong>密集的、基于接触事件的奖励函数</strong>，将每个击打事件都转化为学习信号，直接优化节奏精度。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在超过三十首流行的摇滚、金属和爵士曲目上进行评估，使用F1分数（精确率和召回率的调和平均）作为主要指标，衡量节奏精度。对比的基线方法包括<strong>运动模仿</strong>方法，该方法使用与本文相同的状态和动作空间，但奖励函数改为跟踪从人类演示数据重新定位的关节轨迹。</p>
<p>关键实验结果：Robot Drummer在测试曲目上取得了平均0.89的高F1分数，即使在最具挑战性的曲目上（如林肯公园的《In the End》）也达到了0.83。相比之下，运动模仿基线的平均F1分数仅为0.21，表明其无法适应未见过的新节奏模式。</p>
<p><img src="https://arxiv.org/html/2507.11498v2/extracted/6627388/figures/metrics_f1score.png" alt="F1分数结果"></p>
<blockquote>
<p><strong>图4</strong>：Robot Drummer（蓝色）与运动模仿基线（橙色）在不同歌曲上的F1分数对比。Robot Drummer在所有歌曲上均显著优于基线，展示了其高超的节奏精度。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.11498v2/extracted/6627388/figures/traj_1.png" alt="鼓槌轨迹"><br><img src="https://arxiv.org/html/2507.11498v2/extracted/6627388/figures/traj_2.png" alt="鼓槌轨迹2"></p>
<blockquote>
<p><strong>图6与图7</strong>：学习到的鼓槌末端执行器轨迹（右槌）在三维空间中的可视化。轨迹展示了复杂、非线性的运动模式，这是为了精确命中分布在空间中的不同鼓而自发形成的，而非模仿人类数据。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.11498v2/extracted/6627388/figures/rox_lithium_comp.png" alt="与运动模仿对比"></p>
<blockquote>
<p><strong>图8</strong>：Robot Drummer策略（上）与运动模仿策略（下）在执行同一复杂节奏填充段时的定性对比。运动模仿策略的击打严重偏离节奏（红色叉号表示错过或错误击打），而Robot Drummer策略能精确命中目标。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.11498v2/extracted/6627388/figures/generalist.png" alt="泛化能力"></p>
<blockquote>
<p><strong>图9</strong>：单一通用策略（在所有训练歌曲上训练）与为每首歌曲单独训练的策略在未见过的歌曲上的F1分数对比。通用策略取得了有竞争力的性能（平均0.85），证明了方法的泛化能力。</p>
</blockquote>
<p><strong>消融实验总结</strong>：论文通过消融实验验证了关键组件的贡献。1) <strong>移除接触目标状态</strong>（用连续时间相位替代）：导致F1分数从0.89大幅下降至0.31，证明接触目标作为离散节奏相位至关重要。2) <strong>移除时间分解</strong>（在整个歌曲上训练）：导致训练不稳定且无法收敛，证明了分解对处理长时程任务的必要性。3) <strong>使用稀疏奖励（仅终局奖励）</strong>：策略完全无法学习，凸显了密集接触奖励设计的关键作用。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1) 提出了一个用于人形机器人鼓乐的通用强化学习框架，其核心是<strong>节奏接触链</strong>的任务表述和<strong>时间分解</strong>训练策略。2) 设计了<strong>密集的接触事件奖励函数</strong>，使策略能从每个击打事件中学习，从而掌握高精度时序和协调。3) 首次展示了强化学习能够训练人形机器人全身执行复杂、长时程的鼓乐曲目，并涌现出<strong>跨臂击打、自适应鼓槌分配</strong>等类人策略。</p>
<p><strong>局限性</strong>：论文自身提到，当前框架1) 未建模击打力度（MIDI速度），这影响了音乐表达的动态范围；2) 为简化，同一鼓的多种演奏法（如开/闭踩镲）仅使用了最常见的一种，丢弃了部分表达变化；3) 工作仅在仿真中进行，存在模拟到现实的差距。</p>
<p><strong>对后续研究的启示</strong>：1) 将击打力度控制纳入框架，以增强音乐表现力。2) 扩展以处理同一乐器的多种演奏法。3) 将方法迁移到真实人形机器人平台，解决实际部署中的感知、状态估计和控制问题。这项工作为将人形机器人应用于其他需要长时程、精确时序和身体协调的创造性、过程驱动任务开辟了新途径。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文旨在解决人形机器人实现富有表现力的高精度打鼓这一挑战，其核心是处理音乐表演这一过程驱动任务所要求的毫秒级时序、快速接触与多肢体协调。关键技术是将鼓谱转化为“节奏接触链”，并将长时程乐曲分解为片段，通过强化学习并行训练单一策略。实验在超过三十首曲目上进行，结果表明，机器人鼓手能持续获得高F1分数，并涌现出交叉手臂击打等类人策略。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.11498" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>