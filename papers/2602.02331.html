<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>TTT-Parkour: Rapid Test-Time Training for Perceptive Robot Parkour - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>TTT-Parkour: Rapid Test-Time Training for Perceptive Robot Parkour</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.02331" target="_blank" rel="noreferrer">2602.02331</a></span>
        <span>作者: Zhu, Shaoting, Ye, Baijun, Wang, Jiaxuan, Chen, Jiakang, Zhuang, Ziwen, Mou, Linzhan, Huang, Runhan, Zhao, Hang</span>
        <span>日期: 2026/02/02</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，基于深度强化学习的大规模并行仿真训练与仿真到现实（sim-to-real）迁移技术，已使双足机器人能够在非结构化地形上移动。主流方法通常在程序生成（procedurally generated）的多样化地形上预训练一个通用策略。然而，这类方法存在关键局限性：由简单几何基元合成的仿真地形无法覆盖真实世界中复杂多变的地形类型与空间布局，导致策略在部署时面临分布外（out-of-distribution）问题，难以应对具有任意性和高度挑战性的未知障碍。同时，为快速适应新地形，需要将真实场景高效、高保真地重建为仿真可用的网格，现有方法（如NeRF、3DGS等每场景优化方法）计算密集、流程缓慢，而前馈式或生成式方法又存在尺度模糊或几何失真问题，无法满足快速测试时训练（Test-Time Training, TTT）的需求。</p>
<p>本文针对机器人面对未知、复杂地形（如楔形块、桩、箱体、梯形、窄梁）时泛化能力不足的痛点，提出了一个“真实-仿真-真实”（real-to-sim-to-real）的新视角，通过在新地形上进行快速测试时训练来显著增强机器人的穿越能力。本文的核心思路是采用两阶段端到端学习范式：首先在多样化程序生成地形上预训练一个通用策略，随后利用从真实场景重建的高保真网格，对该策略进行快速微调。</p>
<h2 id="方法详解">方法详解</h2>
<p>TTT-Parkour框架包含三个阶段：预训练、测试时训练和仿真到现实部署。</p>
<p><img src="https://arxiv.org/html/2602.02331v1/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：TTT-Parkour框架总览。包含三个阶段：(1) 预训练：在多样化程序生成地形上预训练通用策略，学习鲁棒的运动基元。(2) 测试时训练：利用带自动尺度恢复和坐标系对齐的前馈式重建，从真实世界捕获数据中重建高保真、仿真就绪的网格，然后在仿真中针对特定地形快速微调策略。(3) 仿真到现实部署：将适配后的策略零样本部署到真实机器人上，穿越复杂的未知障碍。</p>
</blockquote>
<p><strong>1. 策略预训练：</strong><br>将感知运动任务构建为强化学习问题，使用近端策略优化（PPO）进行优化。策略采用基于CNN的深度编码器提取潜在特征，与本体感知信息拼接后输入MLP预测动作。</p>
<ul>
<li><strong>观察空间</strong>：演员（actor）的观察包括本体感知历史序列和深度图像历史序列。本体感知包括基座角速度、投影重力向量、速度指令、关节位置与速度、上一时刻动作。为处理部分可观测性，使用长度为 <code>h=8</code> 的历史滑动窗口。深度图像采用跨步采样以获得长时序信息。评论员（critic）则使用无噪声的特权信息（包括基座线速度）进行引导。</li>
<li><strong>动作</strong>：策略输出目标关节位置，通过PD控制器转换为关节扭矩。</li>
<li><strong>终止条件</strong>：包括机器人卡在起点超过4秒、任何身体连杆接触地面、基座姿态超出阈值。</li>
<li><strong>奖励函数</strong>：由任务奖励（密集的速度跟踪奖励）、正则化奖励（惩罚落脚在边缘、能量消耗、动作变化率）、安全奖励（强制执行关节限位）以及对抗性运动先验（AMP）奖励组成，以鼓励自然鲁棒的运动风格。</li>
</ul>
<p><strong>2. 高效几何重建：</strong><br>为实现快速测试时训练，论文提出了一个集成前馈重建、自动尺度恢复和坐标系对齐的高效自动化重建流程。</p>
<p><img src="https://arxiv.org/html/2602.02331v1/x3.png" alt="重建流程"></p>
<blockquote>
<p><strong>图3</strong>：高效几何重建流程。包含四个阶段：(1) 真实世界捕获。(2) 前馈重建：从RGB序列提供初始场景几何。(3) 尺度恢复：通过将推断深度与传感器深度对齐来校正度量尺度差异。(4) 物理一致的坐标系对齐：利用3D语义分割，将地形z轴与重力对齐，x轴与穿越方向对齐，注册到仿真坐标系。</p>
</blockquote>
<ul>
<li><strong>前馈地形重建</strong>：使用前馈模型处理RGB序列，重建一个尺度模糊的点云，然后应用筛选泊松表面重建得到网格。</li>
<li><strong>尺度恢复</strong>：由于纯RGB或度量前馈方法在某些地形上预测的绝对尺度不可靠，论文通过将前馈模型预测的深度与RGB-D相机提供的度量深度进行对齐来计算缩放因子。具体是计算深度图像下半部分中值深度的比率，以聚焦于地形并减轻远处背景异常值的干扰。</li>
<li><strong>坐标系对齐</strong>：目标是将地形注册到一个物理一致的世界坐标系中，其中原点锚定在起点平台质心，z轴与重力对齐，x轴与预期的穿越方向对齐。首先使用3D分割模型提取语义标记为地面的点，通过RANSAC和PCA鲁棒地估计地面法向量 <code>n</code>，旋转场景使 <code>n</code> 与仿真z轴对齐。然后，基于分割得到的起点和终点平台质心，计算连接向量，并绕z轴旋转场景使该向量与仿真的x轴对齐。</li>
</ul>
<p><strong>3. 策略快速测试时训练：</strong><br>在预训练后，利用重建的网格在特定目标地形上进行快速测试时训练。保持与预训练相同的MDP公式（观察、动作、终止条件、奖励）。论文研究并比较了四种微调策略：<br>(1) <strong>完全微调</strong>：从预训练检查点开始，端到端更新策略网络所有参数。<br>(2) <strong>适配器模块</strong>：在深度编码器和MLP的每一层后插入轻量级适配器，冻结原始权重，仅优化适配器。适配器输出零初始化以在开始时保留原始特征调制。<br>(3) <strong>残差学习</strong>：添加一个并行网络学习加性的动作校正，基础策略冻结，残差输出层零初始化。<br>(4) <strong>最后一层微调</strong>：冻结深度编码器和中间MLP层，仅更新演员策略的最后一层线性层。</p>
<p><strong>创新点</strong>：与现有方法相比，本文的创新具体体现在：1) 提出了一个集成了快速、高保真场景重建的两阶段（预训练+测试时训练）感知运动学习范式；2) 设计了一个结合前馈重建、自动尺度恢复和坐标系对齐的高效重建流程，专为满足测试时训练的速度和精度要求而定制。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验配置</strong>：</p>
<ul>
<li><strong>仿真平台</strong>：IsaacLab (IsaacSim)，使用NVIDIA RTX 5090 GPU，并行4096个机器人智能体。</li>
<li><strong>机器人</strong>：Unitree G1 (29自由度)。</li>
<li><strong>感知</strong>：部署时使用Intel RealSense D435i相机，深度图像处理为32×18的中心底部区域。</li>
<li><strong>测试地形</strong>：五大类13种具体地形，包括楔形块、桩、箱体、梯形、窄梁及其混合变体。预训练使用程序生成地形并采用课程学习策略逐步增加难度。</li>
<li><strong>评估指标</strong>：成功率（成功从起点平台穿越至终点平台且未接触地面或摔倒）。仿真中每个地形进行1000次试验，真实世界进行5次试验。</li>
<li><strong>对比基线</strong>：预训练策略（Pre-train）、从零开始在单个地形训练的策略（Scratch-1）、同时在所有13个地形上微调的策略（TTT-13）、在单个地形上微调的TTT-1策略（本文主要方法）。</li>
</ul>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>测试时训练的必要性与效率</strong>：仿真实验结果（表I）表明，预训练策略在多数极具挑战的地形上成功率极低（如楔形块0.1%，梯形1为0%，桩1为4.4%），显示出有限的零样本泛化能力。而从零开始训练（Scratch-1）在大多数地形上完全失败（成功率0%），证明了大规模预训练课程策略的必要性。本文的TTT-1策略经过微调后，在几乎所有地形上都达到了接近100%的成功率。同时训练所有地形的TTT-13策略性能略逊于TTT-1。</li>
</ol>
<p><img src="https://arxiv.org/html/2602.02331v1/x5.png" alt="训练迭代成功率"></p>
<blockquote>
<p><strong>图5</strong>：测试时训练（TTT-1）迭代过程中的成功率变化。策略在先前未见的地形上迅速收敛至高性能，大多数地形在120次迭代内达到高成功率，对应总适应时间约10分钟。</p>
</blockquote>
<ol start="2">
<li><strong>真实世界性能</strong>：真实世界部署结果（图6）显示，预训练策略在多数复杂障碍上完全失败（成功率0%），而TTT-Parkour显著提升了性能，在箱体和楔形块上达到100%成功率，在其他地形上也将成功率从接近零提升至60%以上。这验证了框架的有效性，但真实世界成功率略低于仿真，归因于硬件不稳定性、地形晃动等未建模动态以及重建误差。</li>
</ol>
<p><img src="https://arxiv.org/html/2602.02331v1/figures/success_real.png" alt="真实世界成功率"></p>
<blockquote>
<p><strong>图6</strong>：预训练策略与TTT-1策略在真实世界的成功率对比。TTT-Parkour显著提升了机器人在复杂未知地形上的穿越能力。</p>
</blockquote>
<ol start="3">
<li><strong>重建质量与速度分析</strong>：论文比较了不同数据源（RGB-D、LiDAR、iPhone扫描、手工制作）的重建效果（图7、表II、III）。RGB-D输入在质量、效率和尺度准确性上取得了最佳平衡，重建时间约2分钟，绝对相对尺度误差极低（桩1为0.002，见表IV），且产生的伪影少于消费级设备。LiDAR尺度最准但流程繁琐、有接缝伪影；iPhone扫描便捷但重建不稳定、有漂浮点伪影；手工制作网格几何过于完美会导致仿真到现实差距。</li>
</ol>
<p><img src="https://arxiv.org/html/2602.02331v1/x6.png" alt="几何对比"></p>
<blockquote>
<p><strong>图7</strong>：不同重建方法的几何对比。使用RGB-D输入的本文流程在质量和效率间取得了平衡，保持了真实的几何保真度，与LiDAR和iPhone扫描相比伪影显著更少（红圈标出）。上排：桩1，下排：窄梁1。</p>
</blockquote>
<ol start="4">
<li><strong>微调策略消融实验</strong>：论文对四种微调策略进行了比较（文中未提供具体数据图，但有描述）。结论是<strong>完全微调</strong>（Full Fine-tuning）在收敛速度和最终性能上表现最佳，因此被选为默认方法。适配器模块和残差学习虽然参数效率高，但性能不及完全微调。最后一层微调则无法有效适应新地形。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一个包含预训练和快速测试时训练的两阶段端到端感知运动学习范式，两者对于穿越极具挑战性的地形都至关重要。</li>
<li>开发了一个快速、前馈式、高保真的几何重建流程，能够从RGB-D输入生成仿真就绪的网格，实现了高效的“真实-仿真-真实”跑酷工作流。</li>
<li>通过大量实验证明，该框架能使双足机器人在极具挑战性的未知地形上快速涌现出敏捷且鲁棒的跑酷能力，性能显著超越基线方法。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到，真实世界部署中仍存在仿真到现实差距，原因包括：硬件不稳定性（相机噪声、执行器动态）、环境不匹配（物理地形元件在机器人交互时会晃动或移位）、以及重建几何与物理地形之间仍存在的差异。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>快速适应范式</strong>：将测试时训练引入具身智能，特别是针对动态、复杂环境的快速适应，是一个有前景的方向。</li>
<li><strong>重建与仿真的紧耦合</strong>：为满足机器人学习对速度和物理准确性的双重需求，需要专门设计高效、高保真的场景数字化流程。</li>
<li><strong>仿真到现实差距的持续攻克</strong>：即使在快速适应后，如何进一步缩小因未建模动态和感知误差导致的性能差距，仍是实际部署的关键。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人在未见复杂地形上动态跑酷的适应性问题，提出TTT-Parkour方法。其核心是一个real-to-sim-to-real框架：首先预训练通用策略，然后利用基于RGB-D的前馈高保真几何重建流程，快速获取新地形网格，并在仿真中进行测试时微调。实验表明，该流程在多数地形上可在10分钟内完成，微调后的策略能成功穿越楔子、窄梁等复杂障碍，并实现零样本仿真到现实迁移。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.02331" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>