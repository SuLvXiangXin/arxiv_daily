<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.04860" target="_blank" rel="noreferrer">2505.04860</a></span>
        <span>作者: Liu, I-Chun Arthur, Chen, Jason, Sukhatme, Gaurav, Seita, Daniel</span>
        <span>日期: 2025/05/08</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>学习双臂操作因其高维度和两臂间所需的紧密协调而具有挑战性。腕部相机（眼在手）的模仿学习通过聚焦于任务相关视图简化了感知，但收集多样化的示教数据成本高昂，因此需要可扩展的数据增强方法。现有工作主要探索了单臂场景下的视觉增强，但将这些方法扩展到双臂操作面临新挑战：需要生成跨双臂视角一致的观测，并产生既有效又可行的对应动作标签。本文针对双臂协调操作中离线数据生成的痛点，提出了一个扩散模型框架，用于同时合成新颖、视角一致的双臂腕部相机图像和关节空间动作标签。本文的核心思路是：利用扩散模型生成协调的双臂视角图像，并引入基于感知的任务状态分解（接触/非接触）与约束优化，以确保增强的状态和动作适合双臂协调。</p>
<h2 id="方法详解">方法详解</h2>
<p>D-CODA是一个为眼在手双臂模仿学习设计的离线数据增强框架。其整体流程是：首先，在原始示教数据集上训练一个条件扩散模型，学习从源视角图像和相机位姿扰动合成目标视角图像。其次，利用SAM2分割模型将任务分解为无接触和接触丰富的状态，并分别采用随机采样和约束优化来生成满足双臂协调约束的相机位姿扰动。最后，使用训练好的扩散模型和采样到的扰动合成新的腕部相机图像，并通过运动学计算生成对应的动作标签，从而构建增强数据集用于策略训练。</p>
<p><img src="https://arxiv.org/html/2505.04860v2/x1.png" alt="方法概述"></p>
<blockquote>
<p><strong>图2</strong>：D-CODA方法概述。(i) 扩散模型训练：学习从源图像 <code>I_a^l</code>, <code>I_a^r</code> 和位姿扰动 <code>Δp^l</code>, <code>Δp^r</code> 合成目标图像 <code>I_b^l</code>, <code>I_b^r</code>。(ii) 相机扰动采样：使用SAM2分解任务状态，对无接触状态（绿/黄点）均匀随机采样扰动，对接触丰富状态（褐红点）使用约束优化采样。(iii) 策略训练：结合原始和增强数据集训练双臂操作策略。</p>
</blockquote>
<p><strong>核心模块1：用于新颖视角合成的扩散模型</strong>。该方法修改了Zhang等人[9]的条件扩散模型，以同时处理左右臂的图像。扩散模型 <code>ε_φ</code> 是一个迭代去噪器，其输入包括：经VQ-GAN编码的源图像潜在向量 <code>V(I_a^l)</code>, <code>V(I_a^r)</code>、目标图像在噪声步 <code>t</code> 的潜在向量 <code>z_{b,t}^l</code>, <code>z_{b,t}^r</code>、以及左右臂的相机位姿变换 <code>Δp^l</code>, <code>Δp^r</code>。模型被训练以预测添加到目标潜在向量中的噪声 <code>ε_l</code>, <code>ε_r</code>，损失函数为 <code>L = ||ε_l - ε^_l||_2^2 + ||ε_r - ε^_r||_2^2</code>。模型基于U-Net架构，并将 <code>Δp^l</code>, <code>(Δp^l)^{-1}</code>, <code>Δp^r</code>, <code>(Δp^r)^{-1}</code> 注入交叉注意力层以融入位姿信息。</p>
<p><strong>核心模块2：相机扰动采样</strong>。这是确保增强数据适用于双臂协调的关键。首先，使用SAM2分割并跟踪夹爪，结合深度图或SSIM指标检测夹爪-物体接触事件，从而将任务轨迹分解为无接触状态和接触丰富状态。对于无接触状态，为每个臂在预设的平移 <code>[m_lb, m_ub]</code> 和旋转 <code>[r_lb, r_ub]</code> 范围内均匀随机采样扰动。对于接触丰富状态，采样被构造为一个约束优化问题，核心见解是对双臂施加相同的扰动以确保协调行为。决策变量是归一化的平移坐标 <code>c_trans</code>，成本函数惩罚过小的扰动、末端执行器离桌面或其他末端执行器过近的情况，并使用基于Levenberg-Marquardt方法的逆运动学求解器检查可行性。优化问题定义为在 <code>c_trans ∈ [-1,1]^3</code> 且 <code>c_trans ≥ m_lb</code> 等约束下最小化 <code>Cost(c_trans)</code>。</p>
<p><strong>核心模块3：动作标注与数据集构建</strong>。给定采样到的相机扰动变换矩阵 <code>T</code>，通过公式 <code>C·T·(C)^{-1}·E</code> 计算扰动后的末端执行器位姿，再使用逆运动学求解器得到扰动后的目标关节位置 <code>ã_t^l</code>, <code>ã_t^r</code>。如果结果配置无效，则丢弃该状态的增强数据。为了缓解行为克隆中的误差累积问题，每隔 <code>k</code> 个时间步用增强的（分布外）状态替换原始状态，而未被增强的动作标签和对应状态则保持在分布内，以指导策略完成任务。</p>
<p><img src="https://arxiv.org/html/2505.04860v2/x2.png" alt="原始与增强相机位姿"></p>
<blockquote>
<p><strong>图3</strong>：真实世界“举起球”任务中原始（蓝点）与增强（褐红点和黄点）相机位姿的等距视图。增强的相机位姿覆盖了原始位姿未占据的更广阔状态空间区域。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2505.04860v2/x3.png" alt="合成图像示例"></p>
<blockquote>
<p><strong>图4</strong>：在模拟的“协调举球”和“协调举托盘”任务上，使用D-CODA合成的腕部相机图像示例。第一列（黑色边框）为原始状态图像，第二列（红色边框）为同一时间步的增强（扰动后）状态图像。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在模拟环境中，使用了基于RLBench的5个双臂任务：协调举球、协调举托盘（简化版）、协调推箱子（简化版）、双按按钮和双臂拉直绳子。每个任务使用100条示教轨迹进行训练和增强。在真实世界中，使用了3个协调任务：举球、举抽屉和推方块，每个任务收集约32条示教，并进行20轮评估。下游策略主要采用Action Chunking with Transformers (ACT)。</p>
<p><strong>对比基线</strong>：</p>
<ol>
<li><strong>Fine-tuned VISTA</strong>：一种使用扩散模型增强第三人称视角的方法，本文将其微调并用于增强俯视相机图像，与原始腕部图像一起训练ACT。</li>
<li><strong>Bimanual DMD</strong>：为每只手臂独立使用DMD模型（一个单臂数据增强方法）合成图像，并使用与D-CODA相同的随机种子和替换间隔 <code>k</code> 生成扰动动作。</li>
<li>**ACT (w/o augment.)**：仅在原始数据上训练的ACT，作为无增强的参考。</li>
<li>**ACT (more data)**：在原始数据外加100条额外示教（无增强）上训练的ACT，作为更多专家数据的上限。</li>
</ol>
<p><strong>模拟实验结果</strong>：<br>表1显示，D-CODA在5个任务中的4个上超越了所有基线。例如，在“协调举球”任务上，D-CODA（2个相机）取得了73.3%的成功率，高于无增强的ACT（56.0%）和Bimanual DMD（50.7%）。在“协调举托盘（简化版）”上，D-CODA达到44.0%，显著优于其他方法。D-CODA甚至在非严格协调任务（如“双按按钮”和“双臂拉直绳子”）上也表现出优势。仅在“协调推箱子（简化版）”上，D-CODA（58.7%）略低于VISTA（76.0%），论文分析是因为腕部相机视角对该任务的场景（箱子与目标区域相对位置）可见性差，但D-CODA仍比无增强基线提升了20%。</p>
<p><img src="https://arxiv.org/html/2505.04860v2/x4.png" alt="模拟实验结果表"></p>
<blockquote>
<p><strong>表1</strong>：模拟实验结果对比。成功率是三次随机种子的平均评估结果。D-CODA在大多数任务上优于基线方法。</p>
</blockquote>
<p><strong>真实世界实验结果</strong>：<br>表2显示，当使用ACT作为下游策略时，D-CODA在三个真实任务上均优于基线。在“举球”任务上，D-CODA成功17/20次，高于无增强ACT的15/20次和VISTA的12/20次。在更具挑战性的“举抽屉”任务上，D-CODA（14/20）显著优于无增强ACT（7/20）和VISTA（0/20）。当使用另一种策略π0-FAST时，D-CODA在“举球”任务上（12/20）也大幅优于无增强基线（2/20）。</p>
<p><img src="https://arxiv.org/html/2505.04860v2/x5.png" alt="真实世界实验结果表"></p>
<blockquote>
<p><strong>表2</strong>：真实世界实验结果，每项任务进行20次试验。D-CODA在使用ACT或π0-FAST作为下游策略时，在多数任务上表现更优。</p>
</blockquote>
<p><strong>消融实验分析</strong>：<br>论文进行了关于替换间隔 <code>k</code> 和是否使用约束优化的消融实验。</p>
<p><img src="https://arxiv.org/html/2505.04860v2/images/figure_kPlotAblation_v4.png" alt="消融实验图"></p>
<blockquote>
<p><strong>图9</strong>：关于替换间隔 <code>k</code>（左图）和是否使用约束优化（右图）的消融研究。左图显示，在“协调举托盘”任务上，<code>k=5</code> 时性能最佳，<code>k=1</code>（每步都替换）会导致性能下降。右图显示，在接触丰富的“举抽屉”任务上，使用约束优化（D-CODA）相比均匀随机采样（D-CODA w/o constraints）能带来显著性能提升。</p>
</blockquote>
<p>左图表明，并非所有状态都被增强（即 <code>k &gt; 1</code>）时策略性能更好，<code>k=1</code>（每步都替换为增强状态）会导致性能下降，这支持了保留部分原始分布内状态以指导策略的必要性。右图表明，在接触丰富的任务（如“举抽屉”）中，使用约束优化采样扰动比均匀随机采样带来显著的性能提升，验证了该组件对于生成协调可行的增强数据的重要性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献包括：1) 提出了一种新颖的、基于扩散模型的双臂操作数据增强方法D-CODA，能够离线生成视角一致的双臂腕部相机图像和对应的关节空间动作标签。2) 设计了一个基于感知的流程，将任务分解为接触/非接触状态，并针对接触状态引入了约束优化相机扰动采样程序，以确保增强数据满足双臂协调约束。3) 在5个模拟和3个真实世界任务上进行了广泛实验，证明D-CODA优于多种基线方法和消融变体，展示了其在眼在手双臂操作中实现可扩展数据增强的潜力。</p>
<p>论文提到的局限性包括：1) 依赖预训练的分割模型（SAM2）进行接触检测，在复杂场景或新物体上可能失效。2) 扩散模型训练和约束优化过程计算成本较高。3) 逆运动学求解器可能无法为所有扰动位姿找到有效解，导致部分增强数据被丢弃。</p>
<p>本工作对后续研究的启示在于：1) 证明了扩散模型在生成复杂的、多视角协调的机器人数据方面的潜力，可扩展到更多臂或更复杂的交互。2) 强调了在数据增强中考虑物理约束（特别是接触约束）对于学习稳健协调策略的重要性。3) 所提出的增强框架是离线的，且与下游策略无关（兼容ACT、π0-FAST等），为提升不同双臂模仿学习算法的数据效率提供了通用工具。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出D-CODA方法，用于解决眼在手双机械臂模仿学习中数据收集成本高、多样性不足的问题。该方法基于扩散模型，合成视角一致的双臂手腕摄像头图像，并同步生成关节空间动作标签；通过约束优化确保增强状态符合双臂协调的物理约束。在5个模拟任务和3个真实任务上的评估表明，D-CODA在2250次模拟试验和300次真实试验中均优于基线方法，证明了其提升数据覆盖和策略泛化能力的有效性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.04860" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>