<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.13979" target="_blank" rel="noreferrer">2601.13979</a></span>
        <span>作者: Pietro Falco Team</span>
        <span>日期: 2026-01-20</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，机器人对可变形线性物体（DLOs，如电缆、软管）的操作主要依赖于视觉感知，利用RGB或RGB-D传感器进行分割和形状重建。尽管在受控环境下能达到较高精度，但这类方法在面对遮挡、背景杂乱、光照变化或部分可见性等真实工业场景中常见的情况时，性能会显著下降。因此，仅靠视觉感知往往无法提供完整可靠的DLO几何表示。触觉感知作为一种互补模态，能够在视觉数据不可用时捕获局部几何信息，但现有工作通常仅在抓取后局部使用，很少被集成到全局形状重建框架中。</p>
<p>本文针对视觉严重遮挡下DLO的全局形状估计这一具体痛点，提出了一种新的跨模态感知视角。受人类根据局部可靠性自适应结合视觉与触觉的感知方式启发，本文提出了一种主动的视觉-触觉跨模态感知框架。其核心思路是：利用基础模型增强的视觉管道提取DLO的拓扑感知表示，并自主识别被遮挡区域；随后通过主动的触觉探索补偿缺失的视觉信息；最后将视觉与触觉点云融合，通过B样条插值获得平滑、完整的电缆形状模型。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的确定性跨模态视觉-触觉方法整体框架如图1所示，旨在重建因视觉遮挡或视觉数据处理不完善而导致部分可观测的DLO形状。该方法将视觉感知和主动触觉探索集成在一个统一的几何重建框架内，其流程在算法1中形式化描述，而用于恢复被遮挡电缆段的主动触觉探索策略则在算法2中形式化。</p>
<p><img src="https://arxiv.org/html/2601.13979v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：所提出的跨模态视觉-触觉感知框架框图：视觉感知由最先进分割网络的自然语言提示触发；聚类算法根据颜色隔离不同的电缆；分割后的图像被转换为点云并进行后处理，触发触觉探索；最后通过B样条插值提供DLO的模型。</p>
</blockquote>
<p><strong>视觉感知与处理</strong>：安装在机器人末端执行器上的RGB-D相机获取场景图像ℐ。预训练网络Florence2使用提示语“shelf and cables”执行语义分割，得到场景中物体的边界框，再由SAM2处理生成分割掩码ℳ。掩码像素被分别处理：代表货架（支撑面）的像素ℐ_B被转换为点云𝒫_B，并应用RANSAC算法拟合平面模型，得到平面法向量ẑ，用于设定触觉探索时末端执行器的姿态。代表电缆的像素ℐ_DLO经过图像模糊和轮廓去除等预处理后，由无监督聚类算法HDBSCAN返回聚类集合𝒞。随后对每个聚类𝒞_i应用骨架化算法，减少像素数量同时保留DLO的拓扑信息，再将骨架化聚类转换为点云𝒫_skeleton。</p>
<p><strong>点云处理与端点搜索</strong>：对𝒫_skeleton进行下采样，将3D立方体内的所有点近似为其质心，得到𝒫_down。为确保后续排序算法收敛，对𝒫_down中欧氏距离低于阈值t_P的点对，用其中点替换，以获得更平滑的点云。然后利用平面法向量ẑ将所有点投影到该平面上，得到𝒫_proj。端点检测采用一种基于在平面上跟随电缆方向的排序算法，排序后的点云𝒫_sorted的首尾点被视为端点。由于遮挡或分割不完善，一个电缆聚类可能被分割成多个线段，各自拥有端点，端点集合ℰ将在触觉探索中用于重建DLO的缺失部分。</p>
<p><strong>主动触觉探索</strong>：机器人利用视觉感知获得的知识和端点信息执行基于梯度的触觉探索（算法2）。对于每个端点e，根据平面法向量ẑ和排序点云𝒫_sorted计算末端执行器的初始期望姿态R_d。其中，末端执行器的y轴方向被设定为沿电缆的方向（与触觉垫最长边垂直，以激活更多触觉单元），z轴方向由法向量ẑ定义。探索点定义为沿电缆y轴方向从端点偏移Δy的位置。机器人移动至该点后，沿ẑ方向下降Δz直至触觉传感器检测到接触。每次接触时获取触觉地图𝒯，并计算其所有点处Hessian矩阵范数构成的矩阵H的范数‖H‖，作为基于曲率的度量指标。若该指标超过阈值t_H，则判定接触到了电缆（而非平坦支撑面），将触觉地图质心投影到平面上并加入触觉点云𝒫_tactile。随后根据新采样点p_new和前一采样点更新末端姿态，继续沿电缆方向探索。当p_new与任一端点的欧氏距离小于阈值d_min时，停止对该端点的探索并将其标记为非端点。若曲率指标未超过阈值，则通过绕ẑ轴旋转θ角来调整探索方向。此过程迭代进行，直至所有端点被处理。</p>
<p><strong>点云融合与插值</strong>：将视觉排序点云𝒫_sorted与触觉点云𝒫_tactile合并，得到𝒫_merged。由于加入了新点，需要对其重新排序并再次进行端点检测，最终通过B样条插值获得平滑的电缆模型曲线𝒮，其点云表示为𝒫_interpolated，首尾点代表DLO的真实端点。</p>
<p><strong>核心创新点</strong>：1) <strong>拓扑感知的视觉表示</strong>：通过骨架化和端点检测，提取电缆的底层曲线结构，形成对噪声、下采样和部分遮挡鲁棒的表征，便于与触觉数据集成。2) <strong>自主触觉探索</strong>：当视觉重建不完整时，由遮挡检测触发主动触觉扫描程序，以恢复缺失的几何形状，这是一种现有DLO重建方法中缺乏的主动补偿机制。3) <strong>统一的点云融合与重建</strong>：提出端点引导的点排序策略，并结合B样条插值，获得平滑、全局一致的电缆模型，即使在涉及多个断开遮挡段的挑战性情况下也有效。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验平台（图2）包括一台7轴Yaskawa Motoman SIA5F机器人，配备眼在手上的Intel Realsense D435i RGB-D相机和一个SUNTouch触觉传感器。实验在两个案例研究中进行：倾斜平面上的单根电缆（CS1）和水平平面上的两根电缆（CS2）。每个案例又分为无遮挡和有遮挡两种情况。</p>
<p><img src="https://arxiv.org/html/2601.13979v1/x2.png" alt="实验设置"></p>
<blockquote>
<p><strong>图2</strong>：实验装置：带有摄像头和触觉传感器的机械臂。</p>
</blockquote>
<p><strong>CS1 (i): 无遮挡单电缆</strong>：图3展示了图像处理结果，成功分割出电缆和倾斜支撑面。图4显示了骨架化电缆点云、支撑面点云，以及经过下采样、近距离点替换和平面投影后的处理结果。触觉探索引入了电缆连接器处的额外点。图5展示了首次排序点云（含端点）、融合视觉与触觉的点云、重新排序后的点云以及最终的B样条插值结果，成功完成了真实端点检测和形状建模。</p>
<p><img src="https://arxiv.org/html/2601.13979v1/x3.png" alt="CS1无遮挡视觉分割"></p>
<blockquote>
<p><strong>图3</strong>：CS1 (i)：相机RGB图像（左上），Florence2/SAM2语义分割结果（右上），分割出的电缆（左下）和支撑表面（右下）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.13979v1/img/1cable_Inc_noOcc_sam2_output.png" alt="CS1无遮挡点云处理"></p>
<blockquote>
<p><strong>图4</strong>：CS1 (i)：骨架化电缆的点云（左上）和倾斜支撑面的点云（右上）。骨架被下采样（左下），随后处理以用中点替换较近的点，然后所有点投影到由RANSAC识别的平面上（右下）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.13979v1/x4.png" alt="CS1无遮挡重建结果"></p>
<blockquote>
<p><strong>图5</strong>：CS1 (i)：首次排序点云，红色端点为端点（左上），合并视觉和触觉点云得到的点云（右上），新排序步骤的结果点云（左下），插值后的点云（右下）。</p>
</blockquote>
<p><strong>CS1 (ii): 有遮挡单电缆</strong>：图6-7显示，一个物体遮挡了部分电缆（包括一个交叉点），导致视觉点云出现空段。图8（左）显示视觉点云的端点检测正确执行。触觉探索（图8右）在已被探索的电缆部分也产生了额外点，这是由于电缆交叉（交角小于45°）可能导致触觉点云更密集。这给寻找真实端点带来了挑战：排序算法可能找到两个以上的端点。为解决此问题，需要对重建后的点云进行第二次下采样和后处理（图9），然后再次排序和插值，最终成功完成重建。</p>
<p><img src="https://arxiv.org/html/2601.13979v1/x5.png" alt="CS1有遮挡视觉分割"></p>
<blockquote>
<p><strong>图6</strong>：CS1 (ii)：相机RGB图像（左上），Florence2/SAM2语义分割结果（右上），分割出的电缆（左下）和支撑表面（右下）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.13979v1/x6.png" alt="CS1有遮挡点云处理"></p>
<blockquote>
<p><strong>图7</strong>：CS1 (ii)：骨架化电缆的点云（左上）和倾斜支撑面的点云（右上）。骨架被下采样（左下），随后处理以用中点替换较近的点，然后所有点投影到由RANSAC识别的平面上（右下）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.13979v1/x7.png" alt="CS1有遮挡端点与融合"></p>
<blockquote>
<p><strong>图8</strong>：CS1 (ii)：首次排序点云，红色端点为端点（左），合并视觉和触觉点云得到的点云（右）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.13979v1/x8.png" alt="CS1有遮挡最终重建"></p>
<blockquote>
<p><strong>图9</strong>：CS1 (ii)：重建点云经过第二次下采样后的结果点云（左上），重建点云经过第二次后处理后的点云（右上），排序步骤的结果点云（左下），插值后的点云（右下）。</p>
</blockquote>
<p><strong>CS2 (i): 无遮挡双电缆</strong>：图10展示了图像处理结果，成功分割出两根不同颜色的电缆和支撑面。图11显示了聚类算法分离出的两个电缆聚类及其对应的后处理点云。每个聚类被独立处理，图12展示了各自的排序结果和触觉探索后的融合点云。图13显示，每个重建聚类都成功完成了真实端点检测和B样条插值。</p>
<p><img src="https://arxiv.org/html/2601.13979v1/x9.png" alt="CS2无遮挡视觉分割"></p>
<blockquote>
<p><strong>图10</strong>：CS2 (i)：相机RGB图像（左上），Florence2/SAM2语义分割结果（右上），分割出的电缆（左下）和支撑表面（右下）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.13979v1/x10.png" alt="CS2无遮挡聚类结果"></p>
<blockquote>
<p><strong>图11</strong>：CS2 (i)：黑色电缆聚类（左上），蓝色电缆聚类（右上），黑色电缆的后处理点云（左下）和蓝色电缆的后处理点云（右下）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.13979v1/x11.png" alt="CS2无遮挡各电缆处理"></p>
<blockquote>
<p><strong>图12</strong>：CS2 (i)：黑色电缆的首次排序点云，红色端点为端点（左上），蓝色电缆的首次排序点云，红色端点为端点（右上），合并视觉和触觉点云得到的黑色电缆点云（左下），合并视觉和触觉点云得到的蓝色电缆点云（右下）。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2601.13979v1/x12.png" alt="CS2无遮挡最终重建"></p>
<blockquote>
<p><strong>图13</strong>：CS2 (i)：黑色电缆的插值点云（左），蓝色电缆的插值点云（右）。</p>
</blockquote>
<p><strong>CS2 (ii): 有遮挡双电缆</strong>：实验同样验证了在部分电缆被遮挡的情况下，该方法能成功重建两根电缆的形状，过程与CS1 (ii)类似，证明了其对多电缆场景下遮挡问题的处理能力。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）提出了一种新颖的、基于基础模型驱动的主动跨模态视觉-触觉感知框架，用于在严重视觉遮挡下重建DLO的全局3D形状。2）实现了拓扑感知的视觉表示（通过骨架化与端点检测）与自主触觉探索的有机结合。3）设计了一种端点引导的点云融合与B样条插值流程，能够生成平滑、完整的电缆几何模型。</p>
<p>论文自身提到的局限性包括：用于端点搜索的排序算法在点云过于密集时性能可能下降，需要依赖下采样和后处理步骤；此外，当电缆段以较小角度交叉时，触觉探索可能会在已探索区域产生冗余点，增加后续处理的复杂性。</p>
<p>这项工作对后续研究的启示在于：它展示了跨模态感知（尤其是结合先进的视觉基础模型与主动触觉）在解决机器人操作中经典感知难题（如遮挡）上的巨大潜力。该方法为在复杂、非结构化的真实工业环境中操作可变形物体提供了更鲁棒的感知解决方案，未来的工作可以探索将此框架扩展到更广泛的物体类别，或集成更高级的主动感知规划策略。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对严重视觉遮挡下的可变形线性物体（如电缆）3D形状重建问题，提出了一种主动跨模态视觉-触觉感知框架。方法融合基于基础模型（SAM、Florence）的视觉分割与自适应触觉探索，通过欧几里得聚类与拓扑保持融合将触觉局部点云与视觉数据合并，并采用端点引导排序的B样条插值实现完整形状重建。实验表明，该框架能在大部分遮挡情况下，准确重建简单或高度弯曲的单根/多根电缆形状，验证了跨模态感知对机器人操纵可变形物体的有效性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.13979" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>