<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>TWIST: Teleoperated Whole-Body Imitation System - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>TWIST: Teleoperated Whole-Body Imitation System</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.02833" target="_blank" rel="noreferrer">2505.02833</a></span>
        <span>作者: Ze, Yanjie, Chen, Zixuan, Araújo, João Pedro, Cao, Zi-ang, Peng, Xue Bin, Wu, Jiajun, Liu, C. Karen</span>
        <span>日期: 2025/05/05</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前人形机器人的全身遥操作系统主要面临协调能力不足的局限。经典方法采用模块化的模型控制器，将遥操作与平衡控制分离处理，这限制了系统实现全身协调行为的能力。近年来，基于学习的控制器展现出潜力，但诸如蹲下从地面抬起箱子等协调的全身技能仍然有限，主要原因是缺乏准确、实时的全身跟踪目标，以及能够鲁棒跟踪这种多样化实时运动的控制器。</p>
<p>本文针对上述痛点，提出通过模仿实时人体全身运动来实现协调的人形机器人遥操作。本文的核心思路是：首先通过运动捕捉（MoCap）设备获取高质量的人体运动数据并重定向为人形机器人参考运动，然后利用一个结合强化学习与行为克隆（RL+BC）的统一神经网络控制器，在仿真中进行大规模训练，最终实现机器人对任意实时人体运动的鲁棒、准确跟踪。</p>
<h2 id="方法详解">方法详解</h2>
<p>TWIST 系统将人形机器人全身遥操作问题构建为一个实时运动跟踪任务。其整体流程分为三个阶段：1）通过重定向互联网人体数据和自采 MoCap 数据，构建人形机器人运动数据集；2）在仿真环境中训练一个统一的全身控制器；3）利用 MoCap 设备对真实世界人形机器人进行遥操作。</p>
<p><img src="https://arxiv.org/html/2505.02833v1/x3.png" alt="系统流程总览"></p>
<blockquote>
<p><strong>图3</strong>：TWIST 系统包含三个阶段：1）通过重定向人体数据构建人形运动数据集；2）在仿真中训练统一的全身控制器；3）使用 MoCap 设备对真实机器人进行遥操作。</p>
</blockquote>
<p><strong>1. 人形运动数据集的构建</strong>：训练数据主要来自公开的 MoCap 数据集（AMASS 和 OMOMO），包含超过 15,000 个运动片段。此外，作者还使用自建的 MoCap 系统采集了一个小规模（150个片段）的内部数据集，该数据包含了真实遥操作环境中的噪声和校准不完美等情况，有助于缩小分布差距。由于人形机器人与人体之间存在形态差异，需将人体运动重定向为人形机器人格式。对于大规模公开数据，采用类似 PHC 的离线重定向器进行优化，追求高质量和平滑性。对于内部数据集，为模拟实时遥操作，采用基于逆运动学（IK）的在线重定向器，其速度更快但运动平滑性较差。为弥合离线与在线重定向的质量差距，作者改进了在线重定向器的优化目标，使其同时优化 3D 关节位置和方向，从而提升了参考运动的质量。</p>
<p><strong>2. 仿真中的全身控制器训练</strong>：这是方法的核心创新。作者采用两阶段的师生框架进行训练。</p>
<ul>
<li><strong>特权教师策略（Privileged Teacher Policy）</strong>：教师策略 π_tea 的输入包含未来 2 秒的参考运动帧序列，使其能够预见并规划未来的跟踪目标，从而学习到更平滑的行为。其奖励函数 r_tea 由跟踪奖励（如关键身体部位位置、关节位置/速度、根位姿/速度跟踪）和惩罚项（如脚部接触、滑动惩罚、动作速率惩罚等）构成，通过 PPO 算法进行优化。</li>
<li><strong>可部署学生策略（Deployable Student Policy）</strong>：由于部署时无法获得未来信息，需要将教师策略蒸馏为学生策略 π_stu。学生策略的输入仅包含本体感知信息和当前单帧参考目标。为应对输入模态不同带来的挑战，作者采用 RL+BC 的混合方法进行优化，损失函数为：L(π_stu) = L_RL(π_stu) + λ D_KL(π_stu ∥ π_tea)。其中 L_RL 是使用与教师相同奖励的 PPO 损失，D_KL 是鼓励模仿教师的 KL 散度，权重 λ 在训练中逐渐减小。此方法结合了 RL 的泛化能力和 BC 的模仿平滑性。</li>
</ul>
<p><strong>3. 真实世界遥操作部署</strong>：训练好的学生策略通过精心调校的域随机化参数（包括基础质量、摩擦力、电机强度、重力变化、对基座和末端执行器的扰动等）实现零样本部署到真实机器人。在线遥操作时，使用 OptiTrack 以 120Hz 捕获人体运动，并通过改进的在线重定向器以 50Hz 生成人形参考运动。控制器接收这些参考运动，在 Nvidia RTX 4090 GPU 上以 50Hz 输出关节位置指令，发送给运行在 1000Hz 的机器人 PD 控制器。</p>
<p>与现有方法相比，TWIST 的创新点具体体现在：1) 采用两阶段师生框架，使最终部署的控制器虽仅观测当前帧，却能表现出基于未来信息规划的平滑行为；2) 引入小规模但更“真实”的 MoCap 数据来桥接仿真与现实的分布差距；3) 改进在线重定向器并引入末端执行器扰动训练，分别提升了参考运动质量和控制器在接触任务中的鲁棒性。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：主要评估平台为 Unitree G1（29自由度，1.3米高）人形机器人，并在 Booster T1 机器人上进行了跨平台验证。使用自采的 MoCap 测试数据集（50个未参与训练的片段）进行定量评估。对比的基线方法包括：单阶段强化学习（RL）、行为克隆（DAgger）以及本文的 RL+BC。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><p><strong>全身遥操作技能展示</strong>：如图2所示，TWIST 使机器人能够执行多样化的、类人的全身技能，包括：全身操作（扶正垃圾桶、蹲下搬箱）、腿部操作（用脚踢球、关门）、全身协调运动（侧向行走、后撤步、蹲行穿越障碍）以及表现性运动（拳击、华尔兹舞蹈）。</p>
</li>
<li><p><strong>控制器性能对比</strong>：</p>
<p><img src="https://arxiv.org/html/2505.02833v1/x6.png" alt="控制器对比"></p>
<blockquote>
<p><strong>图6</strong>：（左）不同控制器在MoCap测试数据上的跟踪误差。（右）不同控制器的行为表现。RL+BC控制器产生平滑且鲁棒的行为。</p>
</blockquote>
<p>图6（左）显示，RL+BC 方法在跟踪误差上显著优于纯 RL 和纯 BC（DAgger）。图6（右）的定性对比表明，纯 RL 常出现脚部滑动等伪影，DAgger 对未见运动的跟踪不稳定，而 RL+BC 则能产生平滑、鲁棒的行为。</p>
</li>
<li><p><strong>消融实验分析</strong>：</p>
<ul>
<li><p><strong>RL+BC &gt; RL &gt; BC</strong>：综合性能表明，RL 比 BC 泛化更好，而两者结合能带来显著提升。</p>
</li>
<li><p><strong>内部MoCap数据的重要性</strong>：即使加入少量内部MoCap数据，也能大幅降低在未见运动上的跟踪误差（图6左、图7右），因为它让控制器提前适应了真实遥操作中的噪声和不完美。</p>
</li>
<li><p><strong>学习施加力的效果</strong>：</p>
<p><img src="https://arxiv.org/html/2505.02833v1/x7.png" alt="力扰动训练效果"></p>
<blockquote>
<p><strong>图7</strong>：（左）真实世界中机器人搬运箱子时的运动曲线。引入末端执行器扰动训练能显著提高稳定性，避免漂移。（右）不同控制器在MuJoCo中跟踪MoCap数据时的运动曲线。</p>
</blockquote>
<p>图7（左）显示，在训练中引入末端执行器扰动，能极大提升控制器在需要接触和施力任务（如持物）中的稳定性。</p>
</li>
<li><p><strong>更好的在线重定向器</strong>：</p>
<p><img src="https://arxiv.org/html/2505.02833v1/x8.png" alt="重定向器与误差分布"></p>
<blockquote>
<p><strong>图8</strong>：（左）不同在线重定向器上的跟踪误差总和。改进的重定向器（联合优化位置和方向）能生成更平滑的参考运动，从而降低跟踪误差。（右）不同身体部位的跟踪误差分布。脚部和手部（末端执行器）误差最大，下半身跟踪比上半身更具挑战性。</p>
</blockquote>
<p>图8（左）表明，改进的在线重定向器（联合优化3D位置和方向）能产生更平滑的参考运动，使控制器的跟踪误差降低。</p>
</li>
</ul>
</li>
<li><p><strong>系统分析</strong>：</p>
<ul>
<li><strong>误差分布</strong>：图8（右）显示，末端执行器（手、脚）的跟踪误差最大，且下半身（脚、膝）的跟踪误差普遍高于上半身（肘、手），这与下半身接触动力学更复杂相符。</li>
<li><strong>遥操作延迟</strong>：总延迟约为0.9秒，主要开销来自生成跟踪目标（0.7秒），策略推理仅需0.2秒。</li>
<li><strong>可达性与失败案例</strong>：如图9所示，系统展现出卓越的全身可达性（机器人手几乎能触及脚趾）。主要失败源于硬件限制，如电机在持续蹲姿任务中容易过热。</li>
</ul>
</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>实现了协调的全身遥操作技能</strong>：TWIST 首次在真实人形机器人上，使用单一神经网络控制器，实现了涵盖全身操作、腿部操作、全身运动协调和表现性运动的多样化、类人全身技能。</li>
<li><strong>提出了鲁棒的训练流程</strong>：系统性地提出了包含两阶段师生框架（RL+BC）、小规模真实MoCap数据桥接、改进的在线重定向器以及末端扰动训练等关键技术的完整训练流程，显著提升了实时运动跟踪的准确性、平滑性和鲁棒性。</li>
<li><strong>展示了跨平台通用性</strong>：方法在 Unitree G1 和 Booster T1 两种不同的人形机器人平台上均验证有效。</li>
</ol>
<p><strong>局限性</strong>（论文自述）：</p>
<ol>
<li><strong>缺乏机器人反馈</strong>：操作者无法接收机器人的自我中心视觉或触觉反馈，在视觉遮挡或抓取操作时存在困难。</li>
<li><strong>硬件可靠性</strong>：当前人形机器人硬件（如电机过热）无法支持长时间连续运行，限制了系统耐力。</li>
<li><strong>对MoCap系统的依赖</strong>：系统依赖非便携、不易普及的动捕系统，限制了其广泛应用。</li>
</ol>
<p><strong>对后续研究的启示</strong>：TWIST 的成功表明，高质量的人体运动数据与鲁棒的学习控制器结合，是解锁人形机器人复杂全身技能的有效路径。未来工作可围绕以下方向展开：1）结合视觉反馈，实现更自然的双向遥操作；2）探索基于RGB的姿势估计等更便携的输入方式，以降低系统门槛；3）利用TWIST收集的遥操作数据，结合人类自我中心数据，来训练视觉运动策略，向更自主的机器人智能迈进。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人缺乏协调的全身遥操作能力这一核心问题，提出了TWIST系统。其关键技术是：首先将人体动捕数据重定向为机器人参考动作，然后结合强化学习与行为克隆（RL+BC）训练一个鲁棒的自适应全身控制器，并引入未来运动帧和真实动捕数据以提升跟踪精度。实验表明，该系统使真实人形机器人首次通过单一神经网络控制器，实现了涵盖全身操纵、腿部操纵、移动和表现性运动在内的多功能、协调的全身运动技能。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.02833" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>