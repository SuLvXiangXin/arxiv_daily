<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Multiagent Systems (cs.MA)</span>
      <h1>Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2504.17950" target="_blank" rel="noreferrer">2504.17950</a></span>
        <span>作者: White, Isadora, Nottingham, Kolby, Maniar, Ayush, Robinson, Max, Lillemark, Hansen, Maheshwari, Mehul, Qin, Lianhui, Ammanabrolu, Prithviraj</span>
        <span>日期: 2025/04/24</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，大多数现实世界任务需要团队协作解决，而辅助性AI智能体有望增强人类的问题解决能力。然而，AI发展长期以来侧重于优化单个智能体在特定任务上达到或超越“人类水平”的准确性，通常通过模仿其他智能体的行为来学习。这种目标意味着每个新训练的智能体旨在取代另一个，而非相互补充，从而削弱了团队潜力。因此，需要创建能够与其他智能体（人类或AI）协作、互补其问题解决能力并并行执行任务的智能体。创建此类协作AI智能体需要确保它们能够在现实世界的具身任务中，与协作者高效、有效地沟通，并在此过程中持续学习和适应。这面临两大挑战：1）<strong>具身性</strong>，即与现实世界交互的主要形式；2）<strong>自然语言</strong>，即我们事实上的沟通形式，同时也是计算机极其复杂的搜索空间。</p>
<p>现有的最先进LLM智能体并未针对多智能体协作进行优化，尤其是在具身场景中。一个主要瓶颈是它们不擅长通过自然语言与其他智能体高效沟通信息。实验表明，当智能体必须明确沟通详细计划时，任务成功率会下降超过15%。本文针对多智能体协作中的通信和协调痛点，提出了一个旨在优化智能体协作能力的新视角。核心思路是创建一个名为<strong>mind craft</strong>的、易于扩展的仿真平台，以及一个名为<strong>MineCollab</strong>的基准测试，以系统评估和促进多智能体具身推理研究。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的核心是一个用于在Minecraft中进行多智能体协作实验的平台<strong>mind craft</strong>，以及在该平台上构建的基准测试套件<strong>MineCollab</strong>。</p>
<p><strong>整体框架/pipeline</strong>：mind craft 的工作流程遵循智能体-环境交互循环。用户或任务配置提供高级指令（例如，“用附近材料建造一座房子”）。智能体接收这些指令，咨询大型语言模型（通过模型请求），并调用高级命令/工具。这些命令随后在Minecraft环境中执行，智能体通过执行日志接收反馈。该平台的核心是一个包含47个参数化工具的库，使LLM能够直接调用高级动作，从而在部分可观察的Minecraft世界中实现灵活、即插即用的协作和具身LLM智能体实验。</p>
<p><img src="https://arxiv.org/html/2504.17950v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：mind craft 工作流程概述。用户或任务配置（左侧）提供指令。智能体（中心）接收这些指令，咨询LLM并调用高级命令/工具。这些命令在Minecraft环境（右侧）中执行，智能体通过执行日志获得反馈。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><p><strong>状态与动作空间</strong>：</p>
<ul>
<li><strong>状态空间</strong>：智能体需要主动查询以获取大多数环境观察信息（如生物群系、库存、附近玩家）。这遵循工具调用方法，例如使用 <code>!nearbyBlocks</code> 和 <code>!craftable</code> 等命令，减少了噪声信息和上下文长度。</li>
<li><strong>动作空间</strong>：mind craft 构建了<strong>47个参数化高级工具</strong>，桥接了类人动作与程序化AI交互之间的差距。例如，智能体可以直接输出 <code>!givePlayer(&quot;randy&quot;, &quot;oak log&quot;, 4)</code> 来执行给予物品的动作，而无需生成复杂的底层代码。这使LLM能够在更高层次的序列动作空间上进行推理。平台也支持智能体输出自定义的Javascript代码以执行特殊动作。</li>
</ul>
</li>
<li><p><strong>智能体架构</strong>：包含四个主要组件：(1) 用于启动和管理智能体的服务器；(2) 用于处理来自玩家和其他智能体消息的主智能体循环；(3) 高级动作命令和观察查询库；(4) 用于提示和调用任意语言模型的层。此外，还支持通过嵌入相似性从当前对话中检索和提示少量示例（一个具身的检索增强生成RAG系统），以增强LLM的能力。</p>
</li>
<li><p><strong>多智能体协作机制</strong>：通过对话管理器实现。智能体可以使用 <code>!startConversation</code> 和 <code>!endConversation</code> 命令随时发起或结束对话。一次只有两个智能体可以对话，但这种成对通信框架可以通过在活跃对话之间转换，很好地扩展到三个或更多智能体。对话管理器还通过暂停或减慢对话来协调动作执行与通信的节奏，确保动作在环境中完成。</p>
</li>
</ol>
<p><strong>与现有方法的创新点</strong>：与Overcooked AI、CerealBar等现有平台相比（如表1所示），mind craft 独特地结合了多轮通信、部分可观察性、长任务序列和定量评估能力。其核心创新在于提供了一个通用、即插即用的框架，通过高级工具抽象简化了与复杂具身环境（Minecraft）的交互，并专门设计了支持复杂多智能体通信和协调的基础设施，从而能更纯粹地评估和提升智能体的协作与具身推理能力本身。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>Benchmark/数据集/实验平台</strong>：实验在<strong>mind craft</strong>平台上进行，使用其内置的<strong>MineCollab</strong>基准测试套件。该套件包含三个需要协作的具身任务领域：<strong>烹饪</strong>（协调收集食材制作餐点）、<strong>制作</strong>（从开采材料组装物品如书架）和<strong>建造</strong>（根据详细蓝图建造结构）。任务具有长序列（平均超过20步）、部分可观察性，并需要沟通协调。通过程序化生成创建了训练和测试任务分割，确保了数据集的多样性和可重复性。还利用LLaMA-70B-3.3-Instruct作为预言机智能体，从成功轨迹中生成用于监督微调（SFT）的数据集。</p>
<p><strong>Baseline方法</strong>：对比了当前最先进的开放权重和封闭权重LLM，包括：<code>gpt-4o</code>, <code>claude-3.5-sonnet</code>, <code>llama3.3-70b-instruct</code>, <code>llama3-8b-instruct</code>，以及用生成数据微调后的 <code>llama3-8b-sft</code>。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>整体性能</strong>：如表3所示，所有模型在协作任务上都面临挑战。即使在相对简单的建造任务中，性能最好的Claude 3.5 Sonnet也只能放置不到40%的总方块。烹饪任务成功率相对较高，但制作和建造任务成功率普遍较低。通过SFT，较小的<code>llama3-8b-sft</code>模型在制作任务上性能超过了<code>gpt-4o</code>和<code>llama3.3-70b-instruct</code>，在建造任务上匹配了70B模型的性能，证明了利用平台生成数据提升模型协作能力的可行性。</li>
<li><strong>具身任务复杂性影响</strong>：通过增加建造蓝图所需的独特材料数量或房间数量来提高任务复杂性。如图3(e)(f)所示，随着任务序列变长、状态-动作空间增大，大多数模型的性能下降（降幅约10%）。定性分析发现，智能体经常“撤销”之前已完成的工作，尤其是在需要记忆的内容增多时。</li>
<li><strong>协作复杂性影响</strong>：<ul>
<li><strong>智能体数量</strong>：如图3(a)(b)所示，与理论预期相反，当协作智能体数量从2个增加到5个时，烹饪和制作任务的性能急剧下降（从高达90%降至不到30%）。这表明协调负载（如避免冗余工作、协调资源使用）急剧增加，成为性能瓶颈。</li>
<li><strong>沟通需求</strong>：如图3(c)(d)所示，当强制智能体通过沟通传达复杂的逐步计划（如制作食谱）时，所有模型在烹饪和制作任务上的性能均下降超过15%。这直接证明了<strong>自然语言通信效率是当前多智能体协作的关键瓶颈</strong>。</li>
</ul>
</li>
</ol>
<p><img src="https://arxiv.org/html/2504.17950v1/x2.png" alt="任务复杂性消融实验"></p>
<blockquote>
<p><strong>图3</strong>：任务复杂性消融实验。(a)(b) 智能体数量增加导致性能显著下降。(c)(d) 隐藏计划（需沟通）导致性能下降超过15%。(e)(f) 建造蓝图复杂性（独特材料数、房间数）增加导致性能下降约10%。</p>
</blockquote>
<p><strong>消融实验总结</strong>：实验系统地消融了任务的两个核心维度——具身推理复杂性（通过蓝图参数）和协作复杂性（通过智能体数量和沟通需求）。结果表明，当前LLM智能体在这两个维度上都存在显著不足：长序列、复杂状态下的规划能力有限；且随着协调方增多或需要详细语言沟通时，协作效率大幅降低。这凸显了超越当前提示和微调方法、开发更先进协作算法的必要性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了 <strong>mind craft</strong>，一个灵活、可扩展的仿真平台，专门用于研究多智能体在丰富具身场景中通过自然语言进行的协作。</li>
<li>引入了 <strong>MineCollab</strong> 基准测试套件，包含烹饪、制作和建造三个实用领域，能够系统评估智能体的具身推理和协作沟通能力。</li>
<li>通过系统的实验分析，揭示了当前最先进的LLM智能体在多智能体协作中的关键瓶颈——<strong>自然语言通信效率</strong>，并证明了任务性能对沟通质量高度敏感。</li>
</ol>
<p><strong>论文自身提到的局限性</strong>：</p>
<ol>
<li>虽然尝试为mind craft添加视觉输入支持，但未进行严格评估。初步测试表明，视觉输入并未显著影响性能，这可能是因为视觉语言模型预训练数据中缺乏复杂的推理数据。</li>
<li>本研究中的评估基于一个固定版本的mind craft，而该项目正在快速发展中。</li>
<li>对于需要3个以上智能体的建造任务，由于闭源API的预算限制，未进行广泛测试。</li>
</ol>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>研究方向</strong>：本文明确指出，现有的提示和微调等标准技术存在局限，需要探索上下文学习和模仿学习之外的更先进方法，以优化多智能体协作。</li>
<li><strong>平台潜力</strong>：mind craft平台支持开放世界游戏、代码生成、开放探索和社会模拟等特性，为未来研究智能体创造力、开放性和社会性等复杂问题提供了新的实验场。</li>
<li><strong>可及性提升</strong>：通过平台生成SFT数据可以有效提升较小模型在协作任务上的性能，这有助于降低相关研究门槛，促进更广泛的研究参与。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文研究大型语言模型如何协作执行复杂的具身推理任务。核心问题是现有LLM智能体在多智能体协作中存在瓶颈，特别是在需要详细沟通的具身场景中。作者提出了一个基于Minecraft的多智能体协作框架和基准测试平台，用于评估协作与具身推理能力。实验发现，当智能体被要求详细沟通任务计划时，性能下降高达15%，表明现有方法在优化多智能体协作方面不足。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2504.17950" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>