<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>DeCo: Task Decomposition and Skill Composition for Zero-Shot Generalization in Long-Horizon 3D Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>DeCo: Task Decomposition and Skill Composition for Zero-Shot Generalization in Long-Horizon 3D Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.00527" target="_blank" rel="noreferrer">2505.00527</a></span>
        <span>作者: Chen, Zixuan, Yin, Junhui, Chen, Yangtao, Huo, Jing, Tian, Pinzhuo, Shi, Jieqi, Hou, Yiwen, Li, Yinchuan, Gao, Yang</span>
        <span>日期: 2025/05/01</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，基于视觉演示和语言指令的语言条件多任务模仿学习（IL）模型已成为机器人操作的主流方法。然而，这些模型在面对新颖的长视野3D操作任务时泛化能力有限，即使这些新任务仅仅是已学技能的顺序组合。例如，模型学会了“打开抽屉”、“将积木放入打开的抽屉”和“关闭抽屉”等独立技能，却无法执行组合指令“将积木放入关闭的抽屉然后关闭抽屉”。其根本原因在于模型缺乏将新任务分解、检索、调度并组合其已学技能的能力。现有利用视觉语言模型（VLM）进行高层次任务规划的方法，往往难以将语义层面的分解与低层次技能执行空间对齐，限制了零样本泛化性能。本文旨在解决这一痛点，提出了一个模型无关的框架DeCo，通过将长视野任务分解为可重用的原子技能并进行组合，以增强多任务IL模型对新颖但可组合的长视野3D操作任务的零样本泛化能力。核心思路是：在训练阶段，基于机械爪与物体的物理交互对原始演示进行分解，构建原子技能库；在推理阶段，利用VLM解析新任务指令并检索相关原子技能，通过空间感知的技能链接模块确保技能间平滑、无碰撞的过渡。</p>
<h2 id="方法详解">方法详解</h2>
<p>DeCo是一个与具体模型无关的框架，旨在增强现有多任务IL模型处理新颖组合长视野任务的能力。其整体流程分为离线训练和在线推理两大部分。</p>
<p><img src="https://arxiv.org/html/2505.00527v1/extracted/6404364/figs/deco_overview2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：DeCo框架总览。左侧（离线阶段）展示了基于物理交互的任务分解与原子技能学习过程；右侧（在线阶段）展示了面对新任务时，VLM引导的规划、技能调度与空间感知的技能链接执行流程。</p>
</blockquote>
<p><strong>1. 基于物理交互的任务分解与技能学习</strong><br>该方法的核心创新之一是对训练数据集的重新组织。DeCo从机械爪与物体的物理交互出发定义任务边界。一个“完整交互”（<code>p^full</code>）定义为机械爪从张开到闭合再回到张开的一个完整周期（两个“循环”）。一个“半交互”（<code>p^half</code>）则是单个循环（如张开到闭合）。论文主要采用<code>p^full</code>作为分解基础。对于原始的多任务IL训练演示集，DeCo根据完整交互的边界将其切割成一系列模块化、可重用的原子任务。例如，指令“将物品放入关闭的抽屉（无需关闭抽屉）”可被分解为“打开抽屉”和“将物品放入打开的抽屉”两个原子任务。每个原子任务与一个自然语言指令配对，形成原子指令库<code>L^a</code>和原子训练数据集<code>T^a</code>。演示数据通过关键帧发现方法处理，每个原子任务以一次完整交互结束，其最后一个关键帧的末端执行器位姿被标记为目标位姿。随后，多任务IL模型<code>M</code>在此原子数据集上进行训练，学习一个语言条件策略<code>π^a_θ</code>，其目标是最小化标准的多任务模仿学习损失<code>L_MT-IL</code>，从而掌握一系列原子技能。</p>
<p><strong>2. VLM引导的规划与技能调度</strong><br>当面对一个新颖的组合长视野任务<code>T^new</code>时，<code>M+DeCo</code>利用强大的VLM（文中使用GPT-4o）进行任务解析和规划。系统向VLM输入新任务的指令、观察到的RGB图像以及预构建的原子指令库<code>L^a</code>。VLM基于其推理能力，从<code>L^a</code>中检索出相关的原子指令，并生成一个执行该新任务所需的原子技能序列计划。在技能执行过程中，系统持续监控机器人位姿，判断其是否与当前原子技能的目标位姿匹配。一旦匹配成功（意味着一次完整交互完成），系统便根据VLM生成的计划，调度并开始执行下一个原子技能。这形成了一个基于目标位姿达成反馈的动态执行循环。</p>
<p><strong>3. 空间感知的技能链接</strong><br>仅仅按语义顺序执行原子技能可能因技能间起始/目标位姿的空间不连续而导致碰撞或失败。为此，DeCo引入了一个空间感知的技能链接模块。当当前技能完成（达到目标位姿）且下一个技能被调度时，系统获取当前技能的目标位姿、下一个技能的预测起始位姿以及场景点云。这些信息被输入一个基于Voxposer改造的空间感知代价地图生成模块，该模块会生成一组无碰撞的“链接位姿”，用于桥接两个技能之间的空间间隙。机器人随后在这些链接位姿上进行基于RRT的运动规划，确保安全、平滑地过渡到下一个技能的起始状态，从而实现长视野任务中多个技能的流畅、可靠组合执行。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：论文在仿真和真实世界两个环境中进行评估。仿真实验使用新提出的<strong>DeCoBench</strong>基准（基于RLBench构建），包含10个原子任务（24个变体）用于训练，以及12个新颖的组合长视野任务（36个变体）用于零样本评估。对比的基线是多任务IL模型本身（<strong>RVT-2, 3DDA, ARP</strong>）及其与DeCo结合的版本（<strong>RVT-2+DeCo, 3DDA+DeCo, ARP+DeCo</strong>）。真实实验使用Franka Panda机器人，基于6个原子任务训练，在9个长视野任务上进行零样本测试。</p>
<p><img src="https://arxiv.org/html/2505.00527v1/extracted/6404364/figs/exp/combine_fig1.png" alt="仿真实验结果对比"></p>
<blockquote>
<p><strong>图4</strong>：在DeCoBench上三个模型及其DeCo增强版本的零样本成功率对比。DeCo为所有基线模型带来了显著提升。</p>
</blockquote>
<p><strong>关键定量结果</strong>：</p>
<ul>
<li><strong>仿真实验</strong>：在12个新组合任务上，DeCo为RVT-2、3DDA和ARP分别带来了<strong>66.67%<strong>、</strong>21.53%</strong> 和 <strong>57.92%</strong> 的绝对成功率提升（图4）。具体到任务，例如在“将物品放入关闭的抽屉然后关闭抽屉”任务中，RVT-2+DeCo的成功率从16.67%提升至100%。</li>
<li><strong>真实世界实验</strong>：RVT-2+DeCo在9个新任务上的平均成功率为73.33%，相比基线RVT-2的20.00%，提升了 **53.33%**（图8）。</li>
</ul>
<p><img src="https://arxiv.org/html/2505.00527v1/extracted/6404364/figs/exp/real_combine.png" alt="真实世界实验结果"></p>
<blockquote>
<p><strong>图8</strong>：真实世界实验中，RVT-2与RVT-2+DeCo在9个长视野任务上的成功率对比。DeCo显著提升了模型在真实环境中的零样本泛化能力。</p>
</blockquote>
<p><strong>消融实验与分析</strong>：</p>
<ul>
<li><strong>交互粒度</strong>：论文对比了基于<code>p^full</code>（完整交互）和<code>p^half</code>（半交互）构建原子任务的DeCo变体。如图5所示，在大多数任务上，基于<code>p^full</code>的DeCo性能更优。作者分析<code>p^half</code>可能导致技能过于碎片化，增加了VLM检索和组合的难度，并可能引入更多需要链接的位姿间隙。</li>
</ul>
<p><img src="https://arxiv.org/html/2505.00527v1/x1.png" alt="交互粒度消融实验"></p>
<blockquote>
<p><strong>图5</strong>：基于完整交互（<code>p^full</code>）和半交互（<code>p^half</code>）的DeCo变体在DeCoBench上的性能对比。<code>p^full</code>在多数任务上表现更好。</p>
</blockquote>
<ul>
<li><strong>技能链接模块的重要性</strong>：图7展示了在具有挑战性的长视野任务中，启用空间感知技能链接模块对成功率的巨大影响。例如，在某个任务中，没有该模块的成功率仅为16.67%，而启用后达到100%。</li>
</ul>
<p><img src="https://arxiv.org/html/2505.00527v1/extracted/6404364/figs/exp/linkpose_success_01.png" alt="技能链接模块消融"></p>
<blockquote>
<p><strong>图7</strong>：空间感知技能链接模块的消融实验结果。该模块对于确保长序列技能的安全、连续执行至关重要。</p>
</blockquote>
<ul>
<li><strong>VLM规划分析</strong>：图6展示了VLM为不同新任务生成的原子技能序列计划示例，证明了其能够有效解析任务并检索正确的原子指令进行组合。</li>
</ul>
<p><img src="https://arxiv.org/html/2505.00527v1/x2.png" alt="VLM规划示例"></p>
<blockquote>
<p><strong>图6</strong>：VLM（GPT-4o）为不同新任务生成的原子技能执行计划示例。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>DeCo</strong>，一个模型无关的框架，通过物理交互驱动的任务分解和VLM引导的技能组合，显著提升了多任务IL模型对新颖组合长视野3D操作任务的零样本泛化能力。</li>
<li>引入了<strong>DeCoBench</strong>，一个专门用于系统评估多任务IL模型在组合长视野任务上零样本泛化能力的基准测试。</li>
<li>在仿真和真实机器人实验中验证了DeCo的有效性与实用性，证明其能够赋能现有模型完成训练中未见的长视野复杂任务。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ul>
<li>框架性能依赖于底层VLM的规划和检索能力，可能存在检索错误或规划偏差。</li>
<li>空间感知技能链接模块依赖于额外的场景点云和基础模型（Voxposer），可能带来一定的计算开销。</li>
<li>当前方法主要处理顺序组合的任务，对于需要条件分支或循环的复杂任务逻辑尚未涉及。</li>
</ul>
<p><strong>对后续研究的启示</strong>：</p>
<ul>
<li>DeCo提供了一种将高层语义规划与低层技能执行空间对齐的有效范式，可推广至其他需要组合推理的机器人学习领域。</li>
<li>基于物理交互的任务分解原则具有通用性，可进一步探索更精细或更抽象的技能表示与边界定义方法。</li>
<li>未来的工作可以探索如何将动态环境状态、任务进度更紧密地集成到技能调度和链接过程中，以处理更开放、不确定的环境。</li>
</ul>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对多任务模仿学习模型在长时程3D操作任务中零样本泛化能力不足的核心问题，提出模型无关框架DeCo。其关键技术包括：将演示分解为原子任务以学习可重用技能；推理时利用视觉语言模型解析指令、检索技能，并通过空间感知技能链模块调度执行以实现平滑过渡。实验显示，DeCo在模拟中使RVT-2、3DDA和ARP模型在12个新组合任务上成功率分别提升66.67%、21.53%和57.92%；真实实验中，平均成功率提高53.33%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.00527" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>