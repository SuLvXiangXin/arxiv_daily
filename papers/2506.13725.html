<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.13725" target="_blank" rel="noreferrer">2506.13725</a></span>
        <span>作者: Song, Wenxuan, Chen, Jiayi, Ding, Pengxiang, Huang, Yuxin, Zhao, Han, Wang, Donglin, Li, Haoang</span>
        <span>日期: 2025/06/16</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>近年来，视觉-语言-动作模型因其强大的多模态理解和泛化能力，成为机器人领域的重要研究方向。然而，其实际部署受到推理速度瓶颈的严重制约，尤其是在需要高频和灵巧操作的任务中。目前，主流的动作生成采用自回归解码，需要执行n次前向传播来生成n个令牌，速度缓慢。近期研究探索了雅可比解码作为一种更高效的替代方案，它将自回归解码重新表述为一个非线性方程组，并通过雅可比定点迭代法求解。理论上，由于雅可比解码允许在单次迭代中并行预测多个正确令牌，其迭代次数k可以少于令牌数n，从而实现加速。但实践表明，在标准的VLA模型上直接应用雅可比解码仅能带来有限的加速（约1.28倍）。其根本原因在于，VLA模型是严格以自回归方式训练的，模型在训练时只接触过真实的前缀令牌。因此，在雅可比解码中，当前面的令牌不正确时（这是雅可比解码中的常态），模型难以生成准确的后续预测，导致每次迭代通常只能正确预测第一个令牌，从而使整个令牌序列收敛缓慢。本文旨在显著提升VLA的推理效率，同时保持其操作性能。核心思路是：通过一致性蒸馏训练，使模型能够从雅可比轨迹上的任意中间状态直接映射到最终解（定点），从而在每次迭代中预测多个正确令牌；并设计早退解码策略，通过适度放宽收敛条件来规避少数低效迭代，进一步释放加速潜力。</p>
<h2 id="方法详解">方法详解</h2>
<p>CEED-VLA的整体框架包含三个阶段：1）利用预训练的教师VLA模型通过雅可比解码生成训练数据集（Jacobi轨迹）；2）通过结合一致性损失和混合标签自回归监督的一致性蒸馏过程训练学生模型；3）在推理时使用早退解码策略进行加速。</p>
<p><img src="https://arxiv.org/html/2506.13725v1/extracted/6546495/image/small_teaser.png" alt="方法总览"></p>
<blockquote>
<p><strong>图2</strong>：CEED-VLA方法整体框架。首先使用预训练VLA（如LLaVA-VLA）进行雅可比解码以生成训练数据集。然后设计了一个包含新颖混合标签监督的有效一致性蒸馏过程来获得学生模型。最后，提出早退解码以进一步释放推理速度。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><strong>教师模型与数据收集</strong>：教师模型为标准的预训练VLA（如LLaVA-VLA、OpenVLA），其以自回归方式根据当前观测和语言指令预测动作。为了收集一致性蒸馏所需的数据，让教师模型在机器人数据集上运行雅可比解码，并记录整个解码过程中产生的动作序列轨迹（即Jacobi轨迹），构建数据集𝒟。轨迹上的每个点是一个中间动作序列，其对应的终点是收敛后的固定点序列。</li>
<li><strong>一致性蒸馏训练</strong>：学生模型Q_θ的参数由教师模型初始化。训练采用双监督目标：<ul>
<li>**一致性损失 (ℒ_C)*<em>：其目标是使学生模型能够将Jacobi轨迹上的任意中间状态𝒴直接映射到对应的固定点𝒴</em>。具体而言，对于随机采样的中间状态𝒴，计算学生模型在𝒴条件下预测的每个令牌分布，与在𝒴*条件下（通过梯度停止获得）预测的分布之间的前向KL散度，并对所有令牌求和取期望。这迫使模型学会在给定可能包含错误的前缀时，仍能输出正确的完整序列。</li>
<li>*<em>混合标签自回归监督 (ℒ_AR)*<em>：为了防止蒸馏过程损害模型原有的自回归生成能力，保留了标准的自回归损失。但直接使用教师模型生成的固定点𝒴</em>作为标签可能存在误差累积。因此，论文提出了混合标签策略：计算𝒴*与真实动作数据之间的L1距离，若距离小于一个学习到的正确性阈值δ_max，则使用𝒴</em>作为监督信号；否则，将标签替换为真实值。这确保了学生模型从可靠的教师信号中学习，同时减轻了蒸馏过程中性能下降的影响。</li>
<li><strong>总损失</strong>：ℒ(θ) = ℒ_C + wℒ_AR，其中w为权重系数。训练算法如图4所示。</li>
</ul>
</li>
<li><strong>早退解码</strong>：经过一致性蒸馏的学生模型使用雅可比解码进行推理。然而，作者发现加速性能受限于少数“低效迭代”——这些迭代由于需要满足严格的收敛条件（连续两次迭代的输出序列完全相等）而需要非常多的步骤（超过30次迭代）。分析表明，机器人任务的成功通常由少数关键状态下的动作决定，大部分状态对动作精度的要求并不苛刻。此外，低效迭代末尾的令牌更新幅度很小，对最终决策贡献有限。因此，论文提出早退解码策略：适度放宽收敛条件，当连续迭代的动作序列足够接近（例如，变化小于某个阈值）时，即提前终止解码。这避免了在低效迭代上浪费时间，显著提升了平均解码速度，且对任务成功率影响甚微。一个更激进早退的变体称为CEED-VLA-Turbo，能实现更快的推理。</li>
</ol>
<p><strong>创新点</strong>：</p>
<ol>
<li>首次将一致性模型的思想引入VLA加速领域，通过蒸馏使模型具备从错误前缀中直接恢复正确序列的能力。</li>
<li>设计了混合标签自回归监督，在一致性蒸馏中稳定训练并保持模型性能。</li>
<li>识别了雅可比解码中“低效迭代”的瓶颈，并提出基于任务结构分析的早退解码策略，进一步实现了实质性加速。</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：</p>
<ul>
<li><strong>基准模型</strong>：使用OpenVLA和LLaVA-VLA作为基础教师模型。</li>
<li><strong>评估环境</strong>：在两个模拟环境（具体环境名需从原文补充）和真实机器人（Franka Emika Panda机械臂）上进行测试。</li>
<li><strong>对比方法</strong>：标准自回归解码、直接在原始VLA上应用的雅可比解码、以及CEED-VLA的不同变体。</li>
<li><strong>评估指标</strong>：任务成功率、解码速度（Hz）、所需迭代次数。</li>
</ul>
<p><img src="https://arxiv.org/html/2506.13725v1/extracted/6546495/image/ceed.jpg" alt="加速效果对比"></p>
<blockquote>
<p><strong>图1</strong>：CEED-VLA在OpenVLA和LLaVA-VLA上的加速效果。左：完成输出所需迭代次数对比，CEED-VLA大幅减少迭代。右：解码速度对比，CEED-VLA在OpenVLA和LLaVA-VLA上分别实现了3.6倍和2.0倍的加速，且性能下降可忽略。CEED-VLA-Turbo能以轻微性能代价实现更少迭代和更高加速。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>模拟实验</strong>：如表2所示（需从原文补充），CEED-VLA在不同基线模型上实现了2倍至4.1倍的推理加速，同时保持了可比的任务成功率。例如，在某个基准上，CEED-VLA将成功率从85.5%略微提升至86.0%，同时速度从10.2 Hz提升至41.7 Hz（4.1倍加速）。</li>
<li><strong>真实世界实验</strong>：在真实机械臂部署中，CEED-VLA实现了4倍的操作频率提升，并在高频灵巧操作任务上取得了更高的成功率。</li>
<li><strong>速度分析</strong>：表1对比了不同解码方法的平均、最小和最大速度（延迟的倒数）。早退解码相比标准雅可比解码，显著提升了平均速度和最小速度，避免了极慢的迭代。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.13725v1/extracted/6546495/image/speedup_vs_accuracy.png" alt="速度与准确率权衡"></p>
<blockquote>
<p><strong>图6</strong>：CEED-VLA和CEED-VLA-Turbo在不同早退阈值下的速度-成功率权衡曲线。展示了通过调整早退条件，可以在速度和准确性之间进行平滑的权衡。</p>
</blockquote>
<p><strong>消融实验</strong>：<br>论文通过消融实验验证了核心设计的有效性。</p>
<ol>
<li><strong>混合标签监督</strong>：移除混合标签（仅使用教师输出作为AR损失标签）会导致成功率显著下降，证明了该策略对于防止误差传播、保持性能至关重要。</li>
<li><strong>早退解码</strong>：对比标准雅可比解码和早退解码，后者在成功率下降极小的情况下，带来了显著的额外速度提升。</li>
<li><strong>训练数据量</strong>：分析了用于一致性蒸馏的Jacobi轨迹数据量对性能的影响，表明即使使用中等规模的数据也能取得良好效果。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.13725v1/extracted/6546495/image/l1_distance.png" alt="L1距离分布"></p>
<blockquote>
<p><strong>图4</strong>：生成的Jacobi轨迹数据集与真实数据之间的L1距离分布。该分布用于确定混合标签监督中的正确性阈值δ_max，以区分可靠和不可靠的教师输出。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了CEED-VLA，一个通用的VLA加速框架，通过一致性蒸馏和早退解码，在保持操作性能的同时实现了显著的推理加速（超过4倍）。</li>
<li>设计了一致性蒸馏流程与混合标签自回归监督，使VLA模型获得了在错误前缀条件下并行预测多个正确令牌的能力，并确保了训练稳定性。</li>
<li>识别了雅可比解码中“低效迭代”的瓶颈，并基于机器人任务的结构特性分析，提出了有效的早退解码策略，进一步释放了加速潜力。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到，一致性蒸馏过程需要从教师模型收集Jacobi轨迹数据，这是一个额外的数据准备步骤。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li>CEED-VLA为加速多模态决策模型提供了一种高效且通用的范式，其思想可能扩展到其他需要序列生成的具身AI任务中。</li>
<li>早退解码策略基于对任务成功关键点的洞察，这种“松弛优化”的思想可能适用于其他对输出精度有不同容忍度的序列生成场景。</li>
<li>混合标签监督机制为在存在噪声或近似监督信号下进行模型蒸馏提供了参考。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对视觉-语言-动作模型推理速度慢、制约机器人高频灵巧任务部署的问题，提出CEED-VLA模型。通过**一致性蒸馏训练**预测多动作令牌以加速，并引入**混合标签监督**减少误差累积；同时设计**早期退出解码策略**，适度放宽收敛条件以提升效率。实验表明，该方法在不同基线上实现了**超过4倍的推理加速**，并在仿真与真实机器人任务中保持了高成功率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.13725" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>