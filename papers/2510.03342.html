<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.03342" target="_blank" rel="noreferrer">2510.03342</a></span>
        <span>作者: Gemini Robotics Team, Abdolmaleki, Abbas, Abeyruwan, Saminda, Ainslie, Joshua, Alayrac, Jean-Baptiste, Arenas, Montserrat Gonzalez, Balakrishna, Ashwin, Batchelor, Nathan, Bewley, Alex, Bingham, Jeff, Bloesch, Michael, Bousmalis, Konstantinos, Brakel, Philemon, Brohan, Anthony, Buschmann, Thomas, Byravan, Arunkumar, Cabi, Serkan, Caluwaerts, Ken, Casarini, Federico, Chan, Christine, Chang, Oscar, Chappellet-Volpini, London, Chen, Jose Enrique, Chen, Xi, Chiang, Hao-Tien Lewis, Choromanski, Krzysztof, Collister, Adrian, D&#39;Ambrosio, David B., Dasari, Sudeep, Davchev, Todor, Dave, Meet Kirankumar, Devin, Coline, Di Palo, Norman, Ding, Tianli, Doersch, Carl, Dostmohamed, Adil, Du, Yilun, Dwibedi, Debidatta, Egambaram, Sathish Thoppay, Elabd, Michael, Erez, Tom, Fang, Xiaolin, Fantacci, Claudio, Fong, Cody, Frey, Erik, Fu, Chuyuan, Gao, Ruiqi, Giustina, Marissa, Gopalakrishnan, Keerthana, Graesser, Laura, Groth, Oliver, Gupta, Agrim, Hafner, Roland, Hansen, Steven, Hasenclever, Leonard, Haves, Sam, Heess, Nicolas, Hernaez, Brandon, Hofer, Alex, Hsu, Jasmine, Huang, Lu, Huang, Sandy H., Iscen, Atil, Jacob, Mithun George, Jain, Deepali, Jesmonth, Sally, Jindal, Abhishek, Julian, Ryan, Kalashnikov, Dmitry, Karagozler, M. Emre, Karp, Stefani, Kecman, Matija, Kew, J. Chase, Kim, Donnie, Kim, Frank, Kim, Junkyung, Kipf, Thomas, Kirmani, Sean, Konyushkova, Ksenia, Ku, Li Yang, Kuang, Yuheng, Lampe, Thomas, Laurens, Antoine, Le, Tuan Anh, Leal, Isabel, Lee, Alex X., Lee, Tsang-Wei Edward, Lever, Guy, Liang, Jacky, Lin, Li-Heng, Liu, Fangchen, Long, Shangbang, Lu, Caden, Maddineni, Sharath, Majumdar, Anirudha, Maninis, Kevis-Kokitsi, Marmon, Andrew, Martinez, Sergio, Michaely, Assaf Hurwitz, Milonopoulos, Niko, Moore, Joss, Moreno, Robert, Neunert, Michael, Nori, Francesco, Ortiz, Joy, Oslund, Kenneth, Parada, Carolina, Parisotto, Emilio, Paryag, Amaris, Pooley, Acorn, Power, Thomas, Quaglino, Alessio, Qureshi, Haroon, Raju, Rajkumar Vasudeva, Ran, Helen, Rao, Dushyant, Rao, Kanishka, Reid, Isaac, Rendleman, David, Reymann, Krista, Rivas, Miguel, Romano, Francesco, Rubanova, Yulia, Sampedro, Peter Pastor, Sanketi, Pannag R, Shah, Dhruv, Sharma, Mohit, Shea, Kathryn, Shridhar, Mohit, Shu, Charles, Sindhwani, Vikas, Singh, Sumeet, Soricut, Radu, Sterneck, Rachel, Storz, Ian, Surdulescu, Razvan, Tan, Jie, Tompson, Jonathan, Tunyasuvunakool, Saran, Varley, Jake, Vesom, Grace, Vezzani, Giulia, Villalonga, Maria Bauza, Vinyals, Oriol, Wagner, René, Wahid, Ayzaan, Welker, Stefan, Wohlhart, Paul, Wu, Chengda, Wulfmeier, Markus, Xia, Fei, Xiao, Ted, Xie, Annie, Xie, Jinyu, Xu, Peng, Xu, Sichun, Xu, Ying, Xu, Zhuo, Yan, Jimmy, Yang, Sherry, Yang, Skye, Yang, Yuxiang, Yu, Hiu Hong, Yu, Wenhao, Yuan, Wentao, Yuan, Yuan, Zhang, Jingwei, Zhang, Tingnan, Zhang, Zhiyuan, Zhou, Allan, Zhou, Guangyao, Zhou, Yuxiang</span>
        <span>日期: 2025/10/02</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，构建通用机器人需要其对物理世界有深刻理解、具备高级推理能力以及通用且灵巧的控制能力。主流的机器人基础模型，如视觉-语言-动作（VLA）模型，旨在通过多模态预训练实现从开放词汇指令到机器人动作的端到端映射。然而，现有方法仍面临关键局限性：首先，模型通常针对单一机器人平台进行训练和微调，难以泛化到形态各异的其他机器人（具身），跨机器人技能零样本迁移能力有限；其次，在处理复杂、多步骤的长视野任务时，模型缺乏显式的内部推理过程，导致任务分解和执行能力不足，且行为对用户不透明；最后，专门针对机器人应用所需的具身推理（如空间理解、任务规划、进度估计）能力尚需提升。</p>
<p>本文针对上述痛点，提出了Gemini Robotics 1.5模型家族。其核心思路是结合一个具备先进具身推理能力的视觉语言模型（VLM）和一个支持跨具身控制与显式“思维”的VLA模型，构建一个智能体系统，使机器人能够“感知、思考、然后行动”，以解决复杂的多步骤任务。</p>
<h2 id="方法详解">方法详解</h2>
<p>Gemini Robotics 1.5模型家族包含两个核心模型：Gemini Robotics 1.5（GR 1.5），一个多具身VLA模型；以及Gemini Robotics-ER 1.5（GR-ER 1.5），一个在具身推理任务上达到先进水平的VLM。二者可结合形成一个强大的智能体框架。</p>
<p><img src="https://..." alt="模型家族与智能体框架"></p>
<blockquote>
<p><strong>图1</strong>：Gemini Robotics 1.5模型家族由VLA模型GR 1.5和VLM模型GR-ER 1.5组成。它们可以组合在一起形成一个强大的智能体框架。</p>
</blockquote>
<p><strong>整体框架与智能体系统架构</strong>：完整的智能体系统由协调器（Orchestrator）和动作模型（Action Model）组成。协调器由GR-ER 1.5实现，负责处理用户输入和环境反馈，控制整体任务流。它将复杂任务分解为可由VLA执行的简单步骤，进行成功检测以决定何时切换步骤，并可调用数字工具（如网络搜索）获取外部信息。动作模型由GR 1.5实现，它将协调器发出的指令翻译成底层机器人动作，作为一个专用工具被协调器调用。</p>
<p><strong>核心创新一：具身思维（Embodied Thinking）</strong>。这是GR 1.5的核心创新，旨在让模型在行动前进行“思考”。具体而言，GR 1.5（Thinking VLA）能够对指令和感知进行显式推理，生成自然语言思维轨迹，并将其附加到上下文窗口后再发出动作。这个过程将复杂的跨模态映射（高层指令→低层动作）分解为两个更简单的阶段：首先，利用VLM骨干的强大视觉-语言能力，将复杂任务转化为一系列具体的、短视野步骤的语言描述；其次，将这些低层语言命令直接映射到机器人动作。这提高了多步骤任务执行的鲁棒性、透明度和安全性。</p>
<p><strong>核心创新二：运动迁移（Motion Transfer, MT）</strong>。GR 1.5引入了一种新的模型架构和训练方法（MT），使其能够从异构、多具身的机器人数据中学习，形成对运动和物理交互效果的统一理解。这使得模型能够零样本控制多个机器人（如ALOHA、双臂Franka、Apollo人形机器人），而无需任何针对特定机器人的训练后微调，并实现了技能在不同机器人间的零样本迁移。</p>
<p><strong>数据与训练</strong>：训练数据集包含在ALOHA、双臂Franka和Apollo人形机器人上收集的多具身机器人数据，以及公开的文本、图像和视频数据。机器人数据涵盖了这些平台上的数千个多样化任务。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在真实机器人上进行A/B/n测试以减少环境方差，并大量使用经过精心对齐的MuJoCo仿真进行评估以加速迭代（超过90%的评估在仿真中进行）。使用了包含230个任务的基准测试集，主要报告进度得分（Progress Score）作为连续、细粒度的性能指标。</p>
<p><strong>基准对比</strong>：将GR 1.5与之前的Gemini Robotics和Gemini Robotics On-Device (GRoD)模型进行对比。评估涵盖四个泛化维度：视觉泛化、指令泛化、动作泛化和任务泛化。</p>
<p><img src="https://..." alt="泛化能力分解"></p>
<blockquote>
<p><strong>图3</strong>：GR 1.5在ALOHA、双臂Franka和Apollo人形机器人上，于四个泛化维度上均一致性地优于基线模型（Gemini Robotics和GRoD），尤其在指令、动作和任务泛化上提升显著。例如，在ALOHA的任务泛化上，GR 1.5进度得分为0.78，远高于Gemini Robotics的0.25和GRoD的0.41。</p>
</blockquote>
<p><strong>消融实验</strong>：为了探究性能提升的来源，进行了关于训练数据和MT机制的消融实验。</p>
<p><img src="https://..." alt="数据集与训练方法消融"></p>
<blockquote>
<p><strong>图4</strong>：在三个机器人平台上，GR 1.5（多具身数据+MT）均优于仅使用多具身数据但无MT的版本，以及仅使用单具身数据且无MT的版本。这证实了多具身数据的有益性，以及MT机制在放大这种正向迁移、实现技能对齐方面的关键作用。</p>
</blockquote>
<p><strong>跨具身技能迁移</strong>：构建了跨具身基准，测试模型在仅由其他机器人数据训练的任务上的表现。</p>
<p><img src="https://..." alt="跨具身基准"></p>
<blockquote>
<p><strong>图5</strong>：左图展示了零样本技能迁移的示例任务；右图显示，任何仅用单具身数据训练的模型在该基准上表现都很差，而结合了跨具身数据和MT训练的GR 1.5取得了显著更好的性能（高进度得分和高成功率）。这表明MT机制促进了不同机器人间的技能迁移。</p>
</blockquote>
<p><strong>思维对行动的影响</strong>：评估了开启“思维”模式对多步骤任务执行的影响。</p>
<p><img src="https://..." alt="多步骤任务思维效果"></p>
<blockquote>
<p><strong>图6</strong>：在ALOHA、双臂Franka和人形机器人的多步骤任务基准上，启用思维模式的GR 1.5相比关闭思维模式，在进度得分上均有显著提升（例如在ALOHA上从0.55提升至0.67）。这证明显式推理有助于分解和执行复杂任务。</p>
</blockquote>
<p><strong>GR-ER 1.5的具身推理能力</strong>：在包含15个学术基准的测试集上评估GR-ER 1.5的具身推理能力（空间推理和问答）及通用性（MMMU、GPQA、Aider Polyglot）。</p>
<p><img src="https://..." alt="具身推理与通用性对比"></p>
<blockquote>
<p><strong>图8</strong>：GR-ER 1.5在保持与同类前沿模型相当通用性的同时，实现了最先进的具身推理性能，拓展了性能帕累托边界。</p>
</blockquote>
<p><strong>复杂指向能力</strong>：GR-ER 1.5在复杂指向任务上展现出先进能力。</p>
<p><img src="https://..." alt="复杂指向性能"></p>
<blockquote>
<p><strong>图10</strong>：在5个指向和点计数基准的混合测试中，GR-ER 1.5在平均指向、空间指向、可操纵指向和点计数等类别上均优于其他前沿模型（如Gemini 2.5 Pro/Flash, GPT-5等），展示了其卓越的空间理解和指令跟随能力。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）提出了一个支持跨机器人零样本控制与技能迁移的多具身VLA模型（GR 1.5），其关键是通过新颖的运动迁移（MT）机制从异构数据中学习统一表示；2）引入了“具身思维”机制，使VLA模型能够通过显式的自然语言推理轨迹分解复杂任务，显著提升了多步骤任务性能、可解释性和恢复能力；3）推出了一个在具身推理基准上达到最先进水平、同时保持广泛通用性的VLM模型（GR-ER 1.5），为高级机器人智能体提供了强大的推理核心。</p>
<p>论文自身提到的局限性包括：尽管仿真评估与真实评估具有强排名一致性，但最终模型质量仍需真实世界评估确认；此外，运动迁移机制在具身形态差异极大（如人形与其他机器人）时的对齐效果可能减弱。</p>
<p>本工作对后续研究的启示包括：显式的、可解释的“思维”过程是提升VLA模型复杂任务处理能力和人机互信的有效途径；通过精心设计的架构和训练方法（如MT），利用多具身数据进行预训练是实现通用机器人控制的一条可行路径；在机器人学习研究中，开发高保真、与真实世界对齐的仿真评估平台可以极大加速研发迭代。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文介绍Gemini Robotics 1.5模型家族，旨在解决通用机器人需深度融合物理理解、高级推理与灵巧控制的核心问题。关键技术包括：1）新颖架构与运动转移机制，支持从异构多体现数据中学习，实现跨机器人零样本技能迁移；2）动作与多级语言推理交织的“思维VLA”，提升复杂多步骤任务分解与执行能力；3）专精具身推理的VLM模型，在视觉空间理解、任务规划等基准上达到新SOTA。实验表明，该模型能直接控制ALOHA、Franka双臂、Apollo人形等多种机器人，无需针对特定机器人进行额外训练。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.03342" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>