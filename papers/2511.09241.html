<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2511.09241" target="_blank" rel="noreferrer">2511.09241</a></span>
        <span>作者: Wei, Yuxi, Wang, Zirui, Yin, Kangning, Hu, Yue, Wang, Jingbo, Chen, Siheng</span>
        <span>日期: 2025/11/12</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在机器人学习领域，数据规模长期以来一直是一个关键瓶颈。对于人形机器人而言，人类视频和运动数据丰富且易于获取，提供了一个免费的大规模数据源。然而，如何有效挖掘原始视频、提取机器人可学习的表征，并利用它们进行可扩展学习，仍然是一个开放性问题。当前主流方法利用人类运动作为先验进行高级控制（如通过文本生成低级执行器的控制信号），但存在关键局限性：首先，人类运动分布与机器人运动不同，重定向过程复杂且会改变分布，从而限制了模态对齐；其次，部分人类运动数据无法被低级执行器执行，降低了数据质量和执行有效性；最后，现有工作受限于小规模数据（如常用的HumanML3D数据集仅包含不到30小时数据），未能充分利用当前可用的海量数据，也缺乏相应的模型缩放研究，未能充分挖掘人类运动数据对人形机器人的潜力。</p>
<p>本文针对这些痛点，提出了新的视角：直接生成高质量、可执行的机器人运动，而非仅仅依赖人类运动，并充分利用大规模人类运动数据的潜力。通过扩展数据规模并相应缩放模型，可以实现更有效的控制能力和更好的泛化性能。本文的核心思路是：首先构建一个从人类视频和运动自动衍生的大规模、高质量机器人运动数据集Humanoid-Union，然后在此基础上提出一个可缩放的、基于文本的机器人运动生成模型SCHUR，以探索数据和模型缩放对高级控制的影响。</p>
<h2 id="方法详解">方法详解</h2>
<p>SCHUR框架采用两阶段范式：第一阶段对机器人运动进行表征和量化（Tokenization），第二阶段基于文本前缀自回归生成运动令牌。其整体流程是：输入文本通过预训练的T5-XL模型转化为文本令牌作为前缀；然后，基于LLaMA架构的生成器利用前缀双向注意力机制，自回归地预测机器人运动令牌；最后，这些运动令牌通过第一阶段的解码器重建为机器人运动序列（包括根位置、根朝向、关节自由度以及虚拟关键点的位置和朝向），进而可以交给一个通用的全身跟踪器执行。</p>
<p><img src="https://arxiv.org/html/2511.09241v2/x4.png" alt="方法框架"></p>
<blockquote>
<p><strong>图4</strong>：SCHUR框架概述。包含两个阶段：第一阶段，使用改进的机器人运动表征和FSQ量化方法将运动序列离散化为令牌；第二阶段，以文本令牌为前缀，使用前缀双向注意力机制自回归生成运动令牌。</p>
</blockquote>
<p><strong>核心模块一：改进的机器人运动表征</strong>。论文发现，仅使用根位置、根朝向和关节自由度（DoFs）的“朴素表征”无法获得足够好的生成效果。因此，在运动重定向过程中，引入了通过前向运动学（FK）计算的、绑定在机器人身上的虚拟关键点的位置和朝向。这些虚拟关键点模仿了人体骨骼拓扑结构，能有效恢复人类运动风格，并在三维欧几里得空间中提供了额外的运动表征。最终的运动表征 <code>e</code> 是根位置、根朝向、关节自由度、虚拟关键点位置和朝向的拼接。</p>
<p><img src="https://arxiv.org/html/2511.09241v2/x3.png" alt="虚拟关键点"></p>
<blockquote>
<p><strong>图3</strong>：常用的SMPL人体骨架与本文绑定的虚拟关键点对比。定义的虚拟关键点拓扑结构更接近SMPL，从而能更准确地表征运动，保持更符合人类运动的风格。</p>
</blockquote>
<p><strong>核心模块二：可缩放且高效的运动量化器（Tokenizer）</strong>。为了将连续运动表征离散化，论文采用了有限标量量化（Finite Scalar Quantization, FSQ）方法，而非传统的VQ-VAE。传统VQ-VAE在码本增大时容易因 <code>argmin</code> 操作导致码本崩溃。FSQ通过一个边界函数（如Sigmoid）和取整操作进行量化，避免了 <code>argmin</code>，从而缓解了崩溃问题，支持更大的码本规模，获得了更好的重建质量和缩放特性。其损失函数直接优化解码器的重建误差。</p>
<p><strong>核心模块三：自回归的基于文本的生成器</strong>。生成阶段采用类似LLaMA的解码器-仅Transformer架构。将文本令牌作为前缀，并采用前缀双向注意力掩码：允许对文本令牌进行双向注意力计算，同时对运动令牌进行自回归预测。这使模型能充分理解文本上下文后再生成运动。损失函数是标准的下一个令牌预测的负对数似然。</p>
<p><strong>创新点</strong>：1) <strong>数据层面</strong>：构建了大规模、高质量的机器人运动数据集Humanoid-Union，并通过全身跟踪器过滤确保数据可执行性；2) <strong>表征层面</strong>：引入了虚拟关键点来丰富机器人运动表征，提升了生成质量；3) <strong>方法层面</strong>：采用FSQ量化策略，有效解决了大规模码本下的崩溃问题，使模型具备良好的缩放能力；4) <strong>流程层面</strong>：直接生成机器人运动，避免了使用人类运动先验带来的重定向和对齐损失。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在Unitree G1（29自由度）机器人上进行。使用了本文构建的Humanoid-Union数据集（超过260小时，17万条序列），并按80%/15%/5%划分训练/测试/验证集。量化器使用卷积残差块作为编码器-解码器。生成器架构与LLaMA对齐。低级执行使用一个在AMASS数据集上预训练的通用全身运动跟踪器。</p>
<p><strong>对比方法</strong>：在量化阶段，与传统的VQ-VAE进行对比。在文本生成阶段，与Human Motion（在人类运动数据上训练）、20% Data（仅使用20%数据训练）、以及MDM等方法进行对比。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>量化器缩放性能</strong>：如图5所示，在不同码本大小下，使用FSQ的SCHUR在MPJPE（平均每关节位置误差）、MPKPE（平均每关键点位置误差）和L1损失上均优于传统VQ-VAE。更重要的是，当码本增大时，VQ-VAE出现崩溃，性能无法提升甚至下降，而FSQ则能持续稳定地提升重建质量，展示了优异的缩放特性。在最大码本设置下，FSQ的码本使用率始终高于99%，而VQ则降至90%以下。</li>
</ol>
<p><img src="https://arxiv.org/html/2511.09241v2/figs/performance_comparison.png" alt="量化器性能对比"></p>
<blockquote>
<p><strong>图5</strong>：SCHUR的量化器与传统VQ-VAE在不同码本大小下的性能对比。FSQ显著优于VQ-VAE，并随着码本增大性能持续提升，而VQ则因崩溃而失效。</p>
</blockquote>
<ol start="2">
<li><strong>文本生成性能与模型缩放</strong>：如表II和图6所示，在文本到运动生成任务上，完整的SCHUR方法在FID（弗雷歇距离）和召回率（R@1, R@2, R@3）指标上均优于对比基线。具体而言，相比之前的方法，FID提升了25%（从16.9降至12.6）。图6进一步表明，随着生成器模型参数规模的增加，SCHUR能够更好地利用数据，在所有指标上持续提升文本-运动对齐质量。同时，更大的码本（得益于更好的量化性能）通常带来更好的生成结果，但当模型参数较小时，大码本难以有效学习。</li>
</ol>
<p><img src="https://arxiv.org/html/2511.09241v2/figs/model_performance_comparison_horizontal.png" alt="生成性能对比"></p>
<blockquote>
<p><strong>图6</strong>：文本生成阶段，在不同码本大小和模型参数规模下的性能对比。模型规模增大能持续提升模态对齐质量；大码本在模型足够大时优势明显。</p>
</blockquote>
<ol start="3">
<li><p><strong>消融实验</strong>：</p>
<ul>
<li><strong>量化器消融（表I）</strong>：在最大码本下对比了不同设置。“Naive Repre”（朴素表征）的性能差于使用虚拟关键点的“Ours”方法，验证了改进表征的有效性。“Human Motion”和“20% Data”的设置性能也较差，分别说明了直接使用人类运动和数据量不足的局限性。</li>
<li><strong>跟踪性能验证（表III）</strong>：将不同方法生成的运动交给全身跟踪器执行，评估成功率（Success Rate）和跟踪误差（MPJPE, MPKPE）。使用完整Humanoid-Union数据集训练的SCHUR（Ours）取得了最高的成功率（0.907）和最低的跟踪误差，与使用原始人类运动数据（Human Motion）或未经过滤的机器人原始数据（W. raw data）相比优势明显，证明了高质量数据和直接生成机器人运动对实际执行有效性的关键作用。</li>
</ul>
</li>
<li><p><strong>真实世界部署</strong>：如图7所示，SCHUR能够处理多样化的文本指令（包括上下肢运动、移动、抽象语义控制和复杂的长期任务），生成全身控制信号，并通过通用全身跟踪器在真实机器人上稳定、精确地执行。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2511.09241v2/x5.png" alt="真实部署"></p>
<blockquote>
<p><strong>图7</strong>：针对不同文本输入的真实世界部署结果。SCHUR能生成多样、高质量的全身运动，并通过跟踪器可靠执行。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1) 构建了大规模、高质量的机器人运动数据集Humanoid-Union，并提供了自动化的数据构建流程；2) 提出了可缩放学习框架SCHUR，通过改进运动表征、采用FSQ量化以及有效的生成架构，实现了高质量的文本到机器人运动生成；3) 系统性地验证了数据和模型缩放对人形机器人高级控制性能的显著提升（如37%的重建改进和25%的对齐改进），并在真实机器人上成功部署。</p>
<p><strong>局限性</strong>：论文自身提到，所构建数据集中的人类运动数据来源多样，可能包含与场景和物体的交互动作，以及一些可能超出当前机器人能力的动作，尽管经过跟踪器过滤，但数据的绝对质量和边界仍有优化空间。此外，研究主要聚焦于运动生成，与更复杂的视觉-语言-动作（VLA）模型的深度结合是未来方向。</p>
<p><strong>对后续研究的启示</strong>：本研究证明了利用海量人类视频数据通过自动化流程构建机器人数据集的可行性，以及在大规模数据上进行模型缩放的有效性。这为机器人学习领域指明了“大数据+大模型”的潜力方向。后续工作可进一步探索：1) 如何集成更多模态（如视觉、力觉）以实现更鲁棒和通用的VLA模型；2) 如何将此类生成模型与低层强化学习策略更紧密地结合；3) 继续扩大数据和模型规模，探索性能瓶颈与规律。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人学习中数据稀缺的关键瓶颈，提出利用丰富的人类视频作为大规模数据源。核心贡献是构建了Humanoid-Union大规模数据集（超260小时高质量机器人运动数据）和SCHUR可扩展学习框架。实验表明，通过数据和模型规模扩展，SCHUR显著提升了运动生成质量与文本-动作对齐能力：在MPJPE指标上重建效果提升37%，在FID指标上对齐效果提升25%，并成功在真实机器人上部署验证。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2511.09241" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>