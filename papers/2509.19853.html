<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>SAGE:State-Aware Guided End-to-End Policy for Multi-Stage Sequential Tasks via Hidden Markov Decision Process - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>SAGE:State-Aware Guided End-to-End Policy for Multi-Stage Sequential Tasks via Hidden Markov Decision Process</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.19853" target="_blank" rel="noreferrer">2509.19853</a></span>
        <span>作者: JingYuan Wang Team</span>
        <span>日期: 2025-09-24</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在机器人操作领域，多阶段顺序任务非常普遍，这类任务通常涉及状态模糊性，即视觉上相似的观察可能对应着不同的正确动作。例如，在“按按钮”任务中，机器人需要按顺序按下黄、粉、蓝三个按钮。在执行每个按钮的按压前，机器人都会抬起手臂观察整个场景，此时获得的视觉图像（显示三个按钮）几乎完全相同，但正确的动作（按压黄色、粉色或蓝色按钮）却截然不同，这构成了典型的状态模糊性挑战。</p>
<p>现有方法主要分为两类：基于记忆的方法和分层任务分解方法。基于记忆的方法（如使用RNN、Transformer-XL）通过引入历史观察来提供上下文，但其存在信息冗余、计算成本高以及难以确定合适历史长度的问题。分层方法则将策略分解为高层控制器（管理阶段切换）和底层策略（执行具体动作），虽然有助于减少模糊性，但高层控制器通常需要大量人工设计（如多层决策树），且底层原语往往过于简单和模块化，限制了灵活性，阶段切换还可能引入延迟。</p>
<p>本文针对多阶段顺序任务中的状态模糊性这一具体痛点，提出了一个新的视角：将任务建模为隐马尔可夫决策过程。其核心思路是：将视觉观察视为潜在环境状态的部分表现，并显式地将任务阶段建模为隐藏变量；通过一个状态转移网络推断隐藏状态，再让一个状态感知动作策略同时基于观察和推断的状态来生成动作，从而在不同任务阶段间实现解耦。</p>
<h2 id="方法详解">方法详解</h2>
<p>SAGE框架的整体目标是通过端到端模仿学习，训练一个基于视觉的机器人操作控制模型。其理论核心是将问题形式化为隐马尔可夫决策过程。在HMDP中，真实的环境状态（即任务阶段）是隐藏的，智能体只能接收到部分观察（如图像）。智能体需要推断隐藏状态，并基于观察和推断状态共同决策。</p>
<p><img src="https://arxiv.org/html/2509.19853v1/x3.png" alt="方法框架"></p>
<blockquote>
<p><strong>图3</strong>：SAGE方法整体流程。左侧展示了结合主动学习和软标签插值的半自动状态标注流程；右侧展示了基于隐马尔可夫决策过程的端到端模型架构，包括状态转移网络和状态感知动作策略。</p>
</blockquote>
<p>整体框架包含两个核心模块：<strong>状态转移网络</strong>和<strong>状态感知动作策略</strong>。它们被集成到一个端到端的架构中进行训练，使用专家示范动作和人工标注的状态作为监督信号。</p>
<p><strong>状态转移网络</strong>：该模块负责根据当前观察 (o_t) 和先前估计的隐藏状态 (\hat{s}<em>{t-1}) 来推断当前隐藏状态 (\hat{s}<em>t)。其设计灵感来源于HMDP中的状态推断公式。具体实现上，论文将理论分析中两个互补的概率估计项（基于观察的 (Pr(s_t|o_t)) 和基于状态转移的 (Pr(s_t|a</em>{t-1}, s</em>{t-1}))）统一到一个神经网络 (f) 中：(\hat{s}<em>t = f(\hat{s}</em>{t-1}, o_t))。网络 (f) 通过监督学习进行训练，损失函数是预测状态概率分布 (\hat{s}_t) 与真实状态标签 (s_t)（one-hot向量）之间的交叉熵损失。</p>
<p><strong>状态感知动作策略</strong>：该模块作为决策智能体，接收当前观察 (o_t) 和状态转移网络推断出的隐藏状态 (\hat{s}_t) 作为联合输入，并输出动作 (a_t = \pi(o_t, \hat{s}_t))。论文实例化了一个基于扩散的策略来生成动作。具体而言，策略网络是一个以观测编码和状态编码为条件的去噪网络。在训练时，通过最小化策略预测动作与专家示范动作之间的误差来优化，对应的奖励函数定义为负的动作误差：(r_t(\theta_\pi) = -||\pi(o_t, \hat{s}_t; \theta_\pi) - a&#39;_t||)。</p>
<p><strong>半自动状态标注流程</strong>：为了减少对隐藏状态进行人工标注的巨大成本，论文提出了一种结合主动学习和软标签插值的策略。首先，使用主动学习（基于不确定性的采样）从大量未标注的示范视频片段中选择最具信息量的少量片段（约13%）进行人工标注。然后，对于剩余的大量未标注数据，利用已训练的状态转移网络为其生成“软标签”（即概率分布），而非硬性的one-hot标签。这些软标签与人工标注的硬标签一同用于网络的进一步训练，从而大幅降低人工标注负担。</p>
<p>与现有方法相比，SAGE的创新点具体体现在：1) <strong>理论形式化</strong>：首次将具有状态模糊性的多阶段顺序任务明确建模为隐马尔可夫决策过程，为解决该问题提供了原则性框架。2) <strong>端到端实现</strong>：通过两个专门的神经模块（状态转移网络和状态感知动作策略）实现了HMDP，并集成为端到端的训练流程，避免了分层方法中高层控制器的手工设计和模块切换延迟。3) <strong>高效标注</strong>：提出的半自动标注策略显著降低了获取状态监督信号所需的人力成本。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在真实机器人上进行，使用了三个涉及状态模糊性的复杂多阶段顺序任务进行评估：<strong>Push Buttons</strong>（按顺序按下三个按钮）、<strong>Rotate Valves</strong>（按顺序旋转三个阀门）以及<strong>Assemble Kits</strong>（按顺序组装零件套件）。</p>
<p>对比的基线方法包括：1) <strong>Diffusion Policy</strong>：一种先进的反应式扩散策略。2) <strong>RDP</strong>：结合视觉-触觉反馈的扩散策略。3) <strong>HDP</strong>：基于层次结构的扩散策略。4) <strong>Hierarchical</strong>：一种手工设计高层状态机、底层使用Diffusion Policy的分层方法。</p>
<p><img src="https://arxiv.org/html/2509.19853v1/x4.png" alt="定量结果"></p>
<blockquote>
<p><strong>图4</strong>：在三个任务上的阶段成功率定量对比。SAGE在标准评估协议下达到了100%的阶段成功率，显著优于所有基线方法。</p>
</blockquote>
<p>关键实验结果如下：在标准评估设置下（每个阶段独立评估），SAGE在三个任务上均实现了<strong>100%的阶段成功率</strong>。而表现最好的基线方法（Hierarchical）在Push Buttons和Rotate Valves任务上成功率分别为86.7%和80%，在Assemble Kits任务上仅为53.3%。Diffusion Policy、RDP和HDP等反应式策略在所有任务上成功率均低于50%，凸显了状态模糊性带来的巨大挑战。</p>
<p><img src="https://arxiv.org/html/2509.19853v1/x5.png" alt="长序列执行"></p>
<blockquote>
<p><strong>图5</strong>：在50步连续执行中的累积错误数。SAGE能够完成整个长序列而不产生任何错误，而基线方法错误不断累积。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.19853v1/figure/ablation.png" alt="消融实验"></p>
<blockquote>
<p><strong>图8</strong>：消融实验结果。对比了使用不同比例人工标注数据（通过主动学习选取）时SAGE的性能。“Ours (soft)”表示使用软标签插值，“Ours (hard)”表示仅使用硬标签。结果表明，结合软标签插值，仅需约13%的片段进行人工标注，即可达到与100%人工标注相近的100%成功率。</p>
</blockquote>
<p>消融实验总结了各组件贡献：<strong>半自动标注策略的有效性</strong>是核心贡献之一。如图8所示，仅对约13%的片段进行人工标注（并通过软标签插值标注其余数据），SAGE即可保持接近100%的任务成功率。若仅使用这13%的硬标签而不进行插值（Ours (hard)），成功率会下降至73.3%。这证明了软标签插值对于利用大量未标注数据、维持高性能至关重要。此外，实验也验证了<strong>状态感知</strong>（即策略同时以观察和隐藏状态为条件）的必要性，移除状态输入会导致性能大幅下降。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：1) <strong>理论框架创新</strong>：首次将机器人多阶段顺序任务中的状态模糊性问题形式化为隐马尔可夫决策过程，为理解和解决该问题提供了新的理论基础。2) <strong>实用算法实现</strong>：设计并实现了包含状态转移网络和状态感知扩散策略的端到端模仿学习框架SAGE，并在真实机器人任务上验证了其高效性（100%成功率）和鲁棒性（长序列无错误）。3) <strong>标注效率提升</strong>：提出了结合主动学习和软标签插值的半自动状态标注流程，大幅降低了模型对昂贵人工标注的依赖（仅需约13%人工标注）。</p>
<p>论文自身提到的局限性包括：方法依赖于专家示范数据；状态转移网络和策略的联合训练可能对初始条件和标注噪声敏感；在非常动态或高度非结构化的环境中，隐藏状态的定义和推断可能变得更具挑战性。</p>
<p>本工作对后续研究的启示在于：HMDP为处理部分可观测的序列决策问题提供了一个有力的形式化工具，可扩展至更广泛的任务。半自动标注策略的思路可迁移至其他需要结构化标签的机器人学习场景。如何进一步减少对专家示范和状态标注的依赖，例如结合强化学习进行自我改进，或是利用大规模基础模型进行状态理解，是值得探索的未来方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对多阶段顺序机器人操作任务中的状态模糊性问题，提出SAGE框架。该方法将任务建模为隐马尔可夫决策过程，通过状态转移网络推断潜在任务阶段，并设计状态感知的动作策略，结合观测与隐藏状态生成动作以消除歧义。为降低标注成本，采用结合主动学习与软标签插值的半自动标注流程。在真实世界的复杂任务实验中，SAGE实现了100%的任务成功率，显著优于基线方法；消融实验表明仅需标注约13%的状态即可保持同等性能。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.19853" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>