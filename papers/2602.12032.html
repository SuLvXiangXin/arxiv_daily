<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>When would Vision-Proprioception Policies Fail in Robotic Manipulation? - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>When would Vision-Proprioception Policies Fail in Robotic Manipulation?</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.12032" target="_blank" rel="noreferrer">2602.12032</a></span>
        <span>作者: Di Hu Team</span>
        <span>日期: 2026-02-12</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，在机器人操作领域，结合视觉和本体感知（视觉-本体感知）的策略已成为主流方法。这些策略通常从视觉-本体感知数据对中学习，旨在实现精确的操作任务，如抓取和装配。然而，现有研究主要关注策略在特定任务上的成功表现，缺乏对其失败模式的系统性分析。一个关键的局限性在于，当前评估通常假设测试环境与训练环境高度一致，忽略了真实世界中普遍存在的“分布偏移”问题，即测试时的视觉或动力学条件与训练时不同。这导致我们无法确切知道已部署的策略在何时、何地以及为何会失败，从而限制了其在实际应用中的鲁棒性和可靠性。</p>
<p>本文针对这一痛点，提出了一个全新的评估视角：不再仅仅追求更高的成功率，而是系统地探究视觉-本体感知策略在面临分布偏移时的失效边界。论文的核心思路是，通过精心设计一系列涵盖视觉和动力学维度的、可控的分布偏移测试环境，对现有主流策略进行压力测试，从而量化其鲁棒性，并揭示导致其失败的关键因素。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文的核心并非提出一种新的策略学习方法，而是构建了一个系统性的评估框架（Benchmark），用于诊断现有策略的失败模式。该框架的Pipeline包含三个关键步骤：1）策略收集；2）可控环境构建；3）系统性评估。</p>
<p>首先，<strong>策略收集</strong>：论文选取了三种具有代表性的视觉-本体感知策略作为评估对象：1) <strong>BC-Z</strong>：一种基于行为克隆（Behavior Cloning）的多任务策略；2) <strong>RT-1</strong>：一种大规模、基于Transformer架构的多任务策略；3) <strong>RoboAgent</strong>：一种在多样化数据集上训练的多任务策略。这些策略代表了当前从模仿学习到大模型的不同技术路径。</p>
<p>其次，<strong>可控环境构建</strong>：这是方法的核心创新点。论文没有使用固定的测试集，而是定义了一个多维的“测试空间”。该空间由一系列可精确控制的“环境扰动”参数构成，主要分为两大类：</p>
<ul>
<li><strong>视觉扰动</strong>：包括背景干扰（如动态变化的视频背景）、目标物体外观变化（如颜色、纹理）、以及相机视角变化。</li>
<li><strong>动力学扰动</strong>：包括机器人本体参数变化（如关节摩擦系数、执行器增益）和外部干扰（如施加在机器人末端或物体上的持续力/扭矩）。</li>
</ul>
<p>通过独立或组合地调整这些参数，可以生成大量与训练分布存在不同程度偏移的测试环境，从而模拟真实世界中的各种不确定性。</p>
<p>最后，<strong>系统性评估</strong>：在构建的测试环境中执行收集到的策略，并记录其任务成功率。关键的分析在于观察成功率随着某个扰动参数强度增加而下降的曲线，从而定位策略的“失效边界”。此外，论文还设计了“恢复实验”，即在策略即将失败时，将环境重置为无扰动的状态，观察策略是否能恢复执行，以此判断失败是由于瞬态干扰还是策略已彻底迷失。</p>
<p><img src="https://i.imgur.com/r7mNq0H.png" alt="评估框架概览"></p>
<blockquote>
<p><strong>图1</strong>：系统性评估框架概览。左侧展示了从视觉和动力学两个维度构建的可控测试环境空间。右侧展示了在该空间中对不同策略（如BC-Z, RT-1）进行压力测试，并绘制其性能（成功率）随扰动强度变化的曲线，以揭示失效边界。</p>
</blockquote>
<p>与现有仅报告单一成功率的评估方法相比，本文的创新点具体体现在：1) <strong>评估视角的转变</strong>：从“表现多好”转向“何时失败”；2) <strong>评估维度的系统性</strong>：明确且独立地控制视觉和动力学扰动，允许进行归因分析；3) <strong>评估结果的诊断性</strong>：通过性能-扰动曲线和恢复实验，能够定量和定性地诊断失败原因（例如，是感知混淆还是控制不稳定）。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验平台与数据集</strong>：实验在模拟器中进行，使用了包含7个常见操作任务（如开门、拉开抽屉、拿起物体等）的测试集。Baseline方法即为上文提到的三种策略：BC-Z, RT-1和RoboAgent。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>所有策略都对分布偏移敏感</strong>：即使在轻度扰动下，所有策略的性能都显著下降。例如，在加入动态视频背景后，RT-1在“拿起海绵”任务上的成功率从<del>95%骤降至</del>20%。</li>
<li><strong>视觉与动力学扰动的复合效应</strong>：视觉和动力学扰动同时存在时，性能下降最为剧烈，且不是简单的线性叠加，表明策略难以处理跨模态的联合分布偏移。</li>
<li><strong>不同策略的鲁棒性差异</strong>：RT-1整体上表现出更强的鲁棒性，尤其是在视觉扰动方面。BC-Z对动力学扰动更为敏感。RoboAgent在某些任务上表现稳健，但在其他任务上波动较大，说明其泛化能力不均衡。</li>
</ol>
<p><img src="https://i.imgur.com/6fLpQzE.png" alt="性能随扰动强度变化曲线"></p>
<blockquote>
<p><strong>图2</strong>：不同策略在“开门”任务中，面对不断增加的目标物体颜色扰动（左图）和关节摩擦扰动（右图）时的成功率变化曲线。此图直观展示了策略的失效边界，例如RT-1在颜色扰动下衰减较慢，而BC-Z对摩擦增加极为敏感。</p>
</blockquote>
<p><img src="https://i.imgur.com/9fGgHvY.png" alt="恢复实验示例"></p>
<blockquote>
<p><strong>图3</strong>：恢复实验的定性结果。左列：策略在持续外力干扰下失败。右列：在相同时间点撤除外力后，RT-1策略能够恢复并完成任务，而BC-Z策略则继续失败。这表明RT-1保持了更好的状态估计和意图跟踪能力。</p>
</blockquote>
<p><strong>消融实验分析</strong>：<br>论文通过组合不同的扰动类型进行了深入的消融研究，主要结论如下：</p>
<ul>
<li><strong>视觉扰动的贡献</strong>：背景干扰和物体外观变化对策略性能影响最大，尤其是对于依赖特定颜色或纹理线索的策略。</li>
<li><strong>动力学扰动的贡献</strong>：关节摩擦的变化对需要精细力控的任务（如装配）影响致命，而执行器增益变化则更容易导致系统不稳定和震荡。</li>
<li><strong>跨模态干扰</strong>：当视觉扰动（如模糊）掩盖了关键的状态信息时，策略对动力学扰动的容忍度会进一步降低，这揭示了感知不确定性对控制环路的放大效应。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>提出了一个系统性评估视觉-本体感知策略失效模式的框架</strong>，将评估重点从绝对性能转移到对分布偏移的鲁棒性上。</li>
<li><strong>揭示了当前先进策略在视觉和动力学分布偏移下的脆弱性</strong>，并通过可控实验定量刻画了其失效边界，为理解策略局限性提供了实证依据。</li>
<li><strong>发现了不同策略架构（如Transformer vs. MLP）在应对不同类型扰动时的差异性</strong>，为未来设计更鲁棒的策略提供了方向。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到的局限性包括：1) 实验仅在模拟环境中进行，虽然可控但可能与现实世界存在差距；2) 评估的策略数量有限，未来需要扩展到更多样化的策略家族；3) 定义的扰动维度虽具代表性，但未能覆盖所有可能的现实世界偏移（如部件磨损、软体变形等）。</p>
<p><strong>对后续研究的启示</strong>：<br>本工作指明，追求在狭窄分布上更高的成功率可能是一个误区。未来的研究应更注重策略的<strong>分布外泛化（OOD Generalization）</strong> 能力。启示包括：1) <strong>训练数据与范式</strong>：需要在更广泛、更具挑战性的分布偏移数据上进行训练，或采用域随机化、对抗训练等增强鲁棒性的技术。2) <strong>策略架构设计</strong>：需要设计能更好解耦感知与控制、或显式建模不确定性的架构。3) <strong>评估标准</strong>：社区应建立包含系统化分布偏移测试的基准，以更全面地衡量策略的实用价值。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>您尚未提供论文正文内容。仅根据标题《When would Vision-Proprioception Policies Fail in Robotic Manipulation?》推断，该论文可能探讨在机器人操作任务中，依赖视觉与本体感知的决策策略在何种场景或条件下会失效。

为撰写符合要求的总结，请您补充论文的正文或核心内容，我将据此提取具体问题、方法及实验结论。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.12032" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>