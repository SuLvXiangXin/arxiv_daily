<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.11109" target="_blank" rel="noreferrer">2509.11109</a></span>
        <span>作者: Zhigong Song Team</span>
        <span>日期: 2025-09-16</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>在模仿学习领域，人形机器人的学习效果通常取决于专家演示的质量与多样性以及感知表示的质量。机器人对环境的感知主要通过RGB图像实现，尽管计算机视觉取得了巨大进展，但学习适用于机器人应用的鲁棒且通用的视觉表示仍然是一个重大挑战。现有方法如高效多尺度注意力（EMA）模块擅长目标检测，能有效增强特征表示，但其仅关注跨空间特征增强，忽略了频域信息。与此同时，小波变换（如离散小波变换DWT）是捕获频域特征的强大工具，在视觉任务中已展现出优势。本文针对EMA模块在特征表示中缺乏频域信息这一具体痛点，提出将小波变换与注意力机制相结合，以更全面地捕获多尺度特征。核心思路是：提出一个名为频率增强小波变换器（FEWT）的模仿学习框架，通过其两个核心模块——频率增强高效多尺度注意力（FE-EMA）和时间序列离散小波变换（TS-DWT）——动态融合跨空间与频域特征，并增强对时间序列多尺度特征的捕捉，从而提升人形机器人的感知表示与任务成功率。</p>
<h2 id="方法详解">方法详解</h2>
<p>FEWT的整体框架基于动作分块变换器（ACT）策略，并训练为一个条件变分自编码器（CVAE），包含编码器和解码器。编码器将动作序列、关节观测和惯性测量单元（IMU）数据压缩为“风格变量”z。解码器则以三个不同视角的图像、关节位置、IMU数据和z为条件，使用变换器编码器生成特征，再通过变换器解码器预测未来k步的动作序列。在测试阶段，z被设为零。</p>
<p><img src="https://..." alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：频率增强小波变换器（FEWT）的模型框架。(a) FEWT的详细架构；(b) 频率增强高效多尺度注意力（FE-EMA）模块的网络架构；(c) 时间序列离散小波变换（TS-DWT）模块的网络架构。</p>
</blockquote>
<p>框架的核心创新在于两个新模块：FE-EMA和TS-DWT。</p>
<ol>
<li><strong>频率增强高效多尺度注意力（FE-EMA）</strong>：此模块在EMA基础上进行了两项关键改进。首先，<strong>频域增强</strong>：利用（哈尔）小波变换将输入特征图X分解为低频近似分量（cA）和水平（cH）、垂直（cV）、对角线（cD）三个方向的高频细节分量，以捕获多尺度频域特征。其次，<strong>自适应融合</strong>：通过一个可学习的标量权重α，动态调整跨空间特征（X_spatial）与经过小波处理后的频域特征（X_fre）的融合比例（X_fused = α·X_spatial + (1-α)·X_fre）。权重α由全局平均池化和线性层生成。该模块还采用分组卷积处理下采样特征，在减少计算量（FLOPs）的同时提升性能（如表I所示）。</li>
<li><strong>时间序列离散小波变换（TS-DWT）</strong>：本文将DWT的创新性应用扩展到时间序列建模。该模块将输入的时间序列张量通过DWT分解为低频（cA）和高频（cD）分量，上采样拼接后，使用一维卷积（Conv1d）进行特征混淆，再通过全连接层计算频域注意力权重，最终与输入张量相乘得到增强后的时间序列特征输出。</li>
</ol>
<p>与现有方法相比，创新点具体体现在：1) 将小波变换引入视觉注意力机制，首次在机器人感知中实现了跨空间与频域特征的自适应平衡融合；2) 将主要用于图像处理的DWT拓展至时间序列分析，增强了模型对动作序列中多尺度时间特征的捕捉能力；3) 整体框架为即插即用式，可有效集成于现有的ACT等模仿学习基线中。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在MuJoCo仿真环境和真实世界人形机器人平台（HBK）上进行。使用了多个仿真与真实任务数据集进行评估，包括立方体转移（Cube Transfer）、双手插入（Bimanual Insertion）、积木搭建（Building blocks）、抽屉存储（Drawer Storage）等（任务细节见表II、表IV）。对比的基线方法包括原始ACT、EMA+ACT、扩散策略（DP）的DDPM和DDIM版本。</p>
<p><strong>关键实验结果</strong>：在仿真任务中，FEWT将原始ACT基线的成功率最高提升了30%（例如在双手插入任务的“插入”阶段，从32%提升至62%，见表III）。在真实世界移动双手操作任务中，FEWT（带IMU数据）能将ACT基线的成功率提升6-12%（见表IV、V）。例如，在“玩偶存储”任务中，成功率从70%提升至82%。</p>
<p><img src="https://..." alt="消融实验表III"></p>
<blockquote>
<p><strong>表III</strong>：ACT仿真任务消融实验的成功率（%）对比。结果表明，单独使用FE-EMA或TS-DWT模块均能提升性能，而二者结合（FEWT）效果最佳，尤其在复杂任务（如Bimanual Insertion）上提升显著。</p>
</blockquote>
<p><img src="https://..." alt="对比实验表V"></p>
<blockquote>
<p><strong>表V</strong>：不同机器人学习策略在仿真与真实任务上的成功率对比实验。FEWT（带IMU）在绝大多数任务上超越了ACT和扩散策略（DP），展示了其优越性。</p>
</blockquote>
<p><img src="https://..." alt="Grad-CAM可视化图3"></p>
<blockquote>
<p><strong>图3</strong>：仿真与真实任务的热力图可视化对比。使用Grad-CAM可视化模型注意力区域。可见，在骨干网络ResNet18中引入FE-EMA模块后，模型对任务关键区域（如物体、抓手）的关注更加集中和准确，这解释了成功率提升的原因。</p>
</blockquote>
<p><img src="https://..." alt="动态权重α变化图6"></p>
<blockquote>
<p><strong>图6</strong>：训练过程中FE-EMA模块动态权重α的变化可视化。在立方体转移和双手插入任务中，α值在训练过程中动态调整，表明模型能够自适应地平衡跨空间与频域特征的融合比例。</p>
</blockquote>
<p><strong>消融实验总结</strong>：表III的消融实验清晰展示了各组件贡献。FE-EMA模块在提升特征提取能力上作用关键（如双手插入任务提升26%）；TS-DWT模块对优化时间序列预测也有明确贡献（提升10%）；两者结合（FEWT）实现了最佳性能，证明了模块设计的有效性。此外，表V表明集成移动底盘IMU数据进一步提升了在动态真实任务中的性能。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：1) 开发了包含人形机器人HBK和外骨骼式遥操作舱的硬件平台，用于收集拟人化动作数据；2) 提出了创新的FEWT模仿学习框架，其FE-EMA模块通过小波变换与自适应融合首次实现了对视觉特征跨空间与频域信息的平衡考量，TS-DWT模块则将小波变换成功应用于时间序列建模以捕获多尺度时间特征；3) 通过详尽的仿真与真实实验验证了FEWT的优越性，其性能显著超过ACT、扩散策略等主流方法，并利用Grad-CAM可视化等手段对模型机理进行了解释。</p>
<p>论文自身提到的局限性包括：扩散策略因高计算量限制了实时图像处理，而本文未明确讨论FEWT的推理速度或计算复杂度是否仍存在瓶颈。此外，实验主要围绕桌面操作任务，在更复杂、非结构化环境中的泛化能力有待进一步验证。</p>
<p>本文的启示在于：将信号处理领域的经典工具（如小波变换）与深度学习模型（如Transformer）结合，是增强机器人感知表示的一条有效路径。关注特征表示在频域的特性，并设计机制实现与空间域特征的自适应融合，对未来开发更鲁棒、高效的机器人视觉感知模型具有借鉴意义。同时，构建低成本、易用的硬件平台与数据收集系统，对于推动仿人机器人算法研究至关重要。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对仿人机器人感知中视觉表示缺乏频域信息的问题，提出了一种名为FEWT的模仿学习框架。其核心技术包括频率增强高效多尺度注意力（FE-EMA）模块和时序离散小波变换（TS-DWT），通过小波分解与残差网络结合，动态融合跨空间与频域的多尺度特征，以增强模型鲁棒性。实验表明，该框架在仿真任务中将先进算法（ACT）的成功率提升高达30%，在真实世界中提升6-12%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.11109" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>