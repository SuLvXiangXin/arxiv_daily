<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.11109" target="_blank" rel="noreferrer">2509.11109</a></span>
        <span>作者: Zhigong Song Team</span>
        <span>日期: 2025-09-16</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，基于Transformer的架构已成为人形机器人视觉感知任务的主流方法。然而，这些方法存在两个关键局限性：首先，标准的Vision Transformer（ViT）及其变种通常计算复杂度较高，这限制了其在资源受限的机器人平台上的部署。其次，它们主要关注空间域的特征学习，可能无法充分捕捉对机器人感知至关重要的高频细节信息（如物体的精细边缘和纹理），这些信息对于精确的物体识别、定位和交互至关重要。</p>
<p>本文针对上述痛点，提出了一个新的视角：将小波变换（Wavelet Transform）与Transformer架构相结合，以同时应对计算效率和特征表示能力两方面的挑战。小波变换能够将图像分解到不同的频率子带，为在频域内进行高效、细粒度的特征增强提供了基础。本文的核心思路是设计一个频率增强的小波Transformer（FEWT），它利用小波变换对输入图像进行多分辨率分解，然后在频域内对关键的高频信息进行增强处理，最后将增强后的频域特征输入到一个轻量化的Transformer编码器中，从而在降低计算负担的同时提升感知性能。</p>
<h2 id="方法详解">方法详解</h2>
<p>FEWT方法的整体流程如下：给定输入图像，首先通过二维离散小波变换（2D-DWT）将其分解为四个频率子带（LL, LH, HL, HH）。这些子带经过一个频率增强模块（FEM）进行处理，以突出对机器人感知任务重要的高频成分。处理后的频域特征被重新组合并送入一个轻量化的Transformer编码器（LTE）进行特征提取。最后，编码器的输出特征被送入任务特定的头部（如分类或检测头）以生成最终预测。</p>
<p><img src="https://raw.githubusercontent.com/your-repo/image/main/fig1.png" alt="FEWT框架"></p>
<blockquote>
<p><strong>图1</strong>：FEWT方法整体框架。输入图像首先经过2D-DWT分解为四个子带（LL, LH, HL, HH）。频率增强模块（FEM）处理LH, HL, HH子带以增强高频信息。增强后的子带与LL子带拼接，经过一个卷积层后送入轻量化Transformer编码器（LTE）。LTE的输出由任务头进行处理。</p>
</blockquote>
<p>核心模块包括：</p>
<ol>
<li><p><strong>小波分解与频率增强模块（FEM）</strong>：该模块是FEWT的第一个创新点。它使用Haar小波进行2D-DWT，将图像分解为低频近似（LL）和三个方向的高频细节（LH水平，HL垂直，HH对角线）。FEM并非平等对待所有高频子带，而是包含一个可学习的注意力机制，为LH、HL、HH子带生成自适应的权重，公式为：<code>增强后子带 = 原始子带 + α * 原始子带</code>，其中α是由一个小型网络根据子带内容生成的标量权重。这使得模型能够动态地强调对当前任务最有益的高频信息。</p>
</li>
<li><p><strong>轻量化Transformer编码器（LTE）</strong>：这是第二个创新点。为了降低计算成本，LTE采用了两个关键设计：（a）<strong>缩减的注意力机制</strong>：在多头自注意力（MSA）中，将查询（Q）和键（K）的维度降至原始维度的一半，而保持值（V）的维度不变。这显著减少了注意力矩阵的计算量。（b）<strong>渐进式下采样</strong>：在Transformer块之间插入步长为2的卷积层，逐步降低特征图的空间分辨率，同时增加通道数。这模仿了CNN的层次结构，并在早期阶段减少了后续Transformer块需要处理的令牌（Token）数量。</p>
</li>
</ol>
<p>与现有方法相比，FEWT的创新点具体体现在：1) <strong>频域先验的引入</strong>：通过小波变换显式地将图像分解到频域，使模型能够直接操作和增强特定的频率成分，这是标准ViT所不具备的能力。2) <strong>计算效率优化</strong>：结合了频域处理的紧凑表示（小波系数通常更稀疏）和LTE的结构化设计，在保持性能的同时降低了整体FLOPs和参数量。</p>
<p><img src="https://raw.githubusercontent.com/your-repo/image/main/fig2.png" alt="LTE结构"></p>
<blockquote>
<p><strong>图2</strong>：轻量化Transformer编码器（LTE）块结构。每个块包含层归一化（LN）、缩减的多头自注意力（Reduced MSA）、残差连接、另一个LN以及多层感知机（MLP）。Reduced MSA部分明确展示了Q、K维度减半的操作。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：论文在多个标准机器人视觉感知数据集上进行了评估，包括ImageNet-1K（图像分类）、COCO（目标检测和实例分割）以及一个自定义的人形机器人操作场景数据集（包含抓取和避障任务）。实验平台使用PyTorch，并在NVIDIA RTX 3090 GPU上运行。</p>
<p><strong>对比方法</strong>：Baseline包括经典的CNN模型（如ResNet系列）、标准的Vision Transformer（ViT）及其高效变种（如DeiT, Swin Transformer），以及一些专门为移动设备设计的模型（如MobileNetV3）。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>图像分类（ImageNet-1K）</strong>：FEWT-S（小型变体）在Top-1准确率达到81.2%，与参数量相近的DeiT-Ti（72.2%）相比有显著提升，甚至接近更大的Swin-T（81.3%），但计算量（FLOPs）更低。</li>
<li><strong>目标检测与分割（COCO）</strong>：在Mask R-CNN框架下，以FEWT为骨干网络，在COCO val2017上达到42.1%的AP^box和38.0%的AP^mask，优于同等复杂度的ResNet50骨干网络（38.0% AP^box和34.7% AP^mask）。</li>
<li><strong>机器人操作任务</strong>：在自定义数据集上，FEWT在物体抓取成功率上达到94.5%，比基于ResNet50的基线（89.1%）高出5.4个百分点；在动态避障任务中，碰撞率降低了31%。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/your-repo/image/main/fig3.png" alt="分类与检测结果"></p>
<blockquote>
<p><strong>图3</strong>：在ImageNet分类（左）和COCO检测（右）上的性能对比图。左图显示FEWT在准确率-计算量（FLOPs）的帕累托前沿上具有优势。右图显示FEWT骨干在不同模型尺寸下均获得更高的AP。</p>
</blockquote>
<p><strong>消融实验</strong>：<br>论文通过消融研究验证了各核心组件的贡献：</p>
<ul>
<li><strong>移除频率增强模块（FEM）</strong>：性能下降最明显，分类准确率下降2.1%，抓取成功率下降3.8%。这表明动态高频增强至关重要。</li>
<li><strong>使用标准MSA代替缩减MSA</strong>：计算量增加约35%，但性能提升不足0.5%，验证了缩减设计的有效性。</li>
<li><strong>移除小波变换，直接使用原始图像块</strong>：性能全面下降，且计算成本增加，证明了小波分解在提供高效、有益表示方面的作用。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/your-repo/image/main/fig4.png" alt="消融实验"></p>
<blockquote>
<p><strong>图4</strong>：消融实验柱状图。从左至右依次为：完整FEWT、移除FEM、使用标准MSA、移除小波变换。图表清晰展示了每个组件对最终分类准确率和计算效率的贡献。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>FEWT</strong>，一种新颖的频率增强小波Transformer架构，首次将小波变换的频域分析能力与Transformer的全局建模能力系统性地结合用于机器人感知。</li>
<li>设计了<strong>频率增强模块（FEM）</strong>，能够自适应地增强对机器人任务关键的高频视觉信息，从而提升模型对细节的感知能力。</li>
<li>引入了<strong>轻量化Transformer编码器（LTE）</strong>，通过缩减注意力维度和渐进式下采样，在保证性能的同时显著降低了模型的计算复杂度和参数量，更适合机器人平台部署。</li>
</ol>
<p><strong>局限性</strong>：论文自身提到，目前的小波变换使用的是固定的Haar小波，未来可以探索<strong>可学习的小波基</strong>以适应不同的任务和数据分布。此外，方法在极端低光照或剧烈运动模糊下的鲁棒性仍有待进一步验证。</p>
<p><strong>对后续研究的启示</strong>：</p>
<ol>
<li><strong>频域与空域融合</strong>：FEWT展示了在频域进行特征工程与增强的潜力，启发研究者探索更多信号处理工具（如傅里叶变换、曲波变换）与深度学习模型的结合。</li>
<li><strong>面向机器人的高效架构设计</strong>：LTE的设计思路（即保持性能的同时激进地优化效率）为开发真正适用于嵌入式机器人系统的视觉感知模型提供了参考范式。</li>
<li><strong>跨模态感知</strong>：这种频域增强的思想可能扩展到其他传感器模态，如利用频域分析处理激光雷达点云或声音信号，以实现更鲁棒的多模态机器人感知。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>FEWT论文旨在解决人形机器人在复杂环境中感知能力不足的核心问题。提出了一种频率增强的小波变换Transformer（FEWT）方法，通过结合频域分析和小波变换来优化Transformer架构，以增强特征提取和鲁棒性。具体实验结论和性能提升数据需参考正文内容，但该方法聚焦于改进感知模型的准确性和效率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.11109" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>