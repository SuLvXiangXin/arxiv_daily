<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Sequential Multi-Object Grasping with One Dexterous Hand - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Sequential Multi-Object Grasping with One Dexterous Hand</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2503.09078" target="_blank" rel="noreferrer">2503.09078</a></span>
        <span>作者: He, Sicheng, Shangguan, Zeyu, Wang, Kuanning, Gu, Yongchong, Fu, Yuqian, Fu, Yanwei, Seita, Daniel</span>
        <span>日期: 2025/03/12</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前灵巧手抓取研究主要集中于单物体场景，这未能充分利用灵巧手的高自由度潜力。在多物体抓取领域，现有方法如MultiGrasp专注于同时抓取紧密相邻的多个物体，其适用性受限；另一些方法则假设手部姿态固定或需要人工将物体放置于手中，缺乏自主性。本文针对一个相对未被探索的领域：自主的顺序多物体抓取，即机器人需先抓取并稳固持有一个物体，然后再去抓取第二个物体，且两个物体可能相距较远。本文的核心思路是：首先合成并验证仅使用手部部分连杆（手指）的单物体抓取姿态，然后将这些已验证的单物体抓取姿态合并，构建出可行的顺序多物体抓取配置，并训练一个基于点云条件的扩散模型来生成抓取姿态。</p>
<h2 id="方法详解">方法详解</h2>
<p>SeqMultiGrasp系统的整体流程分为离线数据合成与在线执行两大部分。离线阶段：1) 定义顺序抓取的手部配置与抓取类型；2) 基于改进的可微分力闭合算法合成单物体抓取候选；3) 在物理仿真器中进行混合验证以筛选稳定可行的抓取；4) 合并互不冲突的单物体抓取以构建多物体抓取配置数据库。在线阶段：5) 使用基于点云条件训练的扩散模型为新的物体对生成抓取姿态；6) 通过启发式的运动规划和抓取执行策略在真实世界中完成顺序抓取。</p>
<p><img src="https://arxiv.org/html/2503.09078v2/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：SeqMultiGrasp方法总览。(a) 不同抓取类型的接触候选点，红点和蓝点分别用于捏取式和侧握式抓取。(b) 多物体抓取配置生成：将验证过的单物体抓取合并为可行的多物体抓取。(c) 真实世界抓取提议过程：基于点云条件的扩散模型生成抓取姿态。(d) 基于启发式的顺序抓取执行示意图。</p>
</blockquote>
<p>核心模块与技术细节如下：</p>
<ol>
<li><strong>手部配置与抓取风格定义</strong>：系统将顺序抓取两个物体的过程分解为两种抓取类型。首先是<strong>捏取式抓取</strong>，使用拇指、食指和中指的任何组合抓取并提起第一个物体。其次是<strong>侧握式抓取</strong>，使用无名指和手掌来抓取第二个物体。这一策略是基于Allegro手的硬件特性 empirically 确定的。</li>
<li><strong>单物体抓取合成</strong>：基于可微分力闭合框架，将抓取合成转化为能量函数最小化问题。能量函数E包含力闭合项、接触点距离惩罚项、穿透惩罚项、手部自穿透惩罚项和关节限位惩罚项。为了适配顺序多物体抓取，本文进行了关键修改：将接触候选点限制在特定手部连杆上（分别对应两种抓取风格）；改进了初始化方法以更适合桌面场景并偏向于捏取和侧握；采用了针对顺序抓取稳定性的混合验证策略。</li>
<li><strong>抓取仿真验证</strong>：在ManiSkill物理仿真器中进行混合验证。<strong>旋转鲁棒性</strong>验证：测试抓取在六个轴对齐重力方向下的稳定性，物体需在2.5秒内保持与手接触。<strong>执行可行性</strong>验证：检查抓取执行过程中是否与环境发生碰撞。通过验证的抓取才被保留。</li>
<li><strong>多物体抓取合并</strong>：将已验证的单物体抓取姿态进行合并，前提是它们所使用的手部连杆和关节完全不相交。合并时，抓取物体的手指关节角按其对应抓取设置，未参与抓取的手指关节角则随机从某个单物体抓取中继承。</li>
<li><strong>基于扩散模型的姿态生成</strong>：为了高效地为新物体对生成抓取姿态，训练了一个条件扩散模型。模型以多个物体的点云为条件，学习去噪并重建手部配置H（包括关节角θ和各物体相对于手的位姿T_j）。网络采用PointNet++提取点云特征，并使用SVD确保预测的旋转矩阵正交性。</li>
<li><strong>启发式执行策略</strong>：采用简单的“挤压-提起”流程，避免复杂的强化学习。首先运动规划到抓取姿态附近的无碰撞预抓取位，然后缓慢接近目标。手部关节控制分两步：先移动到<strong>预抓取关节位置</strong>（指定指尖沿局部x轴缩回2.5厘米），然后移动到<strong>目标关节位置</strong>（指尖尝试相对于原始位置向前移动3厘米）。</li>
</ol>
<h2 id="实验与结果">实验与结果</h2>
<ul>
<li><strong>实验平台与数据集</strong>：使用Franka Panda机械臂和四指Allegro手。仿真实验在ManiSkill中进行，真实实验在实物系统上完成。测试物体来自YCB、ContactDB和Omni6DPose数据集，共选用8个用于捏取抓取的物体和8个用于侧握抓取的物体（仿真与真实物体集合有重叠但不完全相同）。</li>
<li><strong>对比方法</strong>：论文主要进行了两种设置的对比实验：<strong>合成抓取</strong>：直接使用离线合成并验证的抓取姿态进行执行。<strong>学习抓取</strong>：使用训练的扩散模型生成抓取姿态进行执行。合成抓取的结果也作为学习抓取的性能基线。</li>
<li><strong>关键实验结果</strong>：<ol>
<li><strong>单物体抓取合成成功率</strong>：如表I所示，由于使用了更少的手部连杆和严格的验证标准，单物体抓取合成成功率较低（捏取抓取在0.1%-3.3%之间，侧握抓取在1.2%-5.6%之间），但并行化处理使其可行。</li>
<li><strong>仿真多物体抓取成功率</strong>：<br><img src="https://arxiv.org/html/2503.09078v2/x4.png" alt="仿真结果热力图"><blockquote>
<p><strong>图4</strong>：仿真中合成抓取的顺序抓取成功率热力图（基于25次试验）。纵轴为第一个（捏取）物体索引，横轴为第二个（侧握）物体索引。大多数物体组合成功率超过80%，四个达到100%，最低为56%（涉及不稳定的柠檬）。<br>合成抓取在64个物体组合上的平均成功率为**84.8%<strong>。基于扩散模型的学习抓取在1600次仿真试验中的平均成功率为</strong>65.8%**。</p>
</blockquote>
</li>
<li><strong>真实世界多物体抓取成功率</strong>：<br><img src="https://arxiv.org/html/2503.09078v2/x5.png" alt="真实世界试验示例"><blockquote>
<p><strong>图5</strong>：SeqMultiGrasp在仿真（首行）和真实世界（其余行）的试验示例。前三个图像展示抓取第一个物体，后三个展示旋转手部并抓取第二个物体。最后一行展示了一个代表性失败模式：在抓取第二个物体时失去了对第一个物体（百事可乐罐）的控制。<br>在90次使用合成抓取的真实试验中，平均成功率为**53.3%<strong>。在90次使用扩散模型生成抓取的真实试验中，平均成功率为</strong>56.7%**。学习模型的表现与直接执行合成抓取相当，甚至略优，表明其具有良好的泛化能力。</p>
</blockquote>
</li>
</ol>
</li>
<li><strong>消融实验与组件贡献</strong>：论文虽未设置严格的模块消融实验，但通过对比“合成抓取”与“学习抓取”的结果，间接证明了扩散模型能够有效学习从物体点云到可行抓取姿态的映射，其性能可与精心合成验证的抓取库相媲美，且避免了针对新物体对进行耗时的优化合成。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出了一种新颖的、用于生成物理可行的顺序多物体抓取配置的合成流程，包括改进的单物体抓取合成、混合验证和抓取合并策略；2) 构建了一个完整的集成系统（SeqMultiGrasp），首次在真实世界中实现了使用灵巧手的自主顺序多物体抓取；3) 进行了大规模的仿真与真实世界实验（总计180次真实试验），验证了方法的有效性，并展示了基于扩散模型的抓取生成是一个有前景的方向。</p>
<p>论文提到的局限性包括：抓取执行依赖于预定义的手指分配（捏取与侧握），可能限制灵活性；启发式执行策略可能引发意外碰撞导致失败；目前仅专注于顺序抓取两个物体。</p>
<p>这项工作对后续研究的启示在于：为灵巧手操纵开辟了顺序多物体抓取这一新方向；证明了从合成数据中学习抓取策略的可行性；其系统框架（合成-验证-合并-学习）可扩展用于更多物体、更复杂的抓取序列或其他灵巧操作任务。未来的工作可以探索更通用的抓取风格、更鲁棒的执行策略以及端到端的学习方法。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出SeqMultiGrasp系统，旨在解决使用单只高自由度灵巧手顺序抓取多个物体的难题。核心方法是先合成并验证仅使用部分手指的单物体抓取姿态，再合并为多物体抓取配置；实际部署时采用基于点云条件的扩散模型生成抓取姿态，并结合启发式执行策略。实验表明，该系统在模拟和真实场景中分别达到65.8%和56.7%的平均抓取成功率。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2503.09078" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>