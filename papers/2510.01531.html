<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Information Seeking for Robust Decision Making under Partial Observability - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Information Seeking for Robust Decision Making under Partial Observability</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.01531" target="_blank" rel="noreferrer">2510.01531</a></span>
        <span>作者: Tsung-Wei Ke Team</span>
        <span>日期: 2025-10-02</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>目前，基于大型语言模型（LLM）的规划智能体已被广泛用于零样本自主决策，并在交互环境中通过反馈生成和修订动作序列。在部分可观测性（Partial Observability）场景下，现有研究主要侧重于恢复隐藏知识或识别用户指令中缺失的信息。然而，这些方法普遍忽视了一个关键挑战：智能体的内部动态模型（即其对环境状态如何随动作变化的预设）与实际环境动态之间存在不匹配。如果缺乏信息丰富的观测来重新对齐，智能体会形成对潜在状态的不准确信念，从而导致系统性错误的规划。</p>
<p>本文针对智能体内部动态与环境真实动态不匹配这一具体痛点，提出了一个新视角：将信息寻求（Information Seeking）作为决策循环中一个显式的、有计划的行为，而不仅仅是任务规划失败后的被动反应。核心思路是：通过提示LLM主动规划并执行诊断性动作来验证其理解、检测环境变化或测试假设，从而在生成或修订任务导向计划之前，先收集信息以对齐内部动态与外部环境。</p>
<h2 id="方法详解">方法详解</h2>
<p>InfoSeeker是一个将信息寻求与任务导向规划紧密集成在闭环决策过程中的LLM框架。其目标是主动收集信息性观测并纠正LLM预设的内部动态误差，从而在动态和观测均不确定的部分可观测环境中做出最优决策。</p>
<p><img src="https://arxiv.org/html/2510.01531v1/x2.png" alt="系统概览"></p>
<blockquote>
<p><strong>图2</strong>：InfoSeeker系统概览。该框架在一个闭环过程中集成了信息寻求（右上）和任务导向规划（左下）。智能体首先制定并执行策略以获取缺失知识，在生成更有效的任务计划之前解决其内部动态的认知差距。</p>
</blockquote>
<p>整体流程是迭代式的：智能体首先分析过去的交互轨迹以识别不确定性，并采取行动收集信息；接着，它检查由此产生的信息寻求轨迹并细化任务导向计划。通过将信息寻求纳入决策循环，InfoSeeker有效地优化其信念状态，提升了在不确定环境下的性能。</p>
<p>核心模块包括：</p>
<ol>
<li><strong>信息寻求</strong>：与先前主要关注任务指令缺失信息的工作不同，本文提出了一种通用的提示策略。该策略首先引导LLM基于当前观测、先前计划和交互历史进行推理，然后识别有针对性的探索性动作。当检测到不一致时，智能体可以假设潜在错误、设计聚焦实验来测试其假设，或检测环境动态的变化。这个由推理驱动的过程同时支持对内部动态的验证和信息性观测的获取。</li>
<li><strong>信息提取</strong>：在执行探索性动作后，智能体获得一条新轨迹。本文引入一个信息提取模块，提示LLM分析该信息寻求轨迹，提取关键见解，并生成简洁摘要。这些摘要随后被纳入后续任务导向规划的上下文背景中。</li>
<li><strong>任务导向规划</strong>：基于提取的见解，提示LLM生成初始计划或修订先前计划以完成任务。LLM在生成新的任务导向动作序列之前，会对组合的上下文进行推理。执行这些动作后，更新后的轨迹被传回LLM，开启下一轮的信息寻求与任务导向规划循环。此过程持续进行，直到任务完成或达到预定的交互步数。</li>
</ol>
<p>与现有方法相比，创新点具体体现在：现有交互式规划方法（如图1c）仅依赖基于执行反馈的被动适应，而没有显式的信息收集；而InfoSeeker（如图1b）则要求智能体在规划前主动验证其内部动态，通过设计诊断性试验来主动缩小认知差距，从而能够应对观测和动态均不确定的环境。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>本文引入了一套新的基于文本的模拟基准测试套件，用于评估LLM智能体在具有噪声环境动态的部分可观测环境中的鲁棒性。该套件包含5个任务：机器人手臂控制、机器人导航、混合颜色、方块堆叠（单目标）和方块堆叠（多目标）。每个任务都有两个配置：<strong>基础</strong>版本（仅观测不确定，动作结果可预测）和<strong>扰动</strong>版本（额外引入动态不确定，动作可能产生意外结果）。</p>
<p>对比的基线方法包括：ReAct、AdaPlanner以及LLM3的两个变体（回溯和从头开始）。实验在两个LLM（Gemini Flash 2.0和GPT-4o）上进行，主要评估指标为在每任务100个交互步数内的成功率。</p>
<p><img src="https://arxiv.org/html/2510.01531v1/x4.png" alt="定量结果"></p>
<blockquote>
<p><strong>表1</strong>：所提基准测试上的定量结果。报告了成功率（%）。通过结合主动信息寻求，InfoSeeker始终获得更高的成功率，尤其是在扰动条件下表现突出。</p>
</blockquote>
<p>关键实验结果如下：</p>
<ul>
<li><strong>在观测不确定下的性能</strong>：在基础设置和已建立的LLM3、TravelPlanner基准上，InfoSeeker表现出有竞争力且稳健的性能。例如，在混合颜色任务中达到84%的成功率，比最佳基线绝对提升8%；在LLM3基准最困难的场景下，绝对性能提升达20%；在TravelPlanner基准上，最终通过率也优于所有基线。</li>
<li><strong>在观测和动态均不确定下的性能</strong>：这是本文的重点。在扰动设置下，InfoSeeker显著优于所有基线。以机器人手臂控制任务为例，在控制器失准的情况下，InfoSeeker取得了80%的成功率，而最佳基线（LLM3回溯）的性能从基础设置的100%骤降至6%。这表明显式的信息寻求行为至关重要，仅通过提示工程告知环境不确定性（如表4所示）对基线方法提升有限。</li>
<li><strong>模型效率</strong>：尽管信息寻求需要额外的环境交互，但InfoSeeker能更快地诊断失败原因并生成最优计划。在固定1分钟执行时间的方块堆叠（单目标）任务中，InfoSeeker在扰动设置下的成功率比LLM3基线高出36%。如图3（左）所示，InfoSeeker仅用135个交互步数就达到72%的成功率，几乎比仅使用信息寻求模块（Seek）达到类似性能所需的步数少了一半。</li>
</ul>
<p><img src="https://arxiv.org/html/2510.01531v1/x3.png" alt="消融研究"></p>
<blockquote>
<p><strong>图3</strong>：消融研究。在扰动的方块堆叠（单目标）任务上，成功率（%）与交互步数（左）和规划尝试次数（右）的关系。结合信息寻求和信息提取行为使InfoSeeker更高效、更有效。</p>
</blockquote>
<ul>
<li><strong>消融实验</strong>：在扰动方块堆叠任务上的消融实验（图3）总结了各组件的贡献。纯LLM规划器成功率仅42%。仅添加信息提取（Extract）模块提升有限。而引入显式信息寻求（Seek）行为则带来大幅性能提升（成功率至82%）。完整的InfoSeeker（结合寻求与提取）实现了最高成功率，并且效率最高。实验还证实，仅通过上下文学习提供成功案例并不能让基线方法涌现出信息寻求行为，强调了必须在决策循环中显式集成该行为。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：</p>
<ol>
<li>提出了一个基于LLM的规划框架（InfoSeeker），它显式地集成信息寻求，以处理动态和观测两方面的不确定性。</li>
<li>引入了一个新颖的基准测试套件，用于评估在观测和动态均不确定的部分可观测环境中的规划能力。</li>
<li>在基于LLM的规划与部分可观测马尔可夫决策过程（POMDP）之间建立了形式化连接。</li>
</ol>
<p>论文自身提到的局限性包括：当前基准测试是手动构建的，突显了需要对观测和动态双重不确定性下的规划进行更严格评估的需求；此外，方法的有效性可能依赖于LLM自身的推理和规划能力。</p>
<p>本文对后续研究的启示在于：它强调了将主动信息寻求作为一类独立的、目标导向的行为，与任务规划紧密集成，对于在复杂、不确定的现实世界中实现鲁棒决策至关重要。这为开发更适应动态变化环境的AI智能体提供了一个新的设计范式。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对部分可观测环境下，大语言模型（LLM）智能体因内部动态与环境实际动态不匹配而决策脆弱的问题，提出**信息寻求决策规划器（InfoSeeker）**。该框架将任务导向规划与主动信息寻求相结合，驱使LLM通过规划行动验证认知、探测环境变化，从而对齐内部动态。实验表明，InfoSeeker在新型基准测试中相比之前方法取得了**74%的绝对性能提升**，且不损失样本效率，并在机器人操作、网页导航等任务中展现出优异的泛化能力。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.01531" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>