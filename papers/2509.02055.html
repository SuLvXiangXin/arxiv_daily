<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.02055" target="_blank" rel="noreferrer">2509.02055</a></span>
        <span>作者: Xuelong Li Team</span>
        <span>日期: 2025-09-05</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作（VLA）模型通过在大规模、多样化的机器人演示数据集上进行预训练，展现出通用机器人操作的巨大潜力。其标准训练范式包含两个阶段：在大规模跨本体数据集上进行预训练，学习通用的视觉运动先验；然后在针对特定机器人平台和任务的、范围较窄的高质量数据集上进行微调（适应）。然而，当目标机器人本体（如从单臂机器人变为双臂机器人）或任务本身与预训练数据存在差异时，预训练阶段和适应阶段之间的动作分布会出现显著不匹配。这种差异导致直接微调需要大量的适应数据和计算资源，成为VLA模型在实际部署中的主要瓶颈。现有方法多集中于提升参数更新效率或探索不同的架构设计，但往往难以解决任务分布差异，且忽视了更具挑战性的本体不匹配问题。</p>
<p>本文针对在数据受限条件下，实现跨本体和跨任务的VLA高效适应这一核心问题，提出了一种名为“Align-Then-stEer”（ATE）的新视角。其核心思路是：首先通过构建一个统一的潜在动作空间来对齐不同的动作分布，然后利用基于该空间的引导机制，在微调过程中将预训练VLA的输出分布“引导”至目标领域，从而实现数据高效的适应。</p>
<h2 id="方法详解">方法详解</h2>
<p>ATE框架是一个即插即用的两阶段适应方法，整体流程如图2所示。其核心思想是先“对齐”（Align）再“引导”（Steer）。第一阶段，构建一个统一的潜在动作空间，以弥合预训练与适应阶段在动作分布上的差距。第二阶段，设计一个基于该统一潜在空间的引导函数，并将其集成到基于扩散或流匹配的VLA训练目标中，在微调时显式地引导模型输出朝向目标分布。</p>
<p><img src="https://arxiv.org/html/2509.02055v2/x2.png" alt="方法总览"></p>
<blockquote>
<p><strong>图2</strong>：ATE框架总览。(a) 第一阶段：通过利用非对称VAE的模式寻求行为，构建统一动作空间以弥合预训练和适应阶段的本体差距。(b) 第二阶段：在扩散和基于流的VLA中集成分类器引导，将预训练策略引导至特定机器人平台的目标动作分布。</p>
</blockquote>
<p><strong>第一阶段：通过统一潜在动作空间进行对齐</strong><br>此阶段的目标是将预训练和适应阶段中不同本体、不同任务产生的异构动作数据编码到一个统一的、紧凑的潜在空间𝒵中。具体使用两个独立的变分自编码器（VAE）：</p>
<ol>
<li><strong>预训练动作VAE（𝒱_pretrain）</strong>：在预训练数据集𝒟_pretrain上训练。它使用Transformer编码器-解码器架构，将长度为H的预训练动作片段编码为潜在变量z的分布q_ϕ(z)。其训练目标基于InfoVAE，在最大化重构似然的同时，通过KL散度正则化使潜在分布趋向于单位高斯先验p(z)=𝒩(0,I)，并最大化动作与潜在变量间的互信息。</li>
<li><strong>适应动作VAE（𝒱_adaptation）</strong>：在有限的适应数据集𝒟_adaptation上训练。其架构与𝒱_pretrain相同，但关键创新在于其正则化项。它的训练目标（公式6）包含一个反向KL散度项：D_KL(q_ψ(z|ã) ∥ q_ϕ(z))，其中q_ϕ(z)是𝒱_pretrain学到的潜在分布（近似为𝒩(μ_ϕ, Σ_ϕ)）。反向KL散度具有“模式寻求”特性，这鼓励适应动作的潜在分布q_ψ(z)嵌入到预训练潜在分布q_ϕ(z)的某个特定模式中，从而形成一个具有层次结构的统一潜在空间。</li>
</ol>
<p><strong>第二阶段：通过潜在空间引导进行适应</strong><br>此阶段旨在高效微调预训练的扩散或流匹配VLA。受分类器引导扩散模型的启发，ATE设计了一个基于统一潜在空间的引导函数，用于显式地引导策略更新。</p>
<ul>
<li><strong>引导函数设计</strong>：引导的目标是使生成的动作在潜在空间中接近目标分布。定义条件标签y为“动作属于目标分布”。引导函数g定义为生成动作的潜在编码与目标潜在分布均值μ_ψ之间的负L2距离的梯度：g = ∇_{a^k} log p(y|a^k) ≈ -s · ∇_{a^k} ||E_ψ(a^k) - μ_ψ||²，其中E_ψ是适应VAE的编码器，s是引导尺度。</li>
<li><strong>集成到生成模型</strong>：<ul>
<li><strong>对于扩散模型</strong>：根据公式8，将引导梯度g纳入噪声预测中，得到修正后的噪声预测ε̂ = ε_θ - √(1-ᾱ) · g。在训练时，用ε̂替代原始的ε_θ来计算损失（公式2），从而引导去噪过程。</li>
<li><strong>对于流匹配模型</strong>：类似地，将引导梯度g加入到流预测中，修正后的流预测为v̂_θ = v_θ - (1-τ) · g，并用于计算流匹配损失（公式4）。<br>这种引导机制允许模型在少量数据下，快速而精确地将输出分布调整到目标领域。</li>
</ul>
</li>
</ul>
<p><strong>创新点</strong>：与直接微调或仅提升参数效率的方法相比，ATE的创新性体现在：1) 提出了一种利用反向KL散度构建层次化统一动作空间的显式对齐策略，从根本上缓解分布不匹配；2) 提出了一种基于该统一潜在空间的、适用于扩散/流匹配VLA的通用引导机制，实现精准高效的分布转移。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：论文在模拟和真实世界环境中进行了广泛的跨本体和跨任务操作实验。</p>
<ul>
<li><strong>模拟基准</strong>：使用RoboTwin（Franka单臂 vs. UR5双臂）和ManiSkill2（多种机器人抓取与操作任务）。</li>
<li><strong>真实世界平台</strong>：使用RealMan 7自由度双臂机器人进行长视野、灵巧的双臂协调任务。</li>
<li><strong>预训练VLA基础模型</strong>：主要使用基于扩散的GROOT模型，也测试了基于流匹配的π0.5模型。</li>
<li><strong>基线方法</strong>：主要与直接监督微调（SFT）进行对比，也对比了LoRA、视觉令牌缓存等其他高效适应技术。</li>
</ul>
<p><strong>关键实验结果</strong>：<br><img src="https://arxiv.org/html/2509.02055v2/x3.png" alt="模拟实验结果"></p>
<blockquote>
<p><strong>图3</strong>：在RoboTwin和ManiSkill2模拟环境中的跨本体与跨任务适应结果。ATE在绝大多数任务上超越了直接微调（SFT）和其他高效适应方法，在RoboTwin上平均多任务成功率最高提升9.8%。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.02055v2/x4.png" alt="真实世界实验结果"></p>
<blockquote>
<p><strong>图4</strong>：在RealMan双臂机器人上的真实世界长视野任务结果。ATE取得了显著优势，在“制作草莓奶昔”复杂任务中，相比直接微调获得了32%的成功率提升。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.02055v2/x5.png" alt="消融实验"></p>
<blockquote>
<p><strong>图5</strong>：消融研究结果。实验表明，同时使用“对齐”（Align）和“引导”（Steer）两个阶段至关重要，缺少任一组件性能都会显著下降。同时，ATE对引导尺度超参数具有鲁棒性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.02055v2/x6.png" alt="定性结果"></p>
<blockquote>
<p><strong>图6</strong>：真实世界任务的定性对比。ATE方法能生成更精确、物理上更可行的动作序列，例如成功将草莓放入搅拌杯并操作搅拌机，而基线方法则出现动作不协调或无法完成任务的情况。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.02055v2/x7.png" alt="潜在空间可视化"></p>
<blockquote>
<p><strong>图7</strong>：统一潜在空间的可视化（t-SNE）。左图显示，未经对齐，预训练和适应动作的潜在编码是分离的。右图显示，经过ATE对齐后，适应动作的潜在表示（橙色）被成功地嵌入到预训练潜在分布（蓝色）的特定模式中，验证了对齐策略的有效性。</p>
</blockquote>
<p><strong>消融实验总结</strong>：消融实验（图5）验证了ATE两个核心组件的贡献：1) <strong>“对齐”阶段</strong>：构建统一潜在空间是基础，缺少它则无法有效桥接分布差距；2) <strong>“引导”阶段</strong>：在潜在空间上的分类器引导能显著加速和精确化适应过程。两者结合才能实现最佳性能。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了一种新颖的、数据高效的VLA适应框架ATE，通过“先对齐，后引导”的两阶段策略，显式解决了预训练与适应阶段间的动作分布不匹配问题。</li>
<li>提出了一种基于反向KL散度与VAE的统一潜在空间构建方法，能够将目标动作分布嵌入到预训练分布的特定模式中，有效桥接本体与任务差距。</li>
<li>设计了一种适用于扩散/流匹配VLA的潜在空间分类器引导机制，该机制模型无关、即插即用，能以极小的计算开销实现快速精准的适应。</li>
</ol>
<p><strong>局限性</strong>：论文提到，ATE方法依赖于预训练和适应阶段均有可用的动作标注数据来训练各自的VAE。在完全无监督或仅有少量未标注数据的情况下，其适用性可能受限。</p>
<p><strong>启示</strong>：ATE的工作为VLA乃至更广泛的机器人策略适应问题提供了一个新思路：即不局限于直接调整模型参数，而是通过构建中间表示（如统一潜在空间）并利用生成模型的引导特性，来更优雅地处理分布偏移问题。这启发后续研究可以探索更强大的分布对齐技术，或将类似思想应用于其他类型的策略表示（如基于Transformer的自回归模型）。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对预训练视觉-语言-动作模型在下游任务适配时，因机器人形态或任务差异导致动作分布失配、需大量微调数据的问题，提出Align-Then-stEer框架。其核心方法包括：通过基于反向KL散度的变分自编码器将不同动作空间对齐到统一潜在空间；随后在微调中通过引导机制，将模型输出分布推向目标领域。实验表明，相比直接微调，该方法在仿真中平均多任务成功率最高提升9.8%，在真实世界跨形态任务中成功率显著提升32%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.02055" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>