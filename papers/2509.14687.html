<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2509.14687" target="_blank" rel="noreferrer">2509.14687</a></span>
        <span>作者: Tai, Cong, Zheng, Zhaoyu, Long, Haixu, Wu, Hansheng, Xiang, Haodong, Long, Zhengbin, Xiong, Jun, Shi, Rong, Zhang, Shizhuang, Qiu, Gang, Wang, He, Li, Ruifeng, Huang, Jun, Chang, Bin, Feng, Shuai, Shen, Tao</span>
        <span>日期: 2025/09/18</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>人形机器人视觉-语言-动作领域面临几个根本性挑战：高质量交互数据获取成本高昂且危险；现有仿真平台主要针对机械臂，缺乏对人形机器人及灵巧手的支持，且环境真实感不足导致“仿真-现实”鸿沟；缺乏统一的开源基准来客观评估和比较模型性能，阻碍了系统性研究。</p>
<p>本文针对数据获取、基准缺失和Sim2Real迁移三大痛点，提出了一个名为RealMirror的综合性开源具身AI VLA平台。其核心思路是构建一个高效、低成本、无需真实机器人的端到端VLA研发系统，通过建立专用基准促进公平比较，并整合生成模型与3D高斯泼溅技术重建高真实感环境，最终实现零样本（无需微调）的仿真到现实策略迁移。</p>
<h2 id="方法详解">方法详解</h2>
<p>RealMirror平台提供了一个从资产获取、场景构建、数据收集到模型训练、评估及零样本Sim2Real迁移的完整端到端解决方案。</p>
<p><img src="https://arxiv.org/html/2509.14687v1/x1.png" alt="平台总览图"></p>
<blockquote>
<p><strong>图1</strong>：RealMirror平台集成流程总览。平台涵盖了资产获取与场景构建、基于遥操作的优化数据收集、多种VLA模型的训练与评估。为弥合关键的现实鸿沟，平台集成了零样本Sim2Real模块，使用3D高斯泼溅创建机器人及环境的高保真数字孪生，使得纯仿真训练的策略能直接部署到现实世界。</p>
</blockquote>
<p><strong>整体框架与核心模块</strong>：</p>
<ol>
<li><strong>物理仿真场景构建</strong>：基于NVIDIA Isaac Sim平台，整合CAD模型和多种资产库，设计包含复杂布局、可操作物体和真实物理交互的室内场景，并为其分配质量、摩擦等物理属性，为大规模数据收集和训练奠定基础。</li>
<li><strong>高效数据收集、训练与推理系统</strong>：<ul>
<li><strong>基于遥操作的数据收集</strong>：系统包含仿真环境中的运动控制管线（含逆运动学关节控制跳跃过滤、末端执行器位姿通信与漂移补偿等多级过滤机制）和基于WebXR的轻量级实时通信系统。优化后的传输协议使端到端延迟相比通用框架降低了114ms，数据采集高效（例如单臂抓取放置任务平均每条轨迹7.83秒）。</li>
<li><strong>统一训练与推理框架</strong>：训练侧支持ACT、Diffusion Policy、SmolVLA等多种代表性VLA模型，并为其适配了时间集成机制以增强动作预测鲁棒性。推理侧将训练好的模型与Isaac Sim集成，形成接收多模态输入（BGR图像、本体感知状态、语言指令）并实时执行预测动作的闭环评估系统。</li>
</ul>
</li>
<li><strong>人形机器人VLA基准</strong>：包含五个任务场景（厨房清理、空气炸锅操作、流水线分拣、杯间转移、易拉罐堆叠），总计超过1200条高质量仿真轨迹，旨在评估抓放、双臂协作、推拉、动态抓取、精密控制等核心技能。基准提供自动化评估工具和热图分析工具，支持对上述VLA模型的标准化评测。</li>
<li><strong>Sim2Real迁移框架</strong>：为桥接视觉鸿沟，采用差异化策略增强仿真视觉真实感：<ul>
<li><strong>静态环境渲染</strong>：使用3D高斯泼溅从多视角重建真实工作空间的静态场景，作为非交互背景融入仿真器。</li>
<li><strong>高保真关节式机器人模型</strong>：用3DGS重建真实机器人并分割为独立连杆，通过尺度、旋转、平移变换将每个连杆的3DGS点云与Isaac Sim中的USD模型骨架精确对齐，为精确的物理骨架覆盖上逼真的视觉“皮肤”。</li>
<li><strong>交互物体的差异化处理</strong>：对需要高精度接触物理的物体（如灵巧末端、桌面），采用“数字孪生”方法（CAD模型负责物理，3DGS重建负责视觉）；对物理要求较低的物体，则使用少样本3D生成模型快速生成兼具视觉和碰撞表示的多样资产。</li>
<li><strong>坐标系对齐与相机标定</strong>：使用迭代最近点算法对齐Isaac Sim资产与3DGS重建环境。通过运动恢复结构求解真实机器人相机的位姿，由于Isaac Sim坐标系已与3DGS场景对齐，在仿真中相同位姿放置虚拟相机即可实现准确标定。</li>
</ul>
</li>
</ol>
<p><strong>创新点</strong>：与现有平台相比，RealMirror的创新性体现在提供了一个<strong>完整的端到端VLA研发框架</strong>，建立了<strong>首个专注于人形机器人并关联任务与技能的专用VLA基准</strong>，并率先实现了针对灵巧手操作的<strong>零样本Sim2Real迁移验证</strong>。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在RealMirror平台进行，包含VLA基准评测和Sim2Real验证两阶段。</p>
<p><strong>VLA基准实验</strong>：</p>
<ul>
<li><strong>数据集与模型</strong>：使用平台收集的超过1200条轨迹数据集。对比了ACT、Diffusion Policy和SmolVLA三种代表性VLA模型。所有模型处理多视角BGR图像（SmolVLA额外使用语言指令），输出统一的26维动作空间（每臂13维：7维手臂+6维手）。训练10万步，采用时间集成机制。</li>
<li><strong>自动评估协议</strong>：在五个任务场景下定量评估成功率，每个场景有明确的成功判定标准（如厨房清理需双臂协调将指定物品放入篮子）。</li>
<li><strong>关键实验结果</strong>：</li>
</ul>
<p><img src="https://arxiv.org/html/2509.14687v1/figures/model_performance_radar.png" alt="模型性能雷达图"></p>
<blockquote>
<p><strong>图2</strong>：不同模型在五项核心机器人技能上的性能对比雷达图。SmolVLA在抓放和精密控制上平均成功率最高，ACT在动态抓取上优势明显（95%），Diffusion Policy在推拉技能上表现最佳。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.14687v1/x2.png" alt="定性结果"></p>
<blockquote>
<p><strong>图3</strong>：不同VLA算法在基准测试中的定性结果展示，直观呈现了各模型执行任务的过程。</p>
</blockquote>
<p>表III数据显示，SmolVLA取得了最高的平均成功率（79.75%），尤其在精密控制类任务（杯间转移68.00%，易拉罐堆叠62.00%）中优势明显。ACT在厨房清理（100.00%）和动态的流水线分拣（95.00%）中近乎完美。Diffusion Policy在空气炸锅操作（85.50%）中表现最强。从技能层面分析（图2），SmolVLA表现最为均衡，ACT擅长动态抓取，Diffusion Policy擅长推拉。</p>
<p><strong>Sim2Real实验</strong>：</p>
<ul>
<li><strong>设置</strong>：使用ZHIYUAN A2真实机器人。选择ACT模型，在仿真中训练两个任务：1）从桌边抓取薯片放至中心（基础抓放）；2）将右杯中的球倒入左杯（简化版杯间转移）。</li>
<li><strong>视觉真实性对比</strong>：</li>
</ul>
<p><img src="https://arxiv.org/html/2509.14687v1/x3.png" alt="场景对比"></p>
<blockquote>
<p><strong>图4</strong>：传统仿真场景、真实场景与RealMirror重建仿真场景的视觉对比。RealMirror重建的场景视觉上更接近真实世界。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2509.14687v1/x4.png" alt="Sim2Sim与Sim2Real结果对比"></p>
<blockquote>
<p><strong>图5</strong>：Sim2Sim（仿真到仿真）与Sim2Real（仿真到现实）推理结果的对比。模型在真实机器人上成功执行了任务，动作平滑稳定。</p>
</blockquote>
<ul>
<li><strong>结果</strong>：经过3DGS等增强的仿真训练后，模型在真实机器人上实现了零样本迁移。定量上，基础抓放任务准确率达92.86%，复杂的双协作球转移任务准确率达71.43%（无需任何微调）。这证明了平台在桥接Sim2Real鸿沟、实现零样本迁移方面的有效性。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>构建了一个高效、低成本、无需真实机器人的端到端VLA数据收集、训练与推理系统。</li>
<li>提出了一个包含多场景、多技能、自动化评估的人形机器人专用VLA基准，为模型演进和公平比较提供了系统化基础。</li>
<li>通过集成生成模型与3D高斯泼溅技术，实现了高真实感环境与机器人重建，并成功验证了针对灵巧操作任务的零样本Sim2Real迁移可行性。</li>
</ol>
<p><strong>局限性</strong>：论文提到平台仍在持续开发中，包括研发新的自动数据收集方法、扩展仿真场景以生成更大规模高质量数据，以及进行更多零样本Sim2Real实验以验证平台的普适性和鲁棒性。</p>
<p><strong>启示</strong>：RealMirror作为一个开源的综合平台，显著降低了人形机器人VLA研究的门槛。其端到端的框架设计、系统化的基准测试以及对零样本Sim2Real迁移的实证探索，为后续研究提供了可复现的基础设施和明确的技术方向。特别是其通过提升视觉真实感而非依赖域随机化或大量微调来实现Sim2Real的思路，为具身AI研究提供了新的借鉴。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对人形机器人视觉-语言-动作研究面临的数据获取成本高、缺乏统一基准及仿真与现实差距大的核心问题，提出了开源平台RealMirror。该平台构建了高效低成本的数据收集与训练推理系统，并引入专门的人形机器人VLA基准。关键技术在于整合生成模型与3D高斯泼溅来重建逼真环境与机器人模型。核心实验结论表明，平台实现了零样本的仿真到现实迁移，模型仅使用仿真数据训练后，无需微调即可在真实机器人上无缝执行任务。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2509.14687" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>