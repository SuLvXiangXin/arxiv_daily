<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2510.12392" target="_blank" rel="noreferrer">2510.12392</a></span>
        <span>作者: Eunhyeok Park Team</span>
        <span>日期: 2025-10-14</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>生成式行为克隆（GBC）是一种简单有效的机器人学习方法。当前主流方法，如扩散策略，通常采用开环控制：基于单次观测通过扩散过程生成多步动作序列并执行，无需重新规划。这种方法虽展现出高成功率和泛化能力，但其固有的随机性可能导致采样到错误的低保真度动作，引发任务失败。同时，开环控制响应延迟，在动态环境中性能下降。闭环控制虽能即时响应，但每一步都重新采样会导致动作不一致和抖动。因此，现有方法在“一致性”与“反应性”之间存在根本权衡。本文针对扩散策略中动作采样质量不高以及开环/闭环控制模式僵化的问题，提出了两个新视角：通过自引导提升动作保真度与反应性，通过自适应分块动态平衡控制模式。核心思路是：利用模型自身过去决策的信息作为负引导来锐化动作分布，并设计一种根据动作相似性动态切换开环/闭环执行的机制，从而在不增加额外训练或模型的前提下显著提升GBC性能。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出两种无需额外训练、即插即用的技术来增强扩散策略：自引导（Self-Guidance, SG）和自适应分块（Adaptive Chunking）。整体上，模型在推理时，通过SG对每个扩散去噪步骤的噪声预测进行修正，以生成更高质量的动作；同时，通过自适应分块机制，根据新生成动作与已规划动作的相似度，动态决定是沿用旧的动作序列（开环模式）还是采用全新生成的动作序列（闭环模式），从而在保持时序一致性的同时获得必要的反应性。</p>
<p><img src="https://arxiv.org/html/2510.12392v1/figs/main-v11.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：自引导（SG）示意图。通过使用过去状态分布作为负引导，SG有效地锐化了动作分布，或能对环境扰动做出主动反应。</p>
</blockquote>
<p><strong>核心模块一：自引导（SG）</strong><br>SG旨在提高扩散策略生成动作的保真度和对新观测状态的反应速度。其核心创新在于使用模型自身基于过去状态的预测作为负引导信号，而非依赖外部模型或无条件预测。具体公式如下：<br><code>SG: ϵ̂_new ← (1+w) · ϵ_θ(x, s_t) - w · ϵ_θ(x, s_{t-Δt})</code><br>其中，<code>ϵ_θ</code> 是噪声预测网络，<code>s_t</code> 是当前状态，<code>s_{t-Δt}</code> 是过去状态（如上一时刻状态），<code>w</code> 是引导强度系数。实现时只需一次批量推理，输入为拼接的 <code>[s_t, s_{t-Δt}]</code>。SG修改后的采样分布正比于 <code>p_θ(a_t|s_t) · (p_θ(a_t|s_t) / p_θ(a_t|s_{t-Δt}))^w</code>，这鼓励模型赋予那些与过去状态条件分布差异大的动作更高概率，从而快速适应新状态 <code>s_t</code>。论文进一步从时序外推的角度解释SG：公式可重写为 <code>(1-w)·ϵ_θ(x, s_t) + w·(2·ϵ_θ(x, s_t) - ϵ_θ(x, s_{t-Δt}))</code>，在状态变化平滑的假设下，后半部分近似于对未来状态 <code>s_{t+Δt}</code> 的预测。因此，SG引导模型生成的动作隐含了对短期未来动态的预期，提升了前瞻性和反应性。</p>
<p><strong>核心模块二：自适应分块（Adaptive Chunking）</strong><br>该模块旨在根据任务执行阶段的特点，自适应地在开环和闭环控制间切换。观察发现，在需要高精度操作（如抓取）时，可接受的动作空间窄，闭环的反应性优势明显；而在进行大范围运动（如搬运）时，开环的稳定性更佳。自适应分块基于一个动作队列 <code>A_queue</code>。其更新规则是：计算新生成动作块 <code>â_{t:t+H}</code> 的第一个动作 <code>â[0]</code> 与队列中第一个待执行动作 <code>A_queue[0]</code> 的余弦相似度。若相似度高于阈值 <code>τ</code>，则仅将新动作块的最后一个动作 <code>â_{t+H}</code> 加入队列尾部（保持开环执行）；否则，用整个新动作块 <code>â_{t:t+H}</code> 替换当前队列（切换到闭环重新规划）。每一步执行的动作是队列出队的第一个动作 <code>a_t = A_queue.dequeue()</code>。这样，在动作一致性高时维持开环的稳定性，在需要调整时则启用闭环的反应性。</p>
<p><img src="https://arxiv.org/html/2510.12392v1/figs/sims3.png" alt="动作相似度分析"></p>
<blockquote>
<p><strong>图4</strong>：先前规划块中的动作与新规划动作在各时间步的相似度。相似度在简单运动（如移动、搬运）时较高，而在需要高精度时（如尝试抓取）较低。</p>
</blockquote>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在模拟和真实世界环境中进行了广泛评估。模拟实验使用了六个环境，包括Push-T、Robomimic标准基准以及长视野的Kitchen环境。评估指标主要为成功率（Push-T使用目标区域覆盖率）。对比了两种问题设置：1) <strong>动态环境</strong>：在执行时注入时间相关的动作噪声以模拟扰动；2) <strong>静态环境</strong>：理想无噪声环境。</p>
<p><strong>Baseline方法</strong>：1) <strong>Vanilla Diffusion Policy</strong>：原始扩散策略；2) <strong>指数移动平均</strong>：通过混合当前与先前动作来平滑时序；3) <strong>双向解码</strong>：一种最先进的推理时搜索方法，通过评估多个候选动作序列并基于前后向一致性进行选择，但计算成本高。</p>
<p><img src="https://arxiv.org/html/2510.12392v1/figs/closed_open_loop_results.png" alt="仿真实验结果"></p>
<blockquote>
<p><strong>图5</strong>：仿真实验结果（动态环境-上，静态环境-下）。在6个模拟环境中的性能对比，结果是在三个随机种子上的100次测试的平均值。本文方法（Ours）在绝大多数任务中取得了最佳性能。</p>
</blockquote>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>整体性能</strong>：在动态和静态设置下，本文方法在大多数模拟任务中显著优于所有基线。例如，在动态设置下，相比Vanilla Diffusion Policy平均提升23.25%，相比BID提升12.27%。</li>
<li><strong>抗干扰能力</strong>：在Push-T任务中注入不同级别（P=0到3）的随机动作噪声进行测试。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.12392v1/x2.png" alt="噪声水平测试"></p>
<blockquote>
<p><strong>表1</strong>：不同随机性水平下的性能对比（基于Push-T任务）。随着噪声增强（P值增大），所有方法性能下降，但本文方法（Ours）在所有级别上均保持领先优势。</p>
</blockquote>
<ol start="3">
<li><strong>消融实验</strong>：验证了SG和自适应分块各自的作用。SG显著提升了动作保真度和反应性；自适应分块则通过动态切换控制模式，在需要稳定性的任务上避免了闭环控制的不稳定性，在需要精度的任务上获得了闭环的反应性，两者结合带来最佳效果。</li>
<li><strong>真实世界实验</strong>：在Franka机械臂上执行“开罐”和“堆叠”任务。</li>
</ol>
<p><img src="https://arxiv.org/html/2510.12392v1/figs/realreal2.png" alt="真实世界结果"></p>
<blockquote>
<p><strong>图7</strong>：真实世界实验结果。本文方法在开罐和堆叠任务上均取得了最高的成功率，显著优于Vanilla DP和BID方法。</p>
</blockquote>
<ol start="5">
<li><strong>计算效率</strong>：由于SG只需单次批量推理，且自适应分块减少了频繁重新规划的需要，本文方法相比BID将计算成本降低了16倍。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1) 提出了<strong>自引导</strong>，一种高效、无需额外模型的方法，通过利用自身过去预测作为负引导来锐化扩散策略的动作分布，提升保真度与反应性；2) 提出了<strong>自适应分块</strong>，一种根据在线动作相似度动态平衡开环与闭环控制的机制，实现了稳定性与反应性的动态权衡；3) 通过大量实验证明，所提方法能作为即插即用模块显著提升现有扩散策略性能，并在计算效率上具有优势。</p>
<p><strong>局限性</strong>：论文提到，自引导的效果依赖于状态变化的平滑性假设；自适应分块的阈值 <code>τ</code> 需要根据任务进行调节。</p>
<p><strong>后续启示</strong>：本研究展示了利用模型自身内部信息进行引导的潜力，为改善生成式策略的推理性能提供了新思路。其轻量级、即插即用的特性使得它易于集成到现有框架中。未来工作可探索更复杂的引导信号来源，或将自适应决策机制与更精细的任务阶段识别相结合。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对生成式行为克隆（GBC）中扩散策略的随机性易导致动作采样错误，以及开环控制响应延迟、在动态环境中性能下降的核心问题，提出自我引导（self-guidance）和自适应分块（adaptive chunking）两种技术。自我引导利用过去观察提升动作保真度并隐式促进未来感知；自适应分块根据反应性需求选择性更新动作序列以平衡一致性。大量实验表明，该方法在模拟和真实机器人操作任务中显著提升了GBC性能。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2510.12392" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>