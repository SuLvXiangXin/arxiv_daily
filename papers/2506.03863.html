<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.03863" target="_blank" rel="noreferrer">2506.03863</a></span>
        <span>作者: Liqiang Nie Team</span>
        <span>日期: 2025-06-04</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人操作领域的一个核心挑战是建模多任务视觉运动策略。将复杂动作分解为简单、可重用的技能抽象是一种直观的解决思路。现有方法主要利用潜变量模型，例如VQ-VAE，通过学习向量（码本）来学习技能抽象，但它们存在两个关键局限：一是码本坍塌，即大多数码本向量在训练中未被使用，严重限制了捕获多样化机器人行为的能力；二是难以建模所学技能之间的因果关系，导致在需要多个技能精确协调的复杂长视野任务中，技能组合效果不佳。</p>
<p>本文针对这两个具体痛点，提出了新的视角：将动作序列之间的几何关系编码到残差量化过程中，对于学习多样化和可重用的技能至关重要，而不是依赖于直通估计的过度简化梯度分配。本文的核心思路是：提出STAR框架，通过旋转增强的残差技能量化防止码本坍塌，并通过因果技能Transformer显式建模技能间的依赖关系，以实现连贯的行为生成。</p>
<h2 id="方法详解">方法详解</h2>
<p>STAR框架采用两阶段训练策略：首先训练旋转增强的残差技能量化模块以学习技能抽象，然后固定该模块，训练因果技能Transformer进行技能组合。</p>
<p><img src="https://arxiv.org/html/2506.03863v2/x2.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：STAR框架概览。顶部：RaRSQ模块通过旋转增强的残差量化将连续动作序列编码为层次化的离散技能。底部：CST模块处理多模态输入（视觉观察、本体感知状态和语言指令），通过自回归技能预测和动作精炼生成动作。</p>
</blockquote>
<p><strong>1. 旋转增强的残差技能量化</strong><br>RaRSQ旨在从连续动作序列中学习富有表现力且可重用的技能表示。给定一个动作序列 <code>a_t:t+T</code>，首先通过编码器网络 φ 将其编码为潜在向量 <code>z = φ(a_t:t+T)</code>。随后，RaRSQ通过一个迭代过程对 <code>z</code> 进行离散化，该过程结合了残差量化和旋转变换。</p>
<p>具体流程如算法1所示：从初始残差 <code>r_0 = z</code> 开始，对于每个深度 <code>d ∈ {1, …, D}</code>，执行以下步骤：</p>
<ol>
<li><strong>量化</strong>：找到当前残差 <code>r_d-1</code> 在码本 <code>C_d</code> 中的最近邻向量，得到索引 <code>k_d</code>（公式6）。</li>
<li><strong>旋转对齐</strong>：计算一个旋转矩阵 <code>R_d</code>，该矩阵将残差 <code>r_d-1</code> 的方向与选中的码本向量 <code>e_(d, k_d)</code> 对齐（公式9-11）。</li>
<li><strong>应用旋转与缩放</strong>：对残差 <code>r_d-1</code> 应用旋转和缩放变换，得到量化后的向量 <code>q̃_d</code>（公式7）。此处使用停止梯度算子 <code>sg[·]</code> 来保持几何结构。</li>
<li><strong>更新残差</strong>：计算下一层的残差 <code>r_d = r_d-1 - q̃_d</code>（公式8）。</li>
</ol>
<p>最终，技能表示 <code>ẑ</code> 是所有层级旋转量化向量的和（公式12）。在反向传播过程中，梯度通过旋转矩阵流动（公式13）。这种基于旋转的梯度机制使得同一量化区域内的不同点能够根据其几何关系（如相对角度）获得不同的梯度更新，从而有效防止码本坍塌。训练目标结合了重构损失和承诺损失。</p>
<p><strong>2. 因果技能Transformer</strong><br>在获得离散技能表示后，CST模块负责根据多模态观察（图像、状态、语言指令）自回归地预测技能序列，并生成精确的连续动作。其创新点在于层次化预测和连续精炼：</p>
<ul>
<li><strong>层次化自回归预测</strong>：CST顺序地预测从粗到细的技能代码 <code>(k_1, k_2, …, k_D)</code>。在预测第 <code>d</code> 层代码时，模型会考虑当前观察、历史信息以及所有之前预测的更高层（更粗）的技能代码。</li>
<li><strong>动作偏移预测</strong>：为了弥补离散化带来的精度损失，CST借鉴了BeT的思想，在预测离散技能代码的同时，还预测一个连续的“偏移量”。最终的连续动作由解码器根据量化表示 <code>ẑ</code> 重建的基础动作，加上预测的偏移量得到，从而实现更精细的控制。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在LIBERO多任务长视野操作基准和真实世界机器人任务上进行。对比的基线方法包括：BeT、ACT、VQ-BeT、QueST等。</p>
<p><img src="https://arxiv.org/html/2506.03863v2/x3.png" alt="结果对比"></p>
<blockquote>
<p><strong>图3</strong>：在LIBERO基准上的任务成功率对比。STAR在所有任务套件（LIBERO-Goal, LIBERO-Spatial, LIBERO-Object, LIBERO-10）上均显著优于所有基线方法。</p>
</blockquote>
<p>关键实验结果：在LIBERO基准上，STAR相比最强的基线方法（VQ-BeT）取得了约12%的绝对成功率提升。在真实世界的长视野操作任务（如“打开微波炉并加热食物”）中，STAR也展现出卓越的性能。</p>
<p><img src="https://arxiv.org/html/2506.03863v2/x4.png" alt="消融实验"></p>
<blockquote>
<p><strong>图4</strong>：消融研究结果。对比了STAR完整模型及其变体：w/o Rotation（移除旋转增强）、w/o Residual（使用单层VQ）、w/o Offset（移除动作偏移预测）。结果表明，所有组件对最终性能均有重要贡献。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.03863v2/x5.png" alt="码本使用率"></p>
<blockquote>
<p><strong>图5</strong>：码本使用率可视化。与VQ-BeT相比，STAR的RaRSQ机制使得码本向量的使用更加均匀和充分，有效缓解了码本坍塌问题。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.03863v2/x6.png" alt="技能依赖分析"></p>
<blockquote>
<p><strong>图6</strong>：CST中技能依赖关系的可视化。注意力权重图显示，在预测当前技能时，模型会关注之前步骤的相关技能，证明了其建模技能间因果关系的能力。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.03863v2/x7.png" alt="真实世界实验"></p>
<blockquote>
<p><strong>图7</strong>：真实世界机器人任务的成功率。STAR在复杂的长视野任务中表现最佳。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.03863v2/x8.png" alt="定性对比"></p>
<blockquote>
<p><strong>图8</strong>：与基线方法的定性对比。在“堆叠积木”任务中，STAR能生成连贯、精确的动作序列，而基线方法（如VQ-BeT）会出现不协调或错误的动作。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2506.03863v2/x9.png" alt="层次化技能可视化"></p>
<blockquote>
<p><strong>图9</strong>：RaRSQ学习的层次化技能可视化。第一层（k1）编码粗粒度的运动方向（如向左、向右移动），而第二层（k2）编码更精细的动作模式（如抓握、释放），验证了其层次化结构的有效性。</p>
</blockquote>
<p>消融实验总结：移除旋转增强（w/o Rotation）会导致性能显著下降，验证了旋转梯度机制对防止码本坍塌、提升技能多样性的关键作用；移除残差结构（w/o Residual）同样损害性能，证明了层次化技能表示的重要性；移除偏移预测（w/o Offset）会降低动作精度，尤其在需要精细操作的任务中。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）提出了旋转增强的残差技能量化机制，通过编码相对角度关系来保持梯度流中的几何结构，有效防止码本坍塌并学习多样化的技能表示；2）设计了因果技能Transformer，通过层次化自回归预测显式建模技能间的依赖关系，并结合偏移预测实现从离散技能到精确连续控制的桥梁；3）在仿真和真实世界任务上进行了全面实验验证，证明了方法在技能学习和任务性能上的显著提升。</p>
<p>论文自身提到的局限性包括：两阶段训练策略可能带来次优解；在极其复杂或未见过的真实世界任务中，泛化能力仍需进一步探索。</p>
<p>对后续研究的启示：1）在离散表示学习中，考虑样本间的几何关系（而不仅仅是距离）对于保持表示多样性至关重要；2）对于长视野任务，显式建模技能或动作片段间的时序因果关系是提高组合能力的关键；3）结合离散的技能抽象和连续的动作精炼，是平衡表示学习与运动控制精度的一种有效途径。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>STAR论文针对机器人技能学习中代码本崩溃和技能间因果关系建模不足的核心问题，提出旋转增强残差技能量化（RaRSQ）和因果技能变换器（CST）两项关键技术。RaRSQ通过旋转基梯度机制编码相对角度，防止代码本崩溃；CST利用自回归机制显式建模技能依赖关系。实验表明，STAR在LIBERO基准和真实任务上性能超越基线约12%。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.03863" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>