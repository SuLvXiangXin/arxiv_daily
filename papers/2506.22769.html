<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Learning Efficient Robotic Garment Manipulation with Standardization - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Learning Efficient Robotic Garment Manipulation with Standardization</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.22769" target="_blank" rel="noreferrer">2506.22769</a></span>
        <span>作者: Bin He Team</span>
        <span>日期: 2025-06-28</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前机器人衣物操作领域，针对高效的衣物展开任务，主流方法主要分为两类：基于单臂系统的多次交互策略和基于双臂系统的动态抛掷（fling）动作。前者往往需要冗长的执行时间，后者虽然能加速展开过程，但其目标通常仅局限于最大化衣物的表面覆盖率（Coverage）。现有方法普遍忽视了一个关键环节——<strong>标准化</strong>，即在展开的同时将衣物的形状和方向对齐到预定义的要求。这种标准化对于后续的折叠、熨烫、打包等下游任务至关重要。缺乏标准化会导致下游操作变得困难且效果不佳。</p>
<p>本文针对“现有展开方法只追求覆盖率，而未考虑为下游任务准备标准化状态”这一具体痛点，提出了将<strong>展开与标准化统一</strong>的新视角。核心思路是：设计一个名为APS-Net的双臂、多基元（fling和pick-and-place）策略网络，通过一种新型的因子化奖励函数引导学习，在高效展开皱褶衣物的同时，实现其形状、方向和关键点的对齐，从而简化后续折叠任务。</p>
<h2 id="方法详解">方法详解</h2>
<p>APS-Net的目标是将任意皱褶状态的衣物，通过一系列动作操作，转变为标准化、对齐的平整状态，随后基于关键点检测进行折叠。其整体流程是：在每一步，网络接收RGB-D观测图像，预测并执行一个动作基元（fling或p&amp;p），直至衣物足够平整；随后调用关键点检测模型，并基于检测到的关键点执行启发式折叠。</p>
<p><img src="https://arxiv.org/html/2506.22769v1/extracted/6578336/img1-new.jpg" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：方法整体框架。APS-Net接收一批经过旋转和缩放的RGB-D图像作为输入，通过三个编码器（分别对应覆盖率、IoU、关键点奖励）进行处理，每个编码器输出一对解码器（fling和p&amp;p解码器），加权后生成对应的空间动作图。随后应用空间动作掩码过滤无效动作。有效的基元批次被拼接，最终要执行的动作由像素最大值参数化。当衣物充分展平后，采用基于关键点检测的方法进行折叠。</p>
</blockquote>
<p><strong>核心模块与技术细节</strong>：</p>
<ol>
<li><p><strong>动作基元选择与参数化</strong>：APS-Net的核心是智能选择两种动作基元。<strong>动态抛掷（Fling）</strong> 用于快速展开皱褶衣物，其轨迹是预定义的（提升、前摆、后摆、放置）。<strong>拾放（Pick-and-Place， p&amp;p）</strong> 用于精细调整和对齐。网络不直接预测抓取点坐标，而是预测一个中间点<code>(x, y)</code>、旋转角<code>θ</code>和宽度<code>w</code>。对于fling，<code>(x, y±w)</code>即为双抓取点；对于p&amp;p，<code>(x, y)</code>是抓取点，<code>(x, y-w)</code>是放置点。为确保最优抓取点不随衣物物理变换（如旋转）而改变，网络对输入图像进行一系列旋转和缩放变换，以批次方式处理，最终从生成的空间动作图中选择期望值最高的动作和位置。</p>
</li>
<li><p><strong>因子化奖励函数</strong>：这是引导网络学习标准化的关键。奖励函数由三部分加权和构成：<strong>覆盖率奖励（RC）</strong> 鼓励最大化可见表面积；<strong>交并比奖励（RI）</strong> 鼓励当前衣物轮廓与目标轮廓对齐；<strong>关键点距离奖励（RK）</strong> 鼓励衣物关键点（如肩点）靠近其目标位置。通过超参数α和β调整权重，使网络能同时优化覆盖、对齐和关键点定位。</p>
</li>
<li><p><strong>空间动作掩码</strong>：为防止网络选择无效动作（如抓取非衣物区域或导致机械臂碰撞），该方法引入了空间动作掩码。该掩码由工作空间掩码和衣物掩码共同定义，仅保留两者交集内的动作区域，从而过滤掉不安全或不可行的动作选项。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2506.22769v1/extracted/6578336/rebuttal.jpg" alt="空间动作掩码"></p>
<blockquote>
<p><strong>图3</strong>：空间动作掩码示意图。(a)中较小的图表示不同尺度和旋转下各基元的空间动作图切片。应用于每一层的掩码用于过滤无效动作，例如那些会导致机器人末端执行器碰撞或超出衣物的动作。</p>
</blockquote>
<ol start="4">
<li><p><strong>动作优化模块</strong>：在执行fling动作时，抓住衣物的肩部关键点通常能更有效地展平衣物。AOM模块利用APSNet预测的肩部关键点，对网络预测的抓取点进行微调。如果预测抓取点与检测到的肩部关键点足够接近，则将其优化对齐到肩点，从而加速展平过程。</p>
</li>
<li><p><strong>基于关键点的折叠启发式规则</strong>：对于折叠阶段，首先为每类衣物（长袖、连体裤/裤子、裙子）训练一个DeepLabv3关键点检测模型。然后根据检测到的关键点（如袖口、肩部、腰部）定义简单的几何折叠规则（如沿某条线对折）。</p>
</li>
</ol>
<p><img src="https://arxiv.org/html/2506.22769v1/extracted/6578336/rule.jpg" alt="折叠规则"></p>
<blockquote>
<p><strong>图4</strong>：长袖、裤子和裙子的折叠规则。通过定义的关键点（如肩点、腰点）确定折叠线，执行序列化的折叠动作。</p>
</blockquote>
<p><strong>创新点</strong>：与现有方法相比，APS-Net的主要创新在于：1) <strong>统一框架</strong>：首次在同一个学习框架内整合了高效展开与标准化对齐；2) <strong>标准化导向的奖励</strong>：提出的因子化奖励函数明确将形状（IoU）和关键点对齐作为优化目标，而不仅仅是覆盖率；3) <strong>动作选择与优化</strong>：通过空间动作掩码和AOM模块，提升了动作选择的可靠性和展开效率。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在模拟环境和真实世界中进行。模拟实验使用SoftGym环境，并引入了可变质量、刚度和程序化皱纹以增强真实性。真实世界实验使用双UR5机械臂平台。涉及三类衣物：长袖衬衫、连体裤/裤子、裙子。</p>
<p><strong>对比方法</strong>：主要与现有的高效展开方法进行对比，包括：FlingBot、SAC-A、Tears等。</p>
<p><strong>关键实验结果</strong>：</p>
<ol>
<li><strong>模拟展开性能对比</strong>：在长袖衣物上，APS-Net在覆盖率、IoU和关键点距离（KD）三个标准化指标上均优于基线方法。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.22769v1/extracted/6578336/compare.jpg" alt="模拟对比结果"></p>
<blockquote>
<p><strong>图6</strong>：模拟环境下长袖衣物展开性能对比。APS-Net在覆盖率（Cov）、IoU和关键点距离（KD）上均达到最佳。具体数值为：覆盖率提升3.9%，IoU提升5.2%，KD降低0.14（相对减少7.09%）。</p>
</blockquote>
<ol start="2">
<li><strong>消融实验</strong>：验证了各核心组件的贡献。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.22769v1/extracted/6578336/line.png" alt="消融实验"></p>
<blockquote>
<p><strong>图7</strong>：消融实验（动作基元选择、奖励函数、动作优化模块AOM）对长袖衣物展开性能的影响。实验表明，完整的APS-Net（All）性能最优，其中AOM对提升覆盖率贡献显著，而完整的奖励函数对改善IoU和KD至关重要。</p>
</blockquote>
<ol start="3">
<li><strong>多类别衣物展开</strong>：APS-Net成功推广到连体裤/裤子和裙子上，在模拟中均能取得良好的展开与标准化效果。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.22769v1/extracted/6578336/pants-skirts.png" alt="多类别展开"></p>
<blockquote>
<p><strong>图8</strong>：APS-Net在裤子/连体裤和裙子上的模拟展开序列。展示了方法对不同类别衣物的泛化能力。</p>
</blockquote>
<ol start="4">
<li><strong>真实世界折叠验证</strong>：这是本文的核心验证之一。实验表明，经过APS-Net标准化展开后的衣物，其后续折叠的成功率和规整度显著高于仅用传统方法（只追求覆盖率）展开的衣物。</li>
</ol>
<p><img src="https://arxiv.org/html/2506.22769v1/extracted/6578336/fold.jpg" alt="真实世界折叠对比"></p>
<blockquote>
<p><strong>图9</strong>：真实世界折叠任务对比。左侧为仅最大化覆盖率的展开方法（FlingBot）后的折叠结果，衣物不规整；右侧为APS-Net标准化展开后的折叠结果，衣物被整齐折叠，证明了标准化对下游任务的有效性。</p>
</blockquote>
<p><strong>消融实验总结</strong>：完整的APS-Net系统（包含双基元选择、因子化奖励和AOM）性能最佳。其中，AOM模块对快速提升覆盖率贡献明显；因子化奖励函数（特别是IoU和关键点奖励）是实现标准化对齐的关键；空间动作掩码确保了动作的安全性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>APS-Net</strong>，一个将衣物高效展开与标准化对齐统一在自监督学习框架下的新方法。</li>
<li>设计了引导标准化学习的<strong>因子化奖励函数</strong>，以及提升操作效率与安全性的<strong>空间动作掩码</strong>和<strong>动作优化模块</strong>。</li>
<li>通过模拟与真实实验，系统性地验证了<strong>衣物标准化能显著简化后续折叠任务</strong>，为以任务链为导向的衣物操作提供了新思路。</li>
</ol>
<p><strong>局限性</strong>：论文提到，尽管通过数据增强（如可变物理参数、程序化皱纹）和真实图像微调关键点检测模型来缓解，但<strong>模拟到真实的差距仍然存在</strong>。此外，当前方法针对每类衣物需要单独训练关键点检测模型和定义折叠启发式规则。</p>
<p><strong>启示</strong>：本工作表明，在机器人操作中，特别是对于可变形物体，<strong>为下游任务准备一个“良好格式化”的中间状态</strong>可能比孤立地优化单个子任务指标更为重要。这启发后续研究可以更多地关注任务链中不同阶段间的状态衔接与优化，并探索更具通用性的物体表示（如关键点）和规划方法。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人服装操作中因复杂形变和自遮挡导致的标准化难题，提出APS-Net统一框架。该方法融合展开与标准化，采用双机械臂多原始策略（动态甩动与拾放），并设计了结合覆盖率、关键点距离和交并比的因子化奖励函数。实验表明，APS-Net在长袖服装上较现有方法覆盖率提升3.9%，交并比提高5.2%，关键点距离降低7.09%，有效简化了下游折叠任务。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.22769" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>