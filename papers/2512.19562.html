<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2512.19562" target="_blank" rel="noreferrer">2512.19562</a></span>
        <span>作者: Vladimir Petrik Team</span>
        <span>日期: 2025-12-22</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作模型旨在赋予机器人理解自然语言指令并执行通用操作技能的能力。然而，评估其在训练环境之外的泛化能力是一个关键挑战。主流评估方法面临两大困境：其一，在真实世界中进行大规模、多样化的评估成本高昂且难以复现；其二，现有的模拟基准通常支持的扰动类型有限，并且缺乏高保真的视觉呈现和与现实对齐的机器人控制，这导致模拟结果难以可靠地反映模型在复杂现实动态中的性能。本文针对现有模拟基准在真实性、扰动多样性和规模上的局限性，提出了一个经过真实到模拟验证的高保真模拟基准REALM，旨在为VLA模型的泛化能力提供一个可信、可扩展且可复现的评估平台。其核心思路是构建一个集高保真视觉、控制对齐、多样化技能与扰动于一身的模拟环境，并通过大量真实-模拟实验对验证其作为真实世界性能代理的有效性，进而系统性地评估和剖析当前VLA模型的弱点。</p>
<h2 id="方法详解">方法详解</h2>
<p>REALM的整体框架是一个模块化的高保真模拟环境，其输入是待评估的VLA模型策略和指定的任务与扰动配置，输出是模型在多样化条件下的性能量化指标（如分级任务进展率）。其核心设计围绕三个要素：多样化的扰动、分级的评估指标，以及对真实-模拟差距的主动弥合。</p>
<p><img src="https://arxiv.org/html/2512.19562v1/x1.png" alt="任务示例"></p>
<blockquote>
<p><strong>图1</strong>：REALM-base和REALM-articulated任务集中的任务示例。完整基准包含8个基础任务（展示了6个）和2个涉及关节物体的任务（均已展示），用于第五节的大规模评估。</p>
</blockquote>
<p><strong>1. 基准设计：技能、任务与扰动</strong><br>REALM从DROID数据集中衍生出7种常见操作技能：抓取、放置、推、旋转、堆叠、打开和关闭。基于此定义了两个任务集：测试抓放技能的REALM-base（8个任务）和测试打开/关闭抽屉技能的REALM-articulated（2个任务）。任务被定义为在特定场景中操作特定对象的技能实例。<br>为了系统评估泛化能力，REALM实现了15种受控扰动，涵盖视觉、语义和行为三个类别（部分扰动跨多个类别）。</p>
<p><img src="https://arxiv.org/html/2512.19562v1/x2.png" alt="扰动可视化"></p>
<blockquote>
<p><strong>图2</strong>：三类共15种扰动中的9种可视化。<strong>视觉扰动</strong>改变像素空间观测；<strong>语义扰动</strong>要求理解指令语言的不同表述；<strong>行为扰动</strong>要求调整机器人运动策略。</p>
</blockquote>
<p><strong>2. 评估指标：分级任务进展</strong><br>不同于二值成功率，REALM为每种技能定义了一个分级进展标准，作为需要按顺序达成的一系列离散状态序列（如表III所示）。进展率范围从0到1，每个中间阶段权重相等，从而提供更细粒度的性能度量。</p>
<p><strong>3. 核心创新：控制对齐与系统辨识</strong><br>为弥合真实-模拟差距中的控制差距，REALM针对DROID机器人平台，通过系统辨识优化模拟的物理参数以实现轨迹对齐。</p>
<p><img src="https://arxiv.org/html/2512.19562v1/x3.png" alt="控制对齐对比"></p>
<blockquote>
<p><strong>图3</strong>：控制对齐可视化。使用默认控制器（左）和我们的对齐控制（右）在模拟中重放同一条轨迹。黄色轨迹来自真实机器人，蓝色来自模拟。我们的系统辨识实现了显著更真实的轨迹跟随。</p>
</blockquote>
<p>具体而言，模拟控制器根据真实DROID平台重新实现并参数化，留有14个自由参数用于学习模拟关节摩擦和电枢。给定一组N个真实-模拟轨迹对数据集𝒟，通过最小化控制对齐损失函数来优化这些参数：<br>ℒ(𝜽_friction, 𝜽_armature) = Σ_i Σ_t ‖𝒒_i,t_real - 𝒒_i,t_sim‖₂²。<br>优化使用CMA-ES进化算法进行初始估计，随后进行退火参数搜索。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：使用REALM基准，包含REALM-base和REALM-articulated两个任务集（共10个任务）。评估了三个最先进的VLA模型：π₀、π₀-FAST和GR00T N1.5。在默认设置及15种扰动下，每个模型-任务-扰动组合进行25次 rollout，总计约每个模型4000次模拟 rollout。</p>
<p><strong>真实-模拟验证</strong>：通过在近800对真实和模拟 rollout 上进行验证，证明REALM模拟是真实世界性能的可靠代理。</p>
<p><img src="https://arxiv.org/html/2512.19562v1/x4.png" alt="真实-模拟验证设置"></p>
<blockquote>
<p><strong>图4</strong>：我们的设置模拟。为测量真实-模拟差距，我们比较了实验室中真实（未见过的）设置（左）及其在模拟中的“数字孪生”（右）上的任务进展。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2512.19562v1/x5.png" alt="真实-模拟相关性"></p>
<blockquote>
<p><strong>图5</strong>：REALM的真实到模拟验证。左图：在7个任务、5种扰动下，真实世界（x轴）与模拟（y轴）的任务进展呈现强皮尔逊相关性（r），数据点接近恒等线（灰色虚线），且平均最大秩违例值很低。右图：在单个扰动下结果也高度相关。所有设置的p值均小于0.001。</p>
</blockquote>
<p><strong>视觉差距验证</strong>：通过计算π₀模型动作专家在真实和模拟视频帧上的注意力图余弦相似度（达到0.85/1），进一步量化了视觉差距很小，表明模拟渲染本身不足以导致模型预测与真实世界产生巨大差异。</p>
<p><img src="https://arxiv.org/html/2512.19562v1/x6.png" alt="注意力图相似性"></p>
<blockquote>
<p><strong>图6</strong>：π₀动作专家的注意力图。在真实（上）和模拟（下）中重放相同的机器人轨迹，观察到模型关注相似的图像块。计算得到的注意力图余弦相似度为0.85。</p>
</blockquote>
<p><strong>主要评估结果</strong>：</p>
<ol>
<li><strong>总体表现</strong>：π₀-FAST在所有扰动下的平均任务进展率最高，明显优于其他模型；GR00T表现显著较低。</li>
</ol>
<p><img src="https://arxiv.org/html/2512.19562v1/x7.png" alt="平均任务进展"></p>
<blockquote>
<p><strong>图7</strong>：在REALM-base和REALM-articulated任务上的平均任务进展。展示了默认设置（黑色轴）和15种扰动下（彩色轴）的结果。注意纵轴范围为0.0至0.8（满分为1.0）。</p>
</blockquote>
<ol start="2">
<li><strong>扰动效应分析</strong>：使用所有模型和任务上任务进展的均方根偏差来衡量扰动的影响大小。</li>
</ol>
<p><img src="https://arxiv.org/html/2512.19562v1/x8.png" alt="扰动效应RMSD"></p>
<blockquote>
<p><strong>图8</strong>：扰动对任务进展的影响。显示了默认设置与扰动设置之间任务进展的RMSD。扰动按归一化RMSD（每个模型）从左到右排序。误差条反映了效应在不同模型和任务间的偏差。</p>
</blockquote>
<ul>
<li><strong>视觉泛化</strong>：所有纯视觉扰动（V-AUG, V-VIEW, V-SC, V-LIGHT）对模型性能均有明显影响（平均RMSD ≥ 0.12）。其中，改变视角和添加干扰物的影响尤为显著。</li>
<li><strong>语义泛化</strong>：语义扰动对模型极具挑战性。π₀因扩散训练目标在语言理解上表现更差，导致所有语义扰动的RMSD较高。需要世界知识的扰动（S-INT, S-AFF）影响最深。</li>
<li><strong>行为泛化</strong>：行为扰动（常伴随语义/视觉变化）最具挑战性，导致性能大幅下降和较高的RMSD。模型在不同技能间泛化相对较好，但在不同对象间泛化（尤其是未见对象VSB-NOBJ）困难重重。改变操作对象姿态的影响排名第二。</li>
<li><strong>鲁棒性与任务完成</strong>：π₀-FAST在10个任务中的9个上取得了最高的二值成功率。</li>
</ul>
<p><img src="https://arxiv.org/html/2512.19562v1/x9.png" alt="任务成功率"></p>
<blockquote>
<p><strong>图9</strong>：在REALM-base和REALM-articulated任务集上的成功率。小提琴图显示了在均匀Beta先验和观测数据下成功率的贝叶斯后验。</p>
</blockquote>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1) 提出了REALM，一个经过真实到模拟验证的、高保真且控制对齐的模拟基准，用于系统评估VLA模型的泛化能力，支持15种扰动、7种技能和超过3500个对象。2) 通过大量实验证实了该模拟环境作为真实世界性能代理的强相关性，为大规模、可复现的评估提供了可行方案。3) 对当前前沿VLA模型进行了系统性评估，揭示了其在视觉、语义和行为泛化以及任务鲁棒性方面的具体弱点，许多发现与之前小规模真实世界测试观察到的失败模式一致。</p>
<p><strong>局限性</strong>：论文提到，由于精确对齐机器人控制的复杂性，当前版本仅支持DROID这一种机器人 embodiment。此外，基准虽模块化且计划扩展，但初始版本的任务和技能集仍有待丰富。</p>
<p><strong>启示</strong>：研究表明，尽管VLA模型使用了互联网规模数据预训练的VLM主干，并接受了大规模机器人数据训练，但其对语义变化、视角变化、未见对象及对象属性变化的泛化能力仍然不足。这凸显了构建更全面、更真实的模拟基准对于驱动泛化能力研究的重要性。REALM验证的高保真模拟作为评估代理的有效性，为未来以更低成本、更大规模探测模型弱点并指导其改进提供了有力工具。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对视觉-语言-动作模型在真实世界中泛化能力评估困难且成本高昂的问题，提出了REALM基准测试。其核心是构建了一个高保真、控制对齐的仿真环境，包含15种扰动因素、7种操作技能和超过3500个对象，以支持大规模、可重复的泛化能力评测。通过真实到仿真的验证实验，论文表明该仿真环境能有效代理真实世界性能，并系统揭示了当前主流VLA模型在泛化与鲁棒性方面仍面临严峻挑战。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2512.19562" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>