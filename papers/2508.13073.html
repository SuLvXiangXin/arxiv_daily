<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.13073" target="_blank" rel="noreferrer">2508.13073</a></span>
        <span>作者: Liqiang Nie Team</span>
        <span>日期: 2025-08-18</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>机器人操作是机器人与具身人工智能交叉领域的关键挑战，其实现不仅需要精确的运动控制，还需理解复杂动态环境中的视觉与语义信息。传统方法基于精心设计的控制策略和预定义的任务规范，在非结构化、真实世界环境中（尤其是面对新物体、模糊自然语言指令或未见过的环境配置时）表现出可扩展性和泛化能力的固有局限。近年来，在大规模图文数据集上预训练的大视觉语言模型（VLM）展现出连接视觉感知与自然语言理解的卓越能力，超越了单纯的物体识别，实现了整体的上下文理解。将大VLM整合到机器人系统中催生了一类新型模型：基于大VLM的视觉-语言-动作（VLA）模型。这一新兴范式有望克服传统机器人流程的根本局限，使机器人能够理解高级人类指令，泛化到未见过的物体和场景，进行复杂的空间推理，并在动态、非结构化的环境中执行复杂的操作任务。本文核心思路是首次对基于大VLM的VLA模型进行系统性的、以分类学为导向的综述，明确其定义与两大架构范式（单体模型与分层模型），并整合其技术进展、特点与未来方向。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文首先明确定义了基于大VLM的VLA模型：该模型（1）利用大VLM来理解视觉观察和自然语言指令，（2）执行直接或间接服务于机器人动作生成的推理过程。在此基础上，论文区分了两种主要的VLA模型类别，其整体框架对比如下图所示。</p>
<p><img src="https://arxiv.org/html/2508.13073v2/figs/comparison_v5.png" alt="方法框架对比"></p>
<blockquote>
<p><strong>图3</strong>：基于大VLM的VLA模型两大主要类别的比较。<strong>单体模型</strong>（左）在单系统或双系统架构内整合感知、语言理解和动作生成，其中双系统架构包含一个额外的动作专家。<strong>分层模型</strong>（右）通过可解释的中间输出（例如子任务、关键点、程序、可供性图）将规划与策略执行解耦。</p>
</blockquote>
<p><strong>1. 单体模型</strong>：此类模型主要分为单系统和双系统两种实现方式。</p>
<ul>
<li><strong>单系统模型</strong>：将环境理解（包括视觉感知、语言理解和机器人状态感知）与动作生成整合在一个统一的架构中。其经典范式是<strong>自回归解码</strong>，直接借鉴LLM的序列生成能力，将机器人的连续动作空间离散化为令牌序列进行顺序预测。如图4左侧所示，VLM接收视觉观察、自然语言指令和可选的机器人状态作为输入，然后自回归地生成动作令牌，通过下游的解令牌器转换为可执行动作。RT系列（RT-1, RT-2, RT-2-X）和OpenVLA是该范式的典型代表。后续研究围绕<strong>提升模型性能</strong>和<strong>优化推理效率</strong>两个方向衍生出多种变体。性能提升聚焦于：（a）<strong>增强感知模态</strong>：引入3D感知（如Leo Agent、SpatialVLA）、4D时空感知（如TraceVLA、4D-VLA）以及触觉（VTLA）、听觉（VLAS）等多模态信息；（b）<strong>增强推理能力</strong>：通过思维链（CoT）等技术，使模型从简单的反应式控制转向更高级的审慎决策，如ECoT和CoT-VLA。</li>
<li><strong>双系统模型</strong>：将功能划分为两个协作模块：系统2（VLM骨干）执行较慢但更泛化的反思性推理，系统1（动作专家）专注于快速处理以支持反应性行为。这种分工结合了反应速度与深思熟虑的准确性。</li>
</ul>
<p><strong>2. 分层模型</strong>：此类模型明确地将规划与策略执行解耦，其与双系统端到端方法的区别在于两个定义性特征：（1）<strong>结构化的中间输出</strong>：规划器模块生成可解释的表示（如关键点检测、可供性图或轨迹提议），然后由策略模块处理以制定可执行动作；（2）<strong>解耦的训练范式</strong>：允许通过专门的损失函数或API介导的交互，对分层模块进行独立优化。根据中间表示的类型，可进一步细分为基于子任务、关键点、程序等的模型。</p>
<p><img src="https://arxiv.org/html/2508.13073v2/x1.png" alt="单体单系统模型范式详述"></p>
<blockquote>
<p><strong>图4</strong>：单体模型中单系统模型的代表性范式比较。左侧展示了经典的自回归解码范式示意图。右侧上半部分展示了通过融入额外模态、利用思维链推理和加强泛化来增强模型能力的方法。右侧下半部分展示了通过架构细化、参数设计和解码策略来提高推理效率的方法。</p>
</blockquote>
<p>本文的创新点在于首次系统性地提出了基于大VLM的VLA模型的清晰分类法（单体 vs. 分层），并在此框架下细致梳理了各类模型（尤其是单体模型中的单系统模型）的技术演进路径、性能优化方向和效率提升策略，为理解这一快速发展领域提供了结构化的蓝图。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>作为一篇综述性论文，本文并未进行传统意义上的对比实验或消融研究，而是系统性地总结和分析了现有VLA模型的核心特征、性能支撑数据以及所依赖的数据集和基准测试，为评估该领域进展提供了宏观视角。</p>
<p><strong>模型核心特征分析</strong>：论文总结了基于大VLM的VLA模型的四个关键特征，如下图所示。</p>
<p><img src="https://arxiv.org/html/2508.13073v2/figs/midivs_v2.png" alt="VLA模型核心特征"></p>
<blockquote>
<p><strong>图6</strong>：基于大VLM的VLA模型的四个核心特征总结：（a）<strong>多模态融合</strong>：整合视觉、语言、深度、触觉等多模态输入；（b）<strong>指令跟随</strong>：执行从简单到复杂、从具体到开放式的多样化指令；（c）<strong>多维度泛化</strong>：在物体、环境、任务、指令和机器人本体等多个维度上展示泛化能力；（d）<strong>高效部署</strong>：通过模型压缩、动态计算、高效解码和硬件适配等技术实现实际部署。</p>
</blockquote>
<p><strong>数据集与基准测试综述</strong>：论文全面分类并分析了用于VLA模型研究的数据集和基准，涵盖了仿真、真实世界和人类交互数据，如下图所示。例如，大规模真实世界机器人演示数据集（如Open X-Embodiment, OXE）和仿真基准（如RLBench, ManiSkill2）是训练和评估通用VLA模型的基础。此外，还有专注于语言指令复杂性、长视野任务、多模态感知（触觉、音频）以及开放式交互的特殊化数据集。</p>
<p><img src="https://arxiv.org/html/2508.13073v2/figs/data_v4.png" alt="数据集分类"></p>
<blockquote>
<p><strong>图7</strong>：支持大VLM-based VLA模型发展的数据集分类。主要包括：（A）<strong>仿真数据集/基准</strong>，用于可扩展的训练和评估；（B）<strong>真实世界数据集/基准</strong>，提供现实世界的机器人演示；（C）<strong>人类交互数据集</strong>，从人类视频或演示中学习技能；（D）<strong>其他辅助数据集</strong>，如用于触觉、音频感知或开放式任务的数据集。</p>
</blockquote>
<p>本文通过整合这些信息，指明了当前模型评估所依赖的生态系统，并隐含地指出，模型的性能（如RT-2相比RT-1在语义理解和泛化上的显著提升）在很大程度上得益于大规模、多样化的训练数据（如互联网规模的视觉-语言数据和跨机器人的演示数据）以及针对性的基准测试。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li><strong>首次系统性综述</strong>：首次对基于大VLM的VLA模型在机器人操作领域的进展进行了系统性的、以分类学为导向的全面回顾，填补了该交叉领域的综述空白。</li>
<li><strong>提出清晰分类框架</strong>：明确定义了VLA模型，并提出了以“单体模型”和“分层模型”为核心的两级分类法，清晰地区分了不同架构在系统集成粒度和认知分解显式性上的关键设计维度。</li>
<li><strong>整合进展与指明方向</strong>：不仅纵向梳理了技术发展脉络，还横向综合了模型特点、数据集和前沿研究方向（如与强化学习、免训练优化、人类视频学习、世界模型的结合），为领域提供了结构化的知识图谱和未来发展的概念路线图。</li>
</ol>
<p><strong>局限性</strong>：论文自身作为一篇综述，并未提出新的模型，其局限性更多是反映了当前VLA研究领域面临的挑战。文中指出的开放挑战包括：处理复杂长视野任务的<strong>记忆机制</strong>需求；整合3D结构和时间动态的<strong>4D感知</strong>；在资源受限的机器人平台上实现<strong>高效适应与部署</strong>；确保人机交互中的<strong>安全与可靠性</strong>；以及建立更全面、统一的<strong>评估标准与基准</strong>。</p>
<p><strong>对后续研究的启示</strong>：本文为未来研究指明了多个有前景的方向：1) 开发能够存储和利用历史经验的<strong>记忆增强机制</strong>；2) 推进融合时空信息的<strong>4D感知与推理</strong>；3) 探索<strong>参数高效微调</strong>、模型压缩和硬件感知优化以实现<strong>高效部署</strong>；4) 研究<strong>多机器人智能体协作</strong>；5) 增强模型在物理交互中的<strong>安全性与可解释性</strong>。这些方向旨在推动VLA模型从实验室演示走向鲁棒、实用且可信的现实世界机器人应用。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文是一篇关于大型视觉语言模型（VLM）驱动的视觉-语言-动作（VLA）模型在机器人操作领域的系统性综述。核心问题是解决传统基于预定义任务和刚性策略的机器人方法在非结构化、新场景中泛化能力不足的难题。论文提炼了两种关键技术范式：**单体模型**（单/双系统设计）和**分层模型**（通过可解释中间表示解耦规划与执行），并综述了其与强化学习、免训练优化等领域的集成。作为综述，本文未报告具体实验数据，但系统整合了该领域进展，旨在统一分类、减少研究碎片化，并指出了记忆机制、4D感知等未来方向。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.13073" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>