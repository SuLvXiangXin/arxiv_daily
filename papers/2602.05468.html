<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.05468" target="_blank" rel="noreferrer">2602.05468</a></span>
        <span>作者: Shigeki Sugano Team</span>
        <span>日期: 2026-02-05</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前机器人灵巧操作领域的主流方法依赖于高分辨率触觉传感，并利用深度学习模型（如CNN-LSTM、图卷积网络、Transformer）从触觉数据中学习物体属性或控制策略。然而，这些方法存在一个关键局限性：它们通常将所有触觉输入视为由外部物体接触产生，而忽略了多指操作中不可避免的手指-手指、手指-手掌自接触（self-touch）产生的触觉信号。这导致系统容易将自接触误判为物体接触，从而引发不稳定抓握、操作错误甚至物体/机器人损坏。大多数现有方法通过约束运动来避免或忽略自接触信息，这虽然降低了复杂性，但也限制了在自接触不可避免的真实场景中的泛化能力。</p>
<p>本文针对机器人灵巧操作中难以区分自接触与物体接触触觉信号这一具体痛点，借鉴人类感知中的感觉衰减（Sensory Attenuation）原理，提出了一个新视角：通过预测性学习来显式建模自接触动力学，从而在控制过程中衰减可预测的自接触信号，突出外部物体接触信号。本文的核心思路是提出一个名为TaSA的两阶段深度预测学习框架，第一阶段学习自接触动力学模型，第二阶段将该模型集成到运动学习中，以实现基于感觉衰减的鲁棒操作。</p>
<h2 id="方法详解">方法详解</h2>
<p>TaSA框架是一个两阶段学习流程。第一阶段是自接触学习阶段，目标是学习一个从机器人关节状态到自接触触觉反馈的映射模型，该模型独立于外部物体。第二阶段是运动学习阶段，将第一阶段学到的自接触预测模型集成到一个时序模型中，联合处理原始触觉输入和预测的自接触信号，以学习鲁棒的操作策略。</p>
<p><img src="https://arxiv.org/html/2602.05468v1/images/TaSA.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：TaSA方法整体框架。左侧为自接触学习阶段，使用全连接网络（FCN）学习从关节位置到自接触触觉信号的映射。右侧为运动学习阶段，LSTM单元接收关节状态、原始触觉输入和预测的自接触信号，输出下一时刻的关节命令、目标状态和触觉状态预测。一个冻结的自接触模型副本用于从预测的姿态中估计未来的自接触。</p>
</blockquote>
<p><strong>核心模块1：自接触学习阶段</strong><br>该阶段使用一个全连接网络（FCN）来建模自接触动力学。如图2所示，网络在每一时间步t接收当前关节位置q_t和上一时间步的期望关节位置q_{t-1}^{des}作为输入。输入维度为16（8个主动关节×2）。网络输出是预测的自接触触觉状态ŝ_t。使用的触觉传感器是uSkin指尖传感器，每个指尖有30个三轴力传感单元（taxel），因此食指和拇指两个传感器的触觉数据维度为60×3=180。网络结构包含一个编码器（线性层16→64，GELU激活，Dropout 0.2；线性层64→128，GELU）和一个解码器（Dropout 0.2；线性层128→64，GELU；线性层64→188，GELU）。输出包括预测的食指触觉信号（90维）、拇指触觉信号（90维）以及一个辅助的关节状态预测（8维）。损失函数是最小化预测触觉信号ŝ_t与在无物体环境下采集的真实自接触触觉信号s_t之间的误差。训练数据覆盖从张开（无接触）到闭合捏合及摩擦（持续自接触）的各种姿态，使模型学习关节状态变化与特征性自接触触觉模式之间的关联。</p>
<p><img src="https://arxiv.org/html/2602.05468v1/images/selfjointpos.png" alt="自接触学习"></p>
<blockquote>
<p><strong>图2</strong>：自接触学习阶段的示意图。输入是当前和上一时刻的关节位置，通过FCN网络预测自接触产生的触觉信号。</p>
</blockquote>
<p><strong>核心模块2：运动学习阶段</strong><br>如图1右侧和图3所示，该阶段采用一个LSTM网络作为时序模型。其输入包括：当前关节位置q_t、原始触觉输入s_t^{raw}（包含自接触和物体接触）、以及由冻结的自接触模型根据q_t预测的自接触信号ŝ_t^{self}。LSTM隐藏状态维度为128。网络输出包括：下一时刻的关节位置命令q_{t+1}^{cmd}、下一时刻的目标关节状态q_{t+1}^{des}、以及对下一时刻原始触觉状态的预测ŝ_{t+1}^{raw}。此外，一个冻结的自接触模型副本被用于从预测的关节状态q_{t+1}^{des}中估计未来的自接触信号ŝ_{t+1}^{self}。这种设计使得网络能够同时重构原始触觉输出，并维持外部接触与自诱导接触的分离。通过联合推理原始触觉输入和自接触预测，网络学习到一种基于感觉衰减的表征，从而在操作中能识别自接触以保持稳定，并对物体引发的力做出不同的响应。</p>
<p><img src="https://arxiv.org/html/2602.05468v1/images/models.png" alt="模型对比"></p>
<blockquote>
<p><strong>图3</strong>：提出的方法（同时使用原始触觉和预测自接触）与基线方法（仅使用原始触觉）的对比。</p>
</blockquote>
<p><strong>创新点</strong><br>与现有方法相比，TaSA的核心创新在于显式地引入并建模了自接触动力学，并将其作为感觉衰减机制集成到运动学习过程中。现有方法要么忽略自接触，要么将所有触觉视为外部输入，缺乏区分自接触与物体接触的机制。TaSA通过两阶段框架，首先学习一个可预测的自接触模型，然后在运动控制中利用该模型的预测来衰减可预期的触觉信号，从而突出了与任务相关的、不可预测的物体接触信号。这为解决接触密集型灵巧操作中的信号混淆问题提供了一种结构化的感知方法。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：实验在三个需要精细触觉辨别的插入任务上进行：1) 将铅笔芯插入自动铅笔；2) 将硬币投入投币口；3) 将回形针固定到纸上。任务涉及不同的方向、位置和尺寸变化。实验平台使用了一个配备两个uSkin指尖传感器（食指和拇指）的机器人手。基线方法是仅使用原始触觉输入（无自接触预测）的LSTM策略。</p>
<p><img src="https://arxiv.org/html/2602.05468v1/images/tasks.png" alt="实验任务"></p>
<blockquote>
<p><strong>图4</strong>：三个实验任务示意图：回形针固定、硬币插入和铅笔芯插入。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.05468v1/images/setup.png" alt="实验平台"></p>
<blockquote>
<p><strong>图5</strong>：实验设置，展示了机器人手、uSkin传感器和任务物体。</p>
</blockquote>
<p><strong>关键实验结果</strong>：<br>在三个任务上，使用TaSA框架训练的策略相比仅使用原始触觉的基线方法，取得了显著更高的成功率。具体而言：</p>
<ul>
<li><strong>回形针任务</strong>：TaSA成功率为 **86.7%**，而基线为 **53.3%**，相对提升约62.7%。</li>
<li><strong>硬币插入任务</strong>：TaSA成功率为 **80.0%**，基线为 **46.7%**，相对提升约71.2%。</li>
<li><strong>铅笔芯插入任务</strong>：TaSA成功率为 **73.3%**，基线为 **40.0%**，相对提升约83.3%。</li>
</ul>
<p>这些结果表明，基于感觉衰减的结构化触觉感知对于灵巧机器人操作至关重要。</p>
<p><strong>结果可视化与分析</strong>：<br>论文通过PCA将高维触觉数据降维至2D进行可视化，比较了TaSA与基线方法在操作过程中触觉状态的演变。</p>
<p><img src="https://arxiv.org/html/2602.05468v1/images/clip_pca_caseA_initial_raw.png" alt="回形针任务触觉PCA（案例A）"></p>
<blockquote>
<p><strong>图9</strong>：回形针任务案例A的触觉状态PCA图。TaSA方法（右）的触觉状态轨迹在成功插入时展现出更清晰、更集中的模式转换，而基线方法（左）的轨迹更加分散和混乱。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.05468v1/images/coins_pca_caseA_initial_raw.png" alt="硬币任务触觉PCA（案例A）"></p>
<blockquote>
<p><strong>图10</strong>：硬币插入任务案例A的触觉状态PCA图。TaSA方法（右）的轨迹在接近成功时（绿色点）更为一致，表明其对物体接触信号的感知更稳定。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.05468v1/images/lead_pca_caseA_initial_raw.png" alt="铅笔芯任务触觉PCA（案例A）"></p>
<blockquote>
<p><strong>图11</strong>：铅笔芯插入任务案例A的触觉状态PCA图。同样，TaSA方法（右）显示出更有序的触觉状态演化。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2602.05468v1/images/positions.png" alt="不同初始位置触觉PCA"></p>
<blockquote>
<p><strong>图6</strong>：不同初始位置下，TaSA与基线方法在回形针任务中的触觉PCA轨迹对比。TaSA在不同起点下都能收敛到相似的最终状态（成功区域），而基线的轨迹则不一致且常偏离目标。</p>
</blockquote>
<p><strong>消融实验与组件贡献</strong>：<br>论文通过分析自接触预测的准确性以及触觉信号在操作过程中的变化，间接验证了各组件的作用。例如，图7和图8展示了自接触模型在拇指和食指传感器上预测值与真实值的对比，表明模型能够较好地预测自接触产生的力模式。触觉PCA图（图9-14）则表明，集成自接触预测后，策略学习到的触觉表征更能区分操作的关键阶段（如初始接触、滑动、插入成功），这归功于自接触模型的过滤作用使得物体接触信号更加突出。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了TaSA，一个受感觉衰减启发、用于灵巧操作的两阶段深度预测学习框架，首次在机器人操作中显式地建模并利用自接触动力学来区分自接触与物体接触触觉信号。</li>
<li>通过三个精细的插入任务实验，实证了所提方法的有效性，与仅使用原始触觉的基线相比，成功率获得了显著提升（相对提升62.7%到83.3%）。</li>
<li>提供了触觉状态的可视化分析，表明TaSA能使策略学习到更清晰、更稳定的触觉表征，验证了感觉衰减机制在改善触觉感知与控制方面的作用。</li>
</ol>
<p><strong>局限性</strong>：<br>论文自身提到的局限性包括：当前方法主要针对指尖传感器，未来需要扩展到覆盖整个手部表面的触觉皮肤；自接触学习阶段需要在无物体环境下收集数据，这增加了数据收集的步骤；实验任务虽然具有挑战性，但数量和多样性仍有待扩展。</p>
<p><strong>对后续研究的启示</strong>：<br>TaSA框架为机器人触觉感知与控制开辟了一个新方向，即主动建模和利用“预期内”的传感器反馈（如自接触）来增强对“预期外”事件（如物体交互）的感知。后续工作可以探索将类似原理应用于其他模态（如本体感觉）或其他接触密集任务（如装配、工具使用）。此外，如何实现更高效、更在线自适应的自接触模型学习，以及如何将该框架与视觉等其他传感模态更紧密地结合，都是值得研究的方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人灵巧操作中难以区分自身接触与外部物体接触触觉信号的核心问题，提出TaSA框架。该方法采用两阶段深度预测学习：第一阶段学习机器人自身动作产生的触觉动力学模型；第二阶段将该模型融入运动学习，以增强对外部物体接触信号的感知。实验在插入任务中验证了该框架能有效提升操作性能，实现更精细的触觉判别。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.05468" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>