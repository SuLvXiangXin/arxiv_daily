<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Rethinking Visual-Language-Action Model Scaling: Alignment, Mixture, and Regularization - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>Rethinking Visual-Language-Action Model Scaling: Alignment, Mixture, and Regularization</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2602.09722" target="_blank" rel="noreferrer">2602.09722</a></span>
        <span>作者: Wang, Ye, Zheng, Sipeng, Luo, Hao, Zhang, Wanpeng, Yuan, Haoqi, Xu, Chaoyi, Xu, Haiweng, Feng, Yicheng, Yu, Mingyang, Kang, Zhiyu, Lu, Zongqing, Jin, Qin</span>
        <span>日期: 2026/02/10</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，视觉-语言-动作模型被视为通用具身智能的一个有前景的方向。受视觉-语言模型成功经验的启发，机器人领域正从单一任务策略转向旨在跨不同环境解决许多任务的通用策略。一个普遍的观点是，与语言建模类似，机器人泛化能力的提升将主要源于数据和模型规模的扩大。然而，机器人数据本质上是异构的：不同机器人在运动学、关节限制、控制频率、感知模态和动作空间上存在差异，这些差异在设计上往往是不兼容的。因此，扩大异构机器人数据规模是否总能带来正向迁移，还是说本体差异会引入干扰从而限制性能，目前尚不清楚。本文针对这一核心痛点，通过一个受控的实证研究来重新审视VLA模型缩放，聚焦于三个关键设计维度：物理对齐、本体混合和训练正则化。其核心思路是，不提出新架构，而是基于一个代表性的VLA框架构建受控测试平台，系统性地在匹配条件下消融关键设计选择，并引入减少偏见的真实机器人评估协议。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文的研究框架基于一个结合了视觉-语言主干和流匹配的代表性VLA模型，并引入了分组盲集合评估协议。</p>
<p><img src="https://arxiv.org/html/2602.09722v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：系统性的VLA分析框架概览，包含混合专家架构、物理对齐的动作空间和分组盲集合协议。</p>
</blockquote>
<p><strong>整体架构与动作生成</strong>：模型采用混合专家设计。包含两个并行的Transformer骨干：语义专家（从预训练的VLM初始化以保留视觉和语言先验）和动作专家（随机初始化并专用于控制）。两个专家通过层间共享的因果自注意力机制进行交互，使得动作专家能够直接关注完整的视觉-语义上下文。动作生成采用流匹配方法，将动作块的条件分布建模为一个从高斯噪声分布到数据分布的向量场学习问题，通过优化流匹配目标函数进行训练，并在推理时通过求解常微分方程生成平滑的动作序列。</p>
<p><strong>物理对齐的统一动作空间</strong>：为了支持跨异构机器人的可扩展预训练，本文定义了一个物理基础统一动作空间，它作为所有支持的物理自由度的一个超集，并被划分为语义对齐的子空间，包括末端执行器位姿、关节空间命令、夹爪状态、灵巧手状态和辅助机制。为了研究哪种动作参数化方式缩放效果最好，论文在末端执行器子空间内定义了四种坐标映射模式：世界相对、世界增量、末端执行器相对和末端执行器增量。对于每个机器人本体，定义一个嵌入映射将其原生动作空间嵌入到统一空间的相应语义槽中，未使用的维度用二进制掩码禁用。这种构造鼓励模型在跨机器人重叠的子空间中学习共享的物理先验。</p>
<p><strong>分组盲集合评估协议</strong>：为了减少实验者偏见，论文提出了分组盲集合协议。该协议将模型池随机划分为不重叠的小组，在每个任务中，小组内的模型被匿名化并以随机顺序进行评估。系统调度下一个要运行的政策，操作员仅作为执行者进行 rollout 并记录二元成功/失败结果，而无法访问模型身份或版本信息。分组既减少了人类偏好的影响，也支持组间结构化休息以减轻疲劳。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：使用了大规模异构机器人数据进行预训练，包括来自Open X-Embodiment、AgiBot、RoboMind等的真实世界末端执行器数据，以及来自InternData、SO-100等的仿真和关节空间数据。通过动态下采样策略平衡数据，最终有效语料库包含约1.8亿帧转换。下游评估在LIBERO（5样本少样本）和RoboCasa（50样本少样本）仿真基准上进行，并在一台配备两个RGB摄像头的Franka Panda机械臂上进行了四项真实世界任务评估（堆叠碗、放入抽屉、擦拭白板、给植物浇水），所有真实评估均采用盲评协议。</p>
<p><strong>关键实验结果 - 物理对齐</strong>：<br>仿真结果表明，坐标框架强烈影响预训练迁移的性能。在LIBERO上，使用世界坐标系动作的从头训练策略性能优于末端执行器坐标，这可能是因为固定的相机外参和有界工作空间使得利用绝对位置变得容易。然而，预训练后情况反转：世界坐标系变体出现负迁移（平均-0.9%，-0.5%），而末端执行器坐标系变体获得一致增益（平均+2.6%，+2.4%）。这表明世界坐标容易过拟合单一环境规律，而末端执行器坐标在大规模数据中跨不同相机和机器人基座时泛化更好。</p>
<p><img src="https://arxiv.org/html/2602.09722v1/x4.png" alt="动作空间盲评结果"></p>
<blockquote>
<p><strong>图4</strong>：不同动作空间在真实世界的盲评结果。所有增量动作在真实机器人上都表现出原地抖动，无法执行任务（成功率为0%），而相对动作能有效执行。在真实场景中，世界相对和末端执行器相对之间未观察到显著性能差异。</p>
</blockquote>
<p>当视觉语言主干被冻结时，预训练的益处更加明显。在此机制下，末端执行器相对表示获得了最高的平均成功率75.1%和最大的提升+8.2%，证实了末端执行器空间是在视觉主干静态时保存和迁移物理先验的最有效选择。在几何多样的RoboCasa基准上，末端执行器相对表示表现出最可靠的缩放行为，平均成功率从45.1%提升至50.0%。而其他动作表示则不稳定或无效，例如世界增量基本无收益甚至略有负迁移（-0.1%）。</p>
<p><strong>关键实验结果 - 本体混合</strong>：<br>与语言模型的缩放行为相反，扩大机器人预训练语料库并不会带来单调的收益。采用累积包含协议的研究显示，仅使用标准公共数据集的D1混合物在LIBERO上提供了最强的预训练迁移（冻结VLM机制下平均成功率77.3%）。当加入更多真实世界末端执行器数据形成D2时，性能反而下降（平均成功率降至73.8%）。进一步加入仿真末端执行器数据（D3）和关节空间数据（D4）并未使性能恢复至D1的水平。这表明，不加选择地混合异构机器人数据常常会引发负迁移，突显了朴素数据缩放的脆弱性。</p>
<p><img src="https://arxiv.org/html/2602.09722v1/x5.png" alt="数据混合盲评结果"></p>
<blockquote>
<p><strong>图5</strong>：不同预训练数据混合物在真实世界的盲评结果。与仿真实验趋势一致，仅使用OXE的D1混合物性能最佳（平均成功率58.8%），加入更多异构数据后性能下降。</p>
</blockquote>
<p><strong>关键实验结果 - 训练正则化</strong>：<br>论文评估了两种直观的正则化策略：感官随机丢弃（以概率0.2掩码本体感知，并独立以概率0.2丢弃每个相机视图）和两阶段课程学习（第一阶段冻结VLM训练动作专家，第二阶段解冻全部参数）。实验结果表明，在预训练阶段应用这些策略，在下游的LIBERO和RoboCasa微调中，与直接联合优化相比，并未带来一致的性能提升，有时甚至会导致性能下降。这表明这些直观的训练修改在大规模预训练机制下并不能可靠地转化为收益。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1）通过系统的受控实验，确立了末端执行器相对动作表示作为跨异构机器人VLA训练可靠默认选择的有效性；2）揭示了机器人数据缩放的特殊性，即不加区分的异构数据混合常导致负迁移，挑战了“数据越多越好”的朴素观念；3）提出并验证了分组盲集合评估协议，显著减少了真实机器人性能测量中的人为偏见。</p>
<p>论文自身提到的局限性包括：主要探索了基于流匹配的混合专家架构，未测试更广泛的模型家族；数据混合策略相对静态，未探索动态数据调度或更精细的混合比例。</p>
<p>本研究对后续研究的启示在于：构建大规模VLA模型时，应优先考虑物理对齐良好的动作表示（如EEF-Relative）；需要谨慎设计数据混合策略，而非简单汇集所有可用数据；开发更客观、减少偏见的机器人评估协议至关重要；一些在较小规模或其它领域有效的正则化技术，在大规模具身训练中可能需要重新评估其有效性。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对视觉-语言-动作模型在机器人领域缩放的核心问题展开研究：机器人数据具有跨实体、传感器和动作空间的异质性，标准的数据缩放方法是否有效？作者基于一个结合VLM主干与流匹配的代表性框架，通过系统实验检验了三个维度的设计选择：物理对齐、实体混合和训练正则化。核心结论表明：统一的末端执行器相对动作表示对跨实体迁移至关重要；简单混合异构机器人数据集常导致负迁移而非增益；感官丢失和多阶段微调等直观正则化策略在大规模下并不总能提升性能。这项研究挑战了关于具身智能缩放的常见假设，并为利用多样化机器人数据训练大规模VLA策略提供了实用指导。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2602.09722" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>