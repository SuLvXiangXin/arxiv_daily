<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>OASIS: Real-Time Opti-Acoustic Sensing for Intervention Systems in Unstructured Environments - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>OASIS: Real-Time Opti-Acoustic Sensing for Intervention Systems in Unstructured Environments</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.12071" target="_blank" rel="noreferrer">2508.12071</a></span>
        <span>作者: Richard Camilli Team</span>
        <span>日期: 2025-08-16</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>水下高分辨率3D场景重建对于施工、基础设施维护、监测和科学考察等应用至关重要。现有方法主要分为两类：一类是仅依赖声学传感器（如成像声呐）的重建方法，包括基于特征、轮廓、模型和体积的技术。这些方法存在局限性：特征法难以生成密集3D模型；轮廓法和模型法通常需要对环境几何（如平坦海床）或载体运动做出强假设；体积法虽无环境约束，但仅靠声学数据重建的结果难以解释，缺乏语义信息。另一类是光声融合方法，结合了光学相机的高分辨率纹理信息和声呐的可靠几何深度信息，例如基于极线几何或神经渲染（如AoNeuS）的方法。然而，这些方法大多为离线处理，计算复杂（AoNeuS优化需30分钟，渲染需数分钟），无法满足自主或遥操作水下航行器对实时空间感知的迫切需求。</p>
<p>本文针对水下非结构化环境中实时3D感知的痛点，提出了一种新的视角：将声学体积重建（体素雕刻）与光学图像投影相结合，而非依赖计算密集的神经渲染。其核心思路是：首先利用机械臂灵巧性快速采集多视角声呐数据，通过体素雕刻实时重建场景几何（占用网格）；然后基于该几何引导光学相机近距离采集图像，并将光学纹理投影到声学重建的网格上，从而生成兼具几何与语义信息的实时3D场景表示。</p>
<h2 id="方法详解">方法详解</h2>
<p>OASIS的整体流程是一个四阶段管道：1）使用“扫描”轨迹记录声呐数据，初步映射工作空间；2）从声呐数据计算初始占用网格（声学3D重建）；3）利用占用网格获取光学相机的特写视图；4）将光学图像与占用网格融合。</p>
<p><img src="https://arxiv.org/html/2508.12071v1/figures/pipeline.png" alt="方法流程"></p>
<blockquote>
<p><strong>图2</strong>：OASIS方法整体流程。左侧为声学3D重建管线：原始声呐数据经过预处理和体素模板投影，结合位姿信息更新全局体素网格。右侧为光声融合管线：声学重建的网格用于渲染深度图像，与分割后的光学图像结合，通过投影实现纹理贴图。</p>
</blockquote>
<p><strong>核心模块1：声学数据采集与预处理</strong><br>采用“眼在手”配置，传感器安装在机械臂手腕。在未知工作空间，首先执行一个低姿态的“扫描”轨迹（图1）来采集声呐数据。该轨迹使机械臂从其收起位置进行最小幅度移动，以最小化碰撞风险，同时通过在不同俯仰角下摆动肩部偏航关节（±70°）和设置手腕偏航极限（±50°），获得垂直和水平覆盖的、具有垂直视角的数据，以解决声呐高程角模糊性问题。</p>
<p><img src="https://arxiv.org/html/2508.12071v1/figures/trajectory2.png" alt="扫描轨迹"></p>
<blockquote>
<p><strong>图1</strong>：提出的“扫描”轨迹。通过顺序改变手腕俯仰角（45°，30°，15°）并在每个俯仰角下双向摆动肩部偏航关节，记录一系列相交的成像声呐图像，以最小的移动覆盖工作空间。</p>
</blockquote>
<p>声呐数据预处理旨在去除振铃伪影并归一化强度。算法将极坐标数据转为笛卡尔坐标，利用前10个距离单元（约5cm）的背景噪声计算均值μ_bg和标准差σ_bg。对于后续距离单元，采用滑动窗口计算每个距离单元上所有波束强度的均值μ_W和标准差σ_W。若某波束在特定距离单元上的强度值大于μ_W + σ_W，则标记为占用。此统计方法抑制了高强度声学回波产生的振铃。</p>
<p><img src="https://arxiv.org/html/2508.12071v1/figures/preprocess.png" alt="预处理效果"></p>
<blockquote>
<p><strong>图3</strong>：预处理步骤。(a)原始声呐数据，(b)应用预处理后得到的二值占用图，振铃效应减少。</p>
</blockquote>
<p><strong>核心模块2：声学3D重建（体素雕刻）</strong><br>该方法扩展了用于声学数据场景几何推理的min-max体素雕刻方法。流程如下：</p>
<ol>
<li><strong>初始化</strong>：初始化一个覆盖机械臂可达工作空间的体素网格V，以及两个同尺寸的网格G_obs（观测计数）和G_occ（占用计数）。预计算一个“体素模板”，包含充分表示传感器视场所需的最少点集，极大减少了全局帧投影的计算量。</li>
<li><strong>投影与更新</strong>：对每一帧预处理后的二值声呐图像，将体素模板投影到该图像上。模板中的体素若包含任何占用像素则标记为占用。然后利用机械臂正向运动学和关节传感器估计的声呐位姿，将该模板投影到世界坐标系。对于世界坐标系中的每个投影体素，递增G_obs中的对应计数；若该体素被标记为占用，则同时递增G_occ中的计数。</li>
<li><strong>占用决策</strong>：计算每个体素的比率 G_occ / G_obs，并与经验阈值 t_r 比较。比率大于 t_r 的体素在最终体素网格 V 中标记为占用，否则为空。阈值 t_r 用于平衡因噪声、阴影等导致的假阴性（若t_r过高导致地图出现空洞）和因高程角模糊导致的假阳性（若t_r过低导致地图出现错误占用区域）。</li>
</ol>
<p><strong>核心模块3：光声融合</strong><br>声学重建提供了几何信息，但缺乏视觉细节。系统可基于此几何引导机械臂避障，移动到更近距离采集光学图像。融合过程：首先将体素网格V通过行进立方体算法转换为平滑网格。对于每一张光学图像，利用相机内参和由机械臂模型得到的外参（位姿）构建虚拟相机，并从网格渲染出对应的深度图像。分别使用Rembg（ISNet模型）和分水岭算法对光学图像和深度图像进行背景掩码计算，取两者掩码的交集以分割前景物体。最后，利用相机位姿、内参和深度图像，将分割出的像素投影到世界坐标系，并与网格化体素网格一同渲染，实现光学纹理在几何模型上的贴图。</p>
<p><strong>创新点</strong>：1) <strong>实时性</strong>：通过体素模板和轻量级预处理，实现了超越声呐传感器帧率（18 Hz）的处理速度。2) <strong>眼在手安全轨迹</strong>：设计了低姿态扫描轨迹，在安全前提下高效获取多视角数据以解决高程模糊。3) <strong>统计预处理</strong>：提出基于滑动窗口统计的声呐数据二值化方法，有效抑制振铃伪影。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在一个直径2.1米、深1.5米的水箱中进行验证。传感器包括Oculus M1200d多波束成像声呐（10 FPS）和stellarHD水下相机（10 FPS），均安装在Kraft TeleRobotics七自由度液压机械臂手腕（图4）。测试物体包括塑料牛奶箱、金属网、货网和链条，具有不同的材料和几何特性。</p>
<p><img src="https://arxiv.org/html/2508.12071v1/figures/sensor-mount2.png" alt="传感器安装"></p>
<blockquote>
<p><strong>图4</strong>：实验采用的“眼在手”配置。相机视场上半部分与机械臂工作空间内的声呐视场重叠。</p>
</blockquote>
<p><strong>关键结果</strong>：</p>
<ol>
<li><strong>实时性能</strong>：使用0.05米体素分辨率时，处理每帧声呐数据仅需0.052秒，理论最大帧率达18.6 FPS，超过声呐自身10 FPS的采集能力，满足实时性要求。处理时间随体素分辨率提高呈立方级增长（表II）。</li>
<li><strong>重建完整性</strong>：方法能够重建水下物体以及水箱的后壁（图5），表明声呐能够克服部分遮挡和圆形池壁产生的声学混响来捕获工作空间几何信息，即使在光学视线被遮挡时亦然。</li>
</ol>
<p><img src="https://arxiv.org/html/2508.12071v1/figures/top.png" alt="俯视重建"></p>
<blockquote>
<p><strong>图5</strong>：重建结果的俯视图。尽管水箱中的物体有部分遮挡，但水箱的后壁被完整重建。<br>3.  <strong>定量精度</strong>：如表III所示，声学重建在测量水箱宽度（误差5.2 cm）、牛奶箱尺寸（误差6.6 cm）和金属网全宽（误差5.1 cm）上具有较好精度。对于精细结构（如单个网格单元、链条），由于体素分辨率限制，声学重建无法识别，但光学投影结果能提供更精确的测量（如10个网格单元误差1.2 cm）。货网因可变形，未报告精度。<br>4.  <strong>定性结果</strong>：图6对比了原始场景照片、纯声学重建（网格）和光声融合重建（带纹理的网格）的结果。光声融合结果在保留几何的同时，赋予了物体可识别的颜色和纹理信息，极大地提高了场景的可解释性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.12071v1/figures/results-compare.png" alt="结果对比"></p>
<blockquote>
<p><strong>图6</strong>：水箱(a,b)、牛奶箱(c,g)、金属网(d,h)、货网(e,i)和链条(f,j)的重建结果对比。左侧列为原始场景和声学重建网格，右侧列为光声融合后的带纹理网格。</p>
</blockquote>
<p><strong>消融分析</strong>：实验通过改变体素分辨率分析了其对处理速度的影响（表II），体现了方法在精度与实时性之间的权衡。预处理步骤（图3）的有效性通过对比原始数据与二值化结果得到验证，表明其能减少伪影。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1) 提出了一种<strong>实时的光声融合方法</strong>（OASIS），首次将体素雕刻与光学投影结合，在非结构化水下环境中实现了超过传感器采集速率的3D重建。2) 提出了一种针对成像声呐的<strong>统计预处理方法</strong>，用于抑制振铃和归一化强度。3) 设计了一种适用于“眼在手”配置的<strong>安全高效扫描轨迹</strong>，能以最小移动获取解决高程模糊所需的多视角数据。</p>
<p><strong>局限性</strong>：论文指出当前方法<strong>限于小型、静态工作空间</strong>，且<strong>依赖固定基座机械臂提供的精确位姿信息</strong>。在浑浊水域的性能尚未评估。</p>
<p><strong>后续启示</strong>：1) 未来工作可探索<strong>基于目标的跟踪</strong>以处理动态环境，并<strong>集成SLAM方法</strong>以支持自由漂浮的机械臂平台。2) 需要评估方法在<strong>浑浊水域</strong>的表现，并可通过<strong>结合距离相关的颜色校正</strong>来改进光学融合能力，实现多视角图像拼接。3) 该方法低计算和低功耗的特点，使其适用于携带有限机载电源的无人水下航行器，为未来无缆航行器的实时感知提供了可行方案。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出OASIS系统，旨在解决非结构化水下环境中实时3D场景重建的难题，以支持自主或遥控作业。该方法采用光声融合技术，结合光学图像与声纳数据，并利用体素雕刻进行实时重建；系统采用“手眼”配置，通过机械臂在短基线上获取多视角数据。水箱实验验证了该方法的有效性，结果表明其能够为水下操作任务提供实时的空间感知能力。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.12071" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>