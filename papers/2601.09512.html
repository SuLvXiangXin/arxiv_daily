<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2601.09512" target="_blank" rel="noreferrer">2601.09512</a></span>
        <span>作者: Römer, Ralf, Zhang, Yi, Schoellig, Angela P.</span>
        <span>日期: 2026/01/14</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前，为了教授机器人复杂的操作任务，常见的做法是在特定任务数据上微调预训练的视觉-语言-动作模型。然而，这种方法会更新模型已有的表示，因此不适合机器人在现实世界中的长期运行，因为机器人必须持续适应新任务和环境，同时保留已获得的知识。现有的机器人持续学习方法通常需要存储先前数据（示例），难以处理长任务序列，或者依赖任务标识符进行部署。针对这些局限性，本文提出了一种通用的、参数高效的无示例持续学习框架CLARE。本文的核心思路是：向预训练VLA模型中注入轻量级模块化适配器，在学习新任务时根据层间特征相似性自主地仅在必要处扩展模型，在部署时通过基于自编码器的路由机制动态激活最相关的适配器，而无需任务标签。</p>
<h2 id="方法详解">方法详解</h2>
<p>CLARE的整体流程分为训练（动态扩展与适配器训练）和部署（自主路由）两个阶段。其核心是向预训练VLA模型（通常是Transformer架构）中选定的一组前馈网络层注入轻量级适配器作为旁支。学习新任务时，系统根据输入特征与已有任务的相似度，决定是否在某一层创建新的适配器（动态扩展）。部署时，基于每个层附带的多个自编码器判别器的重建误差，选择并激活最相关的适配器（自主路由）。</p>
<p><img src="https://arxiv.org/html/2601.09512v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：CLARE方法整体框架概览。从预训练的VLA开始，CLARE自主且持续地在选定的前馈网络层扩展新的轻量级适配器。在推理时，基于学习到的自编码器判别器捕获的特征相似性，选择最相关的适配器。通过冻结现有参数并仅微调每个阶段的新参数，可以在不灾难性遗忘已学技能的情况下获取新的任务特定知识。</p>
</blockquote>
<p>核心模块包括：</p>
<ol>
<li><strong>模块化适配器</strong>：适配器是轻量级的编码器-解码器结构，插入到选定的可扩展FFN层。对于层ℓ的输入特征𝒙ℓ，第i个适配器的输出为Aℓⁱ(𝒙ℓ) = 𝑾ℓ,iᵘᵖ ReLU(𝑾ℓ,iᵈᵒʷⁿ 𝒙ℓ)，其中r &lt;&lt; dℓ，保证了参数高效。在推理时，被选中的适配器输出会加到原始预训练FFN层的输出上：FFNℓ(𝒙ℓ) = FFNℓᵖʳᵉ(𝒙ℓ) + Aℓ*(𝒙ℓ)。学习新任务时，仅训练新添加的适配器，冻结模型其余部分。</li>
<li><strong>自主路由机制</strong>：每个可扩展层ℓ都配备一组自编码器判别器Dℓ = {Dℓ¹, Dℓ², …}，每个判别器与一个适配器通过映射Bℓ相关联。对于输入特征𝒙ℓ，计算每个判别器的重建误差eℓʲ(𝒙ℓ) = ‖𝒙ℓ - Dℓʲ(𝒙ℓ)‖₂。路由机制选择与具有最小重建误差的判别器相关联的适配器进行激活。这使模型能够基于当前观测自主选择合适的知识模块，无需外部任务标识符。</li>
</ol>
<p><img src="https://arxiv.org/html/2601.09512v1/x2.png" alt="动态扩展与路由细节"></p>
<blockquote>
<p><strong>图2</strong>：CLARE动态扩展与路由机制详解。<strong>上图（推理）</strong>：路由机制根据自编码器判别器的最低重建误差，激活最相关的适配器。<strong>下图（动态扩展）</strong>：计算新任务特征与所有已有判别器的z-score。若所有z-score超过阈值γ，则添加新的适配器和判别器；否则，仅添加一个新的判别器并将其链接到最相关的现有适配器。</p>
</blockquote>
<ol start="3">
<li><strong>动态扩展策略</strong>：这是CLARE的关键创新，旨在实现子线性的参数增长。当学习新任务𝒯ₙ时，对于每个可扩展层ℓ，计算新任务数据在所有已有判别器Dℓʲ上的重建误差的z-score值zℓʲ。如果所有已有判别器的z-score都大于阈值γ，则认为新任务特征在该层与所有旧任务显著不同，需要扩展一个新的适配器Aℓᵏ，并将新添加的判别器Dℓⁿ与之链接。否则，认为现有适配器的知识可迁移至新任务，则仅添加一个新的判别器Dℓⁿ，并将其链接到重建误差最小的现有判别器所对应的适配器。此外，为确保学习稳定性，如果没有任何层被扩展，则强制在最浅层添加一个适配器。</li>
</ol>
<p>与现有方法相比，CLARE的创新点具体体现在：1) <strong>自主路由</strong>：无需任务标识符，基于特征相似性在部署时动态选择知识模块；2) <strong>条件性动态扩展</strong>：并非为每个任务在所有层盲目添加参数，而是根据特征分布变化仅在必要处扩展，实现了高效的知识共享与参数利用。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验在LIBERO机器人操作基准上进行，使用其中的LIBERO-10长视野任务序列进行持续学习评估。基线方法包括：1) <strong>微调</strong>：直接在连续任务上微调整个模型；2) <strong>EWC</strong>：弹性权重巩固；3) <strong>PackNet</strong>：通过剪枝和重训练复用参数；4) <strong>LOTUS</strong>：基于技能库和示例回放的层次方法；5) <strong>SDP</strong>：稀疏扩散策略（需要任务ID）；6) **Adapter (All)**：为每个任务在所有选定层添加适配器（固定扩展）。评估指标为任务成功率。</p>
<p><img src="https://arxiv.org/html/2601.09512v1/images/baseline_comparison.png" alt="基线方法对比"></p>
<blockquote>
<p><strong>图4</strong>：在10个任务序列上的持续学习性能对比。CLARE在最终平均成功率（68.5%）和反向迁移（BWT，+2.4%）方面均显著优于所有基线方法，甚至超过了需要存储示例的LOTUS方法（62.7%）。微调方法发生了严重的灾难性遗忘（最终成功率29.2%）。</p>
</blockquote>
<p>关键实验结果：CLARE在10个任务序列学习完毕后，取得了68.5%的平均成功率，显著优于所有基线。特别是，它超越了需要示例回放的LOTUS（62.7%）和需要任务ID的SDP（59.8%）。CLARE还表现出最小的遗忘，其反向迁移（BWT）指标为+2.4%，表明学习新任务甚至对旧任务有轻微的正向帮助。相比之下，微调方法的成功率降至29.2%，灾难性遗忘严重。</p>
<p><img src="https://arxiv.org/html/2601.09512v1/images/threshold_ablation_plots.png" alt="阈值消融实验"></p>
<blockquote>
<p><strong>图5</strong>：动态扩展阈值γ的消融研究。左图显示，适中的γ值（2.5）在最终性能和参数效率（中图）之间取得了最佳平衡。γ过高（5.0）会导致扩展不足、性能下降；γ过低（1.0）会导致过度扩展、参数增长接近线性且性能未提升。右图展示了不同γ值下各层的实际扩展情况。</p>
</blockquote>
<p>消融实验总结：</p>
<ol>
<li><strong>动态扩展阈值γ</strong>：实验表明，γ=2.5在性能和参数效率间达到最佳平衡。γ过高（5.0）导致扩展不足、性能下降；γ过低（1.0）导致过度扩展、参数增长接近线性且未带来性能增益。</li>
<li><strong>扩展层的位置</strong>：实验发现，在编码器模块的FFN层插入适配器比在解码器模块表现更好。</li>
<li><strong>路由与扩展的必要性</strong>：移除自主路由（使用任务ID选择）或移除动态扩展（固定每任务全层扩展）都会导致性能下降，验证了这两个核心组件的有效性。</li>
</ol>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献在于：1) 提出了一个用于VLA的、无示例且无需任务标识符的持续学习框架CLARE；2) 设计了基于特征相似性的自主路由机制，实现了部署时的任务无关推理；3) 引入了动态扩展策略，以子线性的参数增长（实验中约每任务2%）高效地学习新任务并避免遗忘。</p>
<p>论文提到的局限性包括：目前主要在相对较小的模型上进行验证以降低计算成本，但方法可扩展至更大VLA；路由机制虽然高效，但仍可能发生错误。</p>
<p>本文对后续研究的启示在于：为大规模VLA模型的终身学习提供了一个参数高效、自主性强的可行路径；其“条件性扩展”和“基于特征的路由”思想可迁移至其他模态或架构的持续学习问题中；如何进一步提高路由机制的鲁棒性、处理更复杂的任务间关系是未来的研究方向。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>CLARE论文旨在解决机器人视觉-语言-动作模型在持续学习中的灾难性遗忘问题，使模型能适应新任务同时保留旧知识。提出CLARE框架，关键技术包括：在选定前馈层引入轻量级模块化适配器；基于层间特征相似性指导自主扩展适配器；部署时通过自编码器路由机制动态激活适配器，无需任务标签。在LIBERO基准实验中，CLARE实现了新任务的高性能且无灾难性遗忘，显著优于现有方法。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2601.09512" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>