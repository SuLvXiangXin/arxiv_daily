<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>JAEGER: Dual-Level Humanoid Whole-Body Controller - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>JAEGER: Dual-Level Humanoid Whole-Body Controller</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2505.06584" target="_blank" rel="noreferrer">2505.06584</a></span>
        <span>作者: Ding, Ziluo, Jiang, Haobin, Wang, Yuxuan, Sun, Zhenguo, Zhang, Yu, Niu, Xiaojie, Yang, Ming, Zeng, Weishuai, Xu, Xinrun, Lu, Zongqing</span>
        <span>日期: 2025/05/10</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前人形机器人全身控制（WBC）的主流方法主要分为三类：基于根速度跟踪的粗粒度控制、基于全局关键点位置跟踪以及基于局部关节角度跟踪的细粒度控制。现有方法如OmniH2O和HumanPlus，通常通过模仿人类姿态轨迹来学习运动，并从中衍生出速度跟踪能力。然而，这些方法存在关键局限性：由于人形机器人与人类在形态上的固有差异，完全模仿人类姿态可能会阻碍机器人保持平衡，并难以学习到鲁棒的、具备速度跟踪能力的策略。此外，上下半身功能异构且相互干扰，在单一控制器中联合训练时，上半身的跟踪行为可能因迁就下半身的稳定性而变得过于保守，导致收敛困难。</p>
<p>本文针对上述痛点，提出了两个新视角：1）将粗粒度（根速度跟踪）与细粒度（局部关节角度跟踪）控制能力分离训练，再通过蒸馏整合为一个统一的WBC策略，以解决控制模式兼容性问题；2）将WBC问题重构为一个多智能体系统，将上下半身解耦为两个独立的控制器，以降低动作空间的维度灾难、减少相互干扰并提升系统容错性。本文的核心思路是：设计一个支持两种命令模式的双层控制器，通过课程学习策略，先分别训练上下半身控制器，再进行强化学习优化，最终实现更鲁棒、更通用的人形机器人全身运动控制。</p>
<h2 id="方法详解">方法详解</h2>
<p>JAEGER的整体框架由三个核心组件构成：一个基于MLP的重定向网络、一个双层控制器以及一个结构化的课程学习流程。输入为人类运动数据（AMASS）或实时控制命令（根速度/参考姿态），输出为机器人所有关节的目标位置，经由关节PD控制器执行。</p>
<p><img src="https://arxiv.org/html/2505.06584v2/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：JAEGER方法整体框架。左侧为重定向网络，使用MLP学习人体与机器人姿态间的映射；中间为双层控制器，上下半身由独立的策略网络（Transformer与MLP）分别控制；右侧为课程学习流程，包含监督初始化与强化学习优化两个阶段。</p>
</blockquote>
<p><strong>1. 重定向网络</strong>：为将人类运动数据适配到机器人，本文提出一种高效的基于MLP的重定向方法。首先采用两阶段优化方法处理AMASS数据集，生成大量（人体姿态，机器人姿态）配对数据。随后，使用一个轻量级的三层MLP学习其间的映射关系。相比传统的基于优化的逆运动学（IK）方法，该MLP方法能产生更准确、更平滑的关节角度，且运行频率高达1kHz，避免了帧间抖动，为低延迟遥操作提供了可能。</p>
<p><strong>2. 双层控制器</strong>：本文将WBC问题形式化为一个包含两个智能体的去中心化部分可观测马尔可夫决策过程（Dec-POMDP）。两个策略网络共享观测与奖励。</p>
<ul>
<li><strong>下半身控制器</strong>：任务复杂，需同时跟踪根速度、参考姿态并维持全身平衡。受复杂地形 locomotion 任务的启发，本文采用 <strong>Gated Transformer-XL</strong> 架构（含三层Transformer块）作为策略网络。其门控机制替代了标准残差连接，能更好地适应RL训练，提升学习稳定性与速度。网络输入为15步的历史观测序列。</li>
<li><strong>上半身控制器</strong>：任务相对简单，仅需跟踪参考姿态，无需复杂平衡控制。因此，采用一个轻量级的 <strong>3层MLP</strong> 即可实现所需功能，计算成本低。网络输入为3步的历史观测序列。</li>
</ul>
<p><strong>3. 课程学习策略</strong>：直接使用RL从头训练支持根速度与姿态跟踪的WBC控制器极不稳定。为此，本文设计了分阶段的课程学习：</p>
<ul>
<li><strong>基础策略训练</strong>：首先，固定上半身关节，独立训练下半身控制器，得到一个基础策略（可以是纯 locomotion 或关节角度跟踪策略）。</li>
<li><strong>监督初始化</strong>：随后，进行监督初始化以缓解后续RL训练的不稳定性。具体包括：1）对上半身控制器应用监督学习损失，使其直接模仿参考姿态：<code>L_SL(π^upper) = ‖π^upper(x_t,3) - g_t^upper‖</code>；2）对下半身控制器施加KL正则化损失，防止其偏离已训练好的基础策略：<code>L_KL(π^lower) = D_KL[π^lower(·|x_t,15) || π^base(·|x_t,15)]</code>。此阶段还将姿态幅度减半以简化任务。</li>
<li><strong>强化学习训练</strong>：基于初始化策略，使用PPO算法进行RL优化，以最大化累积奖励。此时将姿态幅度恢复原值。奖励函数（如表1所示）精心设计，包含根速度与方向跟踪、关节角度精确跟踪以及多项提升稳定性与 sim-to-real 能力的正则化项。训练好两种模式（根速度模式、姿态模式）的控制器后，通过模仿学习将其蒸馏到一个单一网络中。</li>
</ul>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在IsaacGym模拟器中，使用两个成人尺寸人形机器人平台进行实验：19自由度的Unitree H1和21自由度的H1-2。后者因上半身更重、控制更难，是更具挑战性的平台。使用从AMASS数据集中筛选出的可行运动子集 <code>𝒬̂</code> 进行评估，采用平均绝对误差（MAE）作为指标。对比的SOTA基线包括：HumanPlus（关节角度跟踪）、ExBody（下半身根速度+上半身关节角度/关键点）和OmniH2O（全局关键点位置跟踪）。为公平比较，所有基线均使用本文的重定向网络进行数据预处理。</p>
<p><strong>主要实验结果</strong>：</p>
<ul>
<li><strong>根速度模式</strong>：如表2所示，在H1和H1-2平台上，JAEGER在根线速度、角速度跟踪误差以及上半身关节角度跟踪误差上均显著优于支持根命令的基线（HumanPlus和ExBody）。例如在H1上，JAEGER的上半身关节跟踪误差约为0.1093弧度（6.26度），而其他方法至少为9.67度；角速度跟踪误差仅为0.0937 rad/s（约5.37度/秒），远低于ExBody的0.4176 rad/s。HumanPlus由于单网络结构，在两方面均表现不足。ExBody因训练数据量小，泛化能力较弱。</li>
<li><strong>姿态模式</strong>：如表3所示，在全身姿态跟踪任务中，JAEGER在上下半身关节角度跟踪精度上同样全面优于HumanPlus和OmniH2O。JAEGER的关节角度跟踪误差仅为其他方法的30%-60%。同时，在根姿态（滚转、俯仰、偏航）跟踪误差上也达到可比甚至更优的水平（如在H1上各项误差均最低）。这表明JAEGER的解耦设计使其能在精确跟踪复杂上身姿态的同时，维持下半身稳定与平衡。</li>
</ul>
<p><strong>消融实验与分析</strong>：</p>
<ul>
<li><strong>重定向网络对比</strong>：与基于优化的IK方法相比，MLP重定向网络在H1平台上将平均关节角度误差降低了23.3%（从0.130 rad降至0.0997 rad），且输出的关节角度序列更平滑，无帧间抖动。</li>
<li><strong>课程学习消融</strong>：实验表明，跳过监督初始化阶段直接进行RL训练，会导致策略收敛到保守的局部最优（上半身跟踪误差增大），甚至引发训练不稳定（下半身失平衡）。监督初始化提供了良好的起点，使后续RL能更快收敛到更优策略。</li>
<li><strong>网络架构选择</strong>：针对下半身控制任务，实验对比了MLP、LSTM和Transformer。结果表明，Transformer在需要高平衡控制的复杂任务中表现最佳，因其能更好地利用历史信息编码环境动态。</li>
</ul>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：1）提出一种基于MLP的高效重定向方法，相比优化IK方法精度更高、输出更平滑；2）创新性地提出双层WBC控制器架构，通过解耦上下半身控制降低了学习难度、减少了干扰并提升了容错性；3）设计了一套结构化的课程学习策略，通过监督初始化引导RL训练，有效解决了联合训练的不稳定性问题。</p>
<p><strong>局限性</strong>：论文提到，对于成人尺寸机器人（如H1-2），从模拟到真实的迁移差距仍然较大，这是一个待解决的挑战。此外，方法需要分别训练两种模式的策略再进行蒸馏，流程相对复杂。</p>
<p><strong>研究启示</strong>：JAEGER的成功表明，针对复杂控制问题，将其分解为功能子模块并采用异构的多智能体架构是有效的思路。将监督学习与强化学习结合的课程学习范式，能为训练高维、多目标策略提供稳定起点。这些设计原则可推广至其他需要精细分层控制的机器人任务中。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出JAEGER，一种解决人形机器人全身控制难题的双层级控制器。核心创新在于将上下半身控制分离为两个独立控制器，以缓解维度灾难并提升容错性。该方法同时支持根速度跟踪（粗粒度控制）与局部关节角度跟踪（细粒度控制）。通过AMASS人体运动数据集，利用重定向网络将人体姿态映射至机器人，并采用课程学习策略（监督学习初始化+强化学习优化）。实验在两种人形机器人平台上验证了该方法在仿真与真实环境中均优于现有技术。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2505.06584" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>