<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Robotics (cs.RO)</span>
      <h1>MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2507.01843" target="_blank" rel="noreferrer">2507.01843</a></span>
        <span>作者: Kuzmenko, Dmytro, Shvai, Nadiya</span>
        <span>日期: 2025/07/02</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>当前机器人多任务学习的主流方法主要分为三类：传统的强化学习（RL）与模仿学习（IL）方法、基于基础模型的视觉-语言-动作（VLA）通用模型，以及混合专家（MoE）架构。传统方法依赖密集奖励或专家示教，泛化能力有限。VLA通用模型（如RT-2、π₀）通过大规模预训练实现了跨任务和具身的泛化，但其“通才”性质可能导致特定任务精度下降、内存使用效率低下，且难以扩展至大规模任务库。现有的机器人MoE方法（如MoLe-VLA、MoDE）虽然通过稀疏激活提升了效率，但通常采用紧密耦合的内部路由机制和联合训练流程，这限制了专家的模块化定制、独立更新和部署灵活性。</p>
<p>本文针对现有MoE系统在<strong>模块化、部署灵活性和专家复用性</strong>方面的关键痛点，提出了一个<strong>架构无关、外部路由</strong>的新视角。核心思路是：将任务路由与策略执行解耦，通过一个轻量级的、基于自然语言指令的外部路由器，动态协调一个由独立预训练和微调的专家（VLA模型）组成的池子，实现零样本的任务到专家匹配。</p>
<h2 id="方法详解">方法详解</h2>
<p>MoIRA框架是一个模块化的元控制器，其整体流程分为两个阶段：路由与执行。输入是自然语言任务指令<code>t</code>和一组专家元描述<code>{m_i}</code>，输出是执行该任务的动作轨迹和结果。</p>
<p><img src="https://arxiv.org/html/2507.01843v1/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图1</strong>：MoIRA框架概览。包含三个核心部分：（1）<strong>微调后的专家</strong>：每个专家是一个配备了专用LoRA适配器的VLA模型；（2）<strong>元描述</strong>：描述每个专家专长的文本摘要<code>m_i</code>；（3）<strong>路由器核心</strong>：通过两种策略之一推断专家索引<code>r</code>：基于文本编码器<code>E</code>的嵌入相似度匹配，或基于提示的语言模型路由。选出的索引<code>r</code>将指引对应的专家进行下游策略推断。</p>
</blockquote>
<p>框架包含三个核心模块：</p>
<ol>
<li><p><strong>专家池</strong>：由多个预训练的VLA模型（如GR00t-N1, π₀）作为主干，每个专家通过独立的<strong>低秩适配器（LoRA）</strong> 在特定任务领域（如GR1的特定具身、LIBERO的语义类别）进行轻量级微调，成为专精于某一领域的“专家”。这使得专家可以独立开发、定制和优化。</p>
</li>
<li><p><strong>元描述</strong>：为每个专家配备文本描述，分为两种类型：<strong>简单描述</strong>（描述低层动作或物体交互）和<strong>抽象描述</strong>（强调高层任务意图或空间推理）。这为路由提供了语义依据。</p>
</li>
<li><p><strong>路由器核心</strong>：一个无需训练的外部模块，负责根据任务指令<code>t</code>和专家元描述<code>{m_i}</code>选择最相关的专家索引<code>r</code>。它实现了两种零样本路由策略：</p>
<p><img src="https://arxiv.org/html/2507.01843v1/x3.png" alt="路由模块"></p>
<blockquote>
<p><strong>图4</strong>：MoIRA路由模块。给定文本任务描述和专家元描述，路由器通过两种策略之一分配专家ID：基于提示的语言模型（SmolLM2）将输入格式化为包含少量示例的推理提示（橙色路径）；轻量级的基于嵌入的方法（MiniLM）计算任务与缓存的元描述之间的余弦相似度（紫色路径）。</p>
</blockquote>
<ul>
<li><strong>基于嵌入的相似性路由</strong>：使用预训练的文本编码器（如MiniLM）将任务<code>t</code>和所有元描述<code>m_i</code>编码为向量，通过余弦相似度选择最匹配的专家：<code>r = argmax_i cos(E(t), E(m_i))</code>。</li>
<li><strong>基于提示的语言模型路由</strong>：使用一个冻结的语言模型（如SmolLM2），将任务指令、专家元描述以及少量示例组合成一个结构化的提示，通过链式推理（Chain-of-Thought）格式让语言模型直接输出最匹配的专家ID。</li>
</ul>
<p>路由决策后，系统根据配置执行专家策略。论文探讨了两种部署配置：</p>
<p><img src="https://arxiv.org/html/2507.01843v1/x2.png" alt="服务配置"></p>
<blockquote>
<p><strong>图3</strong>：MoIRA的服务与推理配置。（I）<strong>所有专家驻留内存</strong>：每个专家（由其LoRA适配器ID标识）常驻GPU内存，可实现近乎即时的专家切换，但VRAM需求随专家数量线性增长。（II）<strong>动态LoRA适配器加载</strong>：单个共享主干根据路由器输入动态加载所需的LoRA适配器，内存开销降至一个模型检查点加一个适配器，但切换专家会引入高达9秒的延迟。</p>
</blockquote>
</li>
</ol>
<p>与现有方法相比，MoIRA的核心创新在于：1) <strong>外部路由</strong>：将路由决策与专家模型架构解耦，支持灵活的即插即用式专家集成；2) <strong>架构无关</strong>：不依赖特定模型结构，任何策略模型均可作为专家主干；3) <strong>零样本路由</strong>：路由器无需针对任务-专家对进行额外训练，仅依赖文本描述。</p>
<h2 id="实验与结果">实验与结果</h2>
<p><strong>实验设置</strong>：在两个机器人基准上进行评估：<strong>GR1</strong>（涵盖三种具身：仅手臂、手臂+腰部、完整上半身）和<strong>LIBERO</strong>（选取空间和目标任务两个语义类别）。使用的基础专家模型是GR00t-N1（GR1）和π₀-base（LIBERO），均通过LoRA进行微调。实验平台为单张NVIDIA RTX A6000 GPU。</p>
<p><strong>对比方法</strong>：包括预训练基线模型、联合训练的通用模型，以及先前的MoE方法（如Tra-MoE, MoDE）。</p>
<p><strong>GR1实验结果</strong>：</p>
<ul>
<li><strong>专家性能</strong>：如表1所示，针对特定具身微调的专家在各自任务上的性能远超预训练基线。例如，Pouring任务的均方误差（MSE）从1.02降至0.008（提升123倍）。</li>
<li><strong>路由性能与泛化</strong>：表2显示，在已知任务上，MoIRA的路由专家性能接近或优于专用专家，且显著优于联合训练的通用模型（如PlacematToPlate任务，专家MSE 0.311 vs 通用模型1.187）。</li>
<li><strong>指令扰动鲁棒性</strong>：对任务指令进行同义改写以测试路由鲁棒性。表4和图6、图7表明，基于SmolLM2的路由器在不同提示类型下均保持稳定性能，而基于MiniLM（抽象描述）的路由器对语言变化更敏感，性能下降明显（如CanSort任务MSE从0.008升至0.160）。</li>
</ul>
<p><img src="https://arxiv.org/html/2507.01843v1/x5.png" alt="扰动指令MSE_MiniLM"></p>
<blockquote>
<p><strong>图6</strong>：使用MiniLM路由器时，GR1中Pouring和CanSort任务在原始与扰动指令下的MSE对比。抽象描述路由在扰动下性能波动更大。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2507.01843v1/x6.png" alt="扰动指令MSE_SmolLM"></p>
<blockquote>
<p><strong>图7</strong>：使用SmolLM2路由器时，GR1中Pouring和CanSort任务在原始与扰动指令下的MSE对比。两种描述下的性能均较为稳定。</p>
</blockquote>
<ul>
<li><strong>零样本泛化到未见任务</strong>：在三个未参与训练的GR1任务上评估。表3和表5显示，MoIRA（特别是使用MiniLM简单描述路由时）在两项任务上（WineToCabinet, CuttingboardToTieredBasket）的MSE显著低于联合训练的通用模型，证明了模块化专业化的有效性。路由准确性（F1分数）对控制性能至关重要，F1低于约0.9时性能会下降。</li>
</ul>
<p><strong>LIBERO实验结果</strong>：</p>
<ul>
<li><strong>专家 vs. 通用模型</strong>：图8和文中数据显示，未经任务微调的π₀基线成功率为0%。经过微调后，专用专家在空间和目标任务上的成功率分别达到94%和93%，与联合训练的通用模型（95%和90%）表现相当或更优。</li>
</ul>
<p><img src="https://arxiv.org/html/2507.01843v1/x7.png" alt="LIBERO成功率"></p>
<blockquote>
<p><strong>图8</strong>：使用π₀-base模型在LIBERO子任务上的成功率对比。专用专家（蓝、黄）在各自领域表现优异，与联合训练的通用模型（绿）和完全微调的通用模型（灰）竞争力相当。</p>
</blockquote>
<ul>
<li><strong>与先进MoE方法对比</strong>：如表6所示，MoIRA在LIBERO上取得了有竞争力的成功率（空间94%，目标93%），同时保持了外部路由的模块化优势。相比之下，MoDE等方法虽然成功率略高（空间90%，目标97%），但采用内部路由，限制了灵活性。</li>
</ul>
<p><strong>消融实验总结</strong>：实验主要对比了两种路由策略（MiniLM vs. SmolLM2）和两种元描述类型（简单 vs. 抽象）的影响。结果表明：1) <strong>路由策略</strong>：SmolLM2（基于提示）通常比MiniLM（基于嵌入）对指令扰动更鲁棒；2) <strong>元描述类型</strong>：对于基于嵌入的路由器，简单描述能提供更可靠的词法匹配，而抽象描述在语言变化下容易失效；对于基于提示的路由器，两种描述均表现良好。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>核心贡献</strong>：</p>
<ol>
<li>提出了<strong>MoIRA</strong>，一个新颖的、架构无关的模块化MoE框架，通过外部文本路由器实现预训练专家之间的零样本任务路由。</li>
<li>系统性地评估并对比了<strong>两种零样本路由策略</strong>（基于嵌入的相似性和基于提示的LM推理）在不同元描述下的性能与鲁棒性。</li>
<li>在<strong>GR1和LIBERO</strong>基准上验证了MoIRA的有效性，表明其能够超越通用模型，并与现有MoE方法竞争，同时具备更优的模块化和部署灵活性。</li>
</ol>
<p><strong>局限性</strong>：</p>
<ol>
<li>路由器的性能依赖于任务和专家描述的<strong>质量与准确性</strong>，不准确或模糊的描述可能导致路由错误。</li>
<li>在动态加载LoRA适配器的配置下，专家切换存在<strong>延迟</strong>（约9秒），可能影响需要快速连续切换任务的场景。</li>
</ol>
<p><strong>研究启示</strong>：</p>
<ol>
<li><strong>模块化与复用</strong>：MoIRA展示了将大型预训练模型分解为可复用、可独立更新的专家模块的可行性，为构建可扩展的机器人系统提供了新范式。</li>
<li><strong>语言作为接口</strong>：强化了自然语言作为协调异构AI模块的高层接口的潜力，提升了系统的可解释性和人机交互性。</li>
<li><strong>未来方向</strong>：可以探索更强大的多模态路由器（结合视觉上下文）、研究如何自动生成或优化专家元描述，以及开发更高效的适配器切换机制以降低延迟。</li>
</ol>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文提出MoIRA，一种用于多任务机器人的模块化指令路由架构，旨在解决现有混合专家系统中路由机制不灵活、需额外训练的问题。其核心是架构无关的模块化框架，采用两种零样本路由方法：基于嵌入相似度的路由和基于提示驱动的语言模型推理路由。实验以gr00t-N1和π0等视觉-语言-动作模型为基础专家，训练低秩适配器进行低开销推理。在GR1 Humanoid任务和LIBERO基准测试中，MoIRA consistently outperforms generalist models and competes with other MoE pipelines，证明了其模块化部署的可行性与高效性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2507.01843" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>