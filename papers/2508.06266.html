<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2508.06266" target="_blank" rel="noreferrer">2508.06266</a></span>
        <span>作者: Liming Chen Team</span>
        <span>日期: 2025-08-08</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>扩散策略已成为机器人操作中一类强大的视觉运动控制器，能够实现稳定训练并表达多模态动作建模。然而，现有方法通常将动作生成视为一个无约束的去噪过程，忽略了关于几何和控制结构的宝贵先验知识。这导致了两个关键局限性：一是忽略了末端执行器与目标物体之间的相对位姿所提供的自然梯度方向；二是从无信息的各向同性高斯先验中采样，迫使策略从一个忽略了测试数据具体特征的非信息初始化中恢复，导致效率低下和失败率增加。</p>
<p>本文针对这一痛点，提出在测试时引入任务特定的约束和先验知识，使已学习的扩散策略能够在不重新训练的情况下动态适应任务结构。其核心思路是：通过几何流形约束引导去噪过程，并利用任务感知的初始化策略，将动作生成从盲目的随机采样转变为几何感知的自适应优化过程，从而提高泛化能力和采样效率。</p>
<h2 id="方法详解">方法详解</h2>
<p>ADPro 的整体框架是一个测试时自适应的扩散策略，旨在加速动作生成过程。其核心改进在于两个方面：一是流形约束去噪，引导更新沿着任务和球形流形进行；二是任务感知初始化，使扩散过程朝着更准确的方向开始，而非从随机噪声出发。</p>
<p><img src="https://arxiv.org/html/2508.06266v2/x1.png" alt="方法框架"></p>
<blockquote>
<p><strong>图2</strong>：自适应扩散策略 ADPro 的流程。首先通过粗糙配准模块提出合理的初始噪声动作 𝐚_M，然后在观测和流形约束的引导下对 𝐚_M 进行去噪。</p>
</blockquote>
<p><strong>核心模块一：流形约束去噪</strong><br>该方法引入了两种互补的流形来约束和引导去噪过程：任务流形和球形流形。</p>
<ol>
<li><strong>任务流形</strong>：机器人动作位于 SE(3) 李群上，末端执行器与目标物体之间的相对位姿定义了通往任务成功的自然梯度方向。为此，该方法将观测引导 ∇_𝐚 L(·,·) 纳入扩散过程，引导更新沿着任务流形的测地线路径进行。具体而言，先通过标准 DDPM 步骤得到一个中间动作 𝐚̃ _{t-1}，然后使用 Tweedie 公式从 𝐚̃ _{t-1} 估计出一个无噪声的动作 𝐚̂ _0。最终，去噪步骤由原始去噪方向和基于 𝐚̂ _0 变换后的夹爪点云与场景点云之间的 Chamfer 距离 L(·,·) 的梯度共同修正，如公式(8)所示。这为逆扩散过程提供了方向性约束，缩短了扩散轨迹。</li>
<li><strong>球形流形</strong>：为了最小化扩散过程中不必要的回溯行为，该方法引入了高斯球形先验来细化反向扩散步长。该先验将噪声采样空间约束在半径为 √d σ 的超球面上的均匀分布，从而将更新步长保持在置信区间内。结合任务流形引导，最终的流形约束去噪更新公式如(9)所示，其中梯度项被归一化，并以 √d σ 作为步长尺度。这确保了更新沿着流形稳定进行。</li>
</ol>
<p><strong>核心模块二：任务感知初始化</strong><br>与在整个噪声空间中采样不同，ADPro 将初始动作的搜索空间限制在特定的局部区域。该方法利用快速全局注册算法，根据测试时夹爪点云 𝐎^{k,0} 和目标场景点云 𝐎^{k,1} 计算一个粗糙的对齐变换（旋转矩阵 R 和平移向量 v），从而得到初始噪声动作 𝐚_M^k。这相当于原始扩散过程中第 M 步（M ≤ T）的噪声输出。这种初始化将扩散过程置于一个与任务相关的区域，有效缩小了搜索空间，加速了收敛。</p>
<p><strong>与现有方法的创新点</strong><br>与将动作生成视为无约束随机过程的传统扩散策略相比，ADPro 的核心创新在于：1) <strong>测试时利用几何先验</strong>：首次在机器人扩散策略中显式地利用末端执行器与目标物体的相对位姿作为引导信号。2) <strong>双重流形约束</strong>：结合任务流形（提供方向）和球形流形（提供稳定性）来结构化去噪轨迹。3) <strong>基于配准的初始化</strong>：用几何上有意义的初始化替代随机噪声初始化。所有这些改进都以<strong>训练免费、即插即用</strong>的方式实现，无需重新训练预训练的扩散模型。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>实验使用了 RLBench、CALVIN 仿真基准和真实世界数据集进行评估。对比的基线方法包括 C2F-ARM、PerAct、HiveFormer、PolarNet、RVT、Act3D 以及扩散策略基线 3D Diffuser Actor (Diffuser)、VPDD 等。</p>
<p><strong>关键实验结果</strong><br>在 RLBench 的 18 个任务上，ADPro 的平均成功率为 83.9%， consistently 优于 vanilla 扩散策略 Diffuser (81.3%)，平均提升 2.6 个百分点，在 “sweep to dustpan”、“sort shape” 和 “insert peg” 等任务上提升尤为显著。<br>在 CALVIN 基准上，ADPro 相比 DP3 基线取得了 9.0% 的相对改进。<br>在采样效率方面，ADPro 仅需 20 个去噪步骤即可达到与使用 100 步的 Diffuser 相当甚至更高的性能，推理速度提升达 25%。</p>
<p><img src="https://arxiv.org/html/2508.06266v2/x2.png" alt="定性结果对比"></p>
<blockquote>
<p><strong>图3</strong>：在 “sort shape” 和 “insert peg” 任务上，ADPro 与 vanilla 扩散策略的轨迹对比。ADPro 仅用三步就完成了第一个任务，展示了高效性和准确性。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.06266v2/figures/rl_actions_plot_open.png" alt="动作参数轨迹"></p>
<blockquote>
<p><strong>图4</strong>：任务 “open drawer” 和 “sweep to dustpan” 完整动作各参数（x, y, z, 旋转, 宽度）的对比。ADPro 有效缓解了 vanilla 扩散策略中坐标和角度的回溯行为。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.06266v2/figures/rl_dsteps_plot_z.png" alt="去噪步数演化"></p>
<blockquote>
<p><strong>图6</strong>：任务 “sweep to dustpan” 前四个动作的去噪步数演化。Diffuser 的均方误差波动较大，表明其轨迹存在显著的回溯行为，而 ADPro 的轨迹更平滑、更高效。</p>
</blockquote>
<p><img src="https://arxiv.org/html/2508.06266v2/figures/influence_dsteps.png" alt="消融实验"></p>
<blockquote>
<p><strong>图7</strong>：不同去噪步数下的消融实验。展示了完整 ADPro、仅使用流形约束、仅使用任务感知初始化以及基线 Diffuser 的性能。ADPro 在更少的步数下实现了更高的成功率。</p>
</blockquote>
<p><strong>消融实验总结</strong><br>消融实验验证了每个核心组件的贡献：1) <strong>仅使用流形约束</strong>：相比基线，在 20 步时成功率有显著提升，证明了流形引导的有效性。2) <strong>仅使用任务感知初始化</strong>：也能带来性能增益，尤其是在步数较少时，证明了初始化的重要性。3) <strong>完整 ADPro</strong>：结合了初始化与流形约束，在所有的去噪步数设置下都取得了最佳性能，特别是在步数较少时优势明显，证明了组件的互补性。</p>
<h2 id="总结与启发">总结与启发</h2>
<p><strong>本文核心贡献</strong>：1) 提出了一个<strong>测试时自适应</strong>的扩散策略框架ADP，无需重新训练即可利用测试时的几何先验提升预训练策略的性能。2) 引入了<strong>流形约束去噪</strong>机制，通过任务流形和球形流形双重引导，结构化去噪轨迹，提升效率和泛化能力。3) 设计了<strong>任务感知的初始化</strong>策略，基于点云配准提供有意义的起点，减少不必要的探索。</p>
<p><strong>论文提到的局限性</strong>：方法的鲁棒性依赖于快速全局配准算法和预训练扩散模型的质量。在点云质量极差或目标物体被严重遮挡等极端情况下，配准可能失败，进而影响初始化。</p>
<p><strong>对后续研究的启示</strong>：本研究展示了在<strong>测试时</strong>利用几何和任务先验来增强机器人策略的巨大潜力，为改善策略的泛化性和效率提供了新视角。其“训练免费、即插即用”的特性使其易于与现有方法集成。未来工作可探索更鲁棒的配准方法、更复杂的流形约束，或将此范式应用于更广泛的机器人策略学习问题中。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对机器人操作中现有扩散策略在测试时缺乏适应性、将动作生成视为无约束去噪过程的问题，提出了一种无需重新训练即可在测试时自适应的扩散策略ADPro。其核心方法包括：1）**流形约束去噪**，利用末端执行器与目标场景的相对位姿作为自然梯度方向，引导去噪沿操作流形的测地线路径；2）**任务感知初始化**，通过夹爪与目标场景的粗略配准来生成结构化的初始噪声动作，减少无效探索。实验表明，该方法在多个基准测试中显著提升了性能，实现了高达25%的更快执行速度，并将成功率提高了超过强基线9个百分点。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2508.06266" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据抓取来源于 Robotics arXiv Daily</span>
    <span>本页由 GitHub Actions 定时更新</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>