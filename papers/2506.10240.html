<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Innovative Adaptive Imaged Based Visual Servoing Control of 6 DoFs Industrial Robot Manipulators - Robotics arXiv Daily</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600&family=Space+Grotesk:wght@500;700&display=swap" rel="stylesheet"/>
  <link rel="stylesheet" href="../assets/styles.css"/>
  <link rel="stylesheet" href="../assets/detail.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"/>
</head>
<body>
  <div class="bg-orbit"></div>
  <header class="site-header">
    <div class="brand">
      <a href="../index.html" class="back-link">← 返回列表</a>
    </div>
  </header>
  <main class="detail-main">
    <article class="detail-card">
      <span class="detail-category">Manipulation</span>
      <h1>Innovative Adaptive Imaged Based Visual Servoing Control of 6 DoFs Industrial Robot Manipulators</h1>
      <div class="detail-meta">
        <span>arXiv: <a href="http://arxiv.org/abs/2506.10240" target="_blank" rel="noreferrer">2506.10240</a></span>
        <span>作者: Francis Assadian Team</span>
        <span>日期: 2025-06-11</span>
      </div>
      <section class="detail-body">
        <h2>📝 详细解读</h2>
        <h2 id="研究背景与动机">研究背景与动机</h2>
<p>图像基视觉伺服（IBVS）方法已在位姿对准等应用中得到了广泛发展。然而，大多数研究集中于当三维点特征位于相机视野内时可被检测到的情况下的控制方案设计。在眼到手（ETH）配置中，当特征点移出相机视野时，机器人会面临信息丢失和控制失效的问题。一种常见的解决方案是安装多个相机以覆盖整个工作空间，但这增加了系统成本和复杂性。本文针对ETH系统中特征点可能移出视野这一具体痛点，提出了一种创新的前馈-反馈自适应控制架构。其核心思路是：设计一个特征估计回路，在特征点位于视野外时确保稳定快速的运动控制；当特征点进入视野后，IBVS反馈回路保证控制末期位姿的精度；同时，在反馈回路中开发自适应控制器，以在整个操作范围内稳定系统。</p>
<h2 id="方法详解">方法详解</h2>
<p>本文提出的控制系统整体框架是一个结合了前馈控制、自适应反馈控制以及特征估计回路的综合架构。其输入是目标特征点图像坐标 ( \overline{p_I} ) 和当前/估计特征点坐标 ( \hat{p_I} ) 或 ( \tilde{p_I} )，输出是发送给机器人关节内环控制的参考关节角度 ( q_{Tref} )。</p>
<p><img src="https://i.imgur.com/placeholder.png" alt="控制框架图"></p>
<blockquote>
<p><strong>图3</strong>：带特征估计的前馈-反馈控制回路框图。蓝色实线为特征点在视野内时的正常反馈回路，绿色虚线为特征点在视野外时启用的特征估计反馈回路。红色框内为硬件在环（HIL）模型。</p>
</blockquote>
<p>系统包含三个核心模块：</p>
<ol>
<li><strong>前馈控制回路</strong>：这是一个开环，旨在存在输入扰动 ( d_{qT} ) 的情况下，将工具尽可能快地移动到接近目标位置。它通过机器人逆运动学模型 ( \mathcal{H} ) 和动态逆模型 ( T_{forward} ) 计算参考关节角 ( q_{T_feedforward} )，其设计使得加入的双极点带宽是原内环闭环系统带宽的10倍（( \tau_{forward} = 0.1\tau_{in} )），从而实现对内环动力学的近似逆，实现快速粗定位。</li>
<li><strong>自适应反馈控制回路</strong>：这是本文的创新核心。它在线性化点 ( \check{q_T}<em>0 ) 处，将包含机器人运动学、动力学和相机模型的非线性组合模型 ( \hat{p_I} = \mathcal{F}(\check{q_T}) ) 线性化为 ( \hat{p_I} = C_1 \check{q_T} + C_2 )。为了处理多变量耦合系统，控制器设计采用Youla参数化方法：首先对线性化模型 ( G</em>{p_outer}^{linear} ) 进行奇异值分解（SVD）得到其Smith-McMillan形式 ( M_p )；然后为解耦后的每个单输入单输出（SISO）通道设计Youla参数矩阵 ( M_Y )，使闭环系统具有二阶巴特沃斯滤波器的特性；最后通过矩阵变换得到耦合的控制器 ( G_{C_outer}^{linear} )。关键的自适应机制在于：控制器并非固定在一个线性化点，而是根据当前图像特征 ( \hat{p_I} ) 估计当前关节角 ( \tilde{q_T} = \mathcal{F}^{-1}(\hat{p_I}) )，并在此估计点在线重新计算雅可比矩阵和相应的Youla控制器，从而适应系统的非线性，确保在全工作范围内的鲁棒性。</li>
<li><strong>特征估计回路</strong>：当工具（特征点）位于相机视野外时，相机无法提供测量值 ( \hat{p_I} )。此时系统切换至特征估计模式，利用相同的组合模型 ( \mathcal{F} ) 和当前关节角 ( q_T ) 来估计特征点的图像坐标 ( \tilde{p_I} = \mathcal{F}(q_T) )，作为反馈信号，从而在视野外阶段维持控制。</li>
</ol>
<p>与现有方法相比，本文的创新点具体体现在：1）提出了一个集成前馈快速定位、自适应反馈精确对准以及特征估计的全工况控制架构，解决了ETH系统视野外控制丢失的问题；2）将Youla鲁棒控制参数化方法与在线模型线性化、解耦相结合，为高度非线性的视觉伺服系统设计自适应控制器，而非使用传统的PID或其变体。</p>
<h2 id="实验与结果">实验与结果</h2>
<p>本文在仿真环境中验证所提控制器的性能，使用的模型包括ABB IRB 4600六自由度工业机器人 manipulator 和Zed 2立体相机模型。仿真针对自动拧紧/拧松制造场景，引导螺丝刀对准螺钉。</p>
<p>论文通过多个场景的仿真来检验控制器的性能和稳定性，但未明确列出对比的基线方法。关键实验结果通过系统响应曲线展示：</p>
<ul>
<li>在目标位置阶跃变化场景下，工具的位置和方向误差能快速收敛。位置误差在约1.5秒后收敛到0.1毫米以内，方向误差收敛到0.1度以内。</li>
<li>自适应控制器能有效处理模型不确定性。在存在模型误差（如工具长度参数不准确）的仿真中，控制器仍能稳定系统并将误差驱动至零，展示了其鲁棒性。</li>
<li>特征估计回路功能得到验证。当工具起始点位于相机视野外时，系统首先基于特征估计进行控制；当工具进入视野后，平滑切换至基于真实图像测量的反馈控制，整个过程稳定。</li>
</ul>
<p><img src="https://i.imgur.com/placeholder.png" alt="位置与方向误差响应"></p>
<blockquote>
<p><strong>图10</strong>：工具位姿误差响应曲线。展示了在自适应控制下，工具末端位置误差（上）和方向误差（下）随时间收敛到零的过程。</p>
</blockquote>
<p><img src="https://i.imgur.com/placeholder.png" alt="存在模型不确定性的响应"></p>
<blockquote>
<p><strong>图11</strong>：存在模型不确定性时的系统响应。即使机器人模型参数存在误差，所提出的自适应控制器仍能实现稳定和精确的位姿对准。</p>
</blockquote>
<p><img src="https://i.imgur.com/placeholder.png" alt="特征点进出视野的响应"></p>
<blockquote>
<p><strong>图12</strong>：特征点进出相机视野时的系统响应。阶段I（0-2秒）：特征点在视野外，使用估计特征 ( \tilde{p_I} ) 控制；阶段II（2秒后）：特征点进入视野，切换至使用测量特征 ( \hat{p_I} ) 控制，误差最终收敛。</p>
</blockquote>
<p>由于论文主要展示所提方法的有效性而非组件消融实验，因此未提供明确的消融研究结果。但通过架构描述可以推断，前馈控制贡献于快速接近阶段，自适应反馈控制贡献于精确对准和鲁棒性，特征估计回路贡献于视野外阶段的连续控制能力。</p>
<h2 id="总结与启发">总结与启发</h2>
<p>本文的核心贡献可概括为三点：</p>
<ol>
<li>提出了一种用于眼到手（ETH）配置的创新前馈-反馈自适应视觉伺服控制架构，该架构通过特征估计回路解决了特征点移出相机视野时的控制难题。</li>
<li>开发了一种基于Youla参数化的自适应反馈控制器，该控制器在线对非线性相机-机器人组合模型进行线性化和解耦，从而能在整个操作范围内稳定系统，并处理模型不确定性。</li>
<li>完整构建了针对工业拧紧场景的系统模型（包括机器人运动学/动力学、立体相机模型）并进行了综合仿真验证，表明方案具有鲁棒性且易于在不同工业机器人系统中实现。</li>
</ol>
<p>论文自身提到的局限性在于，所有验证均基于仿真进行，结论需要在真实物理系统上进一步测试。</p>
<p>本文的工作对后续研究具有重要启示：首先，所提出的前馈-反馈结合特征估计的架构为解决视觉伺服中视野受限问题提供了新思路，可扩展到其他相机配置或任务中。其次，将先进的鲁棒控制理论（如Youla参数化）与在线自适应线性化相结合的方法，为处理视觉伺服中复杂的非线性、耦合动力学问题提供了有力的设计工具。最后，该控制方案强调工程实用性和易于实现，有助于推动先进视觉伺服控制从理论走向工业应用。</p>

      </section>
      <section class="detail-tldr">
        <h2>💡 一句话总结</h2>
        <p>本文针对6自由度工业机器人在图像视觉伺服（IBVS）控制中，当3D点特征位于相机视野外时难以实现稳定精确姿态对齐的问题，提出一种创新的自适应控制方法。该方法采用前馈-反馈结构，结合Youla参数化技术，设计特征估计循环处理视野外特征，并开发自适应控制器在线线性化和解耦非线性相机-机器人模型。通过多种仿真场景验证，该控制器表现出良好的有效性和鲁棒性能，提升了系统在全操作范围内的稳定性。</p>
      </section>
      <div class="detail-actions">
        <a href="http://arxiv.org/abs/2506.10240" target="_blank" rel="noreferrer" class="btn">查看 arXiv 原文</a>
        <a href="../index.html" class="btn btn-outline">返回列表</a>
      </div>
    </article>
  </main>
  <footer class="site-footer">
    <span>数据来源：<a href="https://jiangranlv.github.io/robotics_arXiv_daily/" target="_blank">Robotics arXiv Daily</a></span>
    <span>由 GitHub Actions 自动更新 · AI 摘要仅供参考</span>
  </footer>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}],throwOnError:false})"></script>
</body>
</html>