{"generatedAt":"2026-02-11T15:08:43.683Z","source":"backfill","items":[{"id":"http://arxiv.org/abs/2602.10109","title":"ST4VLA: Spatially Guided Training for Vision-Language-Action Models","arxivId":"2602.10109","date":"2026-02-10","authors":"Jiangmiao Pang Team","category":"Manipulation","summary":"本文提出ST4VLA，旨在解决大型视觉语言模型（VLM）在具体任务中难以将抽象指令转化为低级动作的问题。方法采用**空间引导训练**，包含两个阶段：**空间基础预训练**（通过点、框和轨迹预测学习可迁移的空间先验）和**空间引导动作后训练**（通过空间提示引导动作生成）。实验表明，该方法显著提升了VLA模型的性能，在Google Robot上准确率从66.1提升至84.6，在WidowX Robot上从54.7提升至73.2，并在泛化性和抗干扰性上表现出优势。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.10105","title":"DexImit: Learning Bimanual Dexterous Manipulation from Monocular Human Videos","arxivId":"2602.10105","date":"2026-02-10","authors":"Jiangmiao Pang Team","category":"Manipulation","summary":"论文标题为 \"DexImit: Learning Bimanual Dexterous Manipulation from Monocular Human Videos\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.10101","title":"Robo3R: Enhancing Robotic Manipulation with Accurate Feed-Forward 3D Reconstruction","arxivId":"2602.10101","date":"2026-02-10","authors":"Jiangmiao Pang Team","category":"Manipulation","summary":"本文针对机器人操作中3D感知精度不足的问题，提出Robo3R模型。该方法直接从RGB图像与机器人状态进行前馈式3D重建，核心技术包括：联合推断尺度不变的局部几何与相对相机位姿，通过学习的全局相似变换将其统一到机器人坐标系；采用掩码点云头生成精细点云，以及基于关键点的PnP公式优化相机外参与全局对齐。模型在包含400万帧的合成数据集上训练，实验表明其性能持续优于现有先进重建方法与深度传感器，并在多项下游操作任务中带来性能提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.10093","title":"UniVTAC: A Unified Simulation Platform for Visuo-Tactile Manipulation Data Generation, Learning, and Benchmarking","arxivId":"2602.10093","date":"2026-02-10","authors":"Yao Mu Team","category":"Manipulation","summary":"本文针对机器人接触密集型操作任务中触觉数据获取困难、缺乏统一评估平台的问题，提出统一仿真平台UniVTAC。其核心包括：1）支持三种常用触觉视觉传感器的数据生成平台；2）基于仿真合成数据训练的触觉视觉编码器UniVTAC Encoder；3）包含八个代表性任务的基准测试UniVTAC Benchmark。实验表明，集成该编码器使基准测试平均成功率提升17.1%，真实机器人实验任务成功率提高25%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.10015","title":"RoboSubtaskNet: Temporal Sub-task Segmentation for Human-to-Robot Skill Transfer in Real-World Environments","arxivId":"2602.10015","date":"2026-02-10","authors":"Laxmidhar Behera Team","category":"Manipulation","summary":"论文旨在解决从长视频中分割出机器人可执行的细粒度子任务，以实现安全的人机技能转移。提出了RoboSubtaskNet多阶段框架，结合注意力增强的I3D特征（RGB+光流）与修改的MS-TCN，采用斐波那契膨胀调度捕捉短时转换，并通过交叉熵和时间正则化损失优化分割。引入了RoboSubtask数据集用于医疗和工业场景。实验显示，在GTEA数据集上F1@50达79.5%，编辑准确率88.6%；在自建RoboSubtask数据集上F1@50达94.2%，编辑准确率95.6%。物理实验中，7-DoF机械臂整体任务成功率约91.25%，验证了从感知到执行的可行性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.10013","title":"Learning Force-Regulated Manipulation with a Low-Cost Tactile-Force-Controlled Gripper","arxivId":"2602.10013","date":"2026-02-10","authors":"Yen-Ling Kuo Team","category":"Manipulation","summary":"本文旨在解决机器人对易损物体（如薯片）进行精细力控操作的难题。研究提出了一种低成本（约150美元）的触觉力控夹爪TF-Gripper（力范围0.45–45N），并设计了RETAF学习框架，将高频触觉力调节与机械臂姿态预测解耦。实验表明，相比位置控制，直接力控显著提升了抓取稳定性与任务成功率；触觉反馈对力调节至关重要，RETAF框架在多种任务中均优于基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.09973","title":"RoboInter: A Holistic Intermediate Representation Suite Towards Robotic Manipulation","arxivId":"2602.09973","date":"2026-02-10","authors":"Jiangmiao Pang Team","category":"Manipulation","summary":"论文针对机器人操作中现有数据集成本高、本体依赖性强、多样性不足，导致视觉-语言-动作（VLA）模型泛化困难的核心问题，提出了RoboInter中间表示套件。关键技术包括：RoboInter-Tool半自动标注工具、RoboInter-Data大规模数据集（含超过230k个episodes和10+类中间表示）、RoboInter-VQA具身VQA基准（覆盖29个空间与时间类别）以及RoboInter-VLA集成“计划-然后-执行”框架。该套件通过提供细粒度、多样化的中间表示，为推进鲁棒和可泛化的机器人学习奠定了实用基础。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.09940","title":"Instruct2Act: From Human Instruction to Actions Sequencing and Execution via Robot Action Network for Robotic Manipulation","arxivId":"2602.09940","date":"2026-02-10","authors":"Laxmidhar Behera Team","category":"Manipulation","summary":"本文提出Instruct2Act框架，旨在解决机器人在资源受限环境下难以理解和执行自由形式人类指令的问题。核心方法包括：1）基于BiLSTM与多头注意力自编码器的指令解析模块，将自然语言指令分解为原子动作序列；2）结合动态自适应轨迹径向网络（DATRN）与YOLOv8视觉分析器的机器人动作网络，生成精确控制轨迹。实验表明，该系统在自定义数据集上子动作预测准确率达91.5%，在四种真实机器人任务中整体成功率为90%，单次子动作推理时间小于3.8秒。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.09888","title":"TriPilot-FF: Coordinated Whole-Body Teleoperation with Force Feedback","arxivId":"2602.09888","date":"2026-02-10","authors":"Weiming Zhi Team","category":"Manipulation","summary":"本文针对移动操作机器人全身遥操作中，操作者需同时协调底盘与双臂、并兼顾避障与接触的难题，提出TriPilot-FF系统。其核心创新在于引入脚部操作的踏板，通过低成本激光雷达生成基于障碍物距离的触觉阻力，引导操作者无碰撞移动；同时结合双臂主从遥操作与力反馈，提升接触感知与操作可达性。实验表明，系统能有效辅助操作者完成长时间、需精确底盘协调的任务，并将反馈信号融入ACT策略后进一步提升了性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.09878","title":"MVISTA-4D: View-Consistent 4D World Model with Test-Time Action Inference for Robotic Manipulation","arxivId":"2602.09878","date":"2026-02-10","authors":"Xiangyu Yue Team","category":"Manipulation","summary":"本文提出MVISTA-4D，旨在解决机器人操作中现有世界模型无法预测完整、几何一致的4D场景动态的问题。方法核心包括：1）一个能从单视角RGBD观测生成任意视角、跨模态一致RGBD的4D世界模型，通过跨视角与跨模态特征融合确保几何对齐；2）测试时动作优化策略，通过生成模型反向传播推断最优轨迹潜在变量，并结合残差逆动力学模型将其转化为精确动作。实验在三个数据集上验证了该方法在4D场景生成与下游操作任务上的优越性能，消融实验明确了关键设计的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.09767","title":"Diverse Skill Discovery for Quadruped Robots via Unsupervised Learning","arxivId":"2602.09767","date":"2026-02-10","authors":"Wei Li Team","category":"Manipulation","summary":"本文针对四足机器人无监督技能发现中，单一策略学习效率低、技能表征易重叠以及奖励信号易被黑客攻击导致技能多样性不足的问题，提出了正交混合专家（OMoE）架构和多判别器框架。OMoE防止行为表征坍塌，使单一策略能掌握广泛运动技能；多判别器在不同观测空间运作以缓解奖励黑客。在Unitree A1机器人上的实验表明，该方法提升了训练效率，并使状态空间覆盖率比基线提升了18.3%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.09638","title":"VideoAfford: Grounding 3D Affordance from Human-Object-Interaction Videos via Multimodal Large Language Model","arxivId":"2602.09638","date":"2026-02-10","authors":"Hui Xiong Team","category":"Manipulation","summary":"本文解决3D可操作区域（affordance）定位问题，指出现有方法依赖静态语言/图像线索，缺乏动态交互上下文。为此，作者构建了大规模视频数据集VIDA，并提出VideoAfford模型。关键技术包括：利用多模态大语言模型增强分割与推理能力；通过潜在动作编码器从人-物交互视频中提取动态先验；引入空间感知损失以学习3D空间知识。实验表明，该模型显著优于现有方法，并展现出强大的开放世界泛化与推理能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.09583","title":"Preference Aligned Visuomotor Diffusion Policies for Deformable Object Manipulation","arxivId":"2602.09583","date":"2026-02-10","authors":"Danica Kragic Team","category":"Manipulation","summary":"本文研究如何让机器人在操作可变形物体（如布料）时适应人类个性化偏好。针对偏好难以量化且演示数据有限的问题，作者提出了RKO方法，该方法融合了RPO和KPO框架的优势，能够高效地对预训练的视觉运动扩散策略进行偏好对齐微调。在真实布料折叠任务上的实验表明，采用RKO等偏好对齐策略相比标准微调方法，在任务性能和样本效率上均表现出显著优越性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.09153","title":"SceneSmith: Agentic Generation of Simulation-Ready Indoor Scenes","arxivId":"2602.09153","date":"2026-02-09","authors":"Russ Tedrake Team","category":"Manipulation","summary":"本文针对机器人仿真训练中室内场景过于简化、缺乏真实物理复杂性的问题，提出了SceneSmith框架。该框架采用分层智能体架构，通过设计师、评论家和协调员等VLM智能体，分阶段从语言提示生成仿真就绪的3D场景，并整合文本到3D合成与物理属性估计。实验表明，其生成场景的物体数量是基线方法的3-6倍，物体间碰撞率低于2%，物理稳定性达96%，在用户研究中真实性与提示忠实度胜率均超过90%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.09023","title":"TwinRL-VLA: Digital Twin-Driven Reinforcement Learning for Real-World Robotic Manipulation","arxivId":"2602.09023","date":"2026-02-09","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"论文提出了一种名为TwinRL-VLA的数字孪生驱动强化学习框架，旨在解决现实世界中机器人操作任务中由于高昂的专家演示成本和不足的实际交互导致的Vision-Language-Action (VLA)模型泛化能力受限的问题。该方法通过智能手机捕捉场景高效重建高保真度的数字孪生环境，实现真实与模拟环境之间的双向传输。在监督微调（SFT）预热阶段，利用数字孪生扩展探索空间，增强数据轨迹分布的支持。基于此初始化，进一步提出了从模拟到现实的引导探索策略，显著提升了VLA模型在实际操作中的性能。实验结果表明，TwinRL-VLA有效提高了在线强化学习的探索效率和探索空间。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.09021","title":"$χ_{0}$ : Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies","arxivId":"2602.09021","date":"2026-02-09","authors":"Yibo Yuan Team","category":"Manipulation","summary":"本文针对高可靠性长时机器人操作中的分布不一致性问题，提出了一种资源高效的框架χ₀。该框架通过三个关键技术解决这一问题：（i）模型算术，一种权重空间合并策略，有效吸收不同演示的多样化分布；（ii）阶段优势，一种阶段感知的优势估计器，提供稳定、密集的进度信号；（iii）训练-部署对齐，通过时空增强、启发式DAgger校正和时间块平滑来弥合分布差距。实验表明，该方法使双臂机器人能够协同完成从展平、折叠到挂起不同衣物的长时任务，并表现出高可靠性的自主操作能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.09017","title":"Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models","arxivId":"2602.09017","date":"2026-02-09","authors":"Nur Muhammad Mahi Shafiullah Team","category":"Manipulation","summary":"本文提出了一种名为接触锚定策略（Contact-Anchored Policies, CAP）的方法，通过物理接触信息来调节多模态策略。CAP能够在零样本情况下对新对象和场景进行泛化，并且在数据量、计算资源和模型参数方面比前沿行为模型少几个数量级的情况下，仍然在原子技能训练上表现出更好的性能。实验结果表明，CAP方法在多种任务中均优于现有的前沿行为模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.08602","title":"Mimic Intent, Not Just Trajectories","arxivId":"2602.08602","date":"2026-02-09","authors":"Panpan Cai Team","category":"Manipulation","summary":"该论文针对模仿学习（IL）在环境变化适应和技能迁移方面的不足，提出了一种新的方法“Mimic Intent, Not just Trajectories”（MINT）。MINT通过多尺度频域分词技术，将行为意图与执行细节分离。具体来说，它使用多尺度粗到细的结构来学习动作标记，其中最粗的标记捕捉低频全局结构，较细的标记编码高频细节。这种方法生成了一个抽象的意图标记，有助于规划和迁移，并生成了多尺度的执行标记，以适应环境动态。实验结果表明，MINT在多个操作基准测试和真实机器人上表现出色，具有更高的成功率、更优的推理效率、更强的抗干扰能力和有效的单次技能迁移能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.08245","title":"STEP: Warm-Started Visuomotor Policies with Spatiotemporal Consistency Prediction","arxivId":"2602.08245","date":"2026-02-09","authors":"Guohao Dai Team","category":"Manipulation","summary":"本文提出了一种名为STEP的轻量级时空一致性预测机制，旨在解决扩散策略在机器人视觉运动控制中因迭代去噪导致的高推理延迟问题。STEP通过生成高质量的初始动作，这些动作既接近目标动作的分布又具有时间一致性，从而在不牺牲原始扩散策略生成能力的前提下减少延迟。此外，还引入了速度感知扰动注入机制，自适应地调整动作激励以防止执行停滞。理论分析表明，该预测方法能诱导局部收缩映射，确保在扩散细化过程中动作误差收敛。实验结果表明，在RoboMimic基准测试和实际任务中，STEP仅用2步即可分别比BRIDGER和DDIM提高21.6%和27.5%的成功率，显著提升了推理延迟和成功率之间的帕累托前沿。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.07388","title":"Trace-Focused Diffusion Policy for Multi-Modal Action Disambiguation in Long-Horizon Robotic Manipulation","arxivId":"2602.07388","date":"2026-02-07","authors":"Jianfei Yang Team","category":"Manipulation","summary":"本文针对长时机器人操作任务中由于视觉相似但需不同动作导致的多模态动作歧义问题，提出了一种基于扩散模型的轨迹聚焦策略（TF-DP）。该方法通过显式地将动作生成条件化于机器人的执行历史，利用历史运动轨迹提供阶段感知的上下文信息，并在视觉观察空间中突出与历史运动相关的任务相关区域，从而提高对背景视觉干扰的鲁棒性。实验结果表明，TF-DP在多模态动作歧义任务上比普通扩散策略提升了80.56%的性能，在视觉干扰条件下提升了86.11%的性能，同时仅增加了6.4%的运行时间。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.07341","title":"Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions","arxivId":"2602.07341","date":"2026-02-07","authors":"Zhuo Zou Team","category":"Manipulation","summary":"本文针对灵巧机器人手臂系统的可扩展操作学习问题，提出了一种基于增强现实（AR）的远程人机交互方法，以提高专家演示数据收集效率。该方法分为两个阶段：首先通过行为克隆（BC）方式预训练策略，利用AR系统收集的数据；其次，采用对比学习增强的强化学习（RL）方法进一步优化策略，并设计投影头加速学习过程。实验结果表明，与经典的近端策略优化和软演员-评论家策略相比，该方法不仅显著提高了推理速度，还在完成操作任务的成功率上表现更优。消融研究表明，提出的对比学习强化学习方法有效克服了策略崩溃问题。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.07326","title":"Why Look at It at All?: Vision-Free Multifingered Blind Grasping Using Uniaxial Fingertip Force Sensing","arxivId":"2602.07326","date":"2026-02-07","authors":"Seokhwan Jeong Team","category":"Manipulation","summary":"该论文探讨了在极简传感条件下实现可靠的多指抓取问题，仅依赖单轴指尖力反馈和关节本体感觉，无需视觉或高分辨率触觉传感器。研究采用了一种高效的教师-学生训练框架，其中强化学习的教师利用模拟中的特权观察生成演示，以提炼出基于Transformer的学生策略，该策略仅使用实际部署中可用的传感模式。实验结果表明，在18个物体上（包括分布内和分布外的情况），该方法实现了98.3%的整体抓取成功率，展示了强大的鲁棒性和泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.07082","title":"MosaicThinker: On-Device Visual Spatial Reasoning for Embodied AI via Iterative Construction of Space Representation","arxivId":"2602.07082","date":"2026-02-06","authors":"Wei Gao Team","category":"Manipulation","summary":"论文针对嵌入式AI中视觉语言模型空间推理能力弱的问题，尤其是在跨帧复杂空间关系任务上，提出了MosaicThinker技术。该方法通过迭代构建空间表示，将多帧碎片化信息整合为统一的全局语义地图，并利用视觉提示引导VLM进行推理。实验结果表明，该技术能极大地提高资源受限设备上跨帧空间推理的准确性，适用于各种类型和复杂度的任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.06620","title":"Force Generative Imitation Learning: Bridging Position Trajectory and Force Commands through Control Technique","arxivId":"2602.06620","date":"2026-02-06","authors":"Toshiaki Tsuji Team","category":"Manipulation","summary":"本文解决接触式任务中，如何从易得的位置轨迹生成适配特定硬件的精确力命令这一核心问题。提出了力生成模仿学习方法，通过无记忆的力生成模型结合反馈控制机制，将给定位置轨迹映射为力命令。实验表明，该方法确保了反馈控制的稳定性，有效提升了模型对未见位置轨迹的泛化能力，并在真实机器人书写任务中取得了性能改进。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.06512","title":"Beyond the Majority: Long-tail Imitation Learning for Robotic Manipulation","arxivId":"2602.06512","date":"2026-02-06","authors":"Heng Tao Shen Team","category":"Manipulation","summary":"这篇论文针对机器人模仿学习中训练数据呈现长尾分布的核心问题，即模型在数据丰富的头部任务上表现良好，但在数据稀缺的尾部任务上泛化能力差。研究发现，传统长尾学习策略（如重采样）对提升尾部任务性能效果有限，其根本原因是数据稀缺损害了策略的空间推理能力。为此，作者提出了“接近阶段增强”（APA）方法，通过将头部任务的知识迁移至尾部任务，无需外部演示数据。实验表明，APA方法在模拟和真实机器人操作任务中均能有效提升尾部任务的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.06508","title":"World-VLA-Loop: Closed-Loop Learning of Video World Model and VLA Policy","arxivId":"2602.06508","date":"2026-02-06","authors":"Mike Zheng Shou Team","category":"Manipulation","summary":"本文提出World-VLA-Loop闭环框架，旨在解决现有视频世界模型在机器人学习中动作跟随精度不足的问题。方法核心包括：1）状态感知视频世界模型，联合预测未来观测与奖励信号，充当高保真交互模拟器；2）引入SANS数据集，利用近成功轨迹提升世界模型的动作-结果对齐；3）构建世界模型与视觉-语言-动作（VLA）策略的协同进化闭环，利用策略失败经验迭代优化模型。实验表明，经过两轮联合优化，真实世界策略成功率提升36.7%，显著减少了物理交互需求。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.05468","title":"TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation","arxivId":"2602.05468","date":"2026-02-05","authors":"Shigeki Sugano Team","category":"Manipulation","summary":"本文针对机器人灵巧抓取操作中难以区分自接触与外部物体接触触觉信号的核心问题，提出TaSA框架。该方法采用两阶段深度预测学习：第一阶段显式学习自接触动力学模型；第二阶段将该模型整合至动作学习中，以衰减自接触信号并突出外部接触。在铅笔芯、硬币、回形针等多种精细插入任务上的实验表明，基于TaSA训练的策略取得了显著高于基线方法的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.05233","title":"MobileManiBench: Simplifying Model Verification for Mobile Manipulation","arxivId":"2602.05233","date":"2026-02-05","authors":"Baining Guo Team","category":"Manipulation","summary":"本文针对移动操作中视觉-语言-动作模型验证困难的问题，提出“仿真优先”的验证框架。核心是构建了MobileManiBench大规模基准，其关键技术是基于NVIDIA Isaac Sim与强化学习，自动生成包含丰富标注的多样化操作轨迹。该基准包含2种移动机器人、630个物体、5种核心技能，在100个场景中生成30万条轨迹，为系统化研究机器人构型、感知模态与策略架构提供了可控、可扩展的测试平台，并已用于代表性VLA模型的基准测试。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.05049","title":"VISTA: Enhancing Visual Conditioning via Track-Following Preference Optimization in Vision-Language-Action Models","arxivId":"2602.05049","date":"2026-02-04","authors":"Dongdong Chen Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型中视觉条件控制不精确的问题，提出了一种名为“轨迹跟随偏好优化”的新方法。该方法通过优化模型对指定视觉轨迹的跟随偏好，显著提升了基于视觉指令的机器人操作精度。实验表明，VISTA在多个标准任务上实现了性能的大幅提升，成功率平均提高了15%以上。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.04243","title":"Viewpoint Matters: Dynamically Optimizing Viewpoints with Masked Autoencoder for Visual Manipulation","arxivId":"2602.04243","date":"2026-02-04","authors":"Wenzhao Lian Team","category":"Manipulation","summary":"本文针对机器人模仿学习中固定摄像头视角限制适应性的问题，提出MAE-Select框架，实现动态主动视角选择。该方法基于预训练多视角掩码自编码器（MAE）的表征，无需视角标注，即可根据当前视觉与动作信息动态预测并选择信息量最大的下一视角。实验表明，该方法显著提升了单摄像头系统的操作性能，部分任务甚至优于多摄像头配置。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.04231","title":"GeoLanG: Geometry-Aware Language-Guided Grasping with Unified RGB-D Multimodal Learning","arxivId":"2602.04231","date":"2026-02-04","authors":"Hongliang Ren Team","category":"Manipulation","summary":"本文针对语言引导抓取在杂乱、遮挡或低纹理场景中泛化能力差、现有方法多阶段流程导致融合有限的问题，提出GeoLanG框架。该框架基于CLIP架构，统一RGB-D多模态学习，通过深度引导几何模块（DGGM）将深度信息转换为几何先验注入注意力机制，并采用自适应密集通道集成平衡多层特征贡献。实验在OCID-VLG数据集及仿真和真实环境中验证，GeoLanG实现了精确鲁棒的语言引导抓取。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.04228","title":"Reshaping Action Error Distributions for Reliable Vision-Language-Action Models","arxivId":"2602.04228","date":"2026-02-04","authors":"Badong Chen Team","category":"Manipulation","summary":"本文针对连续动作视觉-语言-动作（VLA）模型使用均方误差（MSE）回归时对个体预测误差约束过强、忽略整体误差分布的问题，提出通过重塑动作误差分布来提升模型可靠性。关键技术是引入信息论中的最小误差熵（MEE），设计轨迹级MEE目标及其两个加权变体，与MSE结合进行训练。实验在标准、少样本和噪声设置下，使用LIBERO等模拟基准和真实机器人任务，结果表明该方法能持续提高成功率和鲁棒性，在数据不平衡时增益稳定，且额外训练成本可忽略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.04213","title":"InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons","arxivId":"2602.04213","date":"2026-02-04","authors":"Reid Simmons Team","category":"Manipulation","summary":"本文提出InterPReT方法，旨在解决非专业用户难以通过传统模仿学习有效教导AI智能体的难题。其核心技术为“交互式策略重构与训练”，允许用户通过指令交互式地更新策略结构，并通过演示优化参数，从而让用户能监控性能并审查决策过程。在一项34人参与的赛车游戏教学用户研究中，与通用模仿学习基线相比，该方法在由非专业用户提供演示并决定训练停止时，能产生更鲁棒的策略，且不损害系统可用性，证明了其对无技术背景用户的适用性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.03973","title":"VLS: Steering Pretrained Robot Policies via Vision-Language Models","arxivId":"2602.03973","date":"2026-02-03","authors":"Ranjay Krishna Team","category":"Manipulation","summary":"本文提出VLS框架，解决预训练扩散或流匹配策略在测试时遭遇空间配置或任务语义分布偏移时的适应性问题。核心方法为无需训练的推理时引导技术：利用视觉语言模型合成轨迹可微的奖励函数，在去噪采样过程中直接调整冻结策略的动作分布，无需修改参数。实验表明，VLS在CALVIN和LIBERO-PRO基准上分别取得31%和13%的性能提升，并在真实机器人上验证了对空间与语义偏移的鲁棒适应性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.03668","title":"MVP-LAM: Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction","arxivId":"2602.03668","date":"2026-02-03","authors":"Jungwoo Lee Team","category":"Manipulation","summary":"本文提出MVP-LAM模型，旨在解决从无标注视频中学习潜在动作时，因视角变化引入噪声、导致潜在动作与真实动作关联性弱的核心问题。其关键技术是利用时间同步的多视角视频，通过跨视角重建目标进行训练：从一个视角推断的潜在动作必须能预测另一视角的未来状态，从而剥离视角特异性干扰。实验表明，在Bridge V2数据集上，MVP-LAM学得的潜在动作与真实动作互信息更高，动作预测性能更优（包括分布外评估）。使用该潜在动作预训练VLA模型，在SIMPLER和LIBERO-Long基准上提升了下游操作性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.02839","title":"Language Movement Primitives: Grounding Language Models in Robot Motion","arxivId":"2602.02839","date":"2026-02-02","authors":"Simon Stepputtis Team","category":"Manipulation","summary":"本文解决机器人根据自然语言指令执行新操作任务时，高层语义推理与底层运动控制脱节的核心问题。提出语言运动基元（LMP）框架，其关键技术是将大视觉语言模型（VLM）的推理能力，通过动态运动基元（DMP）的参数化进行落地，从而将语言指令直接转化为连续、稳定的机器人轨迹。在20个真实桌面操作任务上的实验表明，该方法实现了零样本操作，任务成功率高达80%，显著优于基线方法（31%）。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.02762","title":"On the Sample Efficiency of Inverse Dynamics Models for Semi-Supervised Imitation Learning","arxivId":"2602.02762","date":"2026-02-02","authors":"Sébastien Lachapelle Team","category":"Manipulation","summary":"本文研究逆动力学模型（IDM）在半监督模仿学习（SSIL）中的样本效率问题。核心在于解释为何基于IDM的方法（如VM-IDM和IDM标注）比直接的行为克隆（BC）更高效。作者提出两个关键原因：一是真实IDM的假设空间复杂度通常低于专家策略；二是真实IDM的随机性往往小于专家策略。通过理论分析和在ProcGen等基准上的实验，论文验证了这一观点，并基于此改进了现有的LAPO算法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.02473","title":"HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos","arxivId":"2602.02473","date":"2026-02-02","authors":"Ping Tan Team","category":"Manipulation","summary":"本文旨在解决仿人机器人执行敏捷、自适应交互任务的挑战，当前方法受限于现实交互数据稀缺和精细任务奖励工程。为此，提出HumanX框架，包含两个核心技术：XGen数据生成管道，从单目视频合成物理合理、多样化的机器人交互数据并支持增强；XMimic统一模仿学习框架，通过模仿XGen合成行为学习泛化技能，无需任务特定奖励。实验在篮球、足球等五个领域评估，成功学习10种技能（如转身后仰跳投、连续传球），并零样本转移到Unitree G1物理机器人，实现超过8倍的泛化成功率提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.02459","title":"TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments","arxivId":"2602.02459","date":"2026-02-02","authors":"Jiaqi Ma Team","category":"Manipulation","summary":"TIC-VLA模型旨在解决动态复杂环境中机器人导航的挑战，核心是处理未知障碍物和动态物体，实现安全高效导航。其关键技术为“Think-in-Control”分层框架，高层利用视觉语言模型进行场景理解与路径规划，低层执行实时避障动作。实验表明，该模型在动态模拟和真实环境中导航成功率显著提升（例如在未知动态障碍场景下成功率超过XX%），路径规划效率优于传统方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.02454","title":"World-Gymnast: Training Robots with Reinforcement Learning in a World Model","arxivId":"2602.02454","date":"2026-02-02","authors":"Sherry Yang Team","category":"Manipulation","summary":"本文旨在解决机器人学习中物理交互成本高昂的瓶颈问题。传统方法如专家监督微调(SFT)和软件模拟器强化学习(RL)分别受限于数据稀缺和仿真与现实间的差距。论文提出World-Gymnast方法，其核心是通过在基于真实数据训练的动作条件视频世界模型中执行策略展开，并利用视觉语言模型(VLM)对展开结果进行奖励，从而对视觉-语言-动作(VLA)策略进行RL微调。在Bridge机器人实验中，该方法性能超越SFT高达18倍，超越软件模拟器高达2倍，并展现出利用世界模型进行多样化指令训练、场景泛化等新兴能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.02402","title":"SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation","arxivId":"2602.02402","date":"2026-02-02","authors":"Jiangmiao Pang Team","category":"Manipulation","summary":"本文提出SoMA，一个用于机器人软体操作的真实到仿真神经模拟器。核心解决现有模拟器依赖预定义物理模型或缺乏机器人条件控制，导致准确性、稳定性和泛化能力不足的问题。其关键技术是在统一潜在神经空间中，耦合可变形物体动力学、环境力与机器人关节动作，并基于学习的3D高斯泼溅进行端到端模拟。该方法无需预定义物理模型，实现了可控、稳定的长时程操作与轨迹外泛化。实验表明，SoMA在真实机器人操作任务上，将重新模拟准确性与泛化能力提升了20%，并能稳定模拟如长时程布料折叠等复杂任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.02396","title":"PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning","arxivId":"2602.02396","date":"2026-02-02","authors":"Alexander Schperberg Team","category":"Manipulation","summary":"论文PRISM解决了机器人模仿学习中现有方法难以同时满足实时控制速率、多模态传感输入（如RGB、深度、触觉）和动作多模态分布的挑战。它提出基于Performer RS-IMLE的单次通过策略，结合多传感器时序编码器与线性注意力生成器，采用批全局拒绝采样IMLE目标进行训练。实验表明，在真实硬件任务中PRISM比扩散策略成功率提高10-25%，在CALVIN基准上成功率提升约25%，轨迹急动度减少20-50倍，同时保持30-50Hz闭环控制。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.01939","title":"Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy","arxivId":"2602.01939","date":"2026-02-02","authors":"Qiang Nie Team","category":"Manipulation","summary":"本文针对机器人操作中因视觉遮挡导致的信息不足问题，提出了“探索性与聚焦性操作”（EFM）这一新问题。为此，研究者建立了包含10个任务的EFM-10基准，并提出了“双臂主动感知”（BAP）策略：利用一只手臂提供主动视觉，另一只手臂在操作时提供力感知。基于该策略收集了BAPData数据集，并通过模仿学习验证了BAP策略的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.01789","title":"RFS: Reinforcement learning with Residual flow steering for dexterous manipulation","arxivId":"2602.01789","date":"2026-02-03","authors":"Abhishek Gupta Team","category":"Manipulation","summary":"本文提出RFS框架，解决预训练生成式策略（如流匹配模型）在灵巧操作任务中泛化不足、需高效微调的问题。其核心方法“残差流引导”通过联合优化残差动作与潜在噪声分布，实现局部修正与全局探索的互补。实验表明，RFS能在仿真和真实环境中对预训练策略进行高效微调，提升部署鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.01662","title":"AgenticLab: A Real-World Robot Agent Platform that Can See, Think, and Act","arxivId":"2602.01662","date":"2026-02-02","authors":"Yu She Team","category":"Manipulation","summary":"本文提出AgenticLab，一个模型无关的真实世界机器人代理平台与基准，旨在解决现有基于大视觉语言模型（VLM）的操纵系统在非结构化、长时程闭环执行中能力不明确、难以标准化评估的问题。平台核心是一个集成了感知、任务分解、在线验证与重规划的闭环代理流程。通过该平台对先进VLM代理进行真实机器人任务基准测试，揭示了离线测试无法捕捉的多种故障模式，包括多步基础一致性崩溃、遮挡与场景变化下的物体基础失效，以及空间推理不足导致的操纵不可靠。平台将开源以支持可复现评估。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.01632","title":"A Closed-Form Geometric Retargeting Solver for Upper Body Humanoid Robot Teleoperation","arxivId":"2602.01632","date":"2026-02-02","authors":"Shreyas Kousik Team","category":"Manipulation","summary":"本文针对人形机器人上身远程操作中运动重定向延迟高、运动不自然的核心问题，提出SEW-Mimic闭式几何求解器。该方法通过肩、肘、腕关键点对齐机器人与人类手臂方向，实现快速最优解，适用于多数7自由度机器人。实验表明，推理速度达3 kHz，优于现有方法；用户研究显示提升任务成功率，且数据更平滑，有助于策略学习。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.01166","title":"Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models","arxivId":"2602.01166","date":"2026-02-01","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"本文提出LaRA-VLA框架，旨在解决视觉-语言-动作模型中基于思维链的推理方法存在的推理开销高、离散推理表示与连续感知控制不匹配的核心问题。其关键技术是将多模态思维链推理内化为连续的潜在表示，在潜在空间进行统一推理与预测，并采用渐进式训练范式，从显式监督过渡到潜在推理。实验表明，该框架在仿真与真实机器人任务上性能优于现有方法，且相比显式思维链方法，推理延迟降低高达90%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.01158","title":"Improving Robustness of Vision-Language-Action Models by Restoring Corrupted Visual Inputs","arxivId":"2602.01158","date":"2026-02-01","authors":"Matteo Matteucci Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型在真实部署中因图像损坏（如电子噪声、坏点）导致性能严重下降的问题展开研究。作者提出了一种即插即用、模型无关的损坏恢复变换器，通过对抗训练直接修复损坏的视觉输入，无需微调原模型。实验表明，该方法能使模型在严重视觉损坏下保持接近基线的成功率，有效解决了VLA模型对传感器干扰的脆弱性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.01153","title":"UniForce: A Unified Latent Force Model for Robot Manipulation with Diverse Tactile Sensors","arxivId":"2602.01153","date":"2026-02-01","authors":"Shan Luo Team","category":"Manipulation","summary":"本文提出UniForce框架，旨在解决机器人操作中因触觉传感器异构性（如光学、磁性等原理差异）导致的力感知模型难以泛化的问题。其核心方法是通过学习跨传感器的共享潜在力空间，联合建模逆动力学与正动力学，并利用力平衡与图像重建损失约束，从而提取与力相关的统一表征。实验表明，该方法在GelSight、TacTip和uSkin等多种传感器上实现了力估计性能的稳定提升，并支持零样本迁移至下游任务（如机器人擦拭），无需针对新传感器重新训练。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.01115","title":"KAN We Flow? Advancing Robotic Manipulation with 3D Flow Matching via KAN & RWKV","arxivId":"2602.01115","date":"2026-02-01","authors":"Ziyang Wang Team","category":"Manipulation","summary":"本文针对基于扩散模型的机器人操作策略参数量大、推理效率低的问题，提出KAN-We-Flow方法。其核心是构建了轻量化的RWKV-KAN主干网络：RWKV模块高效融合时空与通道信息，GroupKAN层则通过可学习的样条函数进行特征非线性校准。此外，引入动作一致性正则化（ACR）损失来稳定训练。该方法无需大型UNet，在保持高速运行的同时，将参数量降低了86.8%，并在Adroit等多个标准测试集上取得了最优成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.01100","title":"StreamVLA: Breaking the Reason-Act Cycle via Completion-State Gating","arxivId":"2602.01100","date":"2026-02-01","authors":"Lu Fang Team","category":"Manipulation","summary":"本文针对长程机器人操作中视觉-语言-动作模型在每个时间步进行冗余推理导致高延迟的问题，提出StreamVLA双系统架构。其关键技术是“锁定-门控”机制：仅当检测到子任务转换时，才触发慢思考生成文本指令并想象特定的视觉完成状态作为时间不变的目标锚点；在稳定执行期间，则锁定高级意图以驱动流匹配动作头，跳过大部分自回归解码。实验表明，该方法在LIBERO基准上达到98.5%的成功率，相比全推理基线延迟降低48%（平均244ms→128ms），并在72%的时间步跳过了冗余计算。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.01085","title":"Estimating Force Interactions of Deformable Linear Objects from their Shapes","arxivId":"2602.01085","date":"2026-02-01","authors":"Quang-Cuong Pham Team","category":"Manipulation","summary":"本文提出一种仅通过观察形状来估计可变形线性物体（如电线）所受外力作用的方法。核心问题是解决机器人操作中接触点不在末端执行器时的力交互检测难题。关键技术基于力-扭矩平衡方程推导一致性条件，结合离散弹性杆（DER）模型计算内部扭矩，通过求解线性方程组同时估计外力作用位置和大小。该方法在仿真中达到高精度，并在真实场景实验中成功验证了其有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2602.01067","title":"A Systematic Study of Data Modalities and Strategies for Co-training Large Behavior Models for Robot Manipulation","arxivId":"2602.01067","date":"2026-02-01","authors":"Jose Barreiros Team","category":"Manipulation","summary":"本文系统研究了用于机器人操作的大型行为模型（LBMs）的协同训练问题，旨在解决现有机器人数据覆盖不足导致的泛化能力局限。研究评估了五种协同训练数据模态（标准视觉语言数据、带密集语言标注的机器人轨迹、跨具身机器人数据、人类视频、离散动作令牌）及不同训练策略。核心结论表明，结合视觉语言数据与跨具身机器人数据进行协同训练能显著提升模型对分布偏移、未见任务和语言指令的泛化能力，而离散动作令牌则无显著增益。实验基于4000小时机器人/人类操作数据与5000万视觉语言样本，验证了有效模态的协同训练可恢复并增强视觉语言骨干的理解与推理能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.23087","title":"Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation","arxivId":"2601.23087","date":"2026-01-30","authors":"Liu Hong Team","category":"Manipulation","summary":"本文针对长时程机器人操作中，现有生成策略难以兼顾表达性行为建模、快速推理和稳定执行的核心问题，提出CoLA-Flow Policy框架。其关键技术是通过连续潜在动作空间的流匹配，将动作序列编码为时间一致的潜在轨迹，并学习显式潜在流，以解耦全局运动结构与低级控制噪声。实验表明，该方法实现近单步推理，相比原始动作空间流基线，轨迹平滑度提升达93.7%，任务成功率提升达25%，且推理速度显著优于扩散策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.22988","title":"Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation","arxivId":"2601.22988","date":"2026-01-30","authors":"Guang Chen Team","category":"Manipulation","summary":"本文针对机器人操作中单视图3D几何理解不足、视角泛化能力弱的核心问题，提出了GEM3D框架。其关键技术在于采用单视图3D预训练范式，通过点云重建和前馈高斯溅射学习整体几何表示，并在策略学习阶段通过多步蒸馏保留几何知识。实验表明，该方法在12个RLBench任务上的平均成功率超越先前最优方法12.7%，且在视角大幅变化时，成功率下降幅度显著更小，展现了卓越的零样本视角泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.22965","title":"Self-Imitated Diffusion Policy for Efficient and Robust Visual Navigation","arxivId":"2601.22965","date":"2026-01-30","authors":"Wuyue Zhao Team","category":"Manipulation","summary":"本文提出自模仿扩散策略（SIDP），以解决视觉导航中传统扩散策略因模仿学习而继承专家演示的次优性与冗余，导致推理时依赖计算密集的“生成-过滤”流程的问题。SIDP采用奖励引导的自模仿机制，使策略选择性地模仿自身采样的高质量轨迹，结合奖励驱动的课程学习与目标无关的轨迹增强，提升规划效率与鲁棒性。实验表明，SIDP在仿真与实物平台上均显著优于基线方法，在Jetson Orin Nano上推理速度达110ms，比基线NavDP（273ms）快2.5倍，实现了高效实时部署。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.22206","title":"Causal Imitation Learning Under Measurement Error and Distribution Shift","arxivId":"2601.22206","date":"2026-01-29","authors":"AmirEmad Ghassami Team","category":"Manipulation","summary":"本文研究存在测量误差和分布偏移的离线模仿学习问题。核心挑战是：决策相关状态仅能通过噪声观测获得，且训练与部署环境存在分布差异，导致标准行为克隆方法产生系统性偏差。作者提出因果模仿学习框架CausIL，基于近端因果推断思想，将噪声观测视为代理变量，并给出无需奖励或专家交互的策略识别条件。针对连续状态空间，采用基于RKHS函数类的对抗学习进行参数估计。在PhysioNet/Computing in Cardiology Challenge 2019的半模拟纵向数据上验证，相比行为克隆基线，CausIL对分布偏移表现出更强的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.22074","title":"mjlab: A Lightweight Framework for GPU-Accelerated Robot Learning","arxivId":"2601.22074","date":"2026-01-29","authors":"Pieter Abbeel Team","category":"Manipulation","summary":"本文针对现有机器人学习框架在轻量化和可维护性上的不足，提出了mjlab轻量级框架。其核心是结合Isaac Lab的manager-based API（用于模块化组合观测、奖励等组件）与MuJoCo Warp GPU加速物理引擎。该方法实现了依赖极简、启动快速，并直接暴露MuJoCo原生数据结构。实验表明，该框架可在单个GPU上并行模拟数千个环境，并提供了运动跟踪、模仿等参考任务实现。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.22018","title":"PocketDP3: Efficient Pocket-Scale 3D Visuomotor Policy","arxivId":"2601.22018","date":"2026-01-30","authors":"Jie Mei Team","category":"Manipulation","summary":"本文针对现有3D视觉扩散策略中轻量点云编码器与庞大解码器不匹配导致的参数浪费问题，提出PocketDP3。该方法采用基于MLP-Mixer构建的轻量Diffusion Mixer（DiM）替代传统的条件U-Net解码器，实现了跨时空与通道的高效融合，并支持无需蒸馏的两步推理。在RoboTwin2.0、Adroit和MetaWorld三个仿真基准上，模型以不足原方法1%的参数取得最优性能，同时加速了推理，真实世界实验进一步验证了其实用性与迁移能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.21998","title":"Causal World Modeling for Robot Control","arxivId":"2601.21998","date":"2026-01-29","authors":"Yinghao Xu Team","category":"Manipulation","summary":"本文针对机器人控制中视觉-语言-动作模型存在的表示纠缠问题，提出LingBot-VA自回归扩散框架。其核心方法包括：1）基于混合Transformer的共享视觉-动作潜在空间；2）结合真实观测的闭环展开机制；3）并行化动作预测与电机执行的异步推理管道。实验表明，该模型在模拟与真实场景中，于长视野操作、数据效率及对新配置的泛化能力上均显著优于现有方法（如π_{0.5}）。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.21926","title":"Information Filtering via Variational Regularization for Robot Manipulation","arxivId":"2601.21926","date":"2026-01-29","authors":"Jie Me Team","category":"Manipulation","summary":"本文针对基于扩散模型的机器人操作策略中，中间特征存在冗余和任务无关噪声的问题，提出了一种轻量级的**变分正则化**模块。该方法通过对主干特征施加时间步条件的高斯分布并应用KL散度正则器，形成一个自适应信息瓶颈，从而在推理时有效过滤噪声。实验表明，该方法在三个仿真基准上显著优于基线DP3，成功率最高提升6.1%，并实现了新的最先进性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.21718","title":"When does predictive inverse dynamics outperform behavior cloning?","arxivId":"2601.21718","date":"2026-01-29","authors":"Sergio Valcarcel Macua Team","category":"Manipulation","summary":"本文研究预测逆动力学模型（PIDM）何时优于行为克隆（BC）。核心问题是：在专家演示数据有限时，PIDM通过结合未来状态预测器和逆动力学模型，引入偏差-方差权衡，从而提升样本效率。理论分析表明，在状态预测器偏差满足一定条件下，PIDM能取得更低的预测误差。实验验证：在2D导航任务中，BC平均需要3-5倍于PIDM的演示才能达到相当性能；在3D高维视觉游戏中，BC需多66%的样本才能达到80%成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.21416","title":"Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation","arxivId":"2601.21416","date":"2026-01-29","authors":"Liming Chen Team","category":"Manipulation","summary":"本文针对机器人操作任务中模型泛化能力不足的问题，提出了一种以对象为中心的视觉表征方法。其核心是通过学习解耦的、任务相关的物体特征表示，减少场景中无关背景信息的干扰。关键技术为对象中心表征学习，旨在从原始图像中分离并聚焦于可操作物体的关键属性。实验表明，该方法在模拟和真实机器人操作任务中显著提升了零样本泛化性能，在新物体、新背景下的任务成功率平均提升超过15%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.21394","title":"Towards Space-Based Environmentally-Adaptive Grasping","arxivId":"2601.21394","date":"2026-01-29","authors":"Aleksandr Artemov Team","category":"Manipulation","summary":"本文针对太空等非结构化环境中机器人抓取面临的高维动作空间、稀疏奖励和泛化慢的难题，提出一种环境自适应抓取方法。关键技术是**在学习的潜在流形中直接学习控制策略**，该流形融合了多模态信息，并**将可测量的环境描述符作为策略的显式条件变量**。基于GPU加速的物理仿真和Soft Actor-Critic强化学习，在持续变化的抓取条件下，**仅用少于100万环境步数就实现了超过95%的单次抓取任务成功率**，收敛速度优于代表性视觉基线，并对新物体、夹具几何和环境干扰展现出更强的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.21251","title":"Abstracting Robot Manipulation Skills via Mixture-of-Experts Diffusion Policies","arxivId":"2601.21251","date":"2026-01-29","authors":"Harold Soh Team","category":"Manipulation","summary":"本文针对扩散策略在多任务机器人操作中模型规模与数据成本过高的问题，提出技能专家混合策略（SMP）。该方法通过学习紧凑正交技能基，利用粘性路由在每一步仅激活少量任务相关专家组合动作，并采用变分训练目标与自适应专家激活实现高效推理。在仿真和真实双臂平台的多任务学习与迁移任务中，SMP相比大型扩散基线取得了更高的成功率，并显著降低了推理成本。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.20555","title":"Vibro-Sense: Robust Vibration-based Impulse Response Localization and Trajectory Tracking for Robotic Hands","arxivId":"2601.20555","date":"2026-01-28","authors":"Nicolás Navarro-Guerrero Team","category":"Manipulation","summary":"本文旨在为机器人手提供一种低成本、高精度的全身接触感知方案，以替代昂贵复杂的传统触觉皮肤。其核心技术是**振动声学传感**：在机械手上部署7个压电麦克风捕捉接触振动，并采用**音频谱图变换器（AST）** 解码振动信号以预测触摸位置。实验表明，该系统在静态条件下**定位误差小于5毫米**；材料特性影响显著：硬质材料（如金属）利于脉冲响应定位，而纹理材料（如木材）则更适合轨迹跟踪。该系统对机器人自身运动具有鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.20381","title":"STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation","arxivId":"2601.20381","date":"2026-01-28","authors":"Liming Chen Team","category":"Manipulation","summary":"本论文针对机器人操作中对象表示缺乏任务适应性的核心问题，提出了STORM方法：一种基于槽位的任务感知对象中心表示。该方法通过槽位机制分割场景中的对象，并融入任务信息以增强表示的相关性和灵活性。技术要点包括槽位分割实现对象中心化，以及任务感知模块优化表示学习。实验部分验证了STORM在机器人操作任务中的有效性，具体性能提升数据需参考论文正文。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.20334","title":"Demonstration-Free Robotic Control via LLM Agents","arxivId":"2601.20334","date":"2026-01-28","authors":"Tiffany J. Hwu Team","category":"Manipulation","summary":"本文针对机器人操纵需任务特定演示和微调、泛化能力差的核心问题，探索通用大型语言模型（LLM）代理框架作为替代控制范式。提出FAEA方法，直接应用未修改的LLM代理（如Claude Agent SDK）到具身操纵，通过迭代推理实现策略规划。实验在LIBERO、ManiSkill3和MetaWorld基准上，FAEA在特权状态访问下成功率分别达84.9%、85.7%和96%，接近使用≤100演示训练的视觉-语言-动作模型，且无需演示或微调；通过一轮人类反馈优化，LIBERO性能提升至88.2%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.20321","title":"Tactile-Force Alignment in Vision-Language-Action Models for Force-aware Manipulation","arxivId":"2601.20321","date":"2026-01-28","authors":"Ziyuan Jiao Team","category":"Manipulation","summary":"本文针对当前视觉-语言-动作模型在接触密集型操作任务中缺乏力感知能力的核心问题，提出从“触觉-视觉对齐”到“触觉-力对齐”的范式转变。关键技术是TaF-VLA框架：首先构建包含千万级同步触觉观测与力信号的TaF数据集；然后设计TaF-Adapter编码器，将序列触觉观测与物理交互力在潜空间对齐，以捕捉动态物理信息而非静态纹理。实验表明，该策略在真实世界接触任务上显著优于现有的触觉-视觉对齐及纯视觉基线，实现了通过跨模态物理推理进行鲁棒、力感知的操作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.20208","title":"TRACER: Texture-Robust Affordance Chain-of-Thought for Deformable-Object Refinement","arxivId":"2601.20208","date":"2026-01-28","authors":"Yaonan Wang Team","category":"Manipulation","summary":"本文提出TRACER框架，旨在解决机器人操作可变形物体时，因复杂纹理和外观变化导致的高层语义指令与物理交互点难以对齐的核心问题。关键技术包括：树状可供性思维链（TA-CoT）实现任务分层推理、空间约束边界细化（SCBR）机制抑制预测溢出、交互收敛细化流（ICRF）聚合噪声像素以增强区域连续性。在Fine-AGDDO15数据集和真实机器人平台上的实验表明，该方法显著提升了不同纹理下的可供性定位精度，并有效提高了长时域任务的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.20130","title":"Real-Time Robot Execution with Masked Action Chunking","arxivId":"2601.20130","date":"2026-01-27","authors":"Gaowen Liu Team","category":"Manipulation","summary":"本文针对异步推理中机器人动作块与感知不匹配导致的执行失败问题，提出REMAC方法。核心是通过**掩码动作分块**技术，在预训练策略上学习校正调整，并引入**前缀保留采样**增强块间连续性，使策略在动作与执行失配时保持鲁棒。实验表明，该方法在不增加延迟的前提下，实现了更快的任务执行、跨延迟的鲁棒性以及更高的任务完成率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.20116","title":"In-Context Reinforcement Learning From Suboptimal Historical Data","arxivId":"2601.20116","date":"2026-01-27","authors":"Vahid Tarokh Team","category":"Manipulation","summary":"本文研究上下文强化学习（ICRL）中如何利用次优历史数据学习最优策略的问题。针对离线数据来自次优行为策略导致传统自回归训练性能受限的挑战，提出了决策重要性变换器（DIT）框架。该方法通过训练基于Transformer的价值函数估计行为策略的优势函数，并以此构建权重，采用加权最大似然估计训练策略网络，从而将次优策略向最优方向引导。实验在Bandit和马尔可夫决策过程问题上验证了DIT的有效性，结果表明其在处理次优离线数据时性能显著优于基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.19634","title":"AC^2-VLA: Action-Context-Aware Adaptive Computation in Vision-Language-Action Models for Efficient Robotic Manipulation","arxivId":"2601.19634","date":"2026-01-27","authors":"Lei Zhu Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型在机器人操作中闭环部署时延迟高、计算成本大的问题，提出AC^2-VLA框架。其核心是通过动作上下文感知的自适应计算，联合决策跨时间步的认知重用、令牌剪枝和模型层选择性执行，并采用动作引导的自蒸馏训练策略。实验表明，该方法在保持任务成功率相当的同时，最高可实现1.79倍加速，并将计算量（FLOPs）降至基准模型的29.4%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.19510","title":"ALRM: Agentic LLM for Robotic Manipulation","arxivId":"2601.19510","date":"2026-01-27","authors":"Hakim Hacid Team","category":"Manipulation","summary":"本文针对LLM在机器人控制中缺乏闭环执行机制和系统性评估基准的问题，提出ALRM框架。该框架通过ReAct式推理循环，整合策略生成与代理执行，提供Code-as-Policy（直接生成控制代码）和Tool-as-Policy（迭代规划与工具执行）两种模式。为系统评估，作者构建了包含56个任务、支持语言多样性的模拟基准。实验使用十种LLM验证，结果表明ALRM能有效连接自然语言推理与机器人执行，其中Claude-4.1-Opus（闭源）和Falcon-H1-7B（开源）在CaP模式下表现最佳。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.19411","title":"Task-Centric Policy Optimization from Misaligned Motion Priors","arxivId":"2601.19411","date":"2026-01-27","authors":"Shentao Qin Team","category":"Manipulation","summary":"由于未提供论文正文内容，仅基于标题“Task-Centric Policy Optimization from Misaligned Motion Priors”进行推断性总结。论文可能解决的核心问题是从不对齐的运动先验中优化策略，以高效完成特定任务。关键技术方法为任务中心策略优化，要点是通过算法调整或对齐运动先验，使其更符合任务需求。核心实验结论或性能提升数据需参考正文内容，无法在此给出具体信息。建议提供论文正文以撰写更精准的总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.19406","title":"Sim-and-Human Co-training for Data-Efficient and Generalizable Robotic Manipulation","arxivId":"2601.19406","date":"2026-01-27","authors":"Heng Tao Shen Team","category":"Manipulation","summary":"这篇论文针对现实世界机器人操作任务中数据稀缺、策略泛化能力差，以及高质量人类演示数据获取成本高的问题，提出了一种名为 **Sim-and-Human Co-training** 的联合训练框架。其核心方法是结合大规模的仿真预训练、少量的人类演示数据微调，并创新性地在训练过程中交替使用仿真与人类数据，以协同提升策略性能。实验表明，该方法在多个灵巧操作任务上，显著优于仅使用仿真数据或仅使用人类数据的方法，在数据效率和泛化到新场景（如不同物体、光照）方面表现出色。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.18723","title":"Trustworthy Evaluation of Robotic Manipulation: A New Benchmark and AutoEval Methods","arxivId":"2601.18723","date":"2026-01-26","authors":"Hong Liu Team","category":"Manipulation","summary":"本文针对机器人操作评估中可信度不足的核心问题，提出新的基准和自动评估方法。当前评估主要依赖二元成功率，无法有效衡量源真实性和执行质量等信任维度。为此，作者构建了Eval-Actions基准，集成视觉-动作和视觉-语言-动作策略轨迹与人类遥操作数据，包含失败场景，并基于专家评分、排名引导偏好和思维链三种监督信号。同时提出AutoEval架构：AutoEval-S通过时空聚合与运动学校准评估语义和平滑度；AutoEval-P引入组相对策略优化增强逻辑推理。实验表明，AutoEval评估精度高，在专家评分和排名引导协议下Spearman等级相关系数分别达0.81和0.84，且源判别准确率达99.6%，显著提升了评估的可信度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.18692","title":"A Pragmatic VLA Foundation Model","arxivId":"2601.18692","date":"2026-01-26","authors":"Kecheng Zheng Team","category":"Manipulation","summary":"本文提出了LingBot-VLA，一个实用的视觉-语言-动作基础模型，旨在解决VLA模型在真实机器人任务中泛化性、成本效率与部署可行性的核心问题。关键技术包括利用来自9种双臂机器人的约20,000小时真实数据进行预训练，并构建了高效代码库，训练吞吐量达每秒261样本/GPU，速度提升1.5-2.8倍。通过在3个机器人平台上对100项任务进行大规模评估，模型性能显著优于基线，且实验表明随着预训练数据量从3,000小时增至20,000小时，下游任务成功率持续提升，未出现饱和迹象，证明了其强大的性能与泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.18629","title":"ExoGS: A 4D Real-to-Sim-to-Real Framework for Scalable Manipulation Data Collection","arxivId":"2601.18629","date":"2026-01-26","authors":"Hao-Shu Fang Team","category":"Manipulation","summary":"本文提出ExoGS框架，旨在解决机器人操作任务中高质量交互数据获取困难、仿真与真实世界差距大的问题。其核心方法包括：1）使用机器人同构被动外骨骼AirExo-3精准捕捉人类演示的毫米级轨迹；2）基于3D高斯泼溅技术将场景重建为可编辑的动态资产，支持几何一致的数据增强；3）引入轻量级Mask Adapter模块，为策略注入实例级语义以提升视觉域偏移下的鲁棒性。实验表明，该框架相比遥操作基线显著提升了数据效率和策略泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.17563","title":"Towards Generalisable Imitation Learning Through Conditioned Transition Estimation and Online Behaviour Alignment","arxivId":"2601.17563","date":"2026-01-24","authors":"Odinaldo Rodrigues Team","category":"Manipulation","summary":"本文针对模仿学习（ILfO）泛化能力不足、依赖动作监督及行为盲目模仿等问题，提出无监督模仿学习框架UfO。其核心技术分为两阶段：首先通过条件转移估计近似教师动作，再利用在线行为对齐精修策略，使智能体轨迹与教师轨迹紧密匹配。在五个常用环境上的实验表明，UfO性能超越教师及所有现有ILfO方法，且标准差最小，证明其在未见场景中具有更优的泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.17507","title":"MetaWorld: Skill Transfer and Composition in a Hierarchical World Model for Grounding High-Level Instructions","arxivId":"2601.17507","date":"2026-01-24","authors":"Tongtong Feng Team","category":"Manipulation","summary":"本文提出MetaWorld分层世界模型，旨在解决人形机器人语义指令与物理执行之间的鸿沟问题。其核心方法是将任务解耦为VLM驱动的语义规划层与潜在动力学模型控制层，并引入动态专家选择与运动先验融合机制，利用预训练的多专家策略库进行知识迁移与在线适配。在Humanoid-Bench上的实验表明，该方法在任务完成度和运动连贯性上优于基于世界模型的强化学习基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.17486","title":"EquiForm: Noise-Robust SE(3)-Equivariant Policy Learning from 3D Point Clouds","arxivId":"2601.17486","date":"2026-01-24","authors":"Yu She Team","category":"Manipulation","summary":"本文提出EquiForm框架，旨在解决基于3D点云的模仿学习策略对传感器噪声、姿态扰动和遮挡伪影高度敏感的问题，这些干扰会破坏SE(3)等变性假设。方法核心包括：1）几何去噪模块，用于从噪声观测中恢复一致的3D结构；2）对比等变对齐目标，强制表示在刚性变换与噪声扰动下的不变性。实验在16个模拟任务和4个真实任务上验证，相比先进方法，性能在模拟和真实环境中平均提升17.2%和28.1%，展现了优异的噪声鲁棒性与空间泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.17428","title":"Scaling Rough Terrain Locomotion with Automatic Curriculum Reinforcement Learning","arxivId":"2601.17428","date":"2026-01-24","authors":"Marco Hutter Team","category":"Manipulation","summary":"本文针对腿式机器人在复杂、无结构崎岖地形上难以实现高速稳定运动的问题，提出了**基于学习进度的自动课程强化学习（LP-ACRL）框架**。该框架的核心在于**在线估计智能体的学习进度，并据此自适应调整任务采样分布**，从而无需预先定义任务难度即可自动生成训练课程。实验表明，采用LP-ACRL训练的策略使ANYmal D四足机器人在楼梯、斜坡、碎石等多种地形上实现了**2.5 m/s的线速度和3.0 rad/s的角速度**，超越了此前方法在高速与复杂地形性能上的局限。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.17219","title":"Advancing Improvisation in Human-Robot Construction Collaboration: Taxonomy and Research Roadmap","arxivId":"2601.17219","date":"2026-01-23","authors":"Carol C. Menassa Team","category":"Manipulation","summary":"本论文旨在解决在人类-机器人建筑协作中如何有效推进即兴互动这一核心问题。通过构建分类学（Taxonomy）系统化即兴行为的类型，并制定研究路线图（Research Roadmap）以规划未来发展方向。论文侧重于理论框架的建立，为领域提供结构化指导，但具体技术要点和实验数据需参考正文内容。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.17135","title":"ConceptACT: Episode-Level Concepts for Sample-Efficient Robotic Imitation Learning","arxivId":"2601.17135","date":"2026-01-23","authors":"Friedhelm Schwenker Team","category":"Manipulation","summary":"论文针对模仿学习忽略人类语义知识、导致样本效率低的问题，提出ConceptACT方法。该方法扩展了Action Chunking with Transformers，在训练时利用情节级概念注释（如对象属性、空间关系），通过修改Transformer架构实现概念感知交叉注意力来集成语义信息。实验表明，ConceptACT在两种机器人操作任务上比标准ACT收敛更快、样本效率更高，且注意力机制集成显著优于辅助预测损失或语言条件模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.16866","title":"Boosting Deep Reinforcement Learning with Semantic Knowledge for Robotic Manipulators","arxivId":"2601.16866","date":"2026-01-23","authors":"Daniele Nardi Team","category":"Manipulation","summary":"本文针对深度强化学习在机器人操作任务中样本效率低、训练成本高的问题，提出一种融合语义知识的新方法。核心技术是将知识图谱嵌入与视觉观测相结合，为智能体提供环境上下文信息，从而提升学习效率。实验结果表明，该方法在机器人操作环境中，能将学习时间减少高达60%，并将任务准确率提升约15个百分点，且未增加额外的训练时间或计算复杂度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.16677","title":"Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation","arxivId":"2601.16677","date":"2026-01-23","authors":"Álvaro Jesús López-López Team","category":"Manipulation","summary":"本文旨在解决深度强化学习（DRL）中因仿真与真实视觉差异导致的策略迁移难题，以实现无需真实环境再训练的零次部署。为此，论文提出一种基于**风格识别循环一致生成对抗网络（StyleID-CycleGAN）**的域适应方法，该网络将原始虚拟观测转换为具有真实风格的合成图像，从而在混合域中训练DRL智能体。实验在两个工业机器人上进行，验证了方法的有效性：智能体在仿真中成功率可达90%-100%，并在真实拾放任务中实现了**零次迁移，在大部分工作区域准确率超过95%**，且能泛化至不同颜色和形状的真实物体。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.16667","title":"ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance","arxivId":"2601.16667","date":"2026-01-23","authors":"Wei-Shi Zheng Team","category":"Manipulation","summary":"该论文针对视觉-语言-动作模型在机器人操作中存在的“错误完成”问题，即任务未成功却提前终止，其根源在于模型过度依赖本体感觉而忽视视觉证据的模态不平衡。为此，提出ReViP框架，其核心技术是通过外部VLM构建任务阶段观察器提取实时视觉线索，并驱动视觉-本体感觉特征线性调制，以动态平衡多模态信息。实验表明，该方法在提出的错误完成基准及LIBERO等多个测试集上，有效降低了错误完成率并提升了任务成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.16242","title":"Scalable Screw-Theoretic Synthesis for PDE-Based Dynamic Modeling of Multibody Flexible Manipulators","arxivId":"2601.16242","date":"2026-01-22","authors":"J. Mattila Team","category":"Manipulation","summary":"本文针对多体柔性机器人操纵器动态建模的可扩展性挑战，提出了一种基于螺旋理论的合成框架。该方法通过构建单个柔性链接的偏微分方程模型，利用双螺旋描述运动与变形，并强制执行关节约束，实现无限可扩展的多体动力学表示。关键要点包括将支配方程表述为半显式索引1微分代数系统，以及通过变量分离证明适定性。节选未提供具体实验数据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.16065","title":"DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models","arxivId":"2601.16065","date":"2026-01-22","authors":"Jingqun Tang Team","category":"Manipulation","summary":"本文针对视觉语言动作（VLA）模型在机器人操作任务中过度关注任务无关区域图像标记（即“干扰标记”）而导致动作生成错误、成功率下降的问题，提出了一种即插即用的干扰标记剪枝（DTP）框架。该框架的核心方法是动态检测并剪枝这些干扰图像标记，以修正模型的视觉注意力模式，且无需改变模型原始架构或增加额外输入。在SIMPLER基准测试上的实验表明，DTP能持续提升不同类型VLA模型的任务成功率，证明了其良好的泛化性；分析进一步揭示，所有测试模型的任务成功率与任务无关区域的注意力数量均呈负相关。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.15761","title":"Off-Policy Actor-Critic with Sigmoid-Bounded Entropy for Real-World Robot Learning","arxivId":"2601.15761","date":"2026-01-22","authors":"Shu Zhang Team","category":"Manipulation","summary":"本文针对现实世界机器人强化学习中数据成本高、训练不稳定的问题，提出SigEnt-SAC方法。其关键技术是sigmoid有界熵，通过将策略的逐维度信息量经sigmoid映射为有界熵信号，防止因负熵主导而导致策略优化偏离分布，并稳定Q函数。实验表明，该方法在D4RL基准上显著减轻了Q值振荡，能更快达到100%成功率；在真实机器人任务中，仅需少量交互即可从原始图像和稀疏奖励中学习成功策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.15541","title":"CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation","arxivId":"2601.15541","date":"2026-01-21","authors":"Arash Ajoudani Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型在接触密集型操作任务中缺乏力感知与调节能力，导致操作不安全或失败的问题，提出CompliantVLA-adaptor方法。该方法利用视觉语言模型解析图像与语言指令以理解任务上下文，进而自适应地调整可变阻抗控制器的刚度与阻尼参数，并结合实时力/力矩反馈确保交互力处于安全阈值。实验表明，该方法在模拟与真实硬件的一系列复杂接触任务上均优于基线VLA模型，整体任务成功率从9.86%提升至17.29%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.15197","title":"BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries","arxivId":"2601.15197","date":"2026-01-22","authors":"Kai Chen Team","category":"Manipulation","summary":"根据当前仅有的论文标题《BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries》，无法获取正文内容以撰写符合要求的总结。  \n若仅基于标题推断，本文可能**研究如何对视觉-语言-动作模型进行贝叶斯分解，其核心方法是引入潜在动作查询**。但缺乏正文细节，无法确认具体问题、技术要点及实验数据。  \n建议提供论文正文，以便生成准确、完整的总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.14617","title":"UniCon: A Unified System for Efficient Robot Learning Transfers","arxivId":"2601.14617","date":"2026-01-21","authors":"Weinan Zhang Team","category":"Manipulation","summary":"本文针对异构机器人平台间学习控制器部署困难、接口不一致及中间件效率低下的核心问题，提出了统一框架UniCon。其关键技术在于：通过标准化状态与控制流，将工作流分解为可重用组件的执行图，并分离系统状态与控制逻辑；采用批处理与向量化数据流，以最小化通信开销。实验表明，与基于ROS的系统相比，UniCon在迁移工作流时减少了代码冗余，并实现了更高的推理效率，已成功部署于7家制造商的12款机器人模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.13979","title":"Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects","arxivId":"2601.13979","date":"2026-01-20","authors":"Pietro Falco Team","category":"Manipulation","summary":"本文针对严重视觉遮挡下的可变形线性物体（如电缆）3D形状重建问题，提出了一种主动跨模态视觉-触觉感知框架。方法融合基于基础模型（SAM、Florence）的视觉分割与自适应触觉探索，通过欧几里得聚类与拓扑保持融合将触觉局部点云与视觉数据合并，并采用端点引导排序的B样条插值实现完整形状重建。实验表明，该框架能在大部分遮挡情况下，准确重建简单或高度弯曲的单根/多根电缆形状，验证了跨模态感知对机器人操纵可变形物体的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.13639","title":"A General One-Shot Multimodal Active Perception Framework for Robotic Manipulation: Learning to Predict Optimal Viewpoint","arxivId":"2601.13639","date":"2026-01-20","authors":"Yongchun Fang Team","category":"Manipulation","summary":"本文提出了一种通用的单次多模态主动感知框架，用于解决机器人操作中依赖迭代优化、成本高且任务耦合性强的问题。其核心是构建数据收集流程与最优视角预测网络，通过跨注意力机制对齐融合多模态特征，直接预测相机位姿调整。在视角受限的机器人抓取任务中实例化验证，实验表明该框架显著提升了抓取成功率，真实世界评估成功率接近翻倍，且无需微调即可实现从仿真到现实的迁移。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.13042","title":"Static Is Not Enough: A Comparative Study of VR and SpaceMouse in Static and Dynamic Teleoperation Tasks","arxivId":"2601.13042","date":"2026-01-19","authors":"Kim Baraka Team","category":"Manipulation","summary":"本文针对远程操作接口评估主要关注静态任务、缺乏动态任务研究的问题，比较了VR控制器与SpaceMouse在静态与动态两类任务中的表现。研究采用组内实验设计，评估了成功率、任务时长、累积成功率及用户主观负荷。核心结论表明，VR接口在动态任务中优势显著：成功率更高，所有任务的成功执行时间更短，且用户工作负荷显著更低、可用性更高。为此，作者开源了其VR接口以填补系统空白。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.12993","title":"Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization","arxivId":"2601.12993","date":"2026-01-19","authors":"Zongqing Lu Team","category":"Manipulation","summary":"论文Being-H0.5旨在解决机器人学习中的跨具身泛化问题，即如何让单一模型适应不同形态的机器人，克服数据稀缺和形态异构的挑战。关键技术包括：构建超过35,000小时的UniHand-2.0多模态数据集；提出统一动作空间，将异构控制映射到语义对齐的槽；采用混合变换器架构，结合混合流框架解耦共享运动原语与具身特定专家；引入流形保持门控和通用异步分块提升稳健性。实验表明，该模型在模拟基准LIBERO和RoboCasa上分别达到98.9%和53.9%的性能，并在五个真实机器人平台上实现跨具身部署。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.12952","title":"Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration","arxivId":"2601.12952","date":"2026-01-19","authors":"Mingxuan Jiang Team","category":"Manipulation","summary":"本文针对航天器交会对接控制方法依赖精确动力学模型、在轨鲁棒性有限的问题，提出了一种基于模仿学习的无模型控制框架IL-SRD。其核心创新在于引入了锚定解码器目标机制，通过状态相关的锚点显式约束控制生成过程，确保物理一致性；并采用时间聚合机制来抑制Transformer序列预测中的误差累积。大量仿真实验表明，该方法能实现精确、节能的六自由度交会对接控制，并在显著未知干扰下保持优异的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.12925","title":"ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation","arxivId":"2601.12925","date":"2026-01-19","authors":"F. Richard Yu Team","category":"Manipulation","summary":"本文针对机器人操作任务中，现有扩散策略仅依赖短期观察、训练目标单一导致误差累积的问题，提出前瞻条件扩散策略（ForeDiffusion）。其核心方法是通过构建并注入预测的未来视图表示来引导扩散过程，并采用结合去噪损失与未来观测一致性损失的双损失机制进行统一优化。实验表明，该方法在Adroit和MetaWorld基准测试中平均任务成功率达到80%，在复杂任务上较主流扩散方法提升23%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.12918","title":"Dynamic Hand Gesture Recognition for Robot Manipulator Tasks","arxivId":"2601.12918","date":"2026-01-19","authors":"Laxmidhar Behera Team","category":"Manipulation","summary":"本文针对机器人操纵器任务中的动态手势识别问题，旨在解决手势识别中的精度、个体可变性和实时处理挑战。提出一种基于高斯混合模型（GMM）的无监督学习方法，通过估计多个高斯分布的参数来处理手势的动态变化和重叠类别，实现准确识别。实验结果表明，该方法在训练和实时测试中均表现出高准确性，验证了其有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.12796","title":"Contact-Aware Neural Dynamics","arxivId":"2601.12796","date":"2026-01-19","authors":"Sha Yi Team","category":"Manipulation","summary":"本文针对神经动力学模型中难以准确模拟物体间接触交互的问题，提出了一种接触感知的神经动力学方法。该方法通过神经网络架构集成接触约束，动态编码接触力与运动关系，以提升物理模拟的真实性。实验验证表明，该方法在模拟任务中能有效减少误差，增强交互的稳定性和准确性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.12428","title":"ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models","arxivId":"2601.12428","date":"2026-01-18","authors":"Xin Jin Team","category":"Manipulation","summary":"本文针对视频世界模型在机器人学习中存在的物理失真、逻辑不一致等问题，提出ReWorld框架。其核心是通过强化学习对齐世界模型的物理真实性、任务完成能力、具身合理性与视觉质量。方法上，首先构建大规模视频偏好数据集，并训练分层奖励模型以量化人类偏好；进而提出高效的对齐算法，基于PPO风格优化流程式世界模型。实验表明，ReWorld显著提升了生成视频的物理保真度、逻辑连贯性、具身性与视觉质量，优于现有方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.12397","title":"Learning Diverse Skills for Behavior Models with Mixture of Experts","arxivId":"2601.12397","date":"2026-01-18","authors":"Ziyang Meng Team","category":"Manipulation","summary":"本文针对模仿学习在多任务场景下因任务间干扰导致性能下降的问题，提出Di-BM方法。该方法采用混合专家框架，通过基于能量的模型为各专家建模特定的观测分布，使其专注于不同的技能子区域，并与对应动作模型联合训练。实验表明，Di-BM在多个真实机器人操作任务上显著优于现有基线，且预训练模型在新任务上微调时展现出更高的数据效率和知识复用能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.12116","title":"BiKC+: Bimanual Hierarchical Imitation with Keypose-Conditioned Coordination-Aware Consistency Policies","arxivId":"2601.12116","date":"2026-01-17","authors":"Jia PanI Team","category":"Manipulation","summary":"本文针对机器人双手机器人操作中双臂协调和多阶段处理的挑战，现有方法未明确考虑多阶段性质且推理速度慢。提出BiKC+分层模仿学习框架，包含高层关键姿势预测器和低层一致性模型轨迹生成器：关键姿势预测器预测子目标，轨迹生成器基于历史观测和关键姿势单步推理生成动作序列。仿真和真实实验表明，该方法在成功率和操作效率上显著优于基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.11421","title":"The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents","arxivId":"2601.11421","date":"2026-01-16","authors":"Yong-Lu Li Team","category":"Manipulation","summary":"本文针对当前机器人学习数据集中任务设计单一、缺乏系统性，导致模型评估不全面、难以公平比较的问题，提出了名为“Great March 100”的评估基准。其核心技术方法是基于对现有任务设计的系统分析与扩展，并结合人-物交互原语和物体可供性的洞见，精心设计了100个覆盖广泛交互和长尾行为的多样化任务。实验结果表明，GM-100中的任务不仅具备可执行性，而且具有足够的挑战性，能够有效区分当前各类视觉语言动作模型的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.11394","title":"The Mini Wheelbot Dataset: High-Fidelity Data for Robot Learning","arxivId":"2601.11394","date":"2026-01-16","authors":"Sebastian Trimpe Team","category":"Manipulation","summary":"本文针对学习型控制算法开发缺乏高质量真实世界数据的问题，提出了面向Mini Wheelbot开源平衡机器人的高保真数据集。该数据集以1kHz频率同步提供机载传感器读数、状态估计、运动捕捉真值及视频日志，并通过伪随机二进制激励、非线性模型预测控制与强化学习等多种控制策略，在多个硬件实例和不同表面上采集数据，确保了数据的多样性。数据集支持动力学模型学习、状态估计等算法的基准测试，为不具备实体机器人的研究者提供了可复现的高质量实验平台。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.11269","title":"X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning","arxivId":"2601.11269","date":"2026-01-16","authors":"Huazhe Xu Team","category":"Manipulation","summary":"本文提出X-Distill方法，旨在解决机器人视觉运动策略中数据稀缺场景下，大型视觉Transformer（ViT）难以优化而紧凑CNN泛化能力不足的问题。其核心技术是通过跨架构知识蒸馏，在通用ImageNet数据集上，将冻结的大型DINOv2教师模型的视觉表征迁移至紧凑的ResNet-18学生模型，随后将该编码器与扩散策略头在目标任务上联合微调。实验表明，该方法在34个模拟基准和5个真实任务上，性能均优于从头训练的ResNet、微调的DINOv2，甚至超过了使用点云或更大视觉语言模型的编码器，实现了数据高效的高性能操作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.11266","title":"Skill-Aware Diffusion for Generalizable Robotic Manipulation","arxivId":"2601.11266","date":"2026-01-16","authors":"Wei Zhang Team","category":"Manipulation","summary":"本文针对机器人操作中因忽略技能层面信息导致的泛化能力受限问题，提出Skill-Aware Diffusion（SADiff）方法。该方法通过技能感知编码模块学习技能特定表示，并利用技能约束扩散模型生成以物体为中心的运动流；进一步通过技能检索转换策略，利用轨迹先验将2D运动流细化为可执行3D动作。实验在模拟与真实环境中进行，结果表明SADiff在各种操作任务中实现了良好的性能与泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.10781","title":"Future Optical Flow Prediction Improves Robot Control & Video Generation","arxivId":"2601.10781","date":"2026-01-15","authors":"Juan Carlos Niebles Team","category":"Manipulation","summary":"本文提出FOFPred模型，旨在解决语言条件下、可泛化的未来光流预测难题，以提升机器人控制与视频生成能力。核心方法采用统一的视觉语言模型与扩散架构，结合大规模网络视频-文本数据训练，通过关键的数据预处理与图像预训练从噪声数据中提取有效信号。实验表明，该模型在语言驱动的机器人操控和视频生成任务中均表现出优异的跨领域适应性，验证了统一架构及从多样网络数据中学习的价值。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.09920","title":"SyncTwin: Fast Digital Twin Construction and Synchronization for Safe Robotic Grasping","arxivId":"2601.09920","date":"2026-01-14","authors":"Jiachen Li Team","category":"Manipulation","summary":"本文提出SyncTwin框架，旨在解决动态且视觉遮挡环境下机器人抓取的安全与准确性问题。核心技术包括：1）离线阶段，使用VGGT从RGB图像快速重建物体级3D资产，构建可复用的几何库；2）在线阶段，通过点云分割跟踪物体状态，并采用colored-ICP配准实现真实场景与数字孪生的实时同步。实验表明，该方法在动态遮挡场景中有效提升了抓取准确性与运动安全性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.09605","title":"Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets","arxivId":"2601.09605","date":"2026-01-14","authors":"Zsolt Kira Team","category":"Manipulation","summary":"本文针对机器人视觉策略对相机视角变化敏感、真实数据稀缺且视角单一的问题，提出MANGO方法：一种基于非配对图像翻译的技术，通过引入分割条件InfoNCE损失、高度正则化判别器及改进的PatchNCE损失，保持仿真到真实转换时的视角一致性。仅需少量固定视角真实数据，该方法能生成多样化的未知视角仿真图像。实验表明，经MANGO数据增强训练的模仿学习策略，在原始策略完全失败的视角上成功率可达60%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.09518","title":"Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations","arxivId":"2601.09518","date":"2026-01-14","authors":"Wei-Shi Zheng Team","category":"Manipulation","summary":"该论文旨在解决人形机器人如何从人类-人类交互演示中学习自然、高效的全身交互行为这一核心问题。关键技术方法基于模仿学习框架，通过采集人类交互的运动捕捉数据，提取全身运动特征并迁移到机器人控制策略中。实验表明，该方法能有效提升机器人模仿复杂交互动作的能力，增强交互自然度和任务成功率，具体性能提升数据需参考论文正文。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.09031","title":"Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation","arxivId":"2601.09031","date":"2026-01-13","authors":"Miao Li Team","category":"Manipulation","summary":"本文针对人形机器人操作中精确场景理解与样本高效学习两大挑战，提出RGMP-S框架。其核心技术包括：利用轻量级2D几何先验构建长时域几何先验技能选择器，实现语义指令与空间约束的精准对齐；设计递归自适应脉冲网络，通过递归脉冲参数化机器人-物体交互，以提取长时域动态特征并缓解稀疏演示下的过拟合问题。实验在Maniskill仿真与三种异构真实机器人平台上验证了方法的优越性，性能较基线提升19%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.08731","title":"Learning from Demonstrations via Capability-Aware Goal Sampling","arxivId":"2601.08731","date":"2026-01-13","authors":"He Zhu Team","category":"Manipulation","summary":"本文解决模仿学习在长视野任务中因依赖完美复制专家轨迹而导致的脆弱性和错误累积问题。提出了能力感知目标采样（Cago）方法，其核心是通过动态评估智能体在专家轨迹上的当前能力，自适应地选择略超出其能力的中间目标作为学习指引，从而形成渐进式课程。实验表明，Cago在多个稀疏奖励的目标条件任务中，显著提升了样本效率和最终性能，优于现有基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.08665","title":"VLingNav: Embodied Navigation with Adaptive Reasoning and Visual-Assisted Linguistic Memory","arxivId":"2601.08665","date":"2026-01-13","authors":"Junzhi Yu Team","category":"Manipulation","summary":"本文提出VLingNav模型，旨在解决现有视觉-语言-动作（VLA）模型在具身导航中缺乏显式推理与持久记忆、难以处理复杂长视野任务的问题。其核心技术包括：1）自适应思维链（AdaCoT）机制，动态触发显式推理，实现直觉执行与深思规划的灵活切换；2）视觉辅助语言记忆模块（VLingMem），构建跨模态语义记忆以回顾历史观测、推断环境动态。实验表明，VLingNav在多个具身导航基准上达到SOTA性能，并能零样本迁移至真实机器人，成功执行未见过的导航任务，展现出强大的跨领域泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.08325","title":"ActiveVLA: Injecting Active Perception into Vision-Language-Action Models for Precise 3D Robotic Manipulation","arxivId":"2601.08325","date":"2026-01-13","authors":"Yanwei Fu Team","category":"Manipulation","summary":"本文提出了ActiveVLA框架，旨在解决现有视觉-语言-动作模型依赖静态、末端执行器视角，缺乏主动感知能力，从而限制其在长时程和精细操作任务中性能的问题。其关键技术采用从粗到精的两阶段范式：首先进行关键3D区域定位，然后通过主动视角选择和3D放大进行感知优化。实验表明，该方法在三个仿真基准上超越了先进基线，并能迁移到现实场景中实现高精度操作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.07823","title":"Video Generation Models in Robotics – Applications, Research Challenges, Future Directions","arxivId":"2601.07823","date":"2026-01-12","authors":"Anirudha Majumdar Team","category":"Manipulation","summary":"本文综述了视频生成模型在机器人学中的应用、挑战与未来方向。核心问题是利用视频模型作为具身世界模型，通过高保真视频合成捕捉细粒度机器人-环境交互，以克服传统物理模拟器的局限。关键技术包括基于扩散和流匹配的视频生成模型，应用于低成本数据生成、模仿学习的动作预测、强化学习的动态建模以及视觉规划。论文指出当前挑战包括指令跟随差、物理违规幻觉和不安全内容生成，需未来研究解决以推动安全关键场景的应用。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.07060","title":"PALM: Progress-Aware Policy Learning via Affordance Reasoning for Long-Horizon Robotic Manipulation","arxivId":"2601.07060","date":"2026-01-11","authors":"Ismini Lourentzou Team","category":"Manipulation","summary":"本文提出PALM方法，旨在解决长视野机器人操作任务中的核心挑战，即如何有效处理多步骤、复杂的操作规划与执行。通过结合进度感知的策略学习和可负担推理，PALM能够自适应地跟踪任务进度，并利用物体提供的功能（affordance）进行智能决策，以优化操作序列。关键技术包括进度感知机制和affordance推理模块，帮助机器人动态调整策略。然而，由于正文内容未提供，具体实验结论和性能提升数据无法在此总结，建议参考原文获取详细信息。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.06748","title":"On-the-Fly VLA Adaptation via Test-Time Reinforcement Learning","arxivId":"2601.06748","date":"2026-01-13","authors":"Cheng Han Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型在动态、未见环境中适应性有限的核心问题，提出了一种测试时强化学习框架TT-VLA。该方法的关键在于：在模型推理阶段，利用基于逐步任务进度的密集奖励机制，在线实时优化动作策略，同时保留监督微调/强化学习训练的先验知识。实验表明，该方法在模拟和真实世界的动态场景中，有效提升了模型的整体适应性、稳定性和任务成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.06451","title":"CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method","arxivId":"2601.06451","date":"2026-01-10","authors":"Heewon Kim Team","category":"Manipulation","summary":"本文针对食物切割任务中刀具与可变形材料交互复杂、难以安全收集大规模数据的问题，提出了CulinaryCut-VLAP框架。其核心技术是构建了一个基于物质点法（MPM）的物理模拟器，采用MLS-MPM核心以减少数值耗散，并通过粒子-网格冲量交换来估计瞬态接触力与能量传递。同时，该框架集成了包含多视角视觉、语言指令与力-位姿标签的基准数据集。实验表明，该框架建立了一个尊重切割核心物理、安全且可扩展的学习-评估闭环，为推进可变形物体操纵的视觉-语言-动作模型提供了基础。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.05836","title":"Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning","arxivId":"2601.05836","date":"2026-01-09","authors":"Jyh-Horng Wu Team","category":"Manipulation","summary":"本文针对UR10机械臂路径规划中的奇异性规避问题，提出了一种混合模糊逻辑与强化学习的智能方法。该方法利用模糊逻辑系统处理运动学不确定性并嵌入专家规则，同时结合强化学习（如深度Q网络）在线优化避奇异决策策略。核心实验表明，该混合策略能有效识别并规避奇异位形，在复杂任务中比传统方法路径成功率提升约18%，且关节运动平滑性显著改善。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.05499","title":"TOSC: Task-Oriented Shape Completion for Open-World Dexterous Grasp Generation from Partial Point Clouds","arxivId":"2601.05499","date":"2026-01-09","authors":"Zhiping Cai Team","category":"Manipulation","summary":"本文针对严重部分观测下开放世界物体的任务导向灵巧抓取生成问题，提出**任务导向形状补全**新任务，专注于补全潜在接触区域而非完整物体形状。方法首先利用多个预训练基础模型的零样本能力生成多个任务导向形状补全候选，然后提出**3D判别自编码器**评估并全局优化最合理的候选，最后开发**条件流匹配模型FlowGrasp**从优化形状生成抓取。实验表明，该方法在任务导向抓取和形状补全上达到最先进性能，将抓取位移和倒角距离指标分别提升16.17%和55.26%，并能有效处理严重数据缺失的物体。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.05491","title":"Assembling Solar Panels by Dual Robot Arms Towards Full Autonomous Lunar Base Construction","arxivId":"2601.05491","date":"2026-01-09","authors":"Kazuya Yoshida Team","category":"Manipulation","summary":"本文针对月球基地建设中太阳能电池板自主组装的核心问题，提出了一套面向双机械臂机器人系统的集成方案。关键技术包括：采用YOLOv8.1模型进行太阳能板定向检测的感知模块，以及整合视觉数据与经典控制方法的控制流程，并设计了专用的模块化面板与连接器硬件。实验成功验证了该系统能使双机械臂有效连接任意放置的面板，实现了视觉、控制与硬件在复杂空间任务中的无缝集成。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.05383","title":"Imitation Learning for Combinatorial Optimisation under Uncertainty","arxivId":"2601.05383","date":"2026-01-08","authors":"Louis-Martin Rousseau Team","category":"Manipulation","summary":"本文针对不确定环境下组合优化的模仿学习（IL），核心是系统研究专家策略生成这一关键环节。论文提出了一个专家分类框架，从**不确定性处理方式**（如短视、确定性、多阶段随机）、**最优性水平**和**与学习器的交互模式**三个维度对专家进行刻画。基于此，作者提出了一个支持多专家查询与聚合的**广义DAgger算法**。在一个动态医生分配问题的实验中验证发现：**从随机专家学习的策略性能优于确定性和完全信息专家**；**交互式学习能以更少的专家演示获得更优解**；当随机优化计算困难时，**聚合的确定性专家是有效的替代方案**。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.05336","title":"Intent at a Glance: Gaze-Guided Robotic Manipulation via Foundation Models","arxivId":"2601.05336","date":"2026-01-08","authors":"Yuchen Cui Team","category":"Manipulation","summary":"本文旨在解决机器人控制界面不够直观的问题，特别是在辅助护理场景中。作者提出gamma系统，通过结合自我中心视线跟踪和视觉语言模型，将用户的视线注视点映射为场景上下文，从而推断用户意图并自主执行机器人操作任务。该方法无需针对特定任务进行训练。实验在桌面操作任务上评估表明，gamma相比无推理能力的基线视线控制，能提供更鲁棒、直观且可泛化的控制。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.05248","title":"LaST $_{0}$ : Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model","arxivId":"2601.05248","date":"2026-01-08","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"本文针对机器人视觉-语言-动作模型中显式推理导致的高延迟和语言表示瓶颈问题，提出LaST0框架。其核心是潜在时空思维链，在隐式空间建模未来视觉动态、3D结构及本体状态，并采用混合Transformer的双系统架构，协调低频推理与高频动作生成。在10个真实世界任务中，LaST0相比先前方法将平均成功率提升13%、14%和14%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.05241","title":"RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation","arxivId":"2601.05241","date":"2026-01-08","authors":"Jiangmiao Pang Team","category":"Manipulation","summary":"本文针对机器人操作数据收集困难且现有生成方法难以满足多视图、时序连贯需求的问题，提出RoboVIP框架。其核心是**视觉身份提示**技术，通过提供示例图像作为条件输入，引导扩散模型生成指定场景设置的多视角连贯视频，并构建了从大型数据集中整理视觉身份池的流程。使用该框架增强的数据训练下游策略模型，在仿真和真实机器人实验中均带来了持续的性能提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.04629","title":"UniBiDex: A Unified Teleoperation Framework for Robotic Bimanual Dexterous Manipulation","arxivId":"2601.04629","date":"2026-01-08","authors":"Peng Zhou Team","category":"Manipulation","summary":"本文针对现有遥操作系统在双手灵巧操作中缺乏协调控制、安全机制和力反馈的问题，提出了统一遥操作框架UniBiDex。该框架支持VR与主从两种输入模式，通过集成异构设备到统一控制栈，并采用零空间控制优化双臂配置，确保运动平滑、无碰撞且能感知奇异点。在一个包含五个子任务的长期厨房整理实验中，UniBiDex相比强基线实现了更高的任务成功率、更平滑的运动轨迹和更强的鲁棒性。框架硬件与软件均已开源。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.04194","title":"Choreographing a World of Dynamic Objects","arxivId":"2601.04194","date":"2026-01-07","authors":"Jiajun Wu Team","category":"Manipulation","summary":"本文针对机器人在非结构化动态环境（如家庭、办公室）中操作物体的问题，提出了一种综合感知、推理与动作规划的框架。核心方法结合视觉感知模块与动态图神经网络（DGNN），实时检测物体并建模其状态及交互关系，进而生成机器人动作序列。实验表明，该系统能有效完成如物体重新排列等复杂任务，在模拟环境中显著提升了任务成功率和效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.04137","title":"Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test","arxivId":"2601.04137","date":"2026-01-07","authors":"Jian Tang Team","category":"Manipulation","summary":"本文针对具身AI中视频基础模型作为世界模型的两个核心问题：生成保真度能否满足人类感知、以及模型能否作为现实具身智能体的通用稳健先验。为此，作者提出了**WoW-World-Eval** 基准测试，基于609个机器人操作数据，从感知、规划、预测、泛化、执行五个维度，通过22项指标进行全面评估。实验表明，现有模型在长时程规划（得分17.27）和物理一致性（最高68.02）上表现有限；在逆向动态模型图灵测试中，多数模型成功率接近0%，而WoW模型保持了40.74%的成功率，揭示了生成视频与现实世界之间存在显著差距。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.03782","title":"PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation","arxivId":"2601.03782","date":"2026-01-07","authors":"Li Fei-Fei Team","category":"Manipulation","summary":"本文提出PointWorld，一个用于开放世界机器人操作的大规模预训练3D世界模型。核心问题是让机器人仅凭单张或少量的RGB-D图像与低级动作指令，预测环境在3D空间中对动作的响应。关键技术是将状态与动作统一表示为3D点流，从而直接关联机器人物理几何并支持跨平台学习。模型在包含约200万轨迹、500小时的真实与仿真数据上训练，具备0.1秒的实时推理速度。实验表明，单一预训练模型无需微调或演示，即可让真实Franka机器人完成刚体推动、可变形物体操作及工具使用等多种任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.03200","title":"A High-Fidelity Digital Twin for Robotic Manipulation Based on 3D Gaussian Splatting","arxivId":"2601.03200","date":"2026-01-06","authors":"Chengxu Zhou Team","category":"Manipulation","summary":"本文提出了一种基于3D高斯泼溅（3DGS）的高保真数字孪生框架，旨在解决机器人操作中场景重建速度慢、视觉保真度有限以及逼真模型难以转换为规划可用碰撞几何体的核心问题。关键技术包括：采用3DGS进行快速逼真重建，通过可见性感知语义融合实现3D语义标注，并提出一种基于滤波的高效几何转换方法，生成可直接用于物理仿真的碰撞模型。实验在Franka Emika Panda机器人上进行拾取放置任务验证，结果表明该框架能有效支持真实世界的稳健操作，显著缩小了仿真与现实的差距。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.03044","title":"SOP: A Scalable Online Post-Training System for Vision-Language-Action Models","arxivId":"2601.03044","date":"2026-01-06","authors":"Jianlan Luo Team","category":"Manipulation","summary":"本文提出可扩展在线后训练系统SOP，解决视觉-语言-动作（VLA）模型在现实部署中缺乏专家级任务熟练度的问题。现有方法多为离线、单机器人或任务特定，限制了在线策略适应和可扩展学习。SOP采用在线分布式多任务后训练，通过闭环架构让机器人舰队持续流式传输经验至云端学习器，并异步接收更新策略，实例化交互式模仿学习（HG-DAgger）和强化学习（RECAP）。实验表明，在布料折叠、盒子组装等现实任务中，SOP显著提升VLA模型性能，保持跨任务共享策略，后训练仅需数小时，且性能随机器人数量近线性扩展。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.02456","title":"InternVLA-A1: Unifying Understanding, Generation and Action for Robotic Manipulation","arxivId":"2601.02456","date":"2026-01-05","authors":"Yuchen Zhu Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型缺乏物理动态推理能力，而世界模型又缺乏语义基础的问题，提出InternVLA-A1模型。该模型采用统一的混合Transformer架构，集成了场景理解、视觉预见生成和动作执行三个专家模块。通过在混合合成-真实数据集上预训练，模型在12个真实机器人任务中表现优异，日常任务性能提升14.5%，动态场景（如传送带分拣）性能提升40%至73.3%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.02078","title":"Genie Sim 3.0 : A High-Fidelity Comprehensive Simulation Platform for Humanoid Robot","arxivId":"2601.02078","date":"2026-01-05","authors":"Maoqing Yao Team","category":"Manipulation","summary":"本文针对机器人学习模型依赖大规模真实数据、而现有仿真平台存在碎片化与保真度不足的问题，提出了高保真综合仿真平台Genie Sim 3.0。其核心技术包括：1）Genie Sim Generator，利用大语言模型（LLM）根据自然语言指令快速生成多样化高保真仿真场景；2）首创基于LLM的自动评估基准，通过LLM批量生成评估场景，并借助视觉语言模型（VLM）建立自动化评估流程。平台发布了包含超10,000小时合成数据的开源数据集。实验表明，该数据集支持高效的零样本仿真到现实迁移，验证了合成数据在可控条件下可有效替代真实数据用于策略训练。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.01948","title":"Learning Diffusion Policy from Primitive Skills for Robot Manipulation","arxivId":"2601.01948","date":"2026-01-05","authors":"Dong Xu Team","category":"Manipulation","summary":"本文针对机器人操作中扩散策略依赖全局指令导致动作生成不对齐的问题，提出技能条件扩散策略SDP。该方法将复杂任务分解为“上移”“开爪”等八个可重用基础技能序列，通过视觉语言模型提取观测与指令的离散表示，并设计轻量路由器网络为每个状态分配单一技能，从而构建技能对齐的动作生成策略。实验表明，SDP在两个仿真基准和真实机器人部署中均优于现有方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.01618","title":"Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation","arxivId":"2601.01618","date":"2026-01-04","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"本文针对长时程机器人操作中现有视觉-语言-动作（VLA）策略依赖纯文本、意图隐式、难以在复杂动态场景中实现空间指代与任务分解的问题，提出Action-Sketcher框架。其核心技术是引入“视觉草图”作为中间表示，在机器人视图中绘制点、框、箭头等几何元素以显式表达空间意图，并采用See→Think→Sketch→Act的循环工作流，结合自适应令牌门控策略协调推理、草图修订与动作生成。实验表明，该方法在杂乱场景与多物体任务中提升了长时程任务成功率，增强了对动态场景变化的鲁棒性，并通过可编辑草图提高了系统的可解释性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.01438","title":"Online Estimation and Manipulation of Articulated Objects","arxivId":"2601.01438","date":"2026-01-04","authors":"Sethu Vijayakumar Team","category":"Manipulation","summary":"本文研究服务机器人对未知关节物体的在线估计与操作问题。提出一种融合视觉先验与本体感知的因子图估计方法：首先通过视觉预测关节类型，随后在操作过程中基于螺旋理论分析模型，实时融合运动学与力传感数据更新估计。实验表明，该方法能使机器人在真实场景中自主打开未见过的抽屉，对未知关节物体的操作成功率达到75%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.00969","title":"Value Vision-Language-Action Planning & Search","arxivId":"2601.00969","date":"2026-01-02","authors":"Cyrus Neary Team","category":"Manipulation","summary":"论文针对Vision-Language-Action (VLA)模型在机器人操作中因依赖行为克隆而导致的分布偏移脆弱性问题，提出Value Vision-Language-Action Planning and Search (V-VLAPS)框架。该方法通过为蒙特卡洛树搜索(MCTS)添加轻量级可学习价值函数，在固定VLA骨干(Octo)的潜在表示上训练多层感知机(MLP)，提供明确的成功信号以引导动作选择。实验在LIBERO机器人操作套件上表明，该方法将成功率提升超过5个百分点，同时平均MCTS模拟次数减少5–15%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.00675","title":"RoboReward: General-Purpose Vision-Language Reward Models for Robotics","arxivId":"2601.00675","date":"2026-01-08","authors":"Chelsea Finn Team","category":"Manipulation","summary":"论文《RoboReward: General-Purpose Vision-Language Reward Models for Robotics》旨在解决机器人领域奖励设计复杂、缺乏通用性的核心问题。关键技术为RoboReward模型，通过融合视觉和语言信息构建自适应奖励函数，以提升机器人学习的泛化能力。由于正文内容未提供，具体实验结论如性能提升数据需参考原文，但标题暗示该方法可能优化任务完成效率或跨场景适应性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.00452","title":"Imitation from Observations with Trajectory-Level Generative Embeddings","arxivId":"2601.00452","date":"2026-01-01","authors":"Weitong Zhang Team","category":"Manipulation","summary":"本文研究离线观察模仿学习（LfO）的核心挑战：专家轨迹稀缺且仅含状态观测，而离线次优数据与专家行为分布差异大。为解决该问题，提出轨迹级生成嵌入（TGE）方法：通过在时间扩散模型的潜在空间中最大化专家轨迹的对数似然，利用基于粒子的熵估计构建密集平滑的代理奖励，从而捕捉长期时序动态并弥合分布差异。实验表明，该方法在D4RL运动与操作基准测试中一致匹配或优于现有离线LfO方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2601.00126","title":"Compositional Diffusion with Guided Search for Long-Horizon Planning","arxivId":"2601.00126","date":"2026-01-05","authors":"Danfei Xu Team","category":"Manipulation","summary":"本文针对组合生成模型在长时程规划中面临的“模式平均”问题，提出组合扩散引导搜索方法。该方法在扩散去噪过程中嵌入搜索，通过种群采样探索局部模式的多样组合，利用迭代重采样保证全局一致性，并用似然过滤修剪不可行路径。在七个机器人操作任务上，CDGS达到了与真实数据相当的性能，优于缺乏组合性或需长时程训练数据的基线方法，并能泛化至全景图像生成长视频生成领域。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.25072","title":"Coordinated Humanoid Manipulation with Choice Policies","arxivId":"2512.25072","date":"2025-12-31","authors":"Jitendra Malik Team","category":"Manipulation","summary":"本文针对人形机器人在非结构化环境中实现头、手、腿全身协调操作的挑战，提出了一种结合模块化遥操作界面和Choice Policy学习框架的系统。遥操作界面将控制分解为手眼协调、抓取原语等子模块，以高效收集高质量演示；Choice Policy通过生成并评分候选动作，实现快速推理和多模态行为建模。实验在洗碗机装载和白板擦拭任务中表明，该方法性能显著优于扩散策略和标准行为克隆，并验证了手眼协调对长期任务成功的关键作用。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.24766","title":"Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow","arxivId":"2512.24766","date":"2025-12-31","authors":"Ruohan Zhang Team","category":"Manipulation","summary":"由于您未提供论文正文内容，我无法基于实际研究内容撰写总结。若您能提供正文，我将很乐意协助。\n\n为清晰说明，若论文内容如下所示，总结将按此框架撰写：\n\n**假设正文提及：**\n* 核心问题：现有视频生成模型难以在开放世界中实现对特定物体的精准、连贯操控。\n* 方法：提出Dream2Flow框架，首先生成多视角3D对象流以建立空间连贯性，再以此引导视频的时序生成。\n* 实验：在开放世界操控基准测试中，Dream2Flow在动作准确性和视觉连贯性上比基线模型（如Gen2）提升约15%。\n\n**则可生成总结：**\n本文针对开放世界视频操控中物体运动不连贯、不精准的核心问题，提出Dream2Flow框架。其关键技术是通过生成多视角3D对象流来建模物体的空间运动轨迹，并以此引导视频的时序生成。实验表明，该方法在操控准确性和视觉连贯性上相比基线模型提升显著（约15%），有效 bridging 了视频生成与复杂物体操控。\n\n请您提供论文正文，我将为您生成精准总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.24653","title":"RoboMIND 2.0: A Multimodal, Bimanual Mobile Manipulation Dataset for Generalizable Embodied Intelligence","arxivId":"2512.24653","date":"2026-01-06","authors":"Jian Tang Team","category":"Manipulation","summary":"本文针对现有具身智能数据集规模有限、缺乏多模态感知与双手机器人协同操作能力的问题，提出了RoboMIND 2.0数据集。该数据集核心构建方法是通过移动操作平台搭载双灵巧手，在真实家庭场景中采集包含视觉、触觉、语言指令等多模态数据的大规模人机交互序列。实验表明，数据集包含超过10万条交互数据，覆盖60余类日常操作任务；基于该数据训练的模型在任务泛化性和操作成功率上相比单模态或单手臂基线有显著提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.24638","title":"Resolving State Ambiguity in Robot Manipulation via Adaptive Working Memory Recoding","arxivId":"2512.24638","date":"2025-12-31","authors":"Wenchao Ding Team","category":"Manipulation","summary":"本文针对机器人操作中普遍存在的状态模糊性问题，即相同观测可能对应多个有效行为轨迹，提出PAM方法。该方法通过自适应工作记忆重编码技术，采用分层帧特征提取器生成运动基元与时序消歧表示，并利用上下文路由器压缩历史信息。实验表明，PAM在约10秒（300帧）的历史窗口下，能稳定训练并保持20Hz以上的推理速度，有效处理多种状态模糊场景。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.24428","title":"Subsecond 3D Mesh Generation for Robot Manipulation","arxivId":"2512.24428","date":"2025-12-30","authors":"Daniel Rakita Team","category":"Manipulation","summary":"本文针对机器人操作中3D网格生成的两大挑战：生成高保真网格速度慢（通常需数十秒）且缺乏上下文接地（即正确分割与姿态注册），提出一个端到端系统。该系统集成开放词汇对象分割、加速基于扩散的网格生成和鲁棒点云注册，从单张RGB-D图像在1秒内生成高质量、上下文接地的网格。实验表明，该系统能有效应用于真实操作任务，实现网格作为实时感知与规划的实用表示。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.24288","title":"Real-world Reinforcement Learning from Suboptimal Interventions","arxivId":"2512.24288","date":"2025-12-30","authors":"Jian Tang Team","category":"Manipulation","summary":"本文针对现实世界强化学习中人类干预次优且有噪声的问题，提出SiLRI算法。该方法将在线操作任务建模为约束强化学习优化，约束边界由人类干预的不确定性决定，并引入状态-wise拉格朗日乘子，通过min-max优化联合学习策略与乘子。实验表明，SiLRI能有效利用次优干预，相比先进方法HIL-SERL，达到90%成功率所需时间减少至少50%，并在长时域任务中实现100%成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.24272","title":"Local Path Optimization in The Latent Space Using Learned Distance Gradient","arxivId":"2512.24272","date":"2025-12-30","authors":"Jifeng Guo Team","category":"Manipulation","summary":"本文针对机器人受约束运动规划中，基于流形近似的潜在空间方法存在近似误差、难以精准识别碰撞冲突，导致路径有效性检查与重规划耗时的问题，提出一种在潜在空间中进行局部路径优化的方法。关键技术包括：训练神经网络以潜在向量输入预测机器人与障碍物的最小距离，利用学习到的距离梯度计算潜在空间中的避障移动方向，并将该优化过程与路径检查结合以减少重规划时间。实验表明，该方法在多种规划场景中相比现有算法实现了最快的规划速度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.24210","title":"GR-Dexter Technical Report","arxivId":"2512.24210","date":"2025-12-30","authors":"Hang Li Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型难以扩展到高自由度双手机器人灵巧手操控的难题，提出了GR-Dexter整体框架。其核心方法包括：设计紧凑的21自由度灵巧手、基于头显与数据手套的直观遥操作数据采集系统，以及融合遥操作机器人轨迹、视觉-语言数据和跨体现数据等多种数据源的协同训练方案。实验表明，该框架在真实世界的长周期日常操作和泛化拾放任务中取得了优异性能，并对未见过的物体与指令展现出更强的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.24125","title":"Unified Embodied VLM Reasoning with Robotic Action via Autoregressive Discretized Pre-training","arxivId":"2512.24125","date":"2026-01-01","authors":"Jianlan Luo Team","category":"Manipulation","summary":"本文针对通用机器人系统在开放世界中需同时实现广泛泛化和高精度动作执行的核心难题，提出ERIQ基准以解耦评估具身推理能力，并引入FACT动作标记器，基于流匹配将连续控制离散化为高保真轨迹序列。所构建的GenieReasoner模型通过统一自回归预训练联合优化推理与动作，实验表明其在ERIQ基准上准确率提升41%，重建误差显著降低，在真实机器人操作任务中优于连续和离散动作基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.23703","title":"Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation","arxivId":"2512.23703","date":"2025-12-29","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"本文针对强化学习在机器人操作中奖励函数设计困难的核心问题，提出Robo-Dopamine方法。现有过程奖励模型缺乏步进感知、依赖单视角，导致细粒度评估不可靠，且奖励塑造理论不健全。关键技术包括：通用奖励模型（GRM），通过步进奖励离散化和多视角融合提升准确性；以及Dopamine-RL框架，采用策略不变奖励塑造避免语义陷阱。实验表明，GRM奖励评估达到最先进水平；Dopamine-RL仅用150次在线交互（约1小时）将策略成功率从近零提升至95%，并保持强泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.23616","title":"Interactive Robot Programming for Surface Finishing via Task-Centric Mixed Reality Interfaces","arxivId":"2512.23616","date":"2025-12-29","authors":"Dongheui Lee Team","category":"Manipulation","summary":"本文针对表面精加工任务中，机器人编程依赖专家、设置繁琐的核心问题，提出一种面向非专家的交互式编程方法。关键技术包括：结合人工输入的新型表面分割算法以识别并优化待处理区域，以及基于分割模型自动生成机器人轨迹。通过两项用户研究评估，该任务为中心的混合现实界面显著降低了用户工作量，提升了可用性，使缺乏经验的用户也能有效完成编程。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.23541","title":"Act2Goal: From World Model To General Goal-conditioned Policy","arxivId":"2512.23541","date":"2025-12-29","authors":"Jianlan Luo Team","category":"Manipulation","summary":"本文针对现有视觉目标条件策略在长时程操作中因缺乏任务进展显式建模而性能不佳的问题，提出Act2Goal方法。其核心是整合目标条件视觉世界模型与多尺度时间控制：世界模型预测中间视觉状态序列，多尺度时间哈希（MSTH）技术将其分解为用于细粒度控制的密集近端帧和保证全局一致性的稀疏远端帧，并通过交叉注意力与运动控制耦合。真实机器人实验表明，该方法在分布外任务上实现了零样本强泛化，通过在线自适应，成功率在数分钟内从30%显著提升至90%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.23505","title":"Robust Deep Learning Control with Guaranteed Performance for Safe and Reliable Robotization in Heavy-Duty Machinery","arxivId":"2512.23505","date":"2025-12-29","authors":"Mehdi Heydari Shahna Team","category":"Manipulation","summary":"本文针对重型机械电动化与自主化转型中的控制难题，提出一种保证性能的鲁棒深度学习控制框架。核心方法是采用独立于能源的通用模块化设计降低控制复杂度，并构建分层控制策略，在部分集成AI技术时严格保证安全性能与系统稳定性。研究重点包括开发适用于多体重型机械的通用鲁棒控制、在不确定性与故障下维持预设性能的方案，以及提升学习策略的可解释性与可信度。由于提供的正文节选不包含实验部分，此处无法给出具体的性能提升数据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.23312","title":"Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation: A Comparative Analysis of IKNet Variants","arxivId":"2512.23312","date":"2025-12-29","authors":"Po-Chiang Lin Team","category":"Manipulation","summary":"该论文针对障碍感知机器人操作中的逆运动学问题，提出可解释的神经方法IKNet，并对其变体进行对比分析。核心问题是解决传统逆运动学在复杂环境中处理障碍物时缺乏可解释性的挑战。关键技术方法基于IKNet神经网络，通过比较不同变体（如架构调整或可解释性模块）来优化性能。实验结论显示，通过比较分析，某些IKNet变体在操作精度或计算效率上表现更优，但具体提升数据需参考正文内容。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.23162","title":"SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling","arxivId":"2512.23162","date":"2025-12-30","authors":"Daguang Xu Team","category":"Manipulation","summary":"本文旨在解决手术机器人因缺乏带动作标签的配对视频-动作数据而难以训练自主策略的核心问题。为此，研究构建了带详细文本标注的手术视频数据集SATA，并基于先进世界模型Cosmos2.5开发了SurgWorld，用以生成高质量、可泛化的合成手术视频。关键创新在于首次引入逆动力学模型，从合成视频中推断伪运动学数据，从而生成大量合成配对数据用于训练。实验表明，利用此增强数据训练的手术VLA策略，在真实机器人平台上的性能显著优于仅使用真实演示数据训练的模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.22983","title":"Embodied Robot Manipulation in the Era of Foundation Models: Planning and Learning Perspectives","arxivId":"2512.22983","date":"2025-12-28","authors":"Badong Chen Team","category":"Manipulation","summary":"本文是一篇综述，核心探讨如何在基础模型时代提升机器人操作能力。论文从算法视角，将学习型方法统一抽象为**高层规划**与**低层控制**两大层面。高层规划扩展了任务规划的概念，强调对**语言、代码、运动、功能可供性和3D表示**的推理，以支持结构化、长周期的决策。低层控制则从**输入建模、潜在表示学习和策略学习**三个维度，对基于学习的控制范式进行了分类梳理。论文的主要贡献在于为机器人操作的基础模型设计空间提供了一个清晰的分析框架，并指出了可扩展性、数据效率等未来挑战。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.22854","title":"ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning","arxivId":"2512.22854","date":"2025-12-28","authors":"Hao Zhang Team","category":"Manipulation","summary":"根据您提供的论文标题《ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning》，若要撰写精准总结，需要论文正文中关于**方法细节、实验设置与量化结果**的具体内容。\n\n目前仅基于标题可推断的框架如下：\n*   **核心问题**：解决生成几何一致、自然逼真的人与物体交互（HOI）图像或视频的挑战。\n*   **关键技术**：提出“ByteLoom”系统，核心是**渐进式课程学习**策略，可能分阶段学习人体姿态、物体操控及复杂交互。\n*   **实验结论**：需正文提供，通常涉及在HOI数据集上对比现有方法，在**几何一致性、图像质量**等指标上取得提升（例如，FID、IoU指标的改进百分比）。\n\n**请您提供论文正文，我可以立即为您生成准确、完整的总结。**","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.22824","title":"TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning","arxivId":"2512.22824","date":"2025-12-28","authors":"Laxmidhar Behera Team","category":"Manipulation","summary":"本文提出TEACH方法，解决强化学习智能体在稀疏奖励、复杂环境中探索效率低下的核心问题。其关键技术是设计了一种时序方差驱动的课程学习框架，通过量化状态访问的时间方差自动生成由易到难的训练课程。实验表明，TEACH在MiniGrid、Ant Maze等基准任务上显著提升样本效率，平均性能超越对比课程学习方法达47%，并有效缓解了探索不足与灾难性遗忘问题。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.22575","title":"ParaMaP: Parallel Mapping and Collision-free Motion Planning for Reactive Robot Manipulation","arxivId":"2512.22575","date":"2025-12-27","authors":"Zhiyu Li Team","category":"Manipulation","summary":"本文针对未知环境中机器人操作的实时无碰撞运动规划难题，提出并行建图与规划框架ParaMaP。其核心方法是：在建图侧，采用基于GPU的欧几里得距离变换（EDT）构建密集距离场，并结合机器人掩码更新机制避免误碰撞检测；在规划侧，将运动生成建模为随机优化问题，通过基于采样的模型预测控制（SMPC）框架并行评估大量轨迹，并引入SE(3)上的姿态跟踪度量以确保收敛。整个流水线在GPU上实现以支持高频重规划。该方法在7自由度机械臂的仿真与实物实验中验证了有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.22519","title":"Clutter-Resistant Vision-Language-Action Models through Object-Centric and Geometry Grounding","arxivId":"2512.22519","date":"2025-12-27","authors":"Ngan Le Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型在杂乱现实场景中感知与控制纠缠、语言条件接地不准的问题，提出OBEYED-VLA框架。其核心技术是通过一个感知模块，先利用VLM进行任务相关的对象中心语义接地，再通过几何接地强调对象3D结构，从而将原始RGB观测转换为明确接地的表示，再输入VLA策略。在真实UR10e桌面测试中，该方法在干扰物、目标缺失、背景变化及操作未见对象等挑战性场景下，鲁棒性显著优于基线模型，消融研究证实语义与几何接地均至关重要。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.21970","title":"StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision","arxivId":"2512.21970","date":"2025-12-26","authors":"He Wang Team","category":"Manipulation","summary":"论文StereoVLA针对现有视觉-语言-动作模型因依赖单视图RGB而几何感知不足的问题，提出利用立体视觉增强空间感知。核心方法包括Geometric-Semantic特征提取模块，融合立体差异的几何特征和单眼语义特征，以及辅助交互区域深度估计任务以加速收敛。实验表明，该方法在立体设置下多种任务中大幅优于基线模型，并对相机姿态变化表现出强鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.21898","title":"Flexible Multitask Learning with Factorized Diffusion Policy","arxivId":"2512.21898","date":"2025-12-26","authors":"Yilun Du Team","category":"Manipulation","summary":"本文提出Factorized Diffusion Policy (FDP)，以解决多任务模仿学习中机器人动作分布高度多模态、现有单一策略难以有效拟合和灵活适应的问题。其核心方法是一种模块化扩散策略框架，将复杂动作分布分解为多个专门的扩散模型，每个捕获不同的行为子模式，并通过观察条件路由器在推理时动态组合。该方法基于组合扩散建模，使用连续分数聚合而非离散专家选择，以实现稳定训练并促进模块间清晰分工。实验表明，FDP在模拟基准（MetaWorld、RLBench）和真实机器人操作中，均持续优于现有的模块化及单一模型基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.21586","title":"Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations","arxivId":"2512.21586","date":"2025-12-25","authors":"Dongbin Zhao Team","category":"Manipulation","summary":"本文针对从无动作标签的视频中进行高效模仿学习（ILV）的挑战，提出BCV-LR框架。其核心方法是通过自监督任务从视频提取动作相关潜在特征，并利用基于动态的无监督目标预测帧间潜在动作；随后在线微调，将潜在动作与真实动作空间对齐以进行行为克隆，形成迭代的策略改进循环。实验表明，在离散与连续控制任务中，BCV-LR仅需极少量交互即可达到专家级性能，在24/28的任务上样本效率超越了现有ILV基线和有环境奖励的强化学习方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.21235","title":"RoboCade: Gamifying Robot Data Collection","arxivId":"2512.21235","date":"2025-12-26","authors":"Dorsa Sadigh Team","category":"Manipulation","summary":"请提供论文正文内容，以便我根据具体研究内容撰写总结。目前仅凭标题无法准确提炼方法、实验与结论等关键信息。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.21065","title":"Language-Guided Grasp Detection with Coarse-to-Fine Learning for Robotic Manipulation","arxivId":"2512.21065","date":"2025-12-24","authors":"Hu Cao Team","category":"Manipulation","summary":"本文针对语言引导的机器人抓取任务中，语义基础有限、语言意图与视觉抓取推理对齐弱的问题，提出了LGGD方法。该方法采用从粗到细的学习范式，基于CLIP嵌入进行分层跨模态融合，逐步注入语言线索以增强视觉-语义对齐；并设计语言条件动态卷积头（LDCH）实现指令自适应的粗掩码与抓取预测，最后通过细化模块提升抓取一致性。实验在OCID-VLG和Grasp-Anything++数据集上验证了LGGD优于现有方法，对未见对象和多样语言查询具有强泛化能力，真实机器人部署也证明了其实际有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.21043","title":"Tracing Energy Flow: Learning Tactile-based Grasping Force Control to Prevent Slippage in Dynamic Object Interaction","arxivId":"2512.21043","date":"2025-12-24","authors":"Takamitsu Matsubara Team","category":"Manipulation","summary":"该论文针对动态物体交互中因滚动接触、物体属性未知及外部感知不可靠导致的抓取滑动问题，提出一种基于触觉的抓取力控制方法。核心技术是物理信息能量抽象，将物体建模为虚拟能量容器，通过比较手指施加功率与物体保留能量来推断滑动；并采用基于模型的强化学习框架，学习能量流动力学，利用概率模型预测控制进行实时抓取力优化。实验表明，该方法可在几分钟内从零开始学习，有效减少滑动，延长抓取持续时间，且不依赖外部感知或物体先验知识。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.20876","title":"Proprioception Enhances Vision Language Model in Generating Captions and Subtask Segmentations for Robot Task","arxivId":"2512.20876","date":"2025-12-24","authors":"Tetsuya Ogata Team","category":"Manipulation","summary":"本文旨在解决视觉语言模型（VLMs）因训练数据缺乏机器人低级别运动信息而难以理解包含轨迹的机器人任务视频的核心问题。提出一种通过输入机器人本体感知数据（如关节和末端执行器状态）增强VLM的方法，首先生成多个场景描述并总结为完整任务描述，再通过比较图像描述文本嵌入的相似性实现子任务分割。模拟器实验验证了该方法在提升机器人任务描述和分割性能方面的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.20847","title":"YCB-Handovers Dataset: Analyzing Object Weight Impact on Human Handovers to Adapt Robotic Handover Motion","arxivId":"2512.20847","date":"2025-12-23","authors":"Christian Smith Team","category":"Manipulation","summary":"本文核心是解决机器人交接动作中缺乏对物体重量适应性研究的数据缺口。通过构建YCB-Handovers数据集，记录了2771次人类间交接动作，并分析不同重量物体的影响。关键技术是基于YCB物体集，扩展采集人类交接运动模式，用于驱动重量敏感的运动规划模型。核心贡献是提供了首个涵盖广泛重量范围的交接数据集，包含2771次交互数据，详细分析了重量对人类伸手运动的影响，为机器人实现自然、安全的适应性交接提供了数据基础。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.20188","title":"Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation","arxivId":"2512.20188","date":"2025-12-23","authors":"Lianyang Ma Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型在全身机器人操控中因同步执行导致推理速度慢、控制稳定性差的问题，提出异步快慢VLA框架DuoCore-FS。其核心是通过潜在表示缓冲区连接慢速语义推理与高频动作生成路径，并采用全身动作标记器统一表示动作。该框架支持30亿参数VLM的同时，实现了30Hz的全身动作生成，速度提升约3倍。真实实验表明其任务成功率与响应性均显著优于同步基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.20166","title":"LoLA: Long Horizon Latent Action Learning for General Robot Manipulation","arxivId":"2512.20166","date":"2025-12-23","authors":"Baining Guo Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型在长时程、语言引导的机器人操作任务中，难以利用历史信息和生成连贯动作序列的核心问题，提出了LoLA框架。其关键技术包括：利用视觉语言模型编码历史序列与多视角观测的上下文特征，并引入**状态感知潜在重表示模块**，通过可学习的“具身锚定”潜在空间，将视觉与语言指令显式地映射到物理尺度的机器人运动空间。实验在仿真与真实机器人平台进行，结果表明LoLA显著优于现有方法，在长时程操作任务上表现尤为突出。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.19583","title":"Learning Generalizable Hand-Object Tracking from Synthetic Demonstrations","arxivId":"2512.19583","date":"2025-12-22","authors":"Ping Tan Team","category":"Manipulation","summary":"本文解决从合成数据学习通用化手-物体追踪控制器的数据瓶颈问题。提出两种关键技术：HOP（手-物体规划器）用于合成多样化轨迹；HOT（手-物体追踪器）通过强化学习与交互模仿学习实现合成到物理的迁移。实验表明，该方法能使灵巧手成功追踪长时程复杂序列，包括物体重排与手内敏捷重定向，并泛化至不同物体形状与手部形态。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.19562","title":"REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation","arxivId":"2512.19562","date":"2025-12-22","authors":"Vladimir Petrik Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型在真实世界中泛化能力评估困难且成本高昂的问题，提出了REALM基准测试。其核心是构建了一个高保真、控制对齐的仿真环境，包含15种扰动因素、7种操作技能和超过3500个对象，以支持大规模、可重复的泛化能力评测。通过真实到仿真的验证实验，论文表明该仿真环境能有效代理真实世界性能，并系统揭示了当前主流VLA模型在泛化与鲁棒性方面仍面临严峻挑战。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.19402","title":"Real2Edit2Real: Generating Robotic Demonstrations via a 3D Control Interface","arxivId":"2512.19402","date":"2025-12-22","authors":"Hao Dong Team","category":"Manipulation","summary":"由于您未提供论文正文内容，我无法根据具体研究内容撰写总结。请提供论文的正文部分，我将严格遵循您的要求，为您生成一段精准、简洁的中文总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.19390","title":"TwinAligner: Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for Robotic Manipulation","arxivId":"2512.19390","date":"2025-12-22","authors":"Hao Dong Team","category":"Manipulation","summary":"本文提出TwinAligner系统，旨在解决机器人操作中仿真与现实之间的视觉与动力学差距，以实现高效的数据驱动策略训练。其核心技术包括：视觉对齐模块通过SDF重建与可编辑3DGS渲染实现像素级对齐；动态对齐模块通过分析机器人-物体交互的刚性物理确保动力学一致性。实验表明，该系统能显著提升仿真与真实世界的一致性，使仿真训练的策略在真实场景中实现强大的零样本泛化，且两者性能高度一致。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.19347","title":"OMP: One-step Meanflow Policy with Directional Alignment","arxivId":"2512.19347","date":"2025-12-22","authors":"Yutong Ban Team","category":"Manipulation","summary":"本文针对机器人操作中生成策略的推理延迟与架构复杂度权衡问题，提出单步平均流策略OMP。核心创新包括：引入轻量级方向对齐机制，显式同步预测速度与真实平均速度；采用微分推导方程近似雅可比向量积，解耦前向与反向传播以降低内存开销。在Adroit和Meta-World基准测试中，OMP在成功率和轨迹精度上超越现有方法，尤其在高精度任务中表现优异，同时保持了单步推理的高效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.19269","title":"Translating Flow to Policy via Hindsight Online Imitation","arxivId":"2512.19269","date":"2025-12-22","authors":"Yang Gao Team","category":"Manipulation","summary":"本文针对分层机器人系统中高层规划（如点流）难以转化为可执行低层策略的问题，提出**Hindsight Flow-conditioned Online Imitation (HinFlow)** 方法。该方法通过在线交互收集轨迹，利用**事后目标重标注**技术，将实际达成结果反标为高层目标，进而聚合这些经验以更新一个**目标条件模仿策略**。实验表明，该方法在模拟和真实世界的多种操作任务中，相比基础策略取得了**超过2倍的性能提升**，并能有效利用跨体现视频数据训练的规划器。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.18619","title":"ChronoDreamer: Action-Conditioned World Model as an Online Simulator for Robotic Planning","arxivId":"2512.18619","date":"2025-12-21","authors":"Dan Negrut Team","category":"Manipulation","summary":"本文提出ChronoDreamer，旨在解决接触丰富的机器人操作中，传统仿真器速度慢、仿真到现实存在差距，而现有视频预测模型又忽略物理接触信息的问题。其核心是构建一个动作条件世界模型，关键技术包括：采用空间-时间变换器与MaskGIT式掩码预测，联合预测未来RGB帧、接触图与关节角度；将3D接触力编码为深度加权高斯泼溅图像以供视觉主干处理；在推理时集成基于视觉语言模型的碰撞评判器进行拒绝采样。在DreamerBench数据集上的实验表明，该模型能保持非接触运动的空间连贯性，生成合理的接触预测，其LLM评判器能有效区分碰撞与非碰撞轨迹。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.18583","title":"SD2AIL: Adversarial Imitation Learning from Synthetic Demonstrations via Diffusion Models","arxivId":"2512.18583","date":"2025-12-21","authors":"Xin Xu Team","category":"Manipulation","summary":"本文提出SD2AIL，旨在解决对抗性模仿学习中专家演示数据有限、收集困难的问题。方法核心是：1）利用扩散模型在判别器中生成合成演示，作为伪专家数据以增强真实演示；2）引入优先专家演示回放策略，从大量演示中筛选高价值样本进行训练。在Hopper仿真任务中，该方法取得了3441的平均回报，超越现有最优方法89分，证明了其有效性与鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.18477","title":"STORM: Search-Guided Generative World Models for Robotic Manipulation","arxivId":"2512.18477","date":"2025-12-20","authors":"Keze Wang Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型依赖抽象语言推理、难以进行细粒度物理时空推理的问题，提出了STORM框架。其核心方法整合了扩散式动作生成、条件视频预测和蒙特卡洛树搜索规划，通过视觉推演进行基于前瞻的评估与优化。在SimplerEnv基准测试中，STORM取得了51.0%的平均成功率，超越现有最佳模型；其奖励增强的视频预测将FVD分数降低了75%以上，显著提升了时空保真度和长时程任务中的重规划能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.18396","title":"AOMGen: Photoreal, Physics-Consistent Demonstration Generation for Articulated Object Manipulation","arxivId":"2512.18396","date":"2025-12-20","authors":"Yakun Huang Team","category":"Manipulation","summary":"本文针对关节物体精细操作任务依赖大量昂贵真实演示数据的问题，提出AOMGen框架。该方法仅需单个真实扫描和演示，结合数字资产库，生成视觉逼真且物理状态可验证的训练数据，通过系统变化相机视角、物体风格与位姿来增强数据多样性。实验表明，使用AOMGen数据微调VLA策略后，任务成功率从0%提升至88.7%，并能在未见物体和布局上有效泛化。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.18368","title":"Learning Semantic Atomic Skills for Multi-Task Robotic Manipulation","arxivId":"2512.18368","date":"2025-12-20","authors":"Jingya Wang Team","category":"Manipulation","summary":"本文针对多任务机器人操作中模仿学习面临的泛化挑战，提出了AtomSkill框架。其核心是构建一个**语义接地的原子技能库**，通过夹持器状态关键帧检测与视觉语言模型标注，将演示分割为语义一致的变长技能。同时，**带有关键姿态想象的动作生成模块**能联合预测技能的长期目标姿态与即时动作序列，实现鲁棒的技能组合。实验表明，该方法在多样化的操作任务上性能优于现有先进方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.18068","title":"SurgiPose: Estimating Surgical Tool Kinematics from Monocular Video for Surgical Robot Learning","arxivId":"2512.18068","date":"2025-12-19","authors":"Axel Krieger Team","category":"Manipulation","summary":"本文解决从单目手术视频估计手术工具运动学数据的关键问题，以支持机器人模仿学习。提出SurgiPose方法，其核心技术是基于可微分渲染，通过优化工具姿态参数来最小化渲染图像与真实视频帧的差异，从而推断工具轨迹和关节角度。在da Vinci机器人上的组织提升与针拾取实验表明，使用视频估计的运动学数据训练的策略，其成功率与使用真实运动学数据训练的策略相当，验证了该方法的可行性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.18028","title":"Embodied4C: Measuring What Matters for Embodied Vision-Language Navigation","arxivId":"2512.18028","date":"2025-12-19","authors":"Eric Sax Team","category":"Manipulation","summary":"本文针对现有具身视觉语言导航（VLN）基准难以衡量模型真实推理能力的问题，提出了Embodied4C闭环基准。该基准通过覆盖自动驾驶车辆、无人机和机械臂三种异构平台，设计约1100个一次性推理问题和58个导航任务，系统评估模型在语义、空间、时间和物理四个维度的推理能力，并引入领域远查询以防止过拟合。实验对10个先进VLM和4个具身控制基线进行了全面评估，核心结论表明：跨模态对齐和指令调优比模型规模更重要，而空间与时间推理是可靠具身能力的主要瓶颈。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.18007","title":"Robotic VLA Benefits from Joint Learning with Motion Image Diffusion","arxivId":"2512.18007","date":"2025-12-19","authors":"Juan Carlos Niebles Team","category":"Manipulation","summary":"本文针对机器人视觉-语言-动作模型缺乏预测性运动推理能力的问题，提出一种联合学习运动图像扩散的新策略。方法采用双头设计：动作头预测动作序列，运动头作为扩散变换器预测基于光流的未来运动图像，两者通过共享的VLM骨干进行联合训练，使模型能耦合运动知识与控制表示。实验表明，该方法将π-series VLA在LIBERO基准上的成功率提升至97.5%，在RoboTwin基准上达58.0%，真实世界性能提高23%，显著增强了VLA的运动推理能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.17899","title":"Distributionally Robust Imitation Learning: Layered Control Architecture for Certifiable Autonomy","arxivId":"2512.17899","date":"2025-12-19","authors":"Alberto Speranzon Team","category":"Manipulation","summary":"本文针对模仿学习（IL）在自主系统中因分布偏移（包括策略误差、外生干扰及模型不确定性引起）而导致性能下降的核心问题，提出了一种可认证的分层控制架构。关键技术整合了两种互补方法：泰勒级数模仿学习（TaSIL）用于抵御策略误差引起的分布偏移，L1分布鲁棒自适应控制（L1-DRAC）用于处理随机性与认知不确定性引起的分布偏移。通过构建分布鲁棒模仿策略（DRIP）架构，并精心设计各层的输入输出要求，论文论证了该架构能够为整个学习与控制流程提供可证明的保证，从而为实现全栈可认证的自主系统铺平了道路。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.17853","title":"AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning","arxivId":"2512.17853","date":"2025-12-19","authors":"Karl Schmeckpeper Team","category":"Manipulation","summary":"论文提出AnyTask框架，旨在解决机器人学习中仿真到现实策略学习的数据收集成本高、任务设计人力密集的核心问题。该框架结合大规模并行GPU仿真与基础模型，自动生成多样化操作任务和机器人数据，关键技术包括ViPR（VLM辅助并行细化的任务规划）、ViPR-Eureka（生成密集奖励的强化学习）和ViPR-RL（稀疏奖励下的混合规划学习）三个代理。实验结果表明，基于生成数据训练的行为克隆策略可直接部署到真实机器人，在拾放、开抽屉等任务中泛化至新物体姿态，平均成功率达到44%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.17568","title":"Kinematics-Aware Diffusion Policy with Consistent 3D Observation and Action Space for Whole-Arm Robotic Manipulation","arxivId":"2512.17568","date":"2025-12-19","authors":"Xiang Li Team","category":"Manipulation","summary":"本文针对机器人全身操控中关节空间与任务空间不对齐导致的策略学习复杂、泛化困难问题，提出一种运动学感知的扩散策略框架。其核心是采用手臂表面的一组3D点来统一表示机器人状态和动作，使其与3D点云观测空间保持一致，从而简化学习；并进一步将运动学先验融入扩散过程，以保证输出动作的可行性。仿真与实物实验表明，该方法在身体感知操控任务中，相比现有方法取得了更高的成功率和更强的空间泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.17253","title":"Mitty: Diffusion-based Human-to-Robot Video Generation","arxivId":"2512.17253","date":"2025-12-19","authors":"Mike Zheng Shou Team","category":"Manipulation","summary":"本文针对从人类示范视频直接生成机器人执行视频的核心问题，旨在避免依赖关键点等中间表示导致的信息丢失与累积错误。提出Mitty方法，基于扩散变换器的视频上下文学习技术，利用预训练视频扩散模型，将人类视频压缩为条件令牌，通过双向注意力与机器人去噪令牌融合，实现端到端生成；并开发自动合成管道从自我中心数据生成高质量配对数据以缓解数据稀缺。实验在Human2Robot和EPIC-Kitchens数据集上取得最先进结果，展现出对未见环境的强泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.17183","title":"Semantic Co-Speech Gesture Synthesis and Real-Time Control for Humanoid Robots","arxivId":"2512.17183","date":"2025-12-19","authors":"Gang Zhang Team","category":"Manipulation","summary":"本文提出一种端到端框架，解决人形机器人生成与语音语义匹配的自然手势并实时执行的难题。关键技术包括：基于大语言模型与自回归Motion-GPT的语义感知手势合成模块、采用模仿学习的MotionTracker高保真控制策略，以及通用运动重定向方法。实验表明，该系统能合成语义恰当、节奏协调的手势，并在Unitree G1机器人上准确跟踪与执行，实现了从语音理解到实时物理部署的完整流程。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.17062","title":"Lang2Manip: A Tool for LLM-Based Symbolic-to-Geometric Planning for Manipulation","arxivId":"2512.17062","date":"2025-12-18","authors":"Irfan Hussain Team","category":"Manipulation","summary":"本文提出Lang2Manip工具，解决LLM生成的符号计划在机器人操作仿真中执行时需机器人特定工程或规划器依赖集成的问题。关键技术是构建统一管道，集成LLM-based符号规划器与Kautham运动规划框架，将自然语言指令转换为符号动作，并利用Kautham支持的多规划器（几何、动态、物理驱动等）自动计算和执行无碰撞轨迹，无需额外编码。该工具实现了机器人无关的符号到几何规划，为语言驱动的任务和运动规划提供了灵活、可扩展的解决方案。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.16911","title":"Posterior Behavioral Cloning: Pretraining BC Policies for Efficient RL Finetuning","arxivId":"2512.16911","date":"2025-12-18","authors":"Sergey Levine Team","category":"Manipulation","summary":"本文针对标准行为克隆（BC）预训练策略在后续强化学习（RL）微调中因动作覆盖不足而导致样本效率低下的问题，提出后验行为克隆（PostBC）方法。该方法通过建模演示者行为在给定数据集下的后验分布（而非直接模仿动作），确保对演示动作的覆盖，且预训练性能不低于BC。实验表明，PostBC仅依赖标准监督学习，在机器人控制基准和真实操作任务中，相比BC能显著提升RL微调性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.16881","title":"PolaRiS: Scalable Real-to-Sim Evaluations for Generalist Robot Policies","arxivId":"2512.16881","date":"2025-12-18","authors":"Karl Pertsch Team","category":"Manipulation","summary":"本文针对通用机器人策略性能评估的挑战，提出PolaRiS框架。核心问题是真实评估耗时、不可控，而模拟评估存在视觉与物理领域差距。PolaRiS利用神经重建方法将真实场景短视频转换为高保真交互式模拟环境，并通过模拟数据协同训练实现零样本评估。实验表明，PolaRiS评估与真实世界性能的相关性显著强于现有模拟基准，且能快速创建多样化环境。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.16861","title":"ReinforceGen: Hybrid Skill Policies with Automated Data Generation and Reinforcement Learning","arxivId":"2512.16861","date":"2025-12-18","authors":"Caelan Garrett Team","category":"Manipulation","summary":"论文解决长时程机器人操作任务中演示数据收集昂贵、模仿学习易偏离，以及强化学习探索困难的核心挑战。提出ReinforceGen框架，通过任务分解将任务分割为多个局部技能，并利用自动化数据生成与模仿学习构建初始策略，再结合在线适应和强化学习进行微调改进。在Robosuite数据集上的实验表明，该系统在视觉运动控制下达到80%的成功率，且消融研究证实微调方法带来了89%的平均性能提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.16842","title":"OPENTOUCH: Bringing Full-Hand Touch to Real-World Interaction","arxivId":"2512.16842","date":"2025-12-18","authors":"Paul Pu Liang Team","category":"Manipulation","summary":"本文旨在解决真实世界中缺乏同步全手触觉、第一人称视觉与手部姿态数据的问题。为此，研究团队构建了首个大规模真实环境下的多模态数据集OpenTouch，其核心技术是使用压力传感手套，同步采集了5.1小时视频-触觉-姿态数据，包含约800种物体在14种环境下的交互。实验表明，该数据集中的触觉信号为抓取理解提供了强有力的线索，能有效增强跨模态对齐，并能从真实世界视频中可靠地检索出对应的触觉信息。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.16811","title":"GeoPredict: Leveraging Predictive Kinematics and 3D Gaussian Geometry for Precise VLA Manipulation","arxivId":"2512.16811","date":"2025-12-18","authors":"Li Jiang Team","category":"Manipulation","summary":"本文提出GeoPredict框架，解决现有视觉-语言-动作模型在机器人操作中缺乏3D空间推理能力、反应式决策的问题。方法核心包括：轨迹级模块编码运动历史并预测多步3D关键点轨迹；预测性3D高斯几何模块沿轨迹预测工作空间几何。这些模块仅用于训练时深度渲染监督，推理时仅需轻量查询令牌。实验表明，在RoboCasa Human-50、LIBERO及真实任务中，GeoPredict显著优于现有VLA基线，尤其在几何密集与高空间精度要求场景中表现突出。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.16724","title":"VERM: Leveraging Foundation Models to Create a Virtual Eye for Efficient 3D Robotic Manipulation","arxivId":"2512.16724","date":"2025-12-18","authors":"Liang Wang Team","category":"Manipulation","summary":"本文提出VERM方法，旨在解决3D机器人操作中多固定摄像头带来的信息冗余与计算负担问题。该方法核心是利用基础模型，从3D点云中生成一个虚拟的、任务自适应的视角（虚拟眼），以高效聚焦关键信息并缓解遮挡。技术要点包括深度感知模块和动态由粗到精的处理流程。实验表明，该方法在RLBench仿真和真实场景中均超越先前最佳方法，实现了训练速度1.89倍、推理速度1.54倍的提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.16449","title":"Single-View Shape Completion for Robotic Grasping in Clutter","arxivId":"2512.16449","date":"2025-12-18","authors":"Todor Stoyanov Team","category":"Manipulation","summary":"本文针对机器人抓取在杂乱环境中因单视图遮挡导致几何形状不完整、抓取性能下降的问题，提出基于扩散模型的类别级3D形状补全方法。该方法从单视图深度观测中重建完整物体几何，集成场景分割与抓取推理，为规划提供完整上下文。在家庭物品杂乱场景的初步实验中，抓取成功率比无形状补全基线提高23%，比现有最优形状补全方法提高19%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.16302","title":"ManiLong-Shot: Interaction-Aware One-Shot Imitation Learning for Long-Horizon Manipulation","arxivId":"2512.16302","date":"2025-12-18","authors":"Yang Gao Team","category":"Manipulation","summary":"本文解决当前一次性模仿学习（OSIL）方法难以处理复杂长时程操作任务的问题。提出了ManiLong-Shot框架，其核心是将长时程任务分解为基于物理交互事件的基元序列，而非直接模仿连续轨迹。该方法利用视觉语言模型或基于状态变化的启发式规则驱动分解，对每个基元预测关键的交互不变区域、建立演示与当前场景的对应关系，并计算目标位姿。实验表明，仅在10个短时程任务上训练的模型，可通过单次演示泛化到20个未见长时程任务，相对现有最佳方法性能提升22.8%，并在真实机器人上得到验证。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.16023","title":"CoVAR: Co-generation of Video and Action for Robotic Manipulation via Multi-Modal Diffusion","arxivId":"2512.16023","date":"2025-12-17","authors":"Abhinav Valada Team","category":"Manipulation","summary":"本文提出CoVAR方法，解决机器人操作中视频与动作数据难以协同生成的问题。现有方法存在两阶段流程跨模态信息共享不足，或需从头训练联合扩散模型难以利用预训练知识等局限。CoVAR通过扩展预训练视频扩散模型并附加专用动作扩散模型、引入桥接注意力机制实现跨模态交互、设计动作细化模块提升控制精度，实现了视频与动作的协同生成。实验表明，该方法在多个基准测试中能生成更高质量的视频和更准确的动作，性能显著优于现有基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.15840","title":"Large Video Planner Enables Generalizable Robot Control","arxivId":"2512.15840","date":"2025-12-17","authors":"Yilun Du Team","category":"Manipulation","summary":"本论文针对通用机器人决策模型泛化能力有限的问题，提出基于大规模视频预训练的替代范式，以克服视觉-语言-动作模型因动作数据稀缺导致的泛化不足。方法包括策划互联网规模人类活动视频数据集，首次训练基础模型规模的生成式视频规划模型，通过零样本生成视频计划并后处理提取机器人动作。实验通过第三方选定野外任务和真实机器人验证，实现了成功的物理执行，展示了鲁棒的指令跟随、强泛化及现实世界可行性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.15692","title":"mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs","arxivId":"2512.15692","date":"2025-12-19","authors":"Elvis Nava Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型（VLAs）因预训练数据缺乏动态物理信息而导致数据效率低下的核心问题，提出mimic-video模型。该模型是一种视频-动作模型（VAM），其关键技术是结合预训练的大规模视频模型与基于流匹配的动作解码器，后者作为逆动力学模型，直接从视频潜在表示生成机器人动作。实验表明，该方法在机器人操控任务上达到最优性能，相比传统VLA架构，样本效率提升10倍，收敛速度加快2倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.15020","title":"ISS Policy : Scalable Diffusion Policy with Implicit Scene Supervision","arxivId":"2512.15020","date":"2025-12-17","authors":"Jie Mei Team","category":"Manipulation","summary":"本文针对视觉模仿学习过度依赖物体外观、忽视3D场景结构导致的训练效率低、泛化差问题，提出ISS Policy。该方法是一种基于DiT的3D视觉运动扩散策略，以点云为输入预测连续动作序列。其核心是提出了隐式场景监督模块，通过鼓励模型输出与场景几何演化一致，提升策略性能与鲁棒性。实验表明，该方法在MetaWorld单臂操作和Adroit灵巧手操作任务上达到SOTA性能，并在真实世界展现出强泛化与鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.14666","title":"EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models","arxivId":"2512.14666","date":"2025-12-16","authors":"Mike Zheng Shou Team","category":"Manipulation","summary":"本文针对Vision-Language-Action (VLA) 模型依赖监督微调、缺乏测试时环境适应性的核心问题，提出EVOLVE-VLA测试时训练框架，使模型能通过交互持续学习。关键技术采用学习进度估计器提供密集反馈，并通过累积进度估计机制平滑噪声、渐进视野扩展策略逐步演化策略。实验表明，该框架在长视野任务上性能提升8.6%，1-shot学习提升22.0%，并在未见任务上实现20.8%成功率（纯SFT为0%），涌现出错误恢复和新策略等能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.14217","title":"DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos","arxivId":"2512.14217","date":"2025-12-16","authors":"Gitta Kutyniok Team","category":"Manipulation","summary":"本文针对机器人演示视频生成中可控性不足的问题，提出Draw2Act框架。其核心方法是利用深度感知的轨迹条件视频生成，从输入轨迹提取深度、语义、形状和运动等多维正交表示，并注入扩散模型；同时联合生成空间对齐的RGB与深度视频，通过跨模态注意力机制和深度监督增强时空一致性。实验表明，该方法在Bridge V2等基准测试中，相比现有基线取得了更高的视觉保真度、一致性以及机器人操作成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.13670","title":"NL2SpaTiaL: Generating Geometric Spatio-Temporal Logic Specifications from Natural Language for Manipulation Tasks","arxivId":"2512.13670","date":"2025-12-15","authors":"Mingyu Cai Team","category":"Manipulation","summary":"本文针对机器人操作任务中，如何将自然语言指令精确转换为兼具几何空间关系与时序结构的逻辑规范这一核心问题，提出了NL2SpaTiaL方法。关键技术包括：1）一个生成SpaTiaL逻辑规范与自然语言描述对齐数据集的框架；2）一个配备语义检查器的翻译-验证框架，确保生成的逻辑公式忠实于输入语义。实验表明，基于SpaTiaL的表示能为指令跟随提供更可解释、可验证且可组合的基础。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.13093","title":"PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations","arxivId":"2512.13093","date":"2025-12-15","authors":"Wenjun Zeng Team","category":"Manipulation","summary":"本文针对人形机器人全身控制中强化学习样本效率低下的核心问题，提出PvP框架。该方法利用本体感觉与特权状态的内在互补性，通过对比学习提取紧凑且任务相关的潜在表示，无需手工数据增强。实验在LimX Oli机器人上进行速度跟踪与运动模仿任务，结果表明PvP相比基线状态表示学习方法，显著提升了样本效率与最终性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.13080","title":"Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos","arxivId":"2512.13080","date":"2025-12-15","authors":"Zongqing Lu Team","category":"Manipulation","summary":"本文针对VLA模型因依赖2D视觉输入在3D环境中执行动作而导致的感知与动作接地差距问题，提出空间感知VLA预训练范式。关键技术是通过人类演示视频提取3D视觉与动作注释，进行两阶段对齐：3D视觉预训练融合2D与3D特征，3D动作预训练学习物理动作先验；并实例化为双编码器架构\\ModelName。实验表明，该模型在下游机器人任务中显著提升了2D视觉与3D动作的接地性，实现了更鲁棒和可泛化的策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.11988","title":"CARI4D: Category Agnostic 4D Reconstruction of Human-Object Interaction","arxivId":"2512.11988","date":"2025-12-12","authors":"Stan Birchfield Team","category":"Manipulation","summary":"论文提出CARI4D方法，解决从单目RGB视频中类别无关地重建人类-物体交互4D表示的核心问题，克服了未知物体信息、深度模糊和遮挡等挑战。关键技术包括姿态假设选择算法以集成基础模型预测，通过渲染-比较范式进行联合细化确保对齐，并推理复杂接触以满足物理约束。实验表明，该方法在重建误差上优于先前方法，在分布内数据集上提升38%，在未见数据集上提升36%，并能零样本泛化到野外互联网视频。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.11921","title":"Towards Accessible Physical AI: LoRA-Based Fine-Tuning of VLA Models for Real-World Robot Control","arxivId":"2512.11921","date":"2025-12-11","authors":"Ibrahim Sheikh Mohamed Team","category":"Manipulation","summary":"本文旨在解决将大规模视觉-语言-动作模型高效部署到低成本机器人平台的核心挑战，包括计算资源受限以及对新机器人本体的适配问题。提出采用低秩适配与量化技术对预训练VLA模型进行资源高效的微调，使其能在仅8GB显存的消费级GPU上运行。通过在SO101机械臂上进行真实世界的按钮按压任务实验（基于200个演示片段训练），结果表明该方法在保持计算效率的同时，实现了有效的操作性能，推动了先进机器人操控能力的普及。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.11797","title":"AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis","arxivId":"2512.11797","date":"2025-12-12","authors":"Vitor Guizilini Team","category":"Manipulation","summary":"本文针对机器人模仿学习中数据收集成本高、多样性不足的核心瓶颈，提出AnchorDream方法。该方法重新利用预训练视频扩散模型，通过以机器人运动渲染为条件锚定具身，防止运动失真，从而合成与机器人运动学一致的对象和环境，仅需少量演示即可生成大规模高质量数据集。实验表明，所生成数据显著提升下游策略学习性能，在模拟器基准测试中取得36.4%的相对增益，在真实世界研究中性能近乎翻倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.11609","title":"UniBYD: A Unified Framework for Learning Robotic Manipulation Across Embodiments Beyond Imitation of Human Demonstrations","arxivId":"2512.11609","date":"2025-12-12","authors":"Jinqiao Wang Team","category":"Manipulation","summary":"本文提出UniBYD框架，旨在解决机器人手与人类手之间的“具身差距”导致从人类示范学习操作性能受限的核心问题。关键技术包括：统一的形态学表示（UMR）以建模多样手部形态；动态PPO算法配合退火奖励调度，使强化学习从模仿人类示范过渡至探索适应机器人自身形态的策略；以及基于马尔可夫的混合影子引擎，实现细粒度的人类操作模仿。在提出的多手形态操作基准UniManip上，实验表明其成功率相比现有最优方法提升了67.90%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.11275","title":"Towards Logic-Aware Manipulation: A Knowledge Primitive for VLM-Based Assistants in Smart Manufacturing","arxivId":"2512.11275","date":"2025-12-12","authors":"Daqiang Guo Team","category":"Manipulation","summary":"本文针对智能制造中基于视觉语言模型（VLM）的机器人操作助手，解决其因缺乏执行关键参数（如接触方式、轨迹、容差、力/阻抗）而导致在接触密集型任务中首次尝试易失败的问题。核心方法是提出一个以对象为中心的操作逻辑模式，形式化为八字段元组τ，将上述参数显式编码为可传递的知识信号，并构建一个支持训练时数据增强与测试时逻辑感知检索提示的双重用途知识库。在3D打印机线轴移除任务的协作单元中实例化了该模式与知识库，并采用适应VLM/LLM规划基准的指标分析了τ条件下的规划质量。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.10891","title":"Iterative Compositional Data Generation for Robot Control","arxivId":"2512.10891","date":"2025-12-12","authors":"Eric Eaton Team","category":"Manipulation","summary":"论文针对机器人操控数据收集昂贵、组合任务泛化困难的问题，提出语义组合扩散变换器，将状态过渡分解为机器人、对象、障碍物和目标特定组件，通过注意力机制学习交互；并引入迭代自我改进程序，利用离线强化学习验证合成数据并迭代训练。实验表明，该方法在有限任务训练后能零样本生成高质量过渡数据，从中学习未见任务组合的控制策略，性能显著优于整体和硬编码组合基线，最终解决几乎所有保留任务，学习表示中涌现出有意义组合结构。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.09928","title":"HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models","arxivId":"2512.09928","date":"2025-12-10","authors":"Donglin Wang Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型在长时程操作中因依赖当前观测（时间近视）而导致连贯性下降的问题，提出HiF-VLA框架。该框架以运动表示为紧凑时序上下文，通过**后见编码过去动态、预见推理未来运动**，并经由**后见调制联合专家**实现双向时序推理与“边思考边行动”。实验表明，HiF-VLA在LIBERO-Long与CALVIN ABC-D基准上超越强基线，且推理延迟几乎无增加，在真实长时程操作任务中取得显著性能提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.09851","title":"Simultaneous Tactile-Visual Perception for Learning Multimodal Robot Manipulation","arxivId":"2512.09851","date":"2025-12-10","authors":"Yixin Zhu Team","category":"Manipulation","summary":"本文针对机器人操作中多模态感知与学习框架融合的挑战，提出了一种同步触觉-视觉感知系统。核心问题是现有透皮（STS）传感器无法实现同步多模态感知且触觉跟踪不可靠。作者提出了TacThru传感器（采用全透明弹性体与关键线标记）和TacThru-UMI模仿学习框架（基于Transformer的扩散策略）。在五项真实世界任务实验中，该系统平均成功率高达85.5%，显著优于仅触觉（66.3%）和仅视觉（55.4%）的基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.09510","title":"ViTA-Seg: Vision Transformer for Amodal Segmentation in Robotics","arxivId":"2512.09510","date":"2025-12-10","authors":"Paolo Roberto Massenio Team","category":"Manipulation","summary":"本文解决机器人箱拣选中因遮挡导致的amodal分割问题，以提升抓取规划准确性。提出ViTA-Seg框架，基于Vision Transformer，利用全局注意力恢复完整对象掩码，包括Single-Head（预测amodal掩码）和Dual-Head（同时预测amodal和遮挡掩码）两种架构，并引入ViTA-SimData合成数据集。实验表明，ViTA-Seg Dual Head在COOCA和KINS基准测试上实现了强大的amodal和遮挡分割精度，且计算高效，支持实时机器人操作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.09406","title":"H2R-Grounder: A Paired-Data-Free Paradigm for Translating Human Interaction Videos into Physically Grounded Robot Videos","arxivId":"2512.09406","date":"2025-12-10","authors":"Mike Zheng Shou Team","category":"Manipulation","summary":"本文提出H2R-Grounder框架，旨在解决从人类交互视频学习机器人操作技能时面临的配对数据稀缺和视觉体现差距问题。核心方法采用无需配对数据的范式，通过H2Rep表示法：在训练中修复机器人视频背景并叠加夹持器位姿提示，基于上下文学习微调视频扩散模型（Wan 2.2），生成时将相同流程应用于人类视频以合成机器人操作视频。实验表明，该方法相比基线能生成显著更真实、物理基础更扎实的机器人运动视频，为利用无标注人类视频扩展机器人学习提供了可行路径。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.09297","title":"One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation","arxivId":"2512.09297","date":"2025-12-10","authors":"Kui Jia Team","category":"Manipulation","summary":"本文针对双臂操作中大规模高质量演示数据收集的瓶颈问题，提出BiDemoSyn框架。该方法将任务分解为不变协调块和可变对象调整，通过视觉引导对齐与轻量级轨迹优化，从单个真实演示合成数千个多样且物理可行的演示。在六个双臂任务上的实验表明，基于合成数据训练的策略能鲁棒泛化到新对象姿态和形状，性能显著优于强基线，并实现零样本跨机器人平台迁移。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.09283","title":"UPETrack: Unidirectional Position Estimation for Tracking Occluded Deformable Linear Objects","arxivId":"2512.09283","date":"2025-12-10","authors":"Shifeng Huang Team","category":"Manipulation","summary":"本文提出UPETrack框架，旨在解决被部分遮挡的可变形线性物体（DLO）实时跟踪难题。其核心是单向位置估计（UPE）算法，该算法利用DLO的几何连续性与时空演化规律，通过局部线性组合位移、近端线性约束和历史曲率三项机制，以闭式解直接估计被遮挡节点位置，无需迭代优化。实验表明，UPETrack在定位精度与计算效率上均优于TrackDLO和CDCPD2等先进方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.09101","title":"Masked Generative Policy for Robotic Control","arxivId":"2512.09101","date":"2025-12-09","authors":"Paul Henderson Team","category":"Manipulation","summary":"本文提出掩码生成策略（MGP），以解决现有生成策略在机器人视觉运动模仿学习中存在的推理速度慢、对非马尔可夫任务鲁棒性不足的核心问题。方法将动作离散化为令牌，利用条件掩码变换器并行生成令牌，并快速细化低置信度部分；针对不同任务提出了MGP-Short（并行掩码生成与基于分数的细化）和MGP-Long（单次预测整条轨迹并动态细化）两种采样范式。在150项机器人操作任务上的实验表明，MGP平均成功率提升9%，推理速度加快最高达35倍，在动态与缺失观测环境中成功率提升60%，并能解决其他方法失败的非马尔可夫任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.08548","title":"Bridging Scale Discrepancies in Robotic Control via Language-Based Action Representations","arxivId":"2512.08548","date":"2025-12-09","authors":"Ting Liu Team","category":"Manipulation","summary":"本文针对机器人操作中因平台和任务差异导致的动作数值尺度分布偏移问题，提出一种基于语言的语义化动作表征方法。该方法通过构建强调方向性、忽略数值尺度的运动表征，归一化动作命令，以缓解分布偏移并缩小动作标记与语言词汇的模态间隙。在两大多任务基准上的实验表明，该方法显著提升了策略的泛化性能与跨任务可迁移性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.08545","title":"Curriculum Guided Massive Multi Agent System Solving For Robust Long Horizon Tasks","arxivId":"2512.08545","date":"2025-12-09","authors":"Kalathur Chenchu Kishore Kumar Team","category":"Manipulation","summary":"由于正文内容未提供，基于论文标题《Curriculum Guided Massive Multi Agent System Solving For Robust Long Horizon Tasks》，总结如下：该论文旨在解决鲁棒的长时域任务求解问题，这些任务通常复杂且需持久决策。核心技术方法为课程引导（Curriculum Guided）和大规模多智能体系统（Massive Multi Agent System），其中课程引导通过渐进式学习策略训练智能体，而多智能体系统协同处理任务以提升鲁棒性。实验结论和性能提升数据未在提供内容中详述，需参考论文正文获取具体结果。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.08405","title":"Learning Robot Manipulation from Audio World Models","arxivId":"2512.08405","date":"2025-12-09","authors":"Michael Gienger Team","category":"Manipulation","summary":"本文针对机器人操纵任务中视觉信息模糊或不完整时依赖音频进行多模态推理的核心问题，提出一种生成式潜在流匹配模型。该方法采用基于变压器的流匹配技术，在潜在空间预测未来音频状态，以捕捉音高和节奏模式等物理动态，并集成到机器人策略中实现长期推理。实验表明，在模拟和真实世界的音频感知操纵任务中，该方法相比无未来展望的方法性能更优。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.08188","title":"Embodied Tree of Thoughts: Deliberate Manipulation Planning with Embodied World Model","arxivId":"2512.08188","date":"2025-12-09","authors":"Rui Chen Team","category":"Manipulation","summary":"本文针对机器人长时域操作规划中，视频生成模型缺乏物理基础、易产生幻觉且难以保持物理一致性的问题，提出了一种名为Embodied Tree of Thoughts (EToT) 的Real2Sim2Real规划框架。该框架以基于物理的交互式数字孪生作为具身世界模型，其核心技术是通过两种协同机制在树中搜索可行计划：先验分支基于语义与空间分析生成候选路径，反思分支利用视觉语言模型诊断模拟执行失败并迭代优化规划树。实验表明，该方法在长短时域操作任务上能有效预测物理动态、适应潜在失败，性能持续优于基线模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.07697","title":"Delay-Aware Diffusion Policy: Bridging the Observation-Execution Gap in Dynamic Tasks","arxivId":"2512.07697","date":"2025-12-08","authors":"Shayegan Omidshafiei Team","category":"Manipulation","summary":"本文解决机器人控制中因感知、计算等环节导致的推理延迟（数十至数百毫秒）问题，该延迟造成观察与执行状态不一致，严重影响动态任务性能。作者提出延迟感知扩散策略（DA-DP），通过在训练与推理中显式纳入延迟测量，将零延迟轨迹校正为延迟补偿版本，并对策略进行延迟条件化增强。实验表明，DA-DP在多种任务、机器人及延迟条件下，比无视延迟的方法成功率更高、鲁棒性更强，如在乒乓球任务中能成功击球而基线方法失败。该框架架构无关，可推广至其他模仿学习方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.07582","title":"See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations","arxivId":"2512.07582","date":"2025-12-08","authors":"Yufeng Yue Team","category":"Manipulation","summary":"本文提出ViVLA模型，旨在解决机器人操作策略难以泛化至训练分布外新任务的问题。核心方法是构建一个视觉-语言-动作模型，使其能够通过联合处理单次专家演示视频与机器人实时观测，学习并预测动作序列，从而从一次演示中提炼精细操作知识。关键技术包括一个可扩展的专家-智能体配对数据生成流程，用于合成大规模训练数据。实验表明，ViVLA仅凭一次演示视频即可学习新技能，在未见过的LIBERO任务上性能提升超过30%，使用跨体现视频时增益保持在35%以上，真实世界实验中对未见任务的改进超过38%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.07472","title":"Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation","arxivId":"2512.07472","date":"2025-12-08","authors":"Chang Xu Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型在机器人操作中因分布偏移而陷入“记忆陷阱”、重复执行记忆轨迹而非适应新场景的核心问题，提出了一种轻量级混合框架“可供性场干预”（AFI）。该方法将3D空间可供性场（SAF）作为即插即用模块，通过本体感知检测陷阱，将机器人重定位至高可供性区域，并生成可供性驱动的路径点来引导VLA动作，最终由基于SAF的评分器选择最优轨迹。实验表明，该方法在真实机器人平台的分布外场景下，使不同VLA主干网络的性能平均提升23.5%，在LIBERO-Pro基准上提升20.2%，有效增强了VLA的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.07371","title":"ESPADA: Execution Speedup via Semantics Aware Demonstration Data Downsampling for Imitation Learning","arxivId":"2512.07371","date":"2025-12-08","authors":"Byoung-Tak Zhang Team","category":"Manipulation","summary":"由于您未提供论文正文内容，仅基于标题《ESPADA: Execution Speedup via Semantics Aware Demonstration Data Downsampling for Imitation Learning》进行推断，以下总结可能缺少正文中的具体细节和数据：\n\n本文针对模仿学习中演示数据量过大导致训练计算开销高、效率低的问题，提出ESPADA方法。其核心技术是通过**语义感知的演示数据下采样**，在减少数据量的同时保留关键行为语义信息。实验表明，该方法能显著**加速模型训练或执行过程**，并在性能损失最小的情况下实现效率提升。\n\n建议提供论文正文以获得更精准、包含具体技术与数据的总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.07248","title":"Benchmarking Humanoid Imitation Learning with Motion Difficulty","arxivId":"2512.07248","date":"2025-12-08","authors":"Yipeng Qin Team","category":"Manipulation","summary":"本文针对人形机器人模仿学习中现有评估指标（如关节误差）无法区分策略性能与动作本身难度的问题，提出了一种独立于策略的**动作难度评分（MDS）**。MDS基于刚体动力学，通过分析微小姿态扰动引起的扭矩变化（体积、方差、时间变异性）来量化动作的固有学习难度。基于MDS重构了MD-AMASS数据集，并提出了**最大可模仿难度（MID）**和**难度分层关节误差（DSJE）**两个新评估指标。实验验证表明，MDS能有效解释先进策略的性能差异，例如发现PHC+总体领先，但UHC在简单动作上更优。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.07215","title":"VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation","arxivId":"2512.07215","date":"2025-12-09","authors":"Sungho Kim Team","category":"Manipulation","summary":"本文系统比较了CLIP与DINOv2两种视觉基础模型在抓取场景6D物体姿态估计中的表现。核心问题是探索语义理解与几何精度在任务中的互补性。关键技术为：CLIP通过对比学习实现语言对齐的语义表征，DINOv2通过自蒸馏获取稠密几何特征。实验表明，CLIP方法在语义一致性上更优，而DINOv2方法在几何精度上具有竞争力，为机器人抓取应用中的模型选择提供了依据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.07212","title":"Sample from What You See: Visuomotor Policy Learning via Diffusion Bridge with Observation-Embedded Stochastic Differential Equation","arxivId":"2512.07212","date":"2025-12-08","authors":"Ye Shi Team","category":"Manipulation","summary":"本文针对机器人模仿学习中，扩散模型仅将观测作为高级条件而非整合到扩散过程动态的问题，提出**BridgePolicy**。该方法通过**扩散桥**公式将观测嵌入随机微分方程轨迹，使采样从信息丰富的先验而非随机噪声开始。为解决观测与动作维度异构的难题，引入了**多模态融合模块**和**语义对齐器**。在涵盖52个仿真任务和5个真实任务的广泛实验中，该方法性能**始终优于**现有最先进的生成策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.07032","title":"A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator","arxivId":"2512.07032","date":"2025-12-07","authors":"Gordon Cheng Team","category":"Manipulation","summary":"本文针对移动操作机器人如何以低计算和内存成本，根据触觉输入学习并执行动作序列的问题，提出一种异质联想顺序记忆模型。方法核心包括：使用群体位置编码和Izhikevich神经元模型分别编码关节状态与触觉力；将信号转为双极二进制向量并绑定存储；引入3D旋转位置嵌入以增强二进制空间的可分离性。在覆盖机器人皮肤的丰田HSR上验证，该系统能实现伪顺从控制（连杆随触觉力方向/幅度移动），并可通过持续触觉输入检索多关节抓取序列，具有快速设置、经济高效和一定泛化能力的特点。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.06963","title":"VideoVLA: Video Generators Can Be Generalizable Robot Manipulators","arxivId":"2512.06963","date":"2025-12-07","authors":"Baining Guo Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作（VLA）模型在机器人操作中泛化能力有限的问题，提出VideoVLA方法。该方法基于多模态扩散变换器，将预训练的大规模视频生成模型转化为机器人操纵器，核心创新在于采用双预测策略：同时预测动作序列及其引发的未来视觉结果。实验表明，高质量的视觉想象与可靠的动作预测及任务成功高度相关，该方法展现出强大的泛化能力，包括模仿新技能和处理未见过的物体。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.06628","title":"MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment","arxivId":"2512.06628","date":"2025-12-07","authors":"Xiu Li Team","category":"Manipulation","summary":"本文提出MIND-V框架，旨在解决长时序机器人操作视频生成中数据稀缺、逻辑连贯性与物理合理性不足的核心问题。方法采用分层架构：语义推理中心进行任务规划，行为语义桥转换指令，运动视频生成器渲染视频，并通过基于GRPO强化学习的物理前瞻一致性奖励确保生成内容符合物理规律。实验表明，MIND-V在长时序机器人操作视频生成任务上达到了最先进的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.06038","title":"Closed-Loop Robotic Manipulation of Transparent Substrates for Self-Driving Laboratories using Deep Learning Micro-Error Correction","arxivId":"2512.06038","date":"2025-12-04","authors":"Alexander E. Siemenn Team","category":"Manipulation","summary":"本论文针对自驾实验室中易碎、透明基底的自动化装卸瓶颈，开发了ASHE系统。该方法结合机器人、双驱动分配器与深度学习计算机视觉，通过实时检测与校正微米级放置误差，实现闭环精准操控。实验表明，系统在130次独立透明玻璃基底重载试验中，首次放置准确率达98.5%，并能自动检测并成功校正所有误放。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.05955","title":"SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models","arxivId":"2512.05955","date":"2025-12-05","authors":"Yilun Du Team","category":"Manipulation","summary":"SIMPACT论文旨在解决视觉语言模型(VLMs)缺乏物理动态理解，难以应用于需要细粒度物理推理的机器人操作任务的核心问题。提出SIMPACT框架，通过测试时模拟启用的动作规划，利用预训练视觉基础模型从单RGB-D图像高效构建物理模拟，使VLM能迭代提出动作、观察模拟展开并优化推理。该方法在五个真实世界刚体和可变形操作任务中实现最先进性能，优于现有通用机器人操作模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.05953","title":"Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning","arxivId":"2512.05953","date":"2025-12-05","authors":"Kuan Fang Team","category":"Manipulation","summary":"本文提出COIL框架，旨在解决现有基于3D运动轨迹（flow）的视觉运动控制策略存在的深度模糊、依赖手工设计模块、任务规范不灵活等问题。其核心方法是采用以3D关键点对应关系为导向的任务表示，允许可变的空间与时间粒度；并设计了一个融合多模态信息的时空注意力条件策略。该方法通过自监督流程在仿真中训练，并在真实世界操作任务上实现了优于先前方法的性能，能泛化至不同任务、物体和运动模式。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.05927","title":"World Models That Know When They Don’t Know: Controllable Video Generation with Calibrated Uncertainty","arxivId":"2512.05927","date":"2025-12-05","authors":"Anirudha Majumdar Team","category":"Manipulation","summary":"本文针对可控视频生成模型易产生“幻觉”（生成违背物理现实的帧）且无法评估自身置信度的问题，提出C³方法，首次实现视频模型的校准不确定性量化。核心技术包括：1）利用严格适当评分规则训练模型，使其输出正确且校准的置信度；2）在潜在空间进行密集不确定性估计，避免像素空间方法的训练不稳定与高成本；3）将潜在空间不确定性映射为像素级高分辨率热图，直观标识不可信区域。实验在Bridge和DROID等机器人数据集上验证了该方法能提供校准的不确定性估计，并有效支持分布外检测。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.05599","title":"An Integrated System for WEEE Sorting Employing X-ray Imaging, AI-based Object Detection and Segmentation, and Delta Robot Manipulation","arxivId":"2512.05599","date":"2025-12-05","authors":"Panagiotis Chatzakos Team","category":"Manipulation","summary":"本文针对废旧电子设备中电池的安全、高效自动分拣难题，提出一种集成解决方案。系统核心技术包括：采用双能量X射线成像获取高对比度图像；利用YOLO和U-Net模型对含电池物品进行精确检测与分割；通过智能跟踪与定位算法，引导搭载吸盘的Delta机器人完成选择性抓取与丢弃。该方法已在NVIDIA Isaac Sim仿真环境及真实设备上得到验证。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.05335","title":"State-Conditional Adversarial Learning: An Off-Policy Visual Domain Transfer Method for End-to-End Imitation Learning","arxivId":"2512.05335","date":"2025-12-05","authors":"Shengfan Cao Team","category":"Manipulation","summary":"本文针对端到端模仿学习中目标域数据离策略、无专家且稀缺的视觉域转移挑战，提出状态条件对抗学习（SCAL）。该方法基于理论分析，将目标域模仿损失上界为源域损失与状态条件潜在KL散度之和，并通过对抗判别器估计并最小化该散度以对齐条件潜在分布。在BARC–CARLA模拟器的自动驾驶环境实验中，SCAL实现了鲁棒的域转移和强大的样本效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.05107","title":"STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models","arxivId":"2512.05107","date":"2025-12-04","authors":"Benjamin Busam Team","category":"Manipulation","summary":"本文针对Vision-Language-Action (VLA)模型微调中，现有方法将长时程动作轨迹视为语言序列进行轨迹级优化，导致信用分配粗糙、训练不稳定的问题，提出了Stage-Aware Reinforcement (StARe)模块。该模块将动作轨迹分解为语义阶段，提供密集、可解释的强化信号。基于此，发展了Stage-Aware TPO (StA-TPO)和Stage-Aware PPO (StA-PPO)，并结合Imitation → Preference → Interaction (IPI)序列微调管道。实验在SimplerEnv和ManiSkill3上实现最先进性能，成功率分别达98.0%和96.4%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.05094","title":"From Generated Human Videos to Physically Plausible Robot Trajectories","arxivId":"2512.05094","date":"2025-12-04","authors":"Roei Herzig Team","category":"Manipulation","summary":"本文研究如何利用生成式视频模型作为机器人高级规划器，核心挑战是生成视频存在噪声与形态失真，导致人形机器人难以直接零样本模仿其中的人类动作。为此，作者提出两阶段方法：首先通过4D人体重建模型从视频提取人体运动轨迹并重定向至机器人形态；其次训练GenMimic策略——一种基于3D关键点、采用对称正则化与加权跟踪奖励的物理感知强化学习策略。实验基于合成的GenMimicBench数据集验证，该方法在仿真中优于基线，并在Unitree G1机器人上实现了无需微调的、连贯且物理稳定的零样本运动跟踪。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.05079","title":"Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints","arxivId":"2512.05079","date":"2025-12-04","authors":"Michael Posa Team","category":"Manipulation","summary":"本文解决机器人操作中因遮挡导致物体几何信息不完整、重建困难的问题。核心方法是结合两种互补信息源：基于流匹配3D生成模型的数据驱动形状先验，以及从物理交互中提取的稀疏接触边界约束。通过一种受“拖拽式编辑”启发的接触引导生成框架，将接触信息融入生成过程以消除歧义。实验表明，该方法在合成与真实数据上均优于纯3D生成或仅基于接触优化的方法，实现了更高质量和准确的重建。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04987","title":"Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction","arxivId":"2512.04987","date":"2025-12-04","authors":"Xipeng Qiu Team","category":"Manipulation","summary":"本文旨在解决大语言模型向自主代理转变时，缺乏可扩展基础设施构建高质量交互环境的核心问题。提出统一生态系统Nex，通过NexAU（配置构建复杂代理层次）、NexA4A（自然语言生成多样代理层次）和NexGAP（集成真实环境合成接地轨迹）三个维度提升环境复杂性、多样性和保真度。在SWE-bench和τ²等基准测试中，Nex-N1 consistently outperforms SOTA open-source models and achieves competitive performance frontier proprietary models on complex agentic tasks。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04960","title":"Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies","arxivId":"2512.04960","date":"2025-12-04","authors":"Danica Kragic Team","category":"Manipulation","summary":"本文针对模仿学习获得的视觉运动策略在精度和速度上不及传统控制方法的问题，提出混合扩散模型。核心方法是将开环例程与视觉运动扩散策略相结合，并开发了远程操作增强原语（TAPs），允许演示者无缝执行锁定特定轴、移动至路径点等预定义例程，且模型在推理时能自主触发TAPs。该方法在真实世界的移液、液体转移和容器拧开等任务中得到了验证。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04952","title":"FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via neural Action Tokenization","arxivId":"2512.04952","date":"2025-12-04","authors":"Hang Zhao Team","category":"Manipulation","summary":"本文针对自回归视觉语言动作模型在动作标记化时面临的重建保真度与推理效率的权衡问题，提出FASTer框架。其核心技术包括：1) 可学习的动作标记器FASTerVQ，将动作块编码为单通道图像以捕获时空依赖性；2) 基于此的自回归策略FASTerVLA，采用块状解码与轻量级动作专家。实验表明，该框架在模拟与真实基准测试中，同时实现了更快的推理速度与更高的任务性能，超越了现有先进模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04884","title":"Hoi! – A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation","arxivId":"2512.04884","date":"2025-12-04","authors":"Zuria Bauer Team","category":"Manipulation","summary":"本文针对现有交互数据集在人类活动与机器人操作间存在割裂、缺乏力觉与多视角同步数据的问题，提出了Hoi!多模态数据集。该数据集核心包含3048个交互序列，覆盖381个铰接物体，并首次为每个物体提供四种操作具身（人手、腕戴相机人手、手持UMI夹爪、自定义Hoi!夹爪），同步采集RGB、深度、力觉、触觉及多视角视频。数据集通过标注铰接参数（如开合角度、位移、峰值力），支持跨视角与跨具身的迁移研究，为多模态感知、操作学习及力觉预测等任务提供了基准。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04813","title":"MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation","arxivId":"2512.04813","date":"2025-12-04","authors":"Gao Huang Team","category":"Manipulation","summary":"本文针对机器人模仿学习中因静态数据收集导致空间泛化能力不足的问题，提出MOVE数据收集范式。其核心是在单条演示轨迹中为可移动物体注入运动，从而隐式生成密集多样的空间配置，提升数据效率。实验表明，在需要强空间泛化的模拟任务中，MOVE平均成功率达39.1%，较静态方法（22.2%）相对提升76.1%，并在部分任务上实现2–5倍的数据效率增益。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04731","title":"Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting","arxivId":"2512.04731","date":"2025-12-04","authors":"Xuguang Lan Team","category":"Manipulation","summary":"本文解决机器人操作中模拟到现实（Sim-to-Real）的跨域迁移难题。针对模拟与现实间的视觉差异，提出语义2D高斯泼溅（S2GS）方法，通过构建多视图2D语义场，利用特征级高斯泼溅将其投影至统一3D空间，并过滤无关背景，提取以物体为中心的领域不变特征。实验在ManiSkill仿真环境中进行，并部署至现实场景，结果表明S2GS显著提升了策略在现实世界的泛化性能，实现了高且稳定的任务完成率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04535","title":"GTM: Simulating the World of Tools for AI Agents","arxivId":"2512.04535","date":"2025-12-04","authors":"Jiyan He Team","category":"Manipulation","summary":"本文提出通用工具模型GTM，以解决AI代理直接与多样工具交互训练时成本高、速度慢、开发维护负担重的核心问题。关键技术包括：1）构建15亿参数的GTM作为通用工具模拟器，仅需提示级配置即可模拟工具执行；2）提出上下文感知响应生成（CARG）管道，合成覆盖300个领域、超2万种工具的综合性训练数据。实验表明，GTM在强化学习训练中，模拟速度显著快于真实工具，同时保持可比的输出质量，并展现出优异的泛化与领域适应能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04463","title":"MARL Warehouse Robots","arxivId":"2512.04463","date":"2025-12-04","authors":"Salmon Riaz Team","category":"Manipulation","summary":"本文研究多智能体强化学习在仓库自动化中的协同问题，重点解决稀疏奖励下的协调与信用分配难题。通过比较QMIX（基于价值分解）与IPPO（独立学习）算法，发现QMIX采用超网络混合单调值函数，在CTDE框架下显著优于独立学习。实验表明，QMIX在RWARE环境中平均回报达3.25（IPPO仅0.38），但需超500万步的epsilon退火以应对稀疏奖励。经100万步训练后，智能体在Unity仿真中成功实现稳定包裹配送，但规模扩展至4台以上机器人仍存在挑战。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04446","title":"Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops","arxivId":"2512.04446","date":"2025-12-04","authors":"Minghui Zheng Team","category":"Manipulation","summary":"本文针对报废台式机关键组件（如RAM、CPU）的自动化选择性拆解难题，提出采用端到端的视觉-语言-动作模型。研究通过收集UR5e机器人演示数据集，对OpenVLA和OpenVLA-OFT模型进行微调。实验表明，微调后的VLA模型能可靠完成多个前期拆解步骤，但在某些需高精度操作的子任务上会失败。然而，采用VLA与基于规则控制器结合的混合策略，可成功完成整个拆解流程。这揭示了当前VLA模型在处理精密拆解任务时的局限性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04404","title":"Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation","arxivId":"2512.04404","date":"2025-12-04","authors":"Changju Wu Team","category":"Manipulation","summary":"本文针对动态不确定环境中多机器人自适应协同决策的挑战，提出了交互推理行为树（IIBT）框架。该框架将行为树与基于自由能原则的主动推理相结合，通过扩展IIBT节点引入概率推理，实现分布式在线联合规划与执行。多机器人协作被形式化为自由能最小化过程，机器人基于感知和同伴意图动态更新偏好矩阵以自适应协调。实验表明，IIBT框架将行为树节点复杂度降低超过70%，并在环境不确定性下保持鲁棒、可解释的自适应协作行为。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04399","title":"Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation","arxivId":"2512.04399","date":"2025-12-04","authors":"Hesheng Wang Team","category":"Manipulation","summary":"本论文旨在解决仿生手设计中，如何在保持人手尺寸和15个自由度的前提下，最小化驱动器数量的核心难题。其关键技术是提出了一种新型线缆（肌腱）驱动机制与分布式驱动架构：在前臂布置5个电机提供强力抓握，在手掌集成10个小电机实现精细操作。该设计显著减少了传统线驱系统所需的电机数量。最终系统总重仅1.4千克，实验验证了其兼具出色的灵巧性与强健的抓握能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.04308","title":"ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models","arxivId":"2512.04308","date":"2025-12-03","authors":"Jianwei Zhang Team","category":"Manipulation","summary":"本文提出ResponsibleRobotBench基准，旨在解决当前基于多模态大语言模型（LMM）的机器人系统在复杂高风险环境中缺乏可靠性与安全操作评估标准的核心问题。该基准通过构建包含电气、火灾/化学、人际等多类风险的23个具体任务场景，采用模块化框架支持预定义技能、操作姿态和代码生成等多模态动作表示，并设计细粒度指标评估机器人的风险识别、安全规划与物理执行能力。基准建立了可复现的基线，为推进负责任实体智能的系统化评测提供了统一平台。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03973","title":"Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning","arxivId":"2512.03973","date":"2025-12-03","authors":"Justin Carpentier Team","category":"Manipulation","summary":"本文针对离线强化学习中行为正则化方法无法区分高价值和低价值动作的问题，提出了Guided Flow Policy（GFP）。该方法耦合多步流匹配策略与蒸馏一步行动者，通过加权行为克隆使行动者专注模仿数据集中的高价值动作，流策略则约束行动者与数据集最佳转换对齐并最大化批评者。实验显示，GFP在OGBench、Minari和D4RL基准的144个状态和像素任务中达到最先进性能，在次优数据集和挑战性任务上取得显著提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03911","title":"Autonomous Reinforcement Learning Robot Control with Intel’s Loihi 2 Neuromorphic Hardware","arxivId":"2512.03911","date":"2025-12-03","authors":"Carl Glen Henshaw Team","category":"Manipulation","summary":"本文针对空间与移动机器人面临的功率约束问题，提出一种将强化学习训练的人工神经网络转换为脉冲Sigma-Delta神经网络，并部署至英特尔Loihi 2神经形态硬件的端到端流程。该方法结合了人工神经网络易于训练、仿实转换的优势与脉冲神经网络的高能效特性。以Astrobee自由飞行机器人控制为测试案例，在模拟环境中验证了该流程可实现低延迟、高能效的推理，证明了神经形态硬件用于机器人控制的可行性，为功耗受限环境中的实时控制提供了新途径。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03743","title":"Cross-embodied Co-design for Dexterous Hands","arxivId":"2512.03743","date":"2025-12-03","authors":"Xiaolong Wang Team","category":"Manipulation","summary":"本文针对灵巧操作中机械设计与控制策略分离、协同设计搜索空间巨大的核心问题，提出了一种**跨实体协同设计框架**。该框架的关键在于：1）支持关节、手指、手掌生成的广泛形态搜索空间；2）利用**形态条件化的跨实体控制策略**，实现对庞大设计空间的可扩展评估；3）采用易得组件实现真实制造。实验表明，该框架能实现从设计、训练到实物部署的端到端流程，**可在24小时内完成一款新灵巧手的整个周期**，并在手内旋转等任务中进行了仿真与真实验证。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03724","title":"PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention","arxivId":"2512.03724","date":"2025-12-03","authors":"Mingming Gong Team","category":"Manipulation","summary":"本文针对当前视觉-语言-动作模型在具身任务中生成冗余动作、缺乏精确性的问题，提出PosA-VLA框架。其核心是姿态条件锚点注意力机制，通过姿态条件监督锚定视觉注意力，引导模型聚焦于任务相关区域，从而提升动作生成的精度与效率。该方法基于轻量架构，无需额外感知模块。实验表明，该模型在多种机器人操作基准测试中能更快、更准确地完成任务，例如在抓取任务中比基线模型更早进入成功抓取范围。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03707","title":"ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration","arxivId":"2512.03707","date":"2025-12-03","authors":"Emma Li Team","category":"Manipulation","summary":"本文提出ContactRL框架，解决人机协作中必要物理接触的安全运动规划问题。核心方法是将接触力安全指标直接融入强化学习奖励函数，并采用基于动能的控制屏障函数（eCBF）作为安全护盾。实验表明，该方法在仿真中实现0.2%的安全违规率和87.7%的任务成功率；在真实机器人递送任务中，接触法向力始终低于10N，确保了安全高效的物理协作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03684","title":"A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection","arxivId":"2512.03684","date":"2025-12-03","authors":"Bishakh Bhattacharya Team","category":"Manipulation","summary":"本文提出了一种自主番茄采摘系统，旨在解决复杂环境下对成熟番茄的轻柔、精准抓取与分离问题。核心技术包括：1）结合软性拉胀手指与刚性外骨骼的混合夹持器，实现笼式包覆；2）基于RGB-D相机与Detectron2的视觉管道，通过语义分割识别成熟度，并利用关键点检测定位果梗与果实中心；3）基于虚拟功原理建立伺服扭矩与抓取力的分析模型，并采用PID控制器与力敏电阻实现闭环力控，防止滑脱与损伤；4）利用粒子群优化为5自由度机械臂规划轨迹。实验表明，系统平均采摘周期为24.34秒，总体成功率约80%，且抓取力维持在0.20–0.50 N的低水平。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03556","title":"RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL","arxivId":"2512.03556","date":"2025-12-03","authors":"Yong Li Team","category":"Manipulation","summary":"本文提出RoboScape-R框架，旨在解决传统模仿学习与强化学习在机器人策略跨场景泛化方面的局限性。其核心创新在于利用世界模型作为通用环境代理，并设计了一种基于世界模型的通用奖励机制，该机制从模型学习到的状态转移动力学中生成“内生”奖励。实验表明，该方法为策略训练提供了高效通用的环境，在域外场景下相比基线方法平均性能提升37.5%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03538","title":"AdaPower: Specializing World Foundation Models for Predictive Manipulation","arxivId":"2512.03538","date":"2025-12-03","authors":"Kai Xu Team","category":"Manipulation","summary":"本文提出AdaPower框架，旨在解决世界基础模型生成真实性与机器人控制所需精度之间的差距。通过时空测试时训练实现推理时适配，并利用记忆持久化保证长时程一致性，将通用世界模型转化为专用模型。该框架集成于模型预测控制中，赋能预训练VLA策略，在LIBERO基准上实现任务成功率超过41%的提升，且无需策略重训练，保持了计算效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03444","title":"PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers","arxivId":"2512.03444","date":"2025-12-03","authors":"Minghui Zheng Team","category":"Manipulation","summary":"本文针对神经运动规划器泛化能力受限、网络架构编码效率低的问题，提出PerFACT框架。其核心包含两个关键技术：一是MotionGeneralizer，利用大语言模型（LLM）自动生成语义可行的多样化工作空间，以合成大规模规划数据集；二是融合动作分块变换器网络（MπNetsFusion），通过融合多模态特征提升规划信号编码能力。基于合成的350万条轨迹进行实验，结果表明，所提出的MπNetsFusion在评估任务上的规划速度比现有先进方法快数倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03438","title":"Multimodal Reinforcement Learning with Agentic Verifier for AI Agents","arxivId":"2512.03438","date":"2025-12-03","authors":"Jianfeng Gao Team","category":"Manipulation","summary":"本文针对多模态强化学习（MMRL）中奖励信号稀疏、难以提供细粒度指导的问题，提出了一种名为Argos的智能验证器。该方法的核心是自适应地为每个训练样本从一组教师模型和规则派生的评分函数中选择合适的工具，同时评估最终答案准确性、所指实体与动作的时空定位以及推理过程质量。实验表明，在SFT数据筛选和RL训练中使用Argos，能在空间推理、视觉幻觉及机器人等具身AI任务上取得最先进性能，有效防止训练中智能体崩溃为无根据的解决方案，并减少奖励黑客行为。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03422","title":"What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models","arxivId":"2512.03422","date":"2025-12-03","authors":"Weidong Chen Team","category":"Manipulation","summary":"本论文核心问题是探讨机器人学中最优的3D场景表示方法。全面综述了传统几何表示（如点云、体素、SDF）与神经表示（如NeRF、3DGS）以及新兴基础模型，指出传统稀疏表示主导当前SLAM与定位，而神经表示能集成语义特征和语言先验，提升场景理解与智能。通过比较感知、建图等五大模块中的优缺点，论文预测3D基础模型可能成为未来统一解决方案，但完全实现仍面临挑战。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03347","title":"GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation","arxivId":"2512.03347","date":"2025-12-03","authors":"Nima Fazeli Team","category":"Manipulation","summary":"本文针对模仿学习（IL）在精确操作任务中因累积误差导致轨迹精度不足的核心问题，提出了**抓取物体流形投影（GrOMP）**方法。该方法通过从专家演示中学习一个低维任务空间流形，并将IL策略产生的轨迹投影到该流形上，以消除与流形正交的累积误差。关键技术包括基于主测地线分析（PGA）构建流形，并引入基于多臂老虎机的交互式组件进行流形选择优化。论文在四个使用触觉反馈的真实机器人精确装配任务上验证了该框架。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03044","title":"Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling","arxivId":"2512.03044","date":"2025-12-02","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"本文提出Video2Act，解决现有视频扩散模型（VDM）用于机器人策略学习时，未能充分利用其帧间连贯且物理一致的运动表示的问题。方法上，设计异步双系统：慢系统（VDM）显式提取前景边界与帧间运动变化，过滤背景噪声；快系统（扩散变换器动作头）接收上述运动感知条件，实现高频稳定控制。实验表明，Video2Act在模拟和真实任务中的平均成功率分别超越之前最佳方法7.7%和21.7%，并展现出强泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.03028","title":"SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control","arxivId":"2512.03028","date":"2025-12-02","authors":"Xue Bin Peng Team","category":"Manipulation","summary":"本文针对物理角色控制中运动先验模型可重用性差的问题，提出SMP方法。该方法基于预训练的运动扩散模型与分数蒸馏采样技术，构建可冻结复用的任务无关运动先验。实验表明，该方法生成的运动质量与当前最优对抗模仿方法相当，且通用先验可转化为多种风格先验，并能组合风格合成新动作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.02951","title":"Experimental Characterization of Fingertip Trajectory following for a 3-DoF Series-Parallel Hybrid Robotic Finger","arxivId":"2512.02951","date":"2025-12-02","authors":"Nilanjan Chakraborty Team","category":"Manipulation","summary":"本文针对紧凑型多自由度机器人手指在任务空间轨迹精确跟踪方面研究不足的核心问题，提出并实验表征了一种3自由度串并联混合连杆驱动手指。该手指具有解析正向运动学与封闭形式雅可比矩阵，关键技术是采用解析运动速率控制方案实现闭环任务空间轨迹跟踪。实验结果表明，该手指在直线、圆形及复杂曲线等多种轨迹上均能实现毫米级的指尖跟踪精度，为灵巧手内操作提供了重要的性能基准。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.02851","title":"SwarmDiffusion: End-To-End Traversability-Guided Diffusion for Embodiment-Agnostic Navigation of Heterogeneous Robots","arxivId":"2512.02851","date":"2025-12-02","authors":"Dzmitry Tsetserukou Team","category":"Manipulation","summary":"本文解决现有视觉导航方法依赖手工提示、泛化性差且规划速度慢的问题，提出SwarmDiffusion模型。该模型是一种端到端扩散模型，通过免规划器的轨迹构建流程（随机航点采样、贝塞尔平滑与正则化），并利用VLM监督和紧凑的机器人状态调节，直接从单张RGB图像联合预测可通行性并生成可行轨迹。实验表明，该方法在室内环境及不同机器人平台上实现了80-100%的导航成功率，推理仅需0.09秒，且仅用500个样本即可适应新机器人。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.02787","title":"Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols","arxivId":"2512.02787","date":"2025-12-02","authors":"Yong-Lu Li Team","category":"Manipulation","summary":"本文针对VLA模型在机器人操作中失败诊断和学习能力有限、且现有失败数据集仿真生成导致泛化不足的问题，提出ViFailback框架。该框架利用显式视觉符号高效标注真实失败数据，构建包含58,126个VQA对的大规模ViFailback数据集和ViFailback-Bench基准。基于此训练ViFailback-8B VLM模型，在基准测试中实现显著性能提升，并能生成视觉符号提供纠正指导。真实机器人实验表明，集成该模型可有效辅助VLA模型从失败中恢复。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.02729","title":"RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning","arxivId":"2512.02729","date":"2025-12-02","authors":"Haoqian Wang Team","category":"Manipulation","summary":"本文提出RoboWheel数据引擎，旨在解决机器人学习数据依赖高成本遥操作、缺乏多样性且难以跨形态迁移的问题。其核心方法是通过单目RGB(D)视频重建高精度手物交互轨迹，利用强化学习优化器在接触与穿透约束下确保物理合理性，随后将轨迹重定向至不同形态机器人，并通过仿真增强进行领域随机化以扩展数据分布。实验表明，该引擎生成的轨迹与遥操作数据同样稳定，能持续提升机器人性能，首次定量验证了手物交互视频可作为机器人学习的有效监督信号。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.02609","title":"SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction","arxivId":"2512.02609","date":"2025-12-02","authors":"Yong Zhao Team","category":"Manipulation","summary":"本文针对机器人模仿学习中抓取任务的多模态冲突问题，提出SAM2Grasp框架。核心方法是将任务重构为单模态的提示条件预测问题：利用冻结的SAM2模型提取时序视觉特征，并并行训练一个轻量级动作头。推理时，通过初始提示（如边界框）指定目标物体，动作头即可预测针对该物体的唯一抓取轨迹，SAM2的时序跟踪能力确保后续帧中目标的稳定跟踪。实验表明，该方法在杂乱多物体抓取任务中取得了最先进的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.02020","title":"EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI","arxivId":"2512.02020","date":"2025-12-01","authors":"Xiangyu Xu Team","category":"Manipulation","summary":"本文提出EfficientFlow框架，解决具身AI中生成策略数据效率低（需大量演示）和采样效率低（推理慢）的问题。关键技术包括：将等变性引入流匹配，使用各向同性高斯先验和等变速度预测网络，确保动作分布等变性以提升泛化、减少数据需求；并提出加速正则化策略，通过替代损失加速采样。实验表明，在多个机器人操作基准测试中，该框架在有限数据下达到竞争或更优性能，且推理速度显著提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.02013","title":"ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation","arxivId":"2512.02013","date":"2025-12-01","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型在乐高组装等长时程任务中难以协调高层规划与精细操作的难题，提出统一框架ManualVLA。其关键技术包括：基于混合Transformer架构，设计规划专家生成多模态操作手册，并通过Manual Chain-of-Thought将手册显式与隐式信息输入动作专家以指导执行。实验表明，该模型在乐高组装与物体重排任务上平均成功率比之前最佳分层基线提升32%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01996","title":"Learning Sim-to-Real Humanoid Locomotion in 15 Minutes","arxivId":"2512.01996","date":"2025-12-01","authors":"Pieter Abbeel Team","category":"Manipulation","summary":"本文针对人形机器人从仿真到现实（sim-to-real）的控制策略训练耗时过长、难以快速迭代的问题，提出了一种基于离策略强化学习算法（FastSAC/FastTD3）的简单高效方案。该方法通过大规模并行仿真、精心调校的设计与极简奖励函数，实现了在单张RTX 4090 GPU上仅用**15分钟**即可完成稳健运动策略的训练。实验表明，该方案能在包含随机动力学、崎岖地形及外力扰动等强域随机化条件下，成功部署于Unitree G1与Booster T1机器人，并快速学习全身运动跟踪策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01946","title":"Guardian: Detecting Robotic Planning and Execution Errors with Vision-Language Models","arxivId":"2512.01946","date":"2025-12-02","authors":"Cordelia Schmid Team","category":"Manipulation","summary":"本文针对机器人操作中缺乏全面失败数据、导致视觉语言模型（VLM）失败检测准确性受限的核心问题，提出自动失败合成方法：通过扰动成功轨迹，生成多样化的规划与执行失败案例，并构建三个新基准数据集（RLBench-Fail等）。基于此训练了多视图VLM模型Guardian，用于细粒度失败推理与检测。实验表明，Guardian在现有及新基准上均达到最优性能，集成后能有效提升仿真与真实机器人的任务成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01924","title":"Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model","arxivId":"2512.01924","date":"2025-12-01","authors":"Shingo Murata Team","category":"Manipulation","summary":"本文解决真实世界机器人控制中目标导向与探索性动作的平衡问题。提出了一种新的深度主动推理框架，其核心包括：1）世界模型，在快慢双时间尺度编码环境动态；2）动作模型，通过向量量化将动作序列压缩为抽象动作；3）抽象世界模型，基于抽象动作预测未来慢状态，以实现低成本动作选择。在真实机器人物体操作任务上的实验表明，该框架在多种任务中取得高成功率，能在不确定环境下切换目标与探索行为，并显著提升了动作选择的计算效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01908","title":"SARL: Spatially-Aware Self-Supervised Representation Learning for Visuo-Tactile Perception","arxivId":"2512.01908","date":"2025-12-01","authors":"Dandan Zhang Team","category":"Manipulation","summary":"本文针对接触丰富的机器人操作任务，提出SARL空间感知自监督表征学习框架。核心问题是现有自监督方法将特征图压缩为全局向量，丢失了对操作至关重要的空间结构信息。SARL在BYOL架构基础上，引入三个作用于特征图的空间感知损失（SAL、PPDA、RAM），以保持跨视图的注意力焦点、部件构成和几何关系一致性。在融合视觉-触觉数据上的实验表明，SARL在六个下游任务上均优于九个基线方法；在边姿态回归任务中，其平均绝对误差为0.3955，较次优方法（0.5682）相对提升30%，接近有监督学习上限。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01801","title":"GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation","arxivId":"2512.01801","date":"2025-12-02","authors":"Yonghui Wu Team","category":"Manipulation","summary":"GR-RL旨在解决现有视觉-语言-动作策略在长视野、高精度灵巧操纵任务中因依赖次优人类演示而性能不足的问题。其核心技术包括：基于离线强化学习的进度过滤、形态对称性增强和在线强化学习的噪声预测，以优化演示并提升策略精度。实验表明，GR-RL在自主穿鞋带任务中达到83.3%的成功率，实现了毫米级控制和长视野推理。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01773","title":"IGen: Scalable Data Generation for Robot Learning from Open-World Images","arxivId":"2512.01773","date":"2025-12-01","authors":"Zhi Wang Team","category":"Manipulation","summary":"本文针对开放世界图像缺乏机器人动作数据、难以直接用于策略训练的问题，提出IGen数据生成框架。该框架首先将2D图像转换为结构化3D场景表示，进而利用视觉语言模型进行任务推理，生成SE(3)末端执行器姿态序列作为动作，并合成动态、时序一致的视觉观察。实验验证，IGen能生成高质量的视觉-动作数据，仅使用其合成数据训练的策略，在真实场景中取得了与使用真实数据训练的策略相当的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01715","title":"DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models","arxivId":"2512.01715","date":"2025-12-01","authors":"Zongqing Lu Team","category":"Manipulation","summary":"论文提出DiG-Flow框架，解决视觉-语言-动作（VLA）模型在分布偏移和复杂多步骤任务上性能下降、表示语义不鲁棒的问题。其关键技术是差异引导的流匹配：通过计算观察与动作嵌入的经验分布差异，映射为调制权重，并在流匹配前对观察嵌入进行残差更新，实现几何正则化。实验表明，该方法能以可忽略开销集成到现有VLA架构，持续提升性能，在复杂多步骤任务和有限训练数据下增益尤其显著。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01629","title":"SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge","arxivId":"2512.01629","date":"2025-12-01","authors":"Chenfanfu Jiang Team","category":"Manipulation","summary":"本文提出SPARK框架，解决从单张RGB图像重建仿真就绪铰接物体的难题，克服传统方法依赖专家建模、劳动密集的瓶颈。核心技术融合视觉语言模型提取粗粒度URDF参数与部件图像，并集成扩散transformer生成几何一致的部件与整体形状；进一步通过可微分前向运动学与渲染优化关节类型、轴心和原点。实验表明，SPARK能够生成高质量、跨类别的仿真就绪铰接资产，支持机器人操控等下游应用。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01598","title":"A Cross-Embodiment Gripper Benchmark for Rigid-Object Manipulation in Aerial and Industrial Robotics","arxivId":"2512.01598","date":"2025-12-01","authors":"Ivan Virgala Team","category":"Manipulation","summary":"本文针对现有抓取器基准（如YCB）无法评估跨平台复用性与能耗的问题，提出了跨平台抓取器基准CEGB。该基准在传统指标基础上，新增了**转移时间、能耗和理想负载评估**三个核心组件，以量化抓取器在不同机器人平台（如协作臂、无人机）间的适配性。基于一个轻型自锁抓取器原型的实验表明，该基准能有效评估性能：**跨平台转移中位时间约17.6秒，保持能耗约1.5焦耳/10秒，抓取成功率超90%且周期时间为3.2–3.9秒**，为空中与工业机器人的抓取器提供了可复现的跨平台、能耗感知评估基础。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01446","title":"$\\mathbf{M^3A}$ Policy: Mutable Material Manipulation Augmentation Policy through Photometric Re-rendering","arxivId":"2512.01446","date":"2025-12-01","authors":"Jianfei Yang Team","category":"Manipulation","summary":"本文提出M³A策略，解决机器人操作中因物体材料（如玻璃、金属）的透明或反光特性导致的视觉域偏移和泛化难题。核心方法是通过光度重渲染技术，仅凭单次真实演示，即可生成具有不同材料属性的高度逼真演示数据，从而将操作技能与表面外观解耦。实验表明，该方法在三个真实任务中将平均成功率提升58.03%，并能有效泛化至未见过的材料。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01358","title":"Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1","arxivId":"2512.01358","date":"2025-12-01","authors":"Songhwai Oh Team","category":"Manipulation","summary":"本文针对基础机器人策略在跨具身操作中因模态缺失（如接触和深度信息）导致的性能局限，提出模态增强微调框架。方法包括：在GR1上通过后处理添加二进制接触信号与ZoeDepth深度；在G1上构建多模态数据集，集成cuRobo运动规划与真实接触力测量。实验显示，GR1成功率从51%提升至63%；G1“取苹果入碗”任务中，零射击成功率为0%，标准微调达48%，而接触增强模型最高达到94%，验证了模态增强对跨具身泛化的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01336","title":"Discovering Self-Protective Falling Policy for Humanoid Robot via Deep Reinforcement Learning","arxivId":"2512.01336","date":"2025-12-01","authors":"Donglin Wang Team","category":"Manipulation","summary":"本文针对人形机器人在跌倒时容易损坏的核心问题，提出通过深度强化学习发现自我保护的跌倒策略。关键技术采用深度强化学习方法，通过设计奖励函数和策略优化，训练机器人学习主动调整姿态以减少冲击。实验验证表明，该方法能有效提升机器人的跌倒安全性，降低硬件损伤风险。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01188","title":"Real-World Reinforcement Learning of Active Perception Behaviors","arxivId":"2512.01188","date":"2025-12-01","authors":"Dinesh Jayaraman Team","category":"Manipulation","summary":"本文针对机器人在部分可观测环境下难以通过标准学习技术生成主动感知行为的问题，提出了非对称优势加权回归（AAWR）方法。该方法利用训练时可用的“特权”额外传感器，训练高质量特权价值函数以估计策略优势，并从少量次优演示与粗略策略初始化进行引导。实验表明，AAWR在3种机器人、8个操作任务上优于所有现有方法，能高效生成信息收集行为，使机器人在严重部分可观测条件下有效操作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2512.01061","title":"Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer","arxivId":"2512.01061","date":"2025-11-30","authors":"Yuke Zhu Team","category":"Manipulation","summary":"由于您未提供论文正文内容，我无法基于具体研究内容生成总结。请提供论文的正文部分，我将严格根据您的要求，准确提炼其核心问题、方法要点及实验结论，并确保内容真实、简洁。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.23407","title":"From CAD to POMDP: Probabilistic Planning for Robotic Disassembly of End-of-Life Products","arxivId":"2511.23407","date":"2025-11-28","authors":"Jürgen Fleischer Team","category":"Manipulation","summary":"本文针对报废产品拆卸中产品状态不确定性问题，提出将拆卸建模为部分可观察马尔可夫决策过程（POMDP），以处理因磨损、腐蚀等导致的模型偏差。关键技术包括从CAD数据自动生成POMDP模型的框架，以及基于强化学习和贝叶斯滤波的近似规划方法。实验在三个产品和两个机器人系统上验证，该概率规划框架在平均拆卸时间和方差上优于确定性基线，能泛化到不同机器人设置并成功适应零件缺失或卡住等偏差。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.23300","title":"SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot","arxivId":"2511.23300","date":"2025-11-28","authors":"Dzmitry Tsetserukou Team","category":"Manipulation","summary":"本文提出SafeHumanoid系统，解决人形机器人在人机交互中根据场景上下文和人类接近度自适应调节上肢阻抗和速度以实现安全交互的核心问题。关键技术采用VLM-RAG驱动的视觉管道：通过视觉语言模型处理自我中心图像，结合检索增强生成匹配验证场景数据库，经逆运动学映射生成关节阻抗命令。实验在桌面操作任务（如擦拭、物体传递、液体倾倒）中进行，结果表明系统能上下文感知地调整刚度、阻尼和速度，在保持任务成功率的同时提升安全性，但当前推理延迟高达1.4秒，限制了高动态环境的响应性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.23186","title":"Obstruction reasoning for robotic grasping","arxivId":"2511.23186","date":"2025-11-28","authors":"Fabio Poiesi Team","category":"Manipulation","summary":"本文针对杂乱环境中机器人抓取需预先清除障碍的问题，提出UNOGrasp模型。该模型基于视觉语言进行多步障碍推理，通过目标物体产生的障碍路径、障碍感知视觉线索以及结合监督与强化学习的微调方法，推断抓取序列。实验表明，UNOGrasp在合成与真实环境中显著提升了障碍推理与抓取成功率，优于现有通用及专用模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.23034","title":"LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models","arxivId":"2511.23034","date":"2025-11-28","authors":"Jianlong Fu Team","category":"Manipulation","summary":"本文提出LatBot框架，解决现有潜在动作模型因忽视物理先验而泛化性能受限的问题。方法核心为通用潜在动作学习：以任务指令和多帧图像为输入，同时优化未来帧重建与动作序列预测，并引入动作预测（如夹爪轨迹与朝向）以学习物理先验。技术关键是将潜在动作分解为运动令牌与场景令牌，以区分机器人主动运动与环境变化。实验表明，该方法在仿真与真实机器人任务中均表现优异，仅需每个任务10条真实轨迹即可完成全部五项挑战性任务，证明了强大的少样本迁移能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.22963","title":"Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary","arxivId":"2511.22963","date":"2025-11-28","authors":"Jingya Wang Team","category":"Manipulation","summary":"本文针对仿人机器人难以根据自由形式语言指令执行全身动作的核心问题，提出Humanoid-LLA大型语言动作模型。方法包括：统一运动词汇表对齐人类与机器人运动基元到共享离散空间；词汇指导控制器从特权策略蒸馏确保物理可行性；物理感知强化学习微调提升鲁棒性。实验在仿真和真实Unitree G1机器人上验证，该模型在保持高物理保真度的同时，实现了强语言泛化，在运动自然性、稳定性和执行成功率方面优于现有语言条件控制器。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.22780","title":"Distracted Robot: How Visual Clutter Undermine Robotic Manipulation","arxivId":"2511.22780","date":"2025-11-27","authors":"Xuan Zhao Team","category":"Manipulation","summary":"本文针对视觉杂乱削弱机器人操作性能的核心问题，提出一种基于心理物理学的统一杂乱度量方法，综合考虑干扰物数量、特征和排列，在超真实模拟和现实世界中系统评估视觉-语言-动作（VLA）模型。实验表明，场景杂乱使策略性能下降高达34%，不同VLA策略存在独特脆弱性且成功场景一致性低；杂乱度量是性能下降的有效指标，微调增强数据不能完全消除所有负面影响。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.22777","title":"Improving Robotic Manipulation Robustness via NICE Scene Surgery","arxivId":"2511.22777","date":"2025-11-27","authors":"Amir Rasouli Team","category":"Manipulation","summary":"本文针对机器人模仿学习中因视觉干扰物导致的分布外（OOD）性能下降问题，提出NICE框架。该方法利用图像生成与大型语言模型，对现有演示场景进行对象替换、重风格化及干扰物移除三种编辑，以低成本增强视觉多样性。实验表明，NICE能有效缩小OOD差距：在高度杂乱场景中，空间可供性预测准确率提升超20%；操作任务在干扰环境下的平均成功率提高11%，目标混淆率降低6%，碰撞率减少7%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.22773","title":"CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance","arxivId":"2511.22773","date":"2025-11-27","authors":"Amir Rasouli Team","category":"Manipulation","summary":"本文提出CAPE框架，解决扩散模型在机器人避障任务中因训练数据不足导致的轨迹分布模式覆盖有限、泛化能力差的问题。核心方法是通过“近端模式扩展”和先验种子迭代引导精化，在执行中利用上下文感知的轨迹先验，迭代进行引导去噪，从而扩展轨迹分布模式，生成更平滑、无碰撞的轨迹。在模拟和真实世界杂乱未知环境中的实验表明，该方法相比SOTA方法将成功率分别提升了26%和80%，显著改善了在未见环境中的泛化性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.22555","title":"Beyond Success: Refining Elegant Robot Manipulation from Mixed-Quality Data via Just-in-Time Intervention","arxivId":"2511.22555","date":"2025-11-27","authors":"Meibao Yao Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型因混合质量演示数据导致执行质量不稳定的问题，提出通过即时干预（JITI）机制提升机器人操作的优雅性。方法包括建立LIBERO-Elegant基准以明确评估标准，训练优雅批评器通过离线校准Q学习估计动作质量，推理时JITI监控置信度并选择性干预关键决策。实验表明，优雅批评器能显著提高执行质量，即使对未见任务也有效，实现了更注重执行方式的机器人控制。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.22505","title":"RealD $^2$ iff: Bridging Real-World Gap in Robot Manipulation via Depth Diffusion","arxivId":"2511.22505","date":"2025-11-27","authors":"Jianhua Sun Team","category":"Manipulation","summary":"本文针对机器人操作中模拟环境与真实世界之间的性能差距问题，提出RealD^2 iff方法，通过深度扩散技术生成逼真深度数据来弥合差距。关键技术包括基于扩散模型的深度数据合成与增强，以提升机器人感知能力。实验表明，该方法能有效改善真实场景中的操作精度和鲁棒性，但具体性能提升数据需参考论文正文详述。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.22445","title":"Visual-Geometry Diffusion Policy: Robust Generalization via Complementarity-Aware Multimodal Fusion","arxivId":"2511.22445","date":"2025-11-27","authors":"Jitendra Malik Team","category":"Manipulation","summary":"本文针对模仿学习策略在空间与视觉随机化下泛化能力弱、易过拟合的核心问题，提出了Visual-Geometry Diffusion Policy (VGDP)。其关键技术是互补感知融合模块，通过模态级丢弃强制策略平衡利用RGB与点云线索，并以交叉注意力作为轻量交互层。实验表明，该方法在18个模拟任务和4个真实任务上平均性能提升39.1%，在视觉与空间扰动下的鲁棒性分别平均提升41.5%和15.2%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.22415","title":"Exposing Vulnerabilities in RL: A Novel Stealthy Backdoor Attack through Reward Poisoning","arxivId":"2511.22415","date":"2025-11-27","authors":"Junfeng Wu Team","category":"Manipulation","summary":"本文揭示了强化学习（RL）因依赖奖励信号而面临的安全漏洞，提出了一种通过在训练阶段投毒奖励信号来植入隐蔽后门的攻击方法。其核心技术是一种基于奖励扰动网络和Q值网络的算法，能在保证攻击有效性的同时，最小化对正常奖励数据的扰动，从而确保隐蔽性。在Hopper和Walker2D环境中的实验表明，该攻击具有极强的隐蔽性（正常场景性能仅下降2.18%和4.59%）与高破坏性（触发后性能最大下降82.31%和71.27%），对RL系统的安全构成了严重威胁。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.22364","title":"BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands","arxivId":"2511.22364","date":"2025-11-27","authors":"Jonghyun Choi Team","category":"Manipulation","summary":"根据论文标题“BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands”，该研究旨在解决移动操作机器人如何即时适应新任务并通过开放词汇自然语言命令进行灵活控制的核心问题。关键技术方法BINDER聚焦于结合自适应算法与开放词汇理解，以实现机器人的快速响应和交互。然而，由于未提供论文正文内容，无法提炼具体技术要点或给出实验结论及性能提升数据，建议补充正文以完成精准总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.22195","title":"3D Affordance Keypoint Detection for Robotic Manipulation","arxivId":"2511.22195","date":"2025-11-27","authors":"Marcelo H Ang Team","category":"Manipulation","summary":"本文针对机器人操作中affordance检测的局限性：传统方法仅将其视为语义分割任务，只能回答“对象有何功能”（what），而无法提供“操作位置”（where）和“执行方式”（how）的关键信息。为此，提出融合式affordance关键点网络（FAKP-Net），通过引入3D关键点四元组，协同利用RGB与深度图像，直接预测执行位置、方向及范围。基准测试表明，FAKP-Net在affordance分割和关键点检测任务上均显著优于现有模型；真实世界实验验证了该方法对未见物体的操作可靠性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.21690","title":"TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos","arxivId":"2511.21690","date":"2025-11-26","authors":"Furong Huang Team","category":"Manipulation","summary":"本文提出TraceGen，解决机器人难以从少量演示中学习新任务的问题。核心方法是构建3D轨迹空间（trace-space）作为统一符号表示，并开发TraceGen世界模型在该空间预测运动，以及TraceForge数据管道将异构视频转换为轨迹数据。实验表明，仅用5个目标机器人视频，模型在4项任务上达到80%成功率，推理速度比现有视频世界模型快50-600倍；仅用5个手机拍摄的人类演示视频，在真实机器人上仍能实现67.5%的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.21557","title":"VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation","arxivId":"2511.21557","date":"2025-11-26","authors":"Shaoshuai Shi Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型中末端执行器（两指夹爪）在处理如擦拭玻璃、开无把手抽屉等任务时因接触面积不足或缺乏粘附力而受限的核心问题，提出VacuumVLA：一种低成本集成硬件设计，统一吸盘与夹持工具。关键技术方法为结合机械夹爪和真空吸盘，实现吸持与抓取双模式灵活切换或协同使用。在DexVLA和π0框架下实验验证，机器人成功执行了多个传统两指夹爪无法完成的复杂任务，扩展了VLA系统的实操能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.21542","title":"$\\mathcal{E}_0$ : Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion","arxivId":"2511.21542","date":"2025-11-26","authors":"Guangrun Wang Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型在多样化任务、场景和视角下泛化能力不足，以及生成动作粗糙或不稳定的问题，提出了ℰ₀框架。其核心技术是**连续化离散扩散方法**，将动作生成建模为对**量化动作令牌的迭代去噪**过程，并引入了**球面视角扰动增强**以提升对摄像机偏移的鲁棒性。实验表明，ℰ₀在LIBERO等14个环境中实现了最先进性能，**平均超越强基线10.7%**，并在真实机器人上验证了其精确、鲁棒和可迁移的操控能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.21366","title":"Hybrid Control for Robotic Nut Tightening Task","arxivId":"2511.21366","date":"2025-11-26","authors":"Dmitri Kovalenko Team","category":"Manipulation","summary":"本文针对机器人自主拧螺母这一复杂装配任务，提出一种混合控制系统。核心问题是解决传统方法难以处理的、需精细控制接触力的操作。关键技术采用基于分层运动基元的规划器，以及力控制与位置控制交替切换的控制方案。实验表明，该系统对初始条件变化具有鲁棒性，与基线方法相比，拧紧速度提升14%，同时对操作对象施加的接触力降低了40倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.21264","title":"Sampling-Based Optimization with Parallelized Physics Simulator for Bimanual Manipulation","arxivId":"2511.21264","date":"2025-11-26","authors":"Arun Kumar Singh Team","category":"Manipulation","summary":"本文针对基于学习的双手操作方法在杂乱新场景中泛化能力差的问题，提出一种基于采样的优化框架。核心技术是采用定制化的模型预测路径积分控制（MPPI）算法，结合任务特定代价函数，并利用GPU加速的MuJoCo物理模拟器高效评估交互。该方法成功解决了PerAct 2基准中更具挑战的任务（如带障碍的球体点对点转移），在商用GPU上实现了实时性能，并完成了仿真到现实的迁移。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.21192","title":"When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models","arxivId":"2511.21192","date":"2025-11-26","authors":"Xudong Jiang Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型在未知架构、微调变体及仿真到现实迁移等黑盒场景下，现有对抗补丁攻击过拟合单一模型、缺乏通用性与迁移性的问题，提出了一种通用可迁移补丁攻击框架UPA-RFAS。该框架通过在共享特征空间中学习单一物理补丁，融合特征空间目标、鲁棒性增强的两阶段最小最大优化，以及针对VLA的补丁注意力主导与补丁语义失配损失，以提升跨模型迁移能力。实验表明，UPA-RFAS生成的补丁能够持续在不同模型、任务及视角间有效迁移，为VLA模型的安全性评估建立了强基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.21169","title":"Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation","arxivId":"2511.21169","date":"2025-11-26","authors":"Qijun Chen Team","category":"Manipulation","summary":"本文针对人形机器人在高负载工业场景中需同时具备灵巧操作和主动力交互能力的挑战，提出一种基于强化学习的解耦三阶段训练框架。该框架包含上半身策略、下半身策略和增量命令策略：上半身策略通过嵌入前向运动学先验的启发式奖励函数加速收敛；下半身策略采用基于力的课程学习实现主动力调节；增量命令策略抵消下半身运动引起的末端位移以保障全身协调。在Unitree G1机器人上的实验表明，该方法能完成携带4公斤物体行走、推动总负载112.8公斤推车等高负载任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.21161","title":"MarketGen: A Scalable Simulation Platform with Auto-Generated Embodied Supermarket Environments","arxivId":"2511.21161","date":"2025-11-26","authors":"Zhaoxiang Zhang Team","category":"Manipulation","summary":"本文提出了MarketGen，一个面向复杂超市环境的可扩展模拟平台，旨在解决现有机器人数据集与基准测试局限于家庭或桌面短视程任务的不足。平台核心采用了一种新颖的基于智能体的程序化内容生成框架，支持文本和参考图像等多模态输入，并融合真实世界设计原则，以自动生成完整、结构化且逼真的超市场景。平台提供了一个包含1100多种商品的3D资产库，并设立了包含收银卸货和通道内商品收集两项日常任务的新基准。实验验证了平台的可行性与模拟到现实的迁移能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.21149","title":"Maglev-Pentabot: Magnetic Levitation System for Non-Contact Manipulation using Deep Reinforcement Learning","arxivId":"2511.21149","date":"2025-11-26","authors":"Zongfu Yu Team","category":"Manipulation","summary":"本文针对宏观尺度非接触操纵技术受限于微观尺度（毫克级物体）的问题，提出了Maglev-Pentabot磁悬浮系统。该系统利用深度强化学习（DRL）开发控制策略，通过数值分析优化电磁铁排列以最大化可控空间，并引入动作重映射方法解决磁场强非线性导致的样本稀疏问题，使DRL控制器收敛。实验表明，系统能灵活操纵克重物体，并可泛化到未经训练的运输任务；通过使用更大电磁铁，该方法可扩展至更重物体，为工业机器人应用提供参考框架。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.21135","title":"SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation","arxivId":"2511.21135","date":"2025-11-26","authors":"Yu Zhang Team","category":"Manipulation","summary":"本文提出SocialNav，一个用于社会意识具身导航的基础模型。核心问题是现有导航方法忽视社会合规性，导致机器人行为可能违反社交规范（如穿越草坪）。模型采用分层“大脑-行动”架构：大脑模块基于视觉语言模型理解社会规范并生成思维链解释；行动专家基于条件流匹配生成合规轨迹。通过多阶段训练（模仿学习与SAFE-GRPO强化学习框架）注入社交智能。实验表明，相比现有最佳方法，成功率提升38%，社会合规率提升46%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.20887","title":"ACE-F: A Cross Embodiment Foldable System with Force Feedback for Dexterous Teleoperation","arxivId":"2511.20887","date":"2025-11-25","authors":"Xiaolong Wang Team","category":"Manipulation","summary":"本文提出ACE-F系统，旨在解决现有遥操作平台缺乏集成力反馈、跨形态通用性差且硬件笨重的问题。关键技术包括：通过监测末端轨迹偏差生成虚拟力反馈，无需额外传感器；结合逆运动学与手套追踪实现通用末端重定向算法；融合PD控制与逆动力学的软控制器管道确保安全与精确控制。实验表明，该系统能显著简化多种机器人的控制，使灵巧操作任务如使用鼠标般直观，用户可快速适应并准确完成跨平台遥操作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.20848","title":"NOIR 2.0: Neural Signal Operated Intelligent Robots for Everyday Activities","arxivId":"2511.20848","date":"2025-11-25","authors":"Alex Hodges Team","category":"Manipulation","summary":"本文提出了NOIR 2.0系统，旨在解决脑控机器人系统中解码速度慢、准确性低以及机器人学习需要大量演示数据的问题。该系统采用了更快速准确的脑解码算法，以及基于基础模型的少样本机器人学习算法，能够从极少量演示中预测用户意图。核心实验表明，该系统使任务完成时间减少46%，整体人力时间节省65%，并将预测意图所需的演示从15次大幅降至1次。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.20841","title":"OVAL-Grasp: Open-Vocabulary Affordance Localization for Task Oriented Grasping","arxivId":"2511.20841","date":"2025-11-25","authors":"Odest Chadwicke Jenkins Team","category":"Manipulation","summary":"本文提出OVAL-Grasp方法，解决机器人在开放场景中根据语言任务抓取物体正确部位的问题。该方法采用零样本开放词汇范式，结合大语言模型（LLM）识别任务相关部件，利用视觉语言模型（VLM）进行部件分割，并生成物体可操作区域的2D热图。实验表明，该方法在真实机器人测试中正确识别部件成功率达95%，抓取正确可操作区域成功率为78.3%；在遮挡场景下部件选择成功率为80%，优于现有基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.20593","title":"Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning","arxivId":"2511.20593","date":"2025-11-25","authors":"Abdalla Swikir Team","category":"Manipulation","summary":"本文针对从演示中学习安全稳定的机器人运动规划这一挑战，提出S²-NNDS框架。该方法的核心是同时学习神经网络的动力学系统、神经李雅普诺夫稳定性证书与屏障安全证书，利用神经网络捕捉复杂运动，并通过分裂保形预测提供概率安全保证。实验在LASA手写数据集和Franka机器人演示等2D/3D任务中验证，该方法能从潜在不安全的演示中有效学习出鲁棒、安全且稳定的运动。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.20299","title":"How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks","arxivId":"2511.20299","date":"2025-11-25","authors":"Joost C. Dessing Team","category":"Manipulation","summary":"根据提供的论文标题，本论文的核心问题是研究机器人运动学（如速度、轨迹等参数）如何影响人类在虚拟机器人到人手交接任务中的表现，例如交接效率、错误率或用户体验。然而，由于未提供论文正文内容，无法准确提炼关键技术方法的名称、要点以及核心实验结论或性能提升数据。建议补充论文正文以获取更精准的总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.20275","title":"HAFO: Humanoid Force-Adaptive Control for Intense External Force Interaction Environments","arxivId":"2511.20275","date":"2025-11-25","authors":"Bin He Team","category":"Manipulation","summary":"本文针对人形机器人在强外力交互环境中运动控制不鲁棒、不精确的核心问题，提出HAFO框架。其关键技术是采用双智能体强化学习，通过耦合训练同时优化鲁棒的下肢运动与精确的上肢操作策略，并利用约束残差动作空间提升训练效率。核心创新在于引入弹簧阻尼系统显式建模外力扰动，使策略能通过操控虚拟弹簧实现精细的力适应。实验表明，该单一策略能实现全身控制，在负重、推力扰动及绳索悬吊等多种强交互场景中均表现出色且保持稳定。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.20095","title":"WPT: World-to-Policy Transfer via Online World Model Distillation","arxivId":"2511.20095","date":"2025-11-25","authors":"Xu Yan Team","category":"Manipulation","summary":"论文WPT解决现有世界模型方法因运行时耦合紧密或依赖离线奖励导致的推理开销大、端到端优化困难问题。提出World-to-Policy Transfer训练范式，通过在线世界模型蒸馏，利用可训练奖励模型将候选轨迹与预测动态对齐，注入世界知识到教师策略，再经策略蒸馏和世界奖励蒸馏转移至轻量学生策略。实验显示，WPT在开环基准碰撞率0.11，闭环驾驶得分79.23，超越世界模型和模仿学习方法，且学生策略推理速度提升达4.9倍，保持高性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.19955","title":"ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation","arxivId":"2511.19955","date":"2025-11-25","authors":"Lin Shao Team","category":"Manipulation","summary":"本文针对接触丰富操作中六轴力扭矩传感器成本高、易损坏的核心问题，提出了ShapeForce——一种低成本即插即用的软机器人手腕。其关键技术通过柔顺核心将外力扭矩转换为可测变形，利用基于标记的姿态跟踪估计变形并生成类似力的信号，无需校准或专用电子设备。实验表明，该手腕在多种接触丰富任务中能以极低成本实现与六轴力扭矩传感器相当的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.19932","title":"Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine","arxivId":"2511.19932","date":"2025-11-25","authors":"Tian He Team","category":"Manipulation","summary":"本文针对3D装箱在真实物理环境中因连续重力作用导致物品倒塌的问题，提出了一种结合物理仿真与真实数据反馈的混合强化学习框架。核心方法包括：在仿真中使用领域随机化增强模型泛化能力，并利用真实部署反馈对智能体进行微调。实验表明，该方法有效降低了倒塌率，在物流系统的大规模部署中，相比基线方法将包装倒塌率减少了35%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.19861","title":"GigaWorld-0: World Models as Data Engine to Empower Embodied AI","arxivId":"2511.19861","date":"2025-11-25","authors":"Zheng Zhu Team","category":"Manipulation","summary":"本文提出GigaWorld-0框架，旨在解决具身AI训练数据稀缺且成本高昂的核心问题。该方法包含两大关键技术：GigaWorld-0-Video通过可控视频生成合成纹理丰富、时序连贯的视觉序列；GigaWorld-0-3D结合3D生成与物理可微仿真，确保几何一致性与物理真实性。实验表明，基于GigaWorld-0生成数据训练的VLA模型（如GigaBrain-0）在物理机器人任务上取得了显著性能提升，实现了零真实交互训练下的强泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.19859","title":"Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation","arxivId":"2511.19859","date":"2025-11-25","authors":"Sanglu Lu Team","category":"Manipulation","summary":"本文针对机器人动作生成中，纯文本思维链难以理解复杂视觉细节、视觉与动作模态存在鸿沟，以及多目标训练不稳定的核心问题，提出VITA框架。该方法通过构建视觉与动作的共享离散潜在空间，并引入隐式视觉思维链，使自回归生成的标记能同时解码为未来帧预测与机器人动作，从而统一感知与运动控制。实验表明，VITA在CALVIN、LIBERO和SimplerEnv基准上分别超越基线14.5%、9.6%和12.1%，并在六项真实任务中达到80.5%的平均成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.19647","title":"Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation","arxivId":"2511.19647","date":"2025-11-24","authors":"Dorsa Sadigh Team","category":"Manipulation","summary":"本文针对基础模型在真实世界非结构化环境中因训练数据缺乏而表现脆弱的问题，提出“机器人驱动数据飞轮”框架，将机器人从模型消费者转变为数据生成器。关键技术包括部署机器人（如Scanford移动操作器）在真实场景（如图书馆）中自主收集数据，利用视觉语言模型（VLM）识别书籍，并通过目录自动标注图像以微调模型。实验结果表明，基于2103个书架收集的数据，VLM在多语言书籍识别准确率从32.0%提升至71.8%，域相邻多语言OCR任务中英语从24.8%提升至46.6%、中文从30.8%提升至38.0%，同时节省约18.7小时人力，验证了该框架能持续优化模型并减少人工投入。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.19433","title":"Mixture of Horizons in Action Chunking","arxivId":"2511.19433","date":"2025-11-24","authors":"Mingyu Ding Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型在机器人操作中，因固定动作块长度（视野）导致的性能权衡问题：长视野利于全局规划但损害细粒度精度，短视野则相反。为此，提出混合视野（MoH）策略，将动作块拆分为不同视野的片段，通过共享动作变换器并行处理，并利用轻量线性门融合输出。该方法能同时利用长短期优势，即插即用，且支持动态自适应推理。实验表明，MoH显著提升了模型性能与泛化能力，在混合任务设置下，仅需3万次训练迭代即在LIBERO基准上达到99%的平均成功率，且推理吞吐量较基线提升2.5倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.19315","title":"Rethinking Intermediate Representation for VLM-based Robot Manipulation","arxivId":"2511.19315","date":"2025-11-24","authors":"Chi-Wing Fu Team","category":"Manipulation","summary":"这篇论文针对基于视觉语言模型（VLM）的机器人操作，其核心问题是：如何设计一种中间表示，以同时实现**VLM易于理解**和**动作泛化能力强**这两个常需权衡的目标。\n\n为此，作者提出了名为**SEAM**的中间表示。其关键技术是受上下文无关文法启发，将表示分解为**语义丰富的操作词汇**和**VLM友好的语法规则**，并设计了**开放词汇分割**与**检索增强的少样本学习**策略来精准定位物体部件。\n\n实验表明，SEAM在VLM可理解性和动作泛化性上均优于主流方法，且在所有并行工作中实现了**最短的推理时间**，在多样化的真实世界任务中取得了SOTA性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.19033","title":"ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay","arxivId":"2511.19033","date":"2025-11-24","authors":"Volker Tresp Team","category":"Manipulation","summary":"本文针对基于多模态大语言模型的具身智能体在探索新环境时性能不佳的问题，提出了无需训练的框架ReEXplore。其核心通过两项关键技术解决：一是“回顾性经验回放”，在推理时注入从过往探索中提炼的抽象经验；二是“分层前沿选择”，将庞大的动作空间分解为从粗到细的决策。实验表明，该方法在多个具身探索基准测试中显著优于基线模型，在开源骨干网络下，成功率和导航效率最高可提升3倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.18960","title":"AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention","arxivId":"2511.18960","date":"2025-11-24","authors":"Xiaoyuan Yu Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作（VLA）模型在动态顺序决策中，因独立处理各时刻视觉输入而忽略历史上下文，导致视觉处理效率不高的问题，提出AVA-VLA框架。该框架从部分可观测马尔可夫决策过程（POMDP）视角出发，创新性地引入主动视觉注意力（AVA）模块。AVA利用上一决策步骤产生的循环状态（近似信念状态），计算软权重以动态聚焦于与任务历史相关的关键视觉标记。实验表明，AVA-VLA在LIBERO和CALVIN等机器人基准测试中取得了最先进的性能，并在真实双臂机器人平台上验证了其有效性和良好的仿真到现实迁移能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.18950","title":"Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation","arxivId":"2511.18950","date":"2025-11-24","authors":"Wenjing Qian Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型处理冗余视觉令牌时计算开销大、阻碍实时机器人部署的核心问题，提出Compressor-VLA框架。该方法采用指令引导的混合压缩机制，包含语义任务压缩器（STC）提取整体任务上下文和空间细化压缩器（SRC）保留细粒度空间细节，实现自适应视觉信息压缩。实验表明，在LIBERO基准上模型保持竞争性成功率的同时，计算量（FLOPs）减少59%，视觉令牌数量降低超过3倍，真实机器人部署验证了其模拟到现实的迁移性和实用性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.18878","title":"Accelerating Reinforcement Learning via Error-Related Human Brain Signals","arxivId":"2511.18878","date":"2025-11-24","authors":"Hyo-Jeong Jang Team","category":"Manipulation","summary":"本文研究如何利用错误相关脑电位（ErrPs）加速强化学习，解决高维复杂机器人操作任务中学习效率低的问题。方法上，将离线训练EEG分类器解码的ErrPs集成到奖励塑造中，并通过系统调整人类反馈权重进行优化。实验在7自由度机械臂的障碍物环境中进行，结果显示神经反馈能加速学习，最佳权重下任务成功率有时超过稀疏奖励基线；跨受试者应用时学习持续加速，且留一评估证实了框架对个体EEG解码差异的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.18617","title":"AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations","arxivId":"2511.18617","date":"2025-11-23","authors":"Erdem Biyik Team","category":"Manipulation","summary":"本文提出AutoFocus-IL，旨在解决视觉模仿学习中数据效率低、模型易受无关视觉特征干扰的核心问题。其关键技术是**利用视觉语言模型自动生成时间显著性图谱**，无需额外人工标注，即可识别并跟踪演示视频中的关键物体，进而通过显著性正则化引导策略关注任务相关特征。实验表明，该方法在CARLA仿真和真实机器人任务中，**性能超越了标准行为克隆及需要人类监督的先进基线**，为实现高效、鲁棒的模仿学习提供了一条可扩展的路径。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.18563","title":"Object-centric Task Representation and Transfer using Diffused Orientation Fields","arxivId":"2511.18563","date":"2025-11-23","authors":"Sylvain Calinon Team","category":"Manipulation","summary":"本文针对机器人技能迁移中曲面物体缺乏全局参考系的挑战，提出扩散方向场（DOF）方法。该方法通过偏微分方程扩散过程，在线从点云生成平滑的局部参考帧表示，将任务描述于这些局部帧中，从而将跨形状任务迁移问题简化为建立稀疏关键点对应关系。实验表明，DOF在几何、拓扑及定位扰动下，能成功迁移检查、切片、剥离等需连续物理交互的任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.18509","title":"SafeFall: Learning Protective Control for Humanoid Robots","arxivId":"2511.18509","date":"2025-11-23","authors":"Siyuan Huang Team","category":"Manipulation","summary":"本文针对人形机器人因双足行走易摔倒、导致昂贵硬件损坏的核心问题，提出了SafeFall框架。该框架包含一个基于GRU的轻量级摔倒预测器和一个强化学习保护策略。保护策略仅在预测器判定摔倒不可避免时激活，其训练采用了一种新型的、考虑组件异质性的损伤感知奖励函数，旨在保护头部等脆弱区域并约束关节内力。在Unitree G1机器人上的实验表明，与无保护摔倒相比，SafeFall将峰值接触力降低了68.3%，峰值关节扭矩降低了78.4%，并消除了99.3%的脆弱部件碰撞。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.18322","title":"Learning Visually Interpretable Oscillator Networks for Soft Continuum Robots from Video","arxivId":"2511.18322","date":"2025-11-23","authors":"Takehisa Yairi Team","category":"Manipulation","summary":"本文针对软体连续机器人（SCR）动力学建模中数据驱动方法缺乏可解释性、而模型方法需先验知识的问题，提出一种从视频学习视觉可解释模型的新框架。其核心技术是：（1）注意力广播解码器（ABCD），一种即插即用模块，可生成像素级注意力图以定位各潜在维度的贡献；（2）将这些注意力图与2D振荡器网络耦合，从而无需先验知识即可在图像上直观可视化学习到的动力学参数（质量、刚度、力）。在单/双段SCR实验表明，基于ABCD的模型显著提升了多步预测精度：在双段机器人上，Koopman算子误差降低5.7倍，振荡器网络误差降低3.5倍，并自主发现了振荡器的链式结构。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.18299","title":"MicCheck: Repurposing Off-the-Shelf Pin Microphones for Easy and Low-Cost Contact Sensing","arxivId":"2511.18299","date":"2025-11-23","authors":"Jia-Yeu Lin Team","category":"Manipulation","summary":"论文MicCheck解决机器人模仿学习中视觉难以捕捉接触线索、而现有触觉传感器成本高且集成复杂的问题。方法利用现成蓝牙针式麦克风作为低成本接触传感器，通过3D打印夹持器插入件和标准USB接收器实现即插即用。实验显示：在10类材料分类中准确率达92.9%；在操作任务中，集成音频使捡起倾倒成功率从0.40提升至0.80，并支持拔插等接触密集技能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.17502","title":"RynnVLA-002: A Unified Vision-Language-Action and World Model","arxivId":"2511.17502","date":"2025-11-21","authors":"Hao Chen Team","category":"Manipulation","summary":"论文解决标准VLA模型缺乏动作理解、想象力和物理理解，以及世界模型无法直接生成动作的问题。提出RynnVLA-002统一框架，结合VLA模型（从图像生成动作）和世界模型（用动作预测未来图像状态），通过多模态tokenizer和共享词汇表实现环境动力学与行动规划的联合学习。实验表明，模型在LIBERO仿真基准上达到97.4%成功率（无预训练），在真实LeRobot任务中集成世界模型使整体成功率提升50%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.17441","title":"RoboCOIN: An Open-Sourced Bimanual Robotic Data COllection for INtegrated Manipulation","arxivId":"2511.17441","date":"2025-11-21","authors":"Guocai Yao Team","category":"Manipulation","summary":"本文提出RoboCOIN，旨在解决双手机器人操作中因硬件异构性导致的大规模多样化数据集稀缺的核心问题。关键技术包括：一个开源的多体现双手机器人数据集，涵盖15个平台、超过18万演示，覆盖16个场景的421个任务；分层能力金字塔提供轨迹级、段级和帧级多级注释；CoRobot处理框架采用机器人轨迹标记语言（RTML）实现质量评估、自动注释和统一管理。实验表明，该数据集在多体现双人操作学习中可靠有效，显著提升了多种模型架构和机器人平台的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.17411","title":"SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding","arxivId":"2511.17411","date":"2025-11-21","authors":"Danda Pani Paudel Team","category":"Manipulation","summary":"本文针对机器人基础模型（RFMs）在新环境、任务和体现形式中泛化能力有限的核心问题，指出瓶颈在于现有模型基于缺乏3D空间推理的2D视觉语言模型（VLMs）。提出关键技术方法：通过3D注释增强易收集的非机器人图像数据，训练能单图推断3D物体坐标的SPEAR-VLM，并构建集成3D感知与语言控制的基础模型SPEAR-1。实验表明，SPEAR-1在约45M帧数据上训练，零样本性能在Franka（DROID）设置中优于π0-FAST、匹配π0.5，同时机器人演示数据用量减少20倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.17401","title":"Feasibility of Embodied Dynamics Based Bayesian Learning for Continuous Pursuit Motion Control of Assistive Mobile Robots in the Built Environment","arxivId":"2511.17401","date":"2025-11-21","authors":"Vineet R. Kamat Team","category":"Manipulation","summary":"根据论文标题推断（正文未提供），该研究**探索在建筑环境中辅助移动机器人实现连续追踪运动控制的可行性**，核心方法是**基于具身动力学的贝叶斯学习**。该方法**将机器人本体动力学特性与贝叶斯概率推理结合**，以提升在动态、复杂环境中的追踪适应性与控制鲁棒性。若实验部分完备，预期会**对比传统控制方法，展示其在轨迹平滑性、误差收敛或能耗方面的性能提升**（具体数据需依据正文补充）。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.17373","title":"Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data","arxivId":"2511.17373","date":"2025-11-21","authors":"Hongyang Li Team","category":"Manipulation","summary":"本文提出AMS框架，解决人形机器人控制器难以统一敏捷动态运动与稳定平衡的核心问题。方法利用异构数据源（人类运动捕捉和合成平衡运动），通过混合奖励方案协调优化目标，并采用自适应学习策略高效训练。实验在仿真和真实Unitree G1机器人上验证，单个策略能同时执行跳舞、跑步等敏捷技能，以及零样本的Ip Man's Squat等极端平衡运动，展示了多功能控制能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.17366","title":"METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model","arxivId":"2511.17366","date":"2025-11-21","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"本文针对灵巧操作任务中大规模动作标注数据稀缺的瓶颈，提出METIS模型。核心方法包括：构建整合多源人类与机器人数据的EgoAtlas数据集，并使用紧凑的**运动感知动态**作为统一动作表示；将推理与行动集成于统一的视觉-语言-动作框架。实验表明，METIS在六项真实世界灵巧操作任务中取得了**最高的平均成功率**，并展现出优异的泛化能力与对分布外场景的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.17199","title":"VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation","arxivId":"2511.17199","date":"2025-11-21","authors":"Gim Hee Lee Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型在机器人操作中缺乏时空连贯性的问题，提出VLA-4D模型。关键技术包括：4D感知视觉表示，将1D时间嵌入3D位置形成4D特征并通过交叉注意力融合；时空动作表示，扩展传统动作以纳入时间信息实现规划。实验验证了该方法在多种操作任务中显著提升了动作的时空连贯性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.17079","title":"H-GAR: A Hierarchical Interaction Framework via Goal-Driven Observation-Action Refinement for Robotic Manipulation","arxivId":"2511.17079","date":"2025-11-21","authors":"Zitong Yu Team","category":"Manipulation","summary":"本文针对机器人操作任务中，现有方法以目标无关、单一的方式联合预测观察与动作，导致预测语义失准和行为不连贯的问题，提出了一种分层交互框架H-GAR。其关键技术包括：1）目标条件观察合成器（GOS），基于粗粒度动作和预测的目标观察合成中间观察；2）交互感知动作细化器（IAAR），利用中间观察反馈和历史动作记忆库将粗动作细化为与目标一致的精粒度动作。通过在仿真和真实机器人任务上的大量实验，H-GAR实现了最先进的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16661","title":"Dexterity from Smart Lenses: Multi-Fingered Robot Manipulation with In-the-Wild Human Demonstrations","arxivId":"2511.16661","date":"2025-11-20","authors":"Homanga Bharadhwaj Team","category":"Manipulation","summary":"本文提出Aina框架，旨在解决从真实世界人类视频中学习多指灵巧操作策略的难题，以缩小人机形态差异、减少对机器人数据的依赖。核心方法是利用轻便的Aria Gen 2智能眼镜采集数据，其提供高分辨率RGB图像、准确的3D头手姿态及立体视觉深度估计，进而训练基于3D点云、对背景变化鲁棒的多指手策略。实验在9个日常操作任务上验证了该框架，结果表明其无需任何机器人数据（如在线修正或强化学习）即可直接部署，相比前人方法实现了更便捷的“野外”数据采集与策略迁移。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16651","title":"InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy","arxivId":"2511.16651","date":"2025-11-20","authors":"Jiangmiao Pang Team","category":"Manipulation","summary":"本文旨在解决大规模真实机器人数据收集成本高昂的问题，探索纯合成数据预训练通用视觉-语言-动作模型的潜力。核心方法是构建了InternData-A1大规模高保真合成数据集，其通过一个高度自主、解耦、组合式的仿真流水线生成，涵盖4种机器人形态、18项技能和超过63万条轨迹。实验表明，仅用该合成数据预训练的模型，在49项仿真任务、5项真实任务和4项长时程灵巧操作任务上，性能匹配了当前最强的基于真实数据的π0模型，并展现出零样本仿真到现实的迁移能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16596","title":"Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies","arxivId":"2511.16596","date":"2025-11-20","authors":"Aviv Tamar Team","category":"Manipulation","summary":"本文研究人工触诊，旨在解决当前触觉成像方法主要生成简单力分布图，而人类触诊依赖更复杂特征（如结构对手指运动的反应）的问题。论文提出使用编码器-解码器框架进行自监督学习，从机器人触觉传感器采集的序列中学习软体对象的内部表示，用于触觉成像与变化检测等下游任务。通过模拟与真实（MRI对照）数据集验证，该方法学习到的表示超越了简单的力映射，并成功应用于成像与变化检测任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16449","title":"VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference","arxivId":"2511.16449","date":"2025-11-21","authors":"Bo Zhao Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型处理连续视觉流时计算开销大的问题，指出现有令牌修剪方法仅依赖语义显著性，忽略动作执行信息，导致性能下降。为此，提出VLA-Pruner方法，采用时间感知的双重目标重要性准则（结合语义相关性和动作解码注意力）和双重级别令牌选择策略，自适应保留关键令牌。实验表明，VLA-Pruner在多个VLA架构上优于现有方法，实现最高1.99倍加速，且在50%修剪比例下提升模型性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16407","title":"LAOF: Robust Latent Action Learning with Optical Flow Constraints","arxivId":"2511.16407","date":"2025-11-20","authors":"Wei Li Team","category":"Manipulation","summary":"本文提出LAOF框架，旨在解决大规模视频预训练中潜在动作学习易受动作无关干扰（如动态背景）影响的问题。该方法利用光流作为动作驱动的伪监督信号，通过约束潜在动作表示来抑制背景并聚焦智能体运动，从而提升表征的鲁棒性。实验表明，LAOF学到的表征在下游模仿学习与强化学习任务上优于现有方法；在动作标签极少甚至为零时，其性能可匹配使用1%标签的监督方法，且在标签比例增至10%时仍保持稳定提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16390","title":"Robot Metacognition: Decision Making with Confidence for Tool Invention","arxivId":"2511.16390","date":"2025-11-20","authors":"Pablo Lanillos Team","category":"Manipulation","summary":"本文探讨机器人元认知在工具发明决策中的应用，核心问题是解决机器人在未知环境中通过自信决策自主发明工具的挑战。关键技术方法包括元认知框架和置信度评估算法，用于实时监控决策可靠性并优化工具创新过程。实验表明，该方法能显著提升机器人的决策准确性和工具发明成功率，具体性能提升数据需参考论文正文。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16330","title":"Safe and Optimal Variable Impedance Control via Certified Reinforcement Learning","arxivId":"2511.16330","date":"2025-11-20","authors":"Ravi Prakash Team","category":"Manipulation","summary":"本文针对强化学习在可变阻抗控制中因阻抗增益时变导致的不稳定和不安全探索问题，提出了Certified Gaussian-Manifold Sampling（C-GMS）方法。该方法将策略探索定义为从数学定义的稳定增益调度流形中采样，确保每个策略 rollout 都满足Lyapunov稳定性和执行器可行性，无需奖励惩罚或事后验证。理论保证即使在有界模型误差和部署不确定性下也能实现有界跟踪误差，仿真和真实机器人实验验证了其有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16306","title":"InEKFormer: A Hybrid State Estimator for Humanoid Robots","arxivId":"2511.16306","date":"2025-11-20","authors":"Frank Kirchner Team","category":"Manipulation","summary":"本文针对人形机器人运动中的状态估计问题，提出了一种混合状态估计器InEKFormer。该方法深度融合了不变扩展卡尔曼滤波（InEKF）与Transformer网络，利用Transformer预测卡尔曼增益以补偿模型失配。在RH5人形机器人五种运动类型的数据集上进行评估，结果表明该方法较纯模型方法（InEKF）和现有混合方法（KalmanNet）展现出潜力，同时揭示了在高维状态估计中需要更稳健的自回归训练。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16223","title":"DynaMimicGen: A Data Generation Framework for Robot Learning of Dynamic Tasks","arxivId":"2511.16223","date":"2025-11-20","authors":"Anna Valente Team","category":"Manipulation","summary":"本文提出DynaMimicGen框架，旨在解决机器人模仿学习依赖大量耗时人力演示、难以适应动态环境的核心问题。其关键技术是：基于少量演示，先进行任务分割，再利用动态运动基元（DMPs）泛化行为，生成能实时适应物体位姿、场景几何变化的平滑笛卡尔轨迹。实验表明，用该框架生成数据训练的智能体，在堆叠立方体、向抽屉放置杯子等长时程、接触密集的动态任务中表现强劲，有效实现了在环境变化下的泛化，为规模化机器人学习提供了高效数据生成方案。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16203","title":"When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models","arxivId":"2511.16203","date":"2025-11-20","authors":"Yaochu Jin Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型在现实多模态与黑盒条件下的对抗鲁棒性缺失问题，提出了VLA-Fool框架。该框架统一了三种多模态对抗攻击：基于梯度与提示的文本扰动、基于补丁与噪声的视觉扰动、以及故意破坏感知-指令语义对应的跨模态错位攻击，并首次构建了语义引导的自动提示生成方法。在LIBERO基准上的实验表明，即使轻微的多模态扰动也会导致微调后的OpenVLA模型产生显著的行为偏差，揭示了具身多模态对齐的脆弱性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16175","title":"Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight","arxivId":"2511.16175","date":"2025-11-20","authors":"Zhijie Deng Team","category":"Manipulation","summary":"本文提出Mantis模型，旨在解决现有视觉-语言-动作模型中视觉状态预测导致模型容量分散、训练成本高，以及语言监督不足影响理解与推理能力的问题。其核心技术是解耦视觉预见，通过元查询与扩散Transformer头分离视觉预测任务，使主干模型专注于语言监督下的理解与推理。实验表明，Mantis在LIBERO基准上微调后达到96.7%的成功率，超越基线模型；其变体Mantis-ATE通过自适应时间集成策略，在保持性能的同时将推理次数减少50%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16166","title":"EvoVLA: Self-Evolving Vision-Language-Action Model","arxivId":"2511.16166","date":"2025-11-20","authors":"Hao Tang Team","category":"Manipulation","summary":"本文提出EvoVLA模型，旨在解决长时程机器人操作中VLA模型存在的“阶段幻觉”问题，即智能体利用粗略评估信号走捷径，虚报进度而未真正完成任务。关键技术包括：阶段对齐奖励（SAR）通过三元组对比学习与难负样本防止视觉捷径；基于姿态的对象探索（POE）将好奇心机制锚定于物体-夹爪相对位姿；长时程记忆模块通过选择性上下文与门控融合稳定训练。实验表明，在Discoverse-L基准上，EvoVLA相比最强基线平均成功率提升10.2%（达69.2%），样本效率提高1.5倍，阶段幻觉率从38.5%降至14.8%；真实机器人部署任务平均成功率达54.6%，优于基线11.0个百分点。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16158","title":"MagBotSim: Physics-Based Simulation and Reinforcement Learning Environments for Magnetic Robotics","arxivId":"2511.16158","date":"2025-11-20","authors":"Klaus Neumann Team","category":"Manipulation","summary":"本文针对磁悬浮系统在工业自动化中仅用于运输、未充分利用操作潜力的问题，提出将运输与操作融合为磁机器人集群（MagBots），以提升制造系统的效率、适应性和紧凑性。为此，作者开发了MagBotSim——一个基于物理的磁悬浮系统模拟器，内含强化学习环境，支持轨迹规划与物体操作算法的开发。该模拟器通过将磁悬浮系统建模为机器人集群，为下一代磁驱制造系统的智能算法研发提供了基础平台。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.16050","title":"Bi-AQUA: Bilateral Control-Based Imitation Learning for Underwater Robot Arms via Lighting-Aware Action Chunking with Transformers","arxivId":"2511.16050","date":"2025-11-20","authors":"Yuki Uranishi Team","category":"Manipulation","summary":"本文针对水下机器人操作面临的光照剧烈变化、颜色失真等挑战，提出了首个基于双边控制的模仿学习框架Bi-AQUA。其核心技术是三层光照适应机制：照明编码器自动提取光照表征、FiLM调制实现自适应视觉特征提取、以及在Transformer输入中添加显式光照标记。在真实水下拾放任务的实验中，该框架在不同光照条件下表现出鲁棒性，性能显著优于未建模光照的双边基线，且消融研究证实了所有光照感知组件的关键作用。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.15605","title":"SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models","arxivId":"2511.15605","date":"2025-11-19","authors":"Xipeng Qiu Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型依赖专家演示、存在演示偏差，以及现有强化学习方法因奖励稀疏导致训练效率低的问题，提出自我参考策略优化框架。其核心是**利用当前批次内的成功轨迹作为自参考，并通过世界模型的潜在空间表示稳健衡量行为进展，从而为失败尝试分配渐进式奖励**。在LIBERO基准上，仅用200步强化学习便将成功率从48.9%提升至99.2%，相对改进达103%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.15407","title":"IPR-1: Interactive Physical Reasoner","arxivId":"2511.15407","date":"2025-11-19","authors":"Yong-Lu Li Team","category":"Manipulation","summary":"本文研究智能体能否通过交互学习获得人类式物理推理能力。针对现有方法（VLMs与世界模型）在交互环境中难以捕捉物理因果机制的局限，提出了**IPR交互物理推理器**，其核心是：1）用世界模型推演来评分和强化VLM策略；2）引入**PhysCode物理中心行动编码**，将语义意图与动力学对齐。在1000+异构游戏上预训练后，IPR在生存、探索、目标推理等多层次任务中表现稳健，**整体性能超越GPT-5**，且性能随训练游戏和交互步骤增加而提升，并能零样本迁移到未见游戏。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.15358","title":"Platform-Agnostic Reinforcement Learning Framework for Safe Exploration of Cluttered Environments with Graph Attention","arxivId":"2511.15358","date":"2025-11-19","authors":"George Nikolakopoulos Team","category":"Manipulation","summary":"本文针对自主机器人在障碍物密集环境（如森林、矿井）中实现高效且安全探索的核心挑战，提出了一种平台无关的强化学习框架。其关键技术是结合图神经网络（GNN）策略与安全过滤器：使用PPO算法训练GNN策略进行路径点选择，同时设计一个安全过滤器来修正不可行动作；奖励函数则融合了势场，以权衡接近未探索区域和预期信息增益。通过在仿真和真实实验室环境中的广泛评估，该方法被证明能够实现杂乱空间中的高效与安全探索。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.15279","title":"Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception","arxivId":"2511.15279","date":"2025-11-19","authors":"Wenzhao Lian Team","category":"Manipulation","summary":"本文针对具身AI感知中现有视觉系统被动、无法兼顾宽区域覆盖与细粒度细节获取的核心问题，提出EyeVLA机器人眼球。方法将旋转、缩放等动作离散为动作令牌，与视觉语言模型（VLM）集成，实现视觉、语言和动作的联合建模；通过2D边界框坐标引导推理链，并应用强化学习优化视点选择策略，仅用少量真实数据将VLM能力迁移为视觉语言动作（VLA）策略。实验表明，EyeVLA能根据指令主动旋转和缩放，有效理解真实环境场景并获取更准确的视觉信息，提升了环境感知能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.15200","title":"VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation","arxivId":"2511.15200","date":"2025-11-19","authors":"Yuke Zhu Team","category":"Manipulation","summary":"本文针对人形机器人缺乏自主移动操作技能的核心问题，提出了VIRAL视觉仿真到现实框架。采用教师-学生架构：特权教师策略基于全状态学习长时程移动操作；视觉学生策略通过大规模并行仿真（使用多达64个GPU）与瓦片渲染，结合DAgger和行为克隆进行蒸馏。关键创新包括大规模视觉域随机化（光照、材质等）以及手部与相机的真实-仿真对齐。在Unitree G1机器人上的零样本部署实验表明，仅基于RGB的策略能连续执行54个循环的移动操作，泛化至多样空间与外观变化，且无需真实世界微调，性能接近专家遥操作水平。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.15194","title":"Eq.Bot: Enhance Robotic Manipulation Learning via Group Equivariant Canonicalization","arxivId":"2511.15194","date":"2025-11-19","authors":"Zhenzhou Shao Team","category":"Manipulation","summary":"本文提出Eq.Bot框架，旨在解决机器人操作学习中多模态模型缺乏几何一致性、难以处理空间变换（如旋转、平移）的问题。其核心方法是一种基于SE(2)群等变理论的通用规范化框架，通过将观测映射到规范空间执行策略，再将动作映射回原空间，从而在不修改模型架构的前提下赋予其空间等变性。实验表明，该框架能显著提升CNN与Transformer基模型的性能，在特定任务上成功率从62.4%提升至93.6%，最高性能提升达50.0%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.14759","title":"$π^{*}_{0.6}$ : a VLA That Learns From Experience","arxivId":"2511.14759","date":"2025-11-19","authors":"Zhiyuan Zhou Team","category":"Manipulation","summary":"本文研究如何通过强化学习（RL）让视觉-语言-动作（VLA）模型在现实部署中持续改进。提出通用方法 **Recap（基于优势条件策略的经验与修正强化学习）**，通过优势条件整合演示数据、在线收集数据及自主执行中的专家干预数据，实现VLA的RL训练。实验表明，经Recap训练的模型能在真实家庭中叠衣服、组装纸箱、操作专业咖啡机。在最难任务上，**Recap使任务吞吐量提升一倍以上，失败率降低约一半**。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.14756","title":"HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation","arxivId":"2511.14756","date":"2025-11-18","authors":"Xiaolong Wang Team","category":"Manipulation","summary":"本文针对机器人移动操作中接触丰富任务（如擦拭、开门）的复杂交互动力学问题，提出异构元控制（HMC）框架。核心方案包含：1）HMC-Controller，在扭矩空间动态混合位置、阻抗和混合力-位置等多种控制模式的动作；2）HMC-Policy，采用专家混合路由的异构架构，融合大规模位置数据与精细力感知演示进行学习。在真人形机器人上的实验表明，该方法在顺擦拭桌子、开抽屉等任务上相比基线实现了超过50%的相对性能提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.14565","title":"Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language","arxivId":"2511.14565","date":"2025-11-18","authors":"Andreea Bobu Team","category":"Manipulation","summary":"本文针对机器人从演示中学习奖励函数时容易过拟合、泛化差，以及语言指令模糊导致歧义的核心问题，提出Masked IRL框架。该方法利用大型语言模型（LLM）结合演示（展示如何行动）和语言（指定重要内容），通过推断状态相关性掩码并对无关状态强制不变性，在指令模糊时用LLM推理进行澄清。实验表明，在模拟和真实机器人上，Masked IRL相比先前方法性能提升高达15%，数据使用减少达4.7倍，显著提高了样本效率、泛化能力和对模糊语言的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.14434","title":"Achieving Safe Control Online through Integration of Harmonic Control Lyapunov-Barrier Functions with Unsafe Object-Centric Action Policies","arxivId":"2511.14434","date":"2025-11-18","authors":"Matthias Scheutz Team","category":"Manipulation","summary":"根据论文标题“Achieving Safe Control Online through Integration of Harmonic Control Lyapunov-Barrier Functions with Unsafe Object-Centric Action Policies”，本文旨在解决在线安全控制的核心问题，即如何在动态环境中确保控制系统的安全性，避免不安全行为。关键技术方法包括整合谐波控制Lyapunov-Barrier函数（HCLBF）与不安全对象中心动作策略，通过HCLBF保证系统稳定性，并结合对象中心策略处理不安全对象。然而，由于正文内容未提供，具体实验结论和性能提升数据无法在此总结中给出，需参考论文完整内容以获取详细信息。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.14427","title":"Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning","arxivId":"2511.14427","date":"2025-11-18","authors":"Georgia Chalvatzaki Team","category":"Manipulation","summary":"本文针对接触密集的机器人操作任务中，强化学习智能体难以有效融合视觉、力与本体感觉等多模态传感器信息的问题，提出了一种名为多感官动态预训练（MSDP）的新框架。该方法基于掩码自编码训练Transformer编码器，通过重建部分感官观测实现跨模态预测与融合；在下游策略学习中，采用一种新颖的非对称架构，使评论家通过交叉注意力提取动态任务特征，而行动者使用稳定的池化表征。实验表明，该方法在模拟和真实机器人多种接触密集任务中，能显著加速学习、对传感器噪声等多种扰动具有强鲁棒性，在真实机器人上仅需6000次在线交互即可实现高成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.14396","title":"Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning","arxivId":"2511.14396","date":"2025-11-18","authors":"Hongpeng Wang Team","category":"Manipulation","summary":"本文提出CCoL框架，以解决语言条件操纵任务中行为克隆因复合错误及语义-物理错位导致的执行不准确与中断问题。其核心是通过视觉、语言和本体感觉的连续协同学习生成平滑动作轨迹，并利用双向交叉注意力实现语言语义与视觉运动表征的精细对齐。实验表明，该方法在三个模拟环境中平均性能相对提升8.0%，在双手机器人插入任务中最高提升达19.2%，并在真实机器人测试中展现出良好的泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.14178","title":"Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion","arxivId":"2511.14178","date":"2025-11-18","authors":"Fei Chen Team","category":"Manipulation","summary":"本文旨在解决预训练视觉-语言-动作模型在下游任务部署时性能显著下降，且传统微调方法数据与计算成本高昂的问题。为此，提出了VLA-Pilot方法，这是一种即插即用的推理时策略引导技术，其核心是基于“具身进化扩散”机制，在无需任何微调或额外数据收集的情况下，于运行时优化策略的行为模式选择。实验在涵盖两种机器人平台的六项真实操作任务上进行，结果表明，该方法能显著提升预训练VLA策略的成功率，实现了对多样任务与平台的鲁棒零样本泛化。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.14161","title":"RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action","arxivId":"2511.14161","date":"2025-11-18","authors":"Jiayu Chen Team","category":"Manipulation","summary":"本文针对现有家务整理基准缺乏用户偏好建模、移动性支持且泛化能力差的问题，提出了RoboTidy统一基准。该基准基于3D高斯泼溅（3DGS）技术构建了500个光真实感家庭场景，包含500个对象和容器，并提供6.4k操作轨迹与1.5k导航轨迹，支持视觉-语言-动作（VLA）和视觉-语言-导航（VLN）的训练与评估。通过将整理任务形式化为“动作（对象，容器）”列表，RoboTidy实现了语言引导机器人的整体仿真到现实评估，填补了体现AI中的关键空白。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.14148","title":"AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models","arxivId":"2511.14148","date":"2025-11-18","authors":"Biqing Qi Team","category":"Manipulation","summary":"本文针对传统视觉-语言-动作（VLA）模型采用同步流匹配时，因固定时间表缺乏动作上下文感知与自校正能力，在长时程任务中容易累积错误的问题，提出了异步流匹配框架AsyncVLA。其关键技术包括：1）采用非均匀时间表的异步流匹配，实现基于上下文的动作生成；2）引入置信度评估器，使模型能在执行前选择性修正低置信度动作令牌；3）设计了同步与异步模式的统一训练流程，提升KV缓存利用率。实验表明，AsyncVLA具有高效的数据利用和自校正能力，在机器人操作基准测试中取得了最先进的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.13710","title":"From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands","arxivId":"2511.13710","date":"2025-11-17","authors":"Xiaolong Wang Team","category":"Manipulation","summary":"本论文旨在解决多指机器人手难以在单一系统中同时实现稳定强力抓取和精细精确操作的核心问题。通过联合优化控制策略与硬件设计，引入轻量级指尖几何修改（表示为接触平面）并优化其参数，控制策略动态切换强力与精确模式，将精确操作简化为平行拇指-食指运动。实验表明，在仿真到现实的精确抓取中，对未见物体达到82.5%的零样本成功率；在真实世界捏面包任务中，成功率达93.3%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.13707","title":"OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving","arxivId":"2511.13707","date":"2025-11-17","authors":"Tapomayukh Bhattacharjee Team","category":"Manipulation","summary":"本论文旨在解决机器人护理领域缺乏大规模、多样化专家示范数据的问题。为此，作者构建了OpenRoboCare数据集，其核心技术方法是收集21位职业治疗师执行15项日常护理任务的专家演示，并同步记录RGB-D视频、姿态、眼动、触觉及任务标注这五类模态数据，以全面捕捉护理策略。核心结论表明，该数据集为机器人感知与活动识别研究提供了宝贵资源，并对现有先进方法构成了显著挑战。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.13459","title":"Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness","arxivId":"2511.13459","date":"2025-11-17","authors":"Luis Figueredo Team","category":"Manipulation","summary":"本文针对接触丰富机器人操作中安全、适应性与鲁棒性不足的问题，传统强化学习方法在任务空间缺乏接触感知与能量安全保证。提出一种任务空间能量安全框架，核心方法结合近端策略优化（PPO）与运动基元（ProMPs）生成平滑轨迹，并集成能量感知笛卡尔阻抗控制器以调节交互能量。实验表明，该框架在3D环境多种表面任务上优于现有方法，实现了高成功率、平滑轨迹和能量安全交互。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.13327","title":"ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning","arxivId":"2511.13327","date":"2025-11-17","authors":"Ruizhen Hu Team","category":"Manipulation","summary":"ZeroDexGrasp旨在解决任务导向灵巧抓取在零样本场景下的泛化难题，现有方法依赖大量标注数据，难以适应新物体和复杂任务指令。该框架整合多模态大语言模型，采用基于提示的多阶段语义推理技术，从任务和物体语义中推断初始抓取配置与接触信息，再通过接触引导的抓取优化细化姿势，确保物理可行性与任务对齐。实验表明，该方法能在多样未见物体类别和复杂任务要求上实现高质量零样本灵巧抓取，显著提升机器人抓取的泛化性与智能性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.13312","title":"EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation","arxivId":"2511.13312","date":"2025-11-17","authors":"Sven Behnke Team","category":"Manipulation","summary":"EL3DD论文旨在解决机器人理解自然语言指令并执行多任务操作的核心问题，通过融合视觉与文本输入生成精确的机器人轨迹。关键技术方法扩展了3D Diffuser Actor (3DDA)模型，采用LSeg图像编码器和S-BERT语义编码改进嵌入，并将去噪变压器扩展为潜在扩散模型（LDM）以生成末端执行器轨迹。在CALVIN数据集上的实验表明，模型在各种操作任务上性能显著提升，并提高了多任务顺序执行时的长视野成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.12912","title":"DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping","arxivId":"2511.12912","date":"2025-11-17","authors":"Dongbin Zhao Team","category":"Manipulation","summary":"本文针对模拟训练深度抓取策略转移到现实机器人时，因真实深度图中的传感器噪声和空洞导致的sim2real差距问题，提出DiffuDepGrasp框架。其核心创新Diffusion Depth Generator包含两个模块：Diffusion Depth Module利用时间几何先验训练条件扩散模型以捕获复杂噪声分布，Noise Grafting Module在注入噪声时保持度量准确性。实验表明，该框架仅需原始深度输入，在零样本转移下对12个物体的抓取任务达到95.7%的平均成功率，并具强泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.12878","title":"Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views","arxivId":"2511.12878","date":"2025-11-17","authors":"Hesheng Wang Team","category":"Manipulation","summary":"本文提出Uni-Hand，旨在解决自我中心视角下细粒度手部运动预测的挑战，包括预测目标单一、模态鸿沟、手-头运动耦合及下游任务验证不足等问题。该框架通过视觉-语言融合、全局上下文整合与任务感知文本嵌入注入，实现多模态输入的统一处理；提出双分支扩散模型，同步预测头部与手部运动以捕捉其协同性。实验表明，Uni-Hand在多个公开数据集及新构建的基准测试中达到最先进性能，并有效支持人机策略转移与动作识别等下游任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.12848","title":"Structured Imitation Learning of Interactive Policies through Inverse Games","arxivId":"2511.12848","date":"2025-11-17","authors":"Todd Murphey Team","category":"Manipulation","summary":"本文针对模仿学习在多智能体交互场景中的挑战，提出一种结构化模仿学习框架。核心问题是：如何在无显式通信的共享空间中，让机器人学习与人类协调的交互策略。方法分为两步：首先用标准模仿学习从多智能体演示中提取个体行为模式；然后通过逆向博弈问题结构化地学习智能体间的相互依赖关系。在合成的5智能体社交导航任务中，该方法仅用50条演示就显著提升了非交互策略的性能，达到了与真实交互策略相当的水平。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.12650","title":"Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning","arxivId":"2511.12650","date":"2025-11-16","authors":"Sohom Chakrabarty Team","category":"Manipulation","summary":"本文针对平面机械臂形态优化问题，提出一种基于强化学习的任务感知优化方法。核心是通过奖励反馈（以Yoshikawa可操作性指数为基础）优化连杆长度与关节配置，无需依赖闭式解析解或雅可比模型。研究采用SAC、DDPG、PPO三种RL算法，在圆形轨迹任务中成功复现了理论最优解（等长连杆与正交关节）；在椭圆与矩形轨迹等无解析解任务中，RL方法仍能可靠收敛，而网格搜索等传统方法因维度升高导致计算成本大幅增加。结果表明，强化学习可有效用于已知最优解的验证与复杂任务下的形态优化。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.12436","title":"RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation","arxivId":"2511.12436","date":"2025-11-16","authors":"Long Chen Team","category":"Manipulation","summary":"本文针对机器人在操作与导航中因缺乏细粒度可供性注释，难以推断可操作交互位置（如抓取点、放置区）的问题，提出了RoboAfford++数据集。该数据集利用生成式AI增强，包含86.9万张图像和200万问答注释，覆盖对象可供性识别、预测及空间可供性定位三个关键任务，并配套RoboAfford-Eval评估基准。实验表明，现有视觉语言模型在可供性学习上存在缺陷，但基于RoboAfford++微调后，其推理能力显著提升，验证了数据集的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.11512","title":"Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities","arxivId":"2511.11512","date":"2025-11-14","authors":"Jingyuan Chen Team","category":"Manipulation","summary":"本文针对触觉传感器缺乏标准化导致特征冗余、跨传感器泛化困难，以及触觉、语言、视觉模态交互不足的核心问题，提出TLV-CoRe协同表示学习方法。关键技术包括Sensor-Aware Modulator统一不同传感器触觉特征、触觉无关解耦学习分离冗余特征，以及Unified Bridging Adapter增强三模态交互。实验通过提出的RSS评估框架验证，表明TLV-CoRe显著提升了传感器无关表示学习和跨模态对齐性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.11478","title":"Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective","arxivId":"2511.11478","date":"2025-11-14","authors":"Ngan Le Team","category":"Manipulation","summary":"本文针对机器人在非马尔可夫环境中操作时面临的**对象级部分可观测性**核心问题，即当前观测无法提供决策所需的完整对象交互历史。为此，论文提出**LIBERO-Mem**任务套件进行压力测试，并设计了**Embodied-SlotSSM**框架。该框架通过**slot-state-space建模**重建短期历史，并利用**关系编码器**对齐输入与动作解码，以保持时空一致的槽标识。实验表明，该框架在LIBERO-Mem任务上展现了基准性能，为以对象为中心的机器人策略提供了可扩展的非马尔可夫推理方案。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.11298","title":"Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation","arxivId":"2511.11298","date":"2025-11-14","authors":"Xi Zheng Team","category":"Manipulation","summary":"本文针对机器人操作中视觉-语言-动作模型缺乏系统性真实评估的问题，建立了一个标准化评测框架，对ACT、OpenVLA-OFT、RDT-1B和π₀四种代表性VLA模型进行了基准测试。评估围绕三个维度展开：任务成功率与用时、对分布内及分布外场景的适应性、以及语言指令跟随准确性。核心实验发现，π₀模型在分布外场景下适应性最强，而ACT模型在分布内任务中稳定性最高。分析还揭示了模型在计算需求、数据扩展行为及常见失败模式（如抓取未遂、过早释放）上的差异，为实际部署中的精度、泛化与成本权衡提供了依据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.11223","title":"Sashimi-Bot: Autonomous Tri-manual Advanced Manipulation and Cutting of Deformable Objects","arxivId":"2511.11223","date":"2025-11-14","authors":"Ekrem Misimi Team","category":"Manipulation","summary":"本文针对机器人操纵柔软、易变形且特性不确定的三文鱼柳制作刺身的复杂任务，提出了Sashimi-Bot多机器人协作系统。其核心技术结合了深度强化学习、工具在手机器人操作（包括抓握、切割），并融合视觉与触觉反馈以实现鲁棒性。该系统成功实现了对鱼柳的拉直、协同稳定下的切片以及拾取薄片等一系列自主操作，标志着在可变形物体高级操纵方面取得了重要进展。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.11218","title":"Humanoid Whole-Body Badminton via Multi-Stage Reinforcement Learning","arxivId":"2511.11218","date":"2025-11-14","authors":"Xiaoyu Ren Team","category":"Manipulation","summary":"本文针对人形机器人在动态环境中进行全身协调运动（如打羽毛球）的挑战，提出了一种基于多阶段强化学习的训练框架。核心方法采用三阶段课程学习：先学习步法，再生成精确挥拍动作，最后进行任务优化，无需运动先验或专家示范。部署时结合扩展卡尔曼滤波器预测羽毛球轨迹。实验表明，仿真中双机器人可持续对打21个回合；实物测试中，击球速度可达19.1 m/s，平均回球落点距离4米，验证了该方法在高速动态任务中的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.11052","title":"AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation","arxivId":"2511.11052","date":"2025-11-14","authors":"Lin Shao Team","category":"Manipulation","summary":"本文针对机器人操作中抓取（P）与非抓取（NP）技能自适应集成的核心挑战，提出AdaptPNP框架。该框架基于视觉语言模型（VLM）生成任务计划骨架，利用数字孪生中间层预测对象姿态，并通过控制模块实现在线反馈与重新规划。在模拟和真实环境的混合操作任务中评估，验证了框架能有效组合P和NP技能，推动通用机器人操作能力发展。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.10987","title":"Dexterous Manipulation Transfer via Progressive Kinematic-Dynamic Alignment","arxivId":"2511.10987","date":"2025-11-14","authors":"Yi Sun Team","category":"Manipulation","summary":"本文针对多指灵巧手数据稀缺问题，提出一种手无关的渐进式操作转移系统。核心方法是：先通过运动学匹配建立基础控制信号，再结合动作空间重缩放与拇指引导初始化的残差策略动态优化接触交互，最后计算手腕轨迹以保持操作语义。仅需人类操作视频，系统即可自动为不同任务配置参数。实验表明，该方法能自动生成平滑、语义正确的灵巧手操作轨迹，平均转移成功率达73%，高效且泛化性强。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.10874","title":"Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation","arxivId":"2511.10874","date":"2025-11-14","authors":"Jiaoyang Li Team","category":"Manipulation","summary":"本文针对多机器人协作非抓取操作中，机器人-物体交互分配、接触形态与协调运动联合规划的复杂难题，提出统一框架。核心方法为流匹配协同生成模型，它从视觉观察中联合生成接触形态与操作轨迹，并结合匿名多机器人运动规划器实现大规模协调。实验表明，该方法在模拟挑战性环境中，其运动规划与操作性能均优于基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.10635","title":"Robot Crash Course: Learning Soft and Stylized Falling","arxivId":"2511.10635","date":"2025-11-13","authors":"Moritz Bächer Team","category":"Manipulation","summary":"本文针对双足机器人跌倒时易受物理损伤且姿势不可控的问题，研究如何实现柔软、风格化的受控跌倒。提出一种机器人无关的强化学习奖励函数，平衡用户指定的最终姿势目标与损伤最小化的软跌倒目标；并引入基于模拟的初始和最终姿势采样策略，以增强对广泛跌倒条件的鲁棒性。通过模拟和真实实验验证，该方法能使双足机器人成功执行受控的软跌倒，有效减少冲击并保护关键部件。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.10518","title":"SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation","arxivId":"2511.10518","date":"2025-11-13","authors":"Liqiang Nie Team","category":"Manipulation","summary":"本文针对机器人操作中VLA模型存在的**感知冗余**与**指令-视觉语义对齐表浅**两大核心问题，提出了SemanticVLA框架。其关键技术包括：**SD-Pruner**进行指令引导的视觉特征稀疏化，**SH-Fuser**融合语义与几何特征，**SA-Coupler**增强感知到动作的转换。实验表明，该框架在LIBERO基准上的成功率比OpenVLA提升21.1%，同时训练成本和推理延迟分别降低3.0倍和2.7倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.10276","title":"RoboBenchMart: Benchmarking Robots in Retail Environment","arxivId":"2511.10276","date":"2025-11-13","authors":"Vlad Shakhuro Team","category":"Manipulation","summary":"本文针对现有机器人操作基准测试局限于简化桌面场景的问题，提出了RoboBenchMart基准测试，旨在评估机器人在真实零售环境（特别是黑暗商店）中的复杂操作能力。该环境挑战巨大，包括物品密集堆放和多样的空间布局。关键技术是发布了一套完整的RoboBenchMart工具包，包含程序化商店布局生成器、轨迹生成管道、评估工具和微调基线模型。核心实验结论表明，当前最先进的通用模型难以完成常见的零售任务，凸显了该基准的必要性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.10110","title":"Learning a Thousand Tasks in a Day","arxivId":"2511.10110","date":"2025-11-13","authors":"Edward Johns Team","category":"Manipulation","summary":"本文针对机器人模仿学习数据效率低下的问题，提出了一种高效方法。核心创新是将操作轨迹分解为顺序的**对齐**和**交互**两个阶段，并采用**基于检索的泛化**技术，由此构建了**多任务轨迹迁移（MT3）**方法。实验表明，在每任务演示次数极少（<10次）时，该分解方法比单阶段行为克隆的数据效率**提高了一个数量级**。MT3仅需**单次演示**即可学习日常操作任务，并能泛化到新物体，最终在**24小时内**成功教会机器人**1000个**不同的任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.10087","title":"Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning","arxivId":"2511.10087","date":"2025-11-13","authors":"Xiaocong Li Team","category":"Manipulation","summary":"本文针对离线到在线强化学习（O2O-RL）中多模态行为覆盖不足与在线适应时分布偏移的核心问题，提出统一生成框架UEPO。其关键技术包括：多种子动态感知扩散策略以高效捕获多模态行为；动态分歧正则化机制确保策略多样性符合物理约束；基于扩散的数据增强模块提升动力学模型泛化能力。在D4RL基准测试中，UEPO在运动任务上较Uni-O4绝对性能提升5.9%，在灵巧操作任务上提升12.4%，展现了优异的泛化性与可扩展性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.10079","title":"Physics-informed Machine Learning for Static Friction Modeling in Robotic Manipulators Based on Kolmogorov-Arnold Networks","arxivId":"2511.10079","date":"2025-11-13","authors":"Yinghua Liu Team","category":"Manipulation","summary":"本文针对机器人关节静摩擦建模中传统模型需预定义函数形式的局限性，提出了一种基于Kolmogorov-Arnold网络（KAN）的物理信息机器学习方法。该方法融合样条激活函数与符号回归机制，通过剪枝和属性评分实现模型简化与物理表达式提取，兼顾高精度与可解释性。实验在合成数据及六自由度工业机械臂真实数据上进行验证，结果表明，该方法在不同任务中决定系数均大于0.95，并能成功提取出简洁且物理意义明确的摩擦表达式。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.09958","title":"Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation","arxivId":"2511.09958","date":"2025-11-13","authors":"Changbo Wang Team","category":"Manipulation","summary":"本文针对机器人操作中仅依赖视觉的VLA模型在感知接触事件和动态过程方面的局限性，提出Audio-VLA模型。该模型通过集成接触音频感知，采用DINOv2、SigLIP和AudioCLIP分别编码视觉与音频，以Llama2为骨干，并利用LoRA微调和多模态投影层实现跨模态对齐。在增强音频反馈的仿真环境（RLBench、LIBERO）和真实任务上的实验表明，Audio-VLA性能优于纯视觉方法，所提的任务完成率（TCR）指标有效量化了动态过程感知能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.09932","title":"A Study on Enhancing the Generalization Ability of Visuomotor Policies via Data Augmentation","arxivId":"2511.09932","date":"2025-11-13","authors":"Hanwen Wang Team","category":"Manipulation","summary":"本研究旨在提升视觉运动策略的泛化能力，解决现有数据增强方法生成数据多样性不足、限制策略跨场景部署的问题。提出自动生成广泛随机化数据集的方法，仅需少量人类演示，覆盖多种操纵器与夹持器，并随机化相机姿态、光照、桌面纹理及高度等因素。实验表明，所有随机化因素均能增强策略泛化，多样化轨迹可有效桥接视觉差距，显著提升零样本模拟到真实转移的泛化性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.09737","title":"Out-of-Distribution Generalization with a SPARC: Racing 100 Unseen Vehicles with a Single Policy","arxivId":"2511.09737","date":"2025-11-12","authors":"Peter R. Wurman Team","category":"Manipulation","summary":"本文解决强化学习智能体在测试时无法获取显式上下文信息的情况下，适应未见环境变化（OOD）的泛化挑战。为此，论文提出了**SPARC（单阶段适应鲁棒控制）**方法，其核心创新在于将上下文编码和适应统一到**单训练阶段**，简化了实现并兼容离策略训练。实验在Gran Turismo 7赛车模拟器和风扰动MuJoCo环境中进行，结果表明SPARC实现了**可靠且鲁棒的OOD泛化**，并能在多个评估指标上生成**帕累托最优策略**。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.09727","title":"Baby Sophia: A Developmental Approach to Self-Exploration through Self-Touch and Hand Regard","arxivId":"2511.09727","date":"2025-11-12","authors":"Katerina Pastra Team","category":"Manipulation","summary":"本文提出了一种受婴儿发育启发的强化学习框架，旨在解决机器人如何通过自主自我探索来学习身体感知和视觉-运动协调的核心问题。关键技术方法包括：1）利用内在奖励机制模拟好奇心，驱动自我触摸和手部注视行为；2）通过表征学习将高维触觉输入压缩为紧凑特征，并通过课程学习鼓励广泛的躯体接触；3）通过运动咿呀学语学习手部视觉特征，并利用课程从单手过渡到双手的复杂协调训练。核心实验结论表明，仅依靠内在好奇心信号，无需外部监督，即可驱动机器人实现协调的多模态学习，成功模仿了婴儿从随机运动到有目的行为的发展进程。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.09558","title":"IFG: Internet-Scale Guidance for Functional Grasping Generation","arxivId":"2511.09558","date":"2025-11-12","authors":"Deepak Pathak Team","category":"Manipulation","summary":"本文针对大型视觉模型缺乏几何理解、无法精确控制机器人手进行3D抓取的问题，提出IFG方法。关键技术是结合互联网规模模型的语义分割（SAM与VLPart）与基于仿真的局部感知力闭合优化，生成针对任务相关区域的功能性抓取位姿，并蒸馏训练扩散模型以实现实时点云抓取合成。核心结论是实现无需人工标注数据的高性能语义抓取。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.09555","title":"SpatialActor: Exploring Disentangled Spatial Representations for Robust Robotic Manipulation","arxivId":"2511.09555","date":"2025-11-12","authors":"Gao Huang Team","category":"Manipulation","summary":"本文针对机器人操作中现有视觉方法对深度噪声敏感、空间线索利用不足的问题，提出SpatialActor框架。其核心是通过**解耦表示**，分离语义与几何。关键技术包括：**语义引导的几何模块**，融合噪声深度与专家先验的互补几何信息；**空间变换器**，利用低层空间线索实现精确的2D-3D映射。在超过50个任务的实验中，该方法在RLBench上达到87.4%的SOTA性能，并在不同噪声条件下性能提升13.9%至19.4%，证明了其强鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.07418","title":"Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields","arxivId":"2511.07418","date":"2025-11-10","authors":"Pieter Abbeel Team","category":"Manipulation","summary":"本文针对灵巧手实时多样抓取合成这一核心难题，提出Lightning Grasp算法。其关键技术是引入“接触场”数据结构，将复杂几何计算与搜索过程解耦，从而极大简化问题并实现高速程序化搜索。实验表明，在A100 GPU上，该方法单次前向传播仅需2-5秒即可生成上千个有效抓取，速度较现有最优方法提升数个数量级（有效样本/秒达300-1000），并能适应不规则物体与高自由度手型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.07416","title":"Robot Learning from a Physical World Model","arxivId":"2511.07416","date":"2025-11-10","authors":"Yue Wang Team","category":"Manipulation","summary":"本文针对从生成视频学习机器人操作时，因忽视物理约束导致动作不准确的问题，提出PhysWorld框架。该框架耦合视频生成与物理世界重建，首先生成任务条件视频并重建物理世界，再通过对象中心残差强化学习将视频运动转化为物理准确的动作。实验表明，在多种真实任务中，PhysWorld相比以往方法显著提升了操作精度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.07288","title":"Enabling Off-Policy Imitation Learning with Deep Actor Critic Stabilization","arxivId":"2511.07288","date":"2025-11-10","authors":"Shalabh Bhatnagar Team","category":"Manipulation","summary":"本文针对离线策略模仿学习中因数据分布偏移导致的训练不稳定问题，提出了一种深度行动者批判稳定化方法。该方法结合行动者-批判者框架与稳定化技术，通过优化策略学习和价值估计来增强鲁棒性。具体技术要点和实验性能提升数据需参考论文正文内容。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.06754","title":"SlotVLA: Towards Modeling of Object-Relation Representations in Robotic Manipulation","arxivId":"2511.06754","date":"2025-11-10","authors":"Ngan Le Team","category":"Manipulation","summary":"本文针对机器人多任务操作中现有模型依赖密集嵌入、导致效率低和可解释性差的核心问题，提出了SlotVLA框架。该框架基于槽注意力技术，通过槽基视觉标记器保持物体表示一致性，关系中心解码器生成任务相关嵌入，以及LLM驱动模块转换为可执行动作。同时，引入了LIBERO+数据集以支持评估。实验表明，物体中心槽和物体关系槽表示能大幅减少所需视觉标记数量，同时保持竞争力的泛化性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.06745","title":"Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning","arxivId":"2511.06745","date":"2025-11-10","authors":"Nam Pham Hai Team","category":"Manipulation","summary":"本文针对自监督目标条件强化学习中，机器人自主生成目标时存在的物理不可行性问题，提出PI-RIG方法。核心是设计了增强型物理信息变分自编码器，其关键技术在于将潜在空间显式分离为控制物体动力学的物理变量与捕捉场景外观的环境变量，并通过微分方程约束和守恒定律强制物理一致性。实验表明，该方法在视觉机器人操作任务（如到达、推动、拾放）中，能生成物理一致且可达的目标，显著提升了目标质量、探索效率和技能学习效果。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.06667","title":"Rapidly Learning Soft Robot Control via Implicit Time-Stepping","arxivId":"2511.06667","date":"2025-11-10","authors":"Dezhong Tong Team","category":"Manipulation","summary":"本文致力于解决软体机器人因缺乏易用、通用的模拟框架且计算成本过高，导致基于仿真的策略学习难以实现的问题。其核心技术是采用完全隐式时间步进模拟器DisMech，并结合了类比于刚性机器人关节控制的delta自然曲率控制方法。实验表明，该方法在非接触和接触丰富的场景下，仿真速度分别最高提升了6倍和40倍，策略训练迭代速度提升了超过17倍，实现了速度的显著提升而不损失精度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.06434","title":"Real Garment Benchmark (RGBench): A Comprehensive Benchmark for Robotic Garment Manipulation featuring a High-Fidelity Scalable Simulator","arxivId":"2511.06434","date":"2025-11-09","authors":"Ruigang Yang Team","category":"Manipulation","summary":"本文针对机器人服装操作中因状态空间维度高、动力学复杂导致的模拟保真度不足与速度慢的问题，提出了RGBench基准测试。其核心是开发了高性能模拟器GarmentDynamics，并构建了包含6000多种服装网格的多样化数据集。实验表明，该模拟器显著优于现有方案，将模拟误差降低了20%，同时运行速度提升了3倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.06202","title":"ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval","arxivId":"2511.06202","date":"2025-11-09","authors":"Jeff Ichnowski Team","category":"Manipulation","summary":"本文解决预训练视觉-语言-动作模型在特定部署环境中难以快速适应并达到高成功率的问题。提出ExpReS-VLA方法，其关键技术包括：压缩经验回放缓冲，用嵌入代替原始图像-动作对以减少97%存储；检索增强生成，用余弦相似度检索相似经验；以及阈值混合对比损失，使模型能从成功和失败的演示中学习。实验表明，该方法在仿真任务中显著提升成功率，在物理机器人上仅用12个演示和31秒适应，就将分布内和分布外任务的成功率分别提升至98%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.05996","title":"Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds","arxivId":"2511.05996","date":"2025-11-08","authors":"Jun Liu Team","category":"Manipulation","summary":"本文针对类别级关节物体在动态环境中的6-DoF姿态跟踪难题，提出PPF-Tracker框架。核心方法包括：在SE(3)李群空间对点云进行准规范化，利用点对特征（PPF）的SE(3)不变性预测姿态参数，并结合关节轴语义信息施加统一运动学约束。该框架在合成与真实场景数据上系统评估，展现了强大的泛化能力与鲁棒性，有效支持连续、稳定的多帧姿态跟踪。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.05855","title":"Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills","arxivId":"2511.05855","date":"2025-11-08","authors":"Renjing Xu Team","category":"Manipulation","summary":"本文针对长时程、接触丰富的精细操作任务依赖昂贵人工演示数据的问题，提出一种结合视觉语言模型（VLM）规划与仿真强化学习（RL）的新框架。核心方法包括：1）利用VLM对复杂任务进行高层语义分解与原子技能规划；2）在仿真中为每个原子技能训练带显式力约束的RL策略，确保操作轻柔；3）通过视觉-触觉扩散策略将VLM生成的多样演示提炼为统一的可执行策略。实验表明，该方法无需人工演示即能学习长时程操作策略，并通过原子技能框架实现任务的可扩展泛化。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.05791","title":"VLAD-Grasp: Zero-shot Grasp Detection via Vision-Language Models","arxivId":"2511.05791","date":"2025-11-08","authors":"Aniket Bera Team","category":"Manipulation","summary":"VLAD-Grasp旨在解决机器人抓取依赖大规模专家注释和重新训练、泛化能力有限的核心问题。该方法提出一种基于视觉-语言模型的零样本抓取检测技术：首先提示大模型生成以直杆“刺穿”对象表示对握抓取的目标图像；然后预测深度和分割将其提升至3D；最后通过主成分分析（PCA）和无对应优化对齐点云以恢复可执行抓取姿态。实验显示，在Cornell和Jacquard数据集上，其性能与最先进监督模型竞争或更优，并在Franka Research 3机器人上实现了对新现实物体的零样本泛化。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.05680","title":"VLM-driven Skill Selection for Robotic Assembly Tasks","arxivId":"2511.05680","date":"2025-11-07","authors":"Chang-Hyun Kim Team","category":"Manipulation","summary":"本文针对机器人装配任务中复杂多步骤规划与技能选择的挑战，提出一种结合视觉语言模型（VLM）和模仿学习的框架。方法采用两阶段VLM架构：第一阶段执行视觉场景分析与对象空间标记；第二阶段基于注释输入进行技能推理和参数选择，实现层次化技能分解与自适应操作。实验证明该方法在装配场景中有效，实现了高成功率，并通过结构化原始技能分解保持了可解释性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.05397","title":"EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation","arxivId":"2511.05397","date":"2025-11-07","authors":"Samuel Dickerson Team","category":"Manipulation","summary":"本文提出EveryDayVLA系统，旨在解决现有视觉-语言-动作（VLA）模型依赖昂贵硬件且在陌生、杂乱场景中表现不佳的问题。核心技术包括：1）自适应视野集成器（AdaHorizon），通过监测模型不确定性动态调整动作规划范围并触发实时重规划；2）低成本6自由度机械臂（仅300美元），采用Arduino Uno与PCA9685驱动器实现。实验表明，该系统在LIBERO基准上达到先进水平，在真实任务中分布内性能超越先前方法49%，分布外性能提升34.9%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.05234","title":"Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning","arxivId":"2511.05234","date":"2025-11-07","authors":"Gerhard Neumann Team","category":"Manipulation","summary":"本论文旨在解决基于网格的模拟中如何增强上下文感知能力和提高模拟效率的核心问题。通过引入轨迹级元学习技术，提出了一种学习网格模拟方法，关键技术包括上下文感知模块和元学习框架，以优化模拟轨迹并适应动态环境。论文中进行了实验验证，具体性能提升数据和结论需参考正文内容。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.05199","title":"Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation","arxivId":"2511.05199","date":"2025-11-07","authors":"Feifei Feng Team","category":"Manipulation","summary":"本文提出Retrieving-from-Video (RfV)方法，旨在解决机器人如何利用海量人类演示视频来学习并泛化操作任务的核心问题。关键技术是构建人类任务视频库，并提取物体可供性掩码和手部运动轨迹等中级信息。系统包含视频检索器与策略生成器两个组件，通过检索并融合相关知识来生成策略。实验表明，该方法在模拟和真实环境中相比传统系统性能有显著提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.05158","title":"Follow-Me in Micro-Mobility with End-to-End Imitation Learning","arxivId":"2511.05158","date":"2025-11-07","authors":"Jorge Peña Queralta Team","category":"Manipulation","summary":"本文针对自主微移动平台（如辅助轮椅）在动态拥挤环境中实现“跟随”任务时，如何优化用户体验与舒适度（而非仅关注时间、距离等传统指标）的核心问题展开研究。提出采用端到端模仿学习方法，通过深度神经网络学习人类演示数据，直接生成控制策略。实验表明，该方法相比手动调优控制器能提供更平滑、性能更优的跟随控制，使自主轮椅在现实部署中实现了先进的舒适度水平。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.05052","title":"TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments","arxivId":"2511.05052","date":"2025-11-07","authors":"Yijiang Huang Team","category":"Manipulation","summary":"本文针对机器人在杂乱狭窄环境中操控细长物体（如钢筋）这一核心难题，提出TAPOM方法。现有规划方法在低间隙场景下因采样困难或陷入局部最小值而失败。TAPOM通过任务空间拓扑分析，高层识别关键路径并生成引导关键帧，以指导底层规划器在构型空间中搜索可行轨迹。实验验证表明，该方法在低间隙操控任务上相比先进方法，取得了显著更高的成功率和效率提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.05007","title":"MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery","arxivId":"2511.05007","date":"2025-11-07","authors":"Huazhe Xu Team","category":"Manipulation","summary":"本文提出MoE-DP方法，旨在解决扩散策略在长时程、多阶段机器人操作任务中缺乏阶段意识、无法从子任务失败中恢复且表示难以解释的问题。其核心是在视觉编码器与扩散模型间插入混合专家层，将策略知识分解为多个专家，动态激活以处理任务不同阶段。实验表明，该方法在6个长时程仿真任务受干扰条件下，成功率平均相对提升36%，并在真实世界验证了鲁棒性优势，同时学习到的专家对应可解释的技能基元。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.04831","title":"Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning","arxivId":"2511.04831","date":"2025-11-06","authors":"Gavriel State Team","category":"Manipulation","summary":"本文针对机器人学习数据收集成本高、风险大，且传统CPU仿真难以大规模并行的核心问题，提出了GPU加速的仿真框架Isaac Lab。其关键技术包括高保真GPU并行物理引擎、逼真渲染、模块化架构，并集成了执行器模型、多模态传感器仿真及领域随机化工具。该框架通过GPU原生并行计算，实现了大规模高效仿真，为强化学习和模仿学习提供了统一平台，显著提升了仿真效率与规模。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.04812","title":"Unified Multimodal Diffusion Forcing for Forceful Manipulation","arxivId":"2511.04812","date":"2025-11-06","authors":"Dmitry Berenson Team","category":"Manipulation","summary":"本文针对接触丰富的机器人强力操作任务，提出**多模态扩散强制（MDF）**框架，以解决传统模仿学习方法忽视多模态（如图像、力信号）间时序依赖与跨模态关联的问题。其核心方法采用**2D时间-模态噪声水平矩阵**进行训练，通过**随机部分掩码**策略，迫使扩散模型学习重建轨迹，从而捕获模态间交互与时间动态。实验在模拟与真实环境中的五个强力操作任务上进行，结果表明，MDF在实现多功能性的同时，展现出**强大的性能**，并在**噪声观测下具有优异鲁棒性**。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.04769","title":"ReGen: Generative Robot Simulation via Inverse Design","arxivId":"2511.04769","date":"2025-11-06","authors":"Daniela Rus Team","category":"Manipulation","summary":"ReGen论文针对机器人模拟构建依赖人工、成本高的问题，提出基于逆向设计的生成模拟框架。其核心技术是利用大型语言模型合成场景，通过扩展编码因果关系的定向图，并转化为符号程序来配置模拟环境。在自动驾驶和机器人操作实验中，该框架生成的环境比现有模拟更复杂多样，具有高成功率，并能可控生成极端情况，有效提升策略验证和机器人学习的可扩展性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.04671","title":"X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations","arxivId":"2511.04671","date":"2025-11-06","authors":"Kushal Kedia Team","category":"Manipulation","summary":"本文解决的核心问题是：如何有效利用大量人类演示视频训练机器人策略，克服人类与机器人因形态差异导致的动作执行不匹配问题。关键技术X-Diffusion框架提出：通过前向扩散过程向动作添加噪声，使低层执行差异模糊化而保留高层任务语义；并训练一个分类器判断噪声化动作的来源，仅在分类器无法区分时（即添加足够噪声后）才将人类动作用于策略训练，从而避免学习动力学不可行的动作。实验表明，该方法在五个操作任务上比最佳基线平均成功率提升16%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.04665","title":"Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions","arxivId":"2511.04665","date":"2025-11-06","authors":"Yunzhu Li Team","category":"Manipulation","summary":"本文针对机器人策略在真实世界（特别是涉及可变形物体的任务）中评估成本高、难以复现的问题，提出了一种基于3D高斯泼溅（3DGS）的真实到仿真评估框架。该方法从真实视频构建软体数字孪生，并通过增强的3DGS（具备自动位置、颜色对齐及物体变形处理能力）实现高保真渲染。在毛绒玩具打包、绳子路径规划等任务上的实验表明，该框架的模拟推演结果与真实世界执行性能高度相关，能有效揭示策略的关键行为模式，验证了其作为可信评估工具的潜力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.04381","title":"ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation","arxivId":"2511.04381","date":"2025-11-06","authors":"Chunsheng Liu Team","category":"Manipulation","summary":"本文针对机器人操控中仿真到现实迁移的挑战，提出ForeRobo框架，旨在利用生成式仿真获取无限数据，实现零样本迁移与任务级泛化。其核心方法包括：自引导的“提议-生成-学习-执行”循环，其中ForeGen生成技能一致的目标状态，ForeFormer模型根据场景状态与任务指令预测当前点云中每个点的3D目标位置，从而建立点对应关系，再结合经典控制算法驱动机器人。实验表明，ForeFormer在多种操控任务上比现有最优状态生成模型平均性能提升56.32%；在超过20项真实任务中实现零样本迁移，平均成功率高达79.28%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.04357","title":"GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies","arxivId":"2511.04357","date":"2025-11-06","authors":"Cédric Buche Team","category":"Manipulation","summary":"本文提出GraSP-VLA框架，旨在解决自主机器人在长视野任务中规划能力不足的问题。现有VLA模型缺乏高级符号规划，而符号学习方法泛化性与可扩展性有限。该框架采用神经符号方法，通过连续场景图表示将人类演示转化为符号表示，并以此作为低层VLA策略的协调器，支持动作序列的扩展生成。实验表明，该方法能有效从观测数据生成规划领域，其场景图表示在真实长视野任务中展现出协调VLA策略的潜力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.03996","title":"Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots","arxivId":"2511.03996","date":"2025-11-06","authors":"Mingguo Zhao Team","category":"Manipulation","summary":"这篇论文针对人形机器人足球中感知与动作模块解耦导致的响应延迟、行为不连贯问题，提出一种基于强化学习的统一控制器。方法核心是扩展**Adversarial Motion Priors**至现实动态感知场景，并引入**编码器-解码器架构**与**虚拟感知系统**，从有噪、受限的视觉观测中恢复特权状态，实现感知与动作的主动协调。最终控制器在包括真实RoboCup比赛在内的多种场景中，展现出强大的反应能力和鲁棒的足球技能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.03616","title":"Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning","arxivId":"2511.03616","date":"2025-11-05","authors":"Georgios Chalkiadakis Team","category":"Manipulation","summary":"本文针对模仿学习需要完整状态-动作演示且专家性能可能不是最优的限制，提出深度隐式模仿强化学习框架。核心算法DIIQN通过在线探索重建专家动作，并利用动态置信机制平衡专家引导与自主学习；扩展算法HA-DIIQN引入不可行性检测和桥接过程，以处理专家与代理动作集不同的场景。实验表明，DIIQN相比标准DQN实现高达130%的回报提升，HA-DIIQN学习速度比基线快64%，能有效利用传统方法无法使用的专家数据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.03565","title":"Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent Advances","arxivId":"2511.03565","date":"2025-11-05","authors":"Georgios Chalkiadakis Team","category":"Manipulation","summary":"这是一篇关于模仿学习（IL）的综述论文。其核心目标是梳理深度学习时代下模仿学习的最新进展，并提出一个新颖的分类体系，以更好地反映当前研究格局和趋势。论文的关键方法是构建一个不同于现有分类的新分类法，旨在系统性地归纳近年来为应对泛化、协变量偏移和数据质量等挑战而出现的新方法。作为一篇综述，论文未报告具体的实验性能数据，而是对代表性工作的优势、局限性和评估实践进行了批判性审视，并指出了未来的关键挑战与开放方向。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.03481","title":"Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control","arxivId":"2511.03481","date":"2025-11-05","authors":"Sheng Yi Team","category":"Manipulation","summary":"本文针对仿人灵巧手在复杂度、重量比和力控性能方面难以平衡的问题，提出了一种新型肌腱驱动仿生手DexHand 021及其本体感觉柔顺控制方法。该手采用缆线驱动，具有12个主动和7个被动自由度，重量仅1kg。核心方法是基于本体力感知的导纳控制。实验表明，其单指负载>10N，指尖重复精度<0.001mm，力估计误差<0.2N；相比PID控制，多物体抓取时关节扭矩降低31.19%，显著提升了力控能力与防过载性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.03181","title":"Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control","arxivId":"2511.03181","date":"2025-11-05","authors":"Kensuke Harada Team","category":"Manipulation","summary":"本文针对机器人协作包装纸张时，因纸张形变难以预测且需自适应力控制而导致的协调难题，提出了一种学习框架。该框架整合大型语言模型（LLM）进行高级任务规划，并采用混合模仿学习（IL）与强化学习（RL）的低级策略，其核心是能学习统一策略的Sub-task Aware Robotic Transformer（START）。通过引入子任务ID来显式标记时间，模型能捕捉长距离依赖关系，学习子目标而非简单复制动作序列。实验表明，该框架在真实包装任务中取得了97%的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.03167","title":"Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning","arxivId":"2511.03167","date":"2025-11-05","authors":"Feng Gao Team","category":"Manipulation","summary":"本文针对六足机器人在复杂地形上协调多腿生成自然且鲁棒运动的核心问题，提出基于运动先验的深度强化学习方法。关键技术包括：通过轨迹优化生成平地运动数据作为先验，训练对抗判别器以指导自然步态学习，并设计不对称DRL框架训练控制器。实验表明，学习策略成功转移到真实六足机器人，在无视觉信息下实现复杂地形的自然行走，展现出显著鲁棒性，是强化学习控制器在真实六足机器人上的首次应用。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.03078","title":"3D Cal: An Open-Source Software Library for Calibrating Tactile Sensors","arxivId":"2511.03078","date":"2025-11-04","authors":"Gregory Reardon Team","category":"Manipulation","summary":"本文针对触觉传感器校准过程临时、劳动密集型的问题，提出了3D Cal开源软件库。其核心方法是将低成本3D打印机改造为自动化探测设备，以生成大规模标记训练数据，并利用自定义卷积神经网络进行深度图重建。实验通过校准DIGIT和GelSight Mini两种商用视觉触觉传感器，验证了该方法的有效性；通过数据消融研究确定了实现准确校准所需的数据量，并在未见物体上测试了模型的校准精度与泛化性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.02504","title":"Dexterous Robotic Piano Playing at Scale","arxivId":"2511.02504","date":"2025-11-04","authors":"Dieter Büchler Team","category":"Manipulation","summary":"本文研究大规模灵巧机器人钢琴演奏问题，该任务具有高维度、接触密集、需快速精确控制的特点。提出OmniPianist智能体，其核心方法包括：1) 基于最优运输的自动指法策略，无需人类示范；2) 训练超2000个强化学习智能体，收集包含超100万条轨迹的RP1M++数据集；3) 采用流匹配变换器进行大规模模仿学习。实验表明，该智能体能够演奏近千首音乐曲目，实现了无需人工标注指法的大规模、多样化钢琴演奏。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.02239","title":"LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation","arxivId":"2511.02239","date":"2025-11-04","authors":"Changhyun Choi Team","category":"Manipulation","summary":"本文提出LACY框架，以解决机器人操作中单向语言到动作（L2A）映射导致的策略缺乏深层理解、泛化能力有限的问题。其核心是构建一个基于视觉语言模型的语言-动作循环，通过联合训练L2A（语言生成动作）、A2L（动作解释为语言）和L2C（语言一致性验证）三个任务，实现双向映射。关键创新在于L2A2L自循环能自主生成训练数据，并利用L2C进行主动数据增强以筛选低置信度样本，从而实现无人工标注的自我改进。实验表明，在抓放任务中，LACY相比基线方法平均将任务成功率提升了56.46%，并获得了更鲁棒的语言-动作关联。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.02097","title":"A Step Toward World Models: A Survey on Robotic Manipulation","arxivId":"2511.02097","date":"2025-10-31","authors":"Heng Tao Shen Team","category":"Manipulation","summary":"本文是一篇综述，旨在厘清机器人操作中“世界模型”的定义模糊问题。论文通过分析该领域方法，归纳出三类关键技术：基于视频生成的预测模型、抽象状态表示模型、以及视觉-语言-动作模型。文章指出，完全实现的世界模型应具备感知、预测与控制的核心能力，并总结了其关键组件，为构建通用实用的机器人世界模型提供了理论框架。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.01999","title":"TRACE: Textual Reasoning for Affordance Coordinate Extraction","arxivId":"2511.01999","date":"2025-11-03","authors":"Matthew S. Brown Team","category":"Manipulation","summary":"本文针对视觉语言模型(VLMs)将高级指令转化为精确机器人操作坐标时空间推理能力不足的问题，提出了TRACE方法。该方法的核心是引入文本推理链，通过构建包含指令与显式推理文本的TRACE数据集来微调VLM，使其在预测坐标前先进行外部化的文本推理。实验表明，该方法在Where2Place基准测试上达到48.1%的准确率，相对提升9.6%，且在更具挑战性的子集上达到55.0%，性能提升与推理数据量直接相关。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.01914","title":"iFlyBot-VLA Technical Report","arxivId":"2511.01914","date":"2025-11-01","authors":"Jia Pan Team","category":"Manipulation","summary":"很抱歉，我无法根据您提供的“iFlyBot-VLA Technical Report”这一标题生成论文总结，因为我未能接收到论文的正文内容。\n\n为了给您撰写一段精准、简洁的总结，请您**补充提供论文的正文部分**。一旦获得正文，我将立即为您提取核心问题、关键技术方法和核心实验结论。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.01501","title":"SE(3)-PoseFlow: Estimating 6D Pose Distributions for Uncertainty-Aware Robotic Manipulation","arxivId":"2511.01501","date":"2025-11-03","authors":"Georgia Chalvatzaki Team","category":"Manipulation","summary":"本文针对6D物体姿态估计中因遮挡、对称性等导致的姿态模糊性问题，提出了一种概率框架SE(3)-PoseFlow。其核心方法是利用SE(3)流形上的流匹配技术，建模完整的6D姿态分布，提供基于样本的估计以表征不确定性，而非输出单一确定性结果。该方法在Real275、YCB-V和LM-O数据集上取得了最先进性能，并能将姿态分布估计应用于主动感知、不确定性感知抓取合成等下游机器人操作任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.01331","title":"RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models","arxivId":"2511.01331","date":"2025-11-03","authors":"Donglin Wang Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型在分布外部署时，因观测噪声与动作扰动导致泛化可靠性不足的问题，提出鲁棒性感知的强化学习后训练方法RobustVLA。该方法通过引入两种正则化提升鲁棒性：Jacobian正则化降低模型对观测噪声的敏感性，平滑正则化稳定策略以应对动作扰动。实验表明，RobustVLA在多种机器人环境中，其鲁棒性与可靠性显著优于现有先进方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.01224","title":"Embodiment Transfer Learning for Vision-Language-Action Models","arxivId":"2511.01224","date":"2025-11-03","authors":"Yaxin Peng Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型在多机器人协作中表现不佳、难以生成有效动作序列的问题，提出了具身迁移学习框架ET-VLA。其核心技术包括：1）合成持续预训练，利用合成数据预热模型以学习新机器人的正确动作和精确令牌数，无需昂贵真人演示；2）具身思维图，将子任务建模为节点，以区分不同机器人的功能与角色。实验在三个双手机器人平台上验证，该方法在六项真实任务上性能超越OpenVLA达53.2%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.00555","title":"Improving Robustness to Out-of-Distribution States in Imitation Learning via Deep Koopman-Boosted Diffusion Policy","arxivId":"2511.00555","date":"2025-11-01","authors":"Zhongliang Jiang Team","category":"Manipulation","summary":"本文针对模仿学习中扩散策略难以捕捉多步间强时间依赖、对分布外状态鲁棒性差的问题，提出深度库普曼增强的双分支扩散策略（D3P）。方法核心是双分支架构：视觉分支编码任务进程，融合分支整合多模态输入实现精确操作，并引入深度库普曼算子学习视觉时序动态。实验表明，D3P在六项模拟任务上平均性能超越现有最优扩散策略14.6%，在三项真实机器人任务上提升15.0%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2511.00153","title":"EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations","arxivId":"2511.00153","date":"2025-10-31","authors":"Philipp Wu Team","category":"Manipulation","summary":"本文提出EgoMI框架，旨在解决模仿学习中因人类主动视觉行为与机器人静态感知系统不匹配导致的具身鸿沟问题。核心方法是同步采集人类操作时的末端执行器与主动头部运动轨迹，并设计记忆增强策略以处理快速变化的视角。在配备驱动相机头的双手机器人上实验表明，显式建模头部运动的策略性能持续优于基线方法，有效提升了半人形机器人的模仿学习鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.27666","title":"Whole-Body Proprioceptive Morphing: A Modular Soft Gripper for Robust Cross-Scale Grasping","arxivId":"2510.27666","date":"2025-10-31","authors":"Xiaonan Huang Team","category":"Manipulation","summary":"本文提出一种新型模块化软体抓取器，旨在解决传统软体抓手因形态固定而无法适应多尺度、多几何形状物体抓取的问题。其核心方法是构建一个由分布式、自感知气动模块组成的网络，通过**全身本体感知形变**技术，使抓手能智能重构整体拓扑结构，形成可控的多边形抓取形态。实验表明，该抓手抓取范围显著扩大，可稳定抓取尺寸差异达10倍的标准与不规则物体，并实现了多物体抓取、内部钩取等新功能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.27558","title":"Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs","arxivId":"2510.27558","date":"2025-10-31","authors":"Shinkyu Park Team","category":"Manipulation","summary":"本文提出一种无需领域特定训练的机器人操作框架，旨在解决基于自然语言指令执行准确、长期序列任务的问题。其核心方法是分层整合多个预训练基础模型：LLM解析指令，VLM提供感知，推理模型生成任务序列，并引入动态维护的场景图以增强空间感知与推理。通过桌面操作实验验证，该框架展现了利用现成基础模型构建机器人系统的潜力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.27114","title":"Learning Generalizable Visuomotor Policy through Dynamics-Alignment","arxivId":"2510.27114","date":"2025-10-31","authors":"Jungwoo Lee Team","category":"Manipulation","summary":"本文针对行为克隆方法因数据有限导致泛化性差的问题，提出了一种**动态对齐流匹配策略**。该方法的核心是让策略模型与动态模型在动作生成过程中**相互提供纠正反馈**，通过流外推技术实现动作生成与动态预测的对齐。实验表明，该方法在真实机器人操作任务上**泛化性能优于基线**，尤其在包含视觉干扰和光照变化的分布外场景中表现出更强的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.26670","title":"Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation","arxivId":"2510.26670","date":"2025-10-30","authors":"Qiaojun Yu Team","category":"Manipulation","summary":"本文针对扩散模仿学习中随机微分方程（SDE）方法采样慢、常微分方程（ODE）方法易模式崩溃，难以兼顾多模态行为与实时效率的问题，提出混合一致性策略（HCP）。该方法先运行短随机SDE前缀至自适应切换时间，再通过一步一致性跳跃输出动作；关键技术为时变一致性蒸馏，结合轨迹一致性目标与去噪匹配目标以对齐生成。实验表明，HCP仅用25步SDE加一跳，在准确性与模式覆盖率上接近80步DDPM教师模型，同时显著降低推理延迟，实现了机器人策略中多模态与实时性的有效解耦。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.26406","title":"Human-in-the-loop Online Rejection Sampling for Robotic Manipulation","arxivId":"2510.26406","date":"2025-10-30","authors":"Yansong Tang Team","category":"Manipulation","summary":"本文提出人机交互在线拒绝采样方法，以解决视觉-语言-动作模型在机器人操作后训练中强化学习不稳定、模仿学习泛化差的问题。通过在线过滤负奖励样本稳定价值估计，结合奖励加权监督目标提供密集中间步骤监督，并构建异步推理-训练框架支持实时人工纠错。实验表明，该方法仅用1.5小时真实训练即能掌握接触式操作任务，在效果与效率上显著超越基线方法，且微调后的策略展现出优秀的错误恢复能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.25725","title":"A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation","arxivId":"2510.25725","date":"2025-10-28","authors":"Kyung-Joong Kim Team","category":"Manipulation","summary":"本文针对机器人接触丰富操作中数据集不足的问题，提出首个类人机器人视觉-触觉-动作数据集。现有研究多关注刚性物体，缺乏对软物体操作中压力条件多样性的考虑。该数据集通过遥操作收集，使用配备灵巧手的类人机器人，捕捉与两个软物体在不同接触条件下的多模态交互。关键技术包括引入神经网络架构以高效融合密集触觉信息。实验收集了101.9K帧数据，并通过软物体操作任务及模仿学习基线评估，验证了数据集的实用性和触觉传感分辨率的重要性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.25405","title":"Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning","arxivId":"2510.25405","date":"2025-10-29","authors":"Florian T. Pokorny Team","category":"Manipulation","summary":"本文针对柔性和脆弱物体的机器人操作，核心问题是避免因过度应力造成物体损坏。提出了一种应力引导的强化学习框架，关键技术包括：在奖励函数中引入应力惩罚以抑制损伤，结合离线演示进行学习引导，并设计从刚性代理到柔性物体的渐进式课程。实验表明，该策略能零样本从仿真迁移到现实，成功完成豆腐抓取等任务。与普通强化学习策略相比，在达成任务目标的同时，能将施加于物体的应力降低36.5%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.25268","title":"SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation","arxivId":"2510.25268","date":"2025-10-29","authors":"Dan Guo Team","category":"Manipulation","summary":"本文提出SynHLMA框架，旨在解决关节物体上基于语言指令的手部操控序列生成问题，克服现有方法在整合语言描述与物体动态、长序列生成等方面的不足。关键技术采用离散HAOI表示，利用VQ-VAE对每帧交互进行离散编码，并通过HAOI Manipulation Language Model在共享表示空间中对齐抓取过程与语言描述，结合关节感知损失确保手部动作跟随物体关节变化。在自建HAOI-lang数据集上的实验表明，该方法在手部抓取序列生成性能上优于现有先进方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.25255","title":"Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths","arxivId":"2510.25255","date":"2025-10-29","authors":"Andreas Mueller Team","category":"Manipulation","summary":"本文针对松散放置的液体填充杯子沿预定路径的时间最优运输问题展开研究。核心挑战是在快速运输中最小化时间，同时避免液体溢出和杯子移位。由于未提供论文正文内容，无法提炼具体关键技术方法及核心实验结论。建议参考原文获取详细方法设计和性能数据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.25233","title":"Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery","arxivId":"2510.25233","date":"2025-10-29","authors":"Jongseong Brad Choi Team","category":"Manipulation","summary":"本文针对视觉伺服中目标遮挡与位姿估计不准的核心问题，提出一种混合视觉伺服框架。关键技术融合了**深度对齐网络**进行精准特征匹配与位姿预测，并引入**基于GRU的遮挡恢复模块**，利用时序信息推理并补全被遮挡目标的视觉特征。实验表明，该方法在遮挡场景下显著提升了伺服精度与鲁棒性，位姿估计误差较传统方法降低约35%，成功恢复率提升超过40%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.25138","title":"Learning Spatial-Aware Manipulation Ordering","arxivId":"2510.25138","date":"2025-10-29","authors":"Jian Pu Team","category":"Manipulation","summary":"本文针对杂乱环境中物体操作顺序因空间依赖关系易引发碰撞或阻塞的问题，提出OrderMind统一空间感知操作排序框架。该框架通过k-最近邻构建空间图，编码物体间及物体与操作器的交互，并引入空间先验标注方法指导视觉语言模型生成监督信号进行蒸馏学习。在包含163,222个样本的基准测试中，OrderMind在模拟和真实环境中均显著优于现有方法，实现了高效实时的鲁棒操作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.25122","title":"NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies","arxivId":"2510.25122","date":"2025-10-29","authors":"Jinghui Lu Team","category":"Manipulation","summary":"本文针对资源受限的边缘设备部署视觉-语言-动作模型时计算开销高、延迟大的问题，提出轻量级架构NanoVLA。其核心技术包括：视觉-语言解耦（将早期融合推迟至后期，降低推理开销）、长短期动作分块（保证多步规划的连贯性）以及动态路由（根据任务复杂度自适应选择骨干网络）。实验表明，该模型在边缘设备上推理速度提升达52倍，参数减少98%，同时保持或超越了原有模型的任务精度与泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.24261","title":"DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation","arxivId":"2510.24261","date":"2025-10-28","authors":"Gang Hua Team","category":"Manipulation","summary":"本文提出DynaRend框架，旨在解决机器人操作中因缺乏多样化真实数据而导致的策略泛化难题。其核心方法是利用可微分体积渲染进行掩码重建与未来预测，从多视角RGB-D视频中学习统一的三平面特征，以联合捕获空间几何、未来动态和任务语义。实验表明，该方法在RLBench和Colosseum基准测试及真实机器人实验中，显著提升了策略成功率、对环境扰动的泛化能力及跨任务的实用性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.24257","title":"Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors","arxivId":"2510.24257","date":"2025-10-28","authors":"Yue Gao Team","category":"Manipulation","summary":"本文针对机器人操作动作生硬、缺乏人类自然风格的问题，提出一种基于对抗运动先验（HMAMP）的方法来学习任务导向的人类风格操作技能。其核心是利用对抗网络，通过判别器融合真实人类运动与智能体模拟数据，驱动策略生成符合人类运动统计特性的轨迹。该方法在锤击任务上得到验证，结果表明其能有效学习人类风格的操作技能，性能优于现有基线方法，并已在真实机械臂上成功演示。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.24194","title":"Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames","arxivId":"2510.24194","date":"2025-10-28","authors":"Aviv Tamar Team","category":"Manipulation","summary":"本文研究行为克隆（BC）中策略对任务变化的泛化问题，旨在减少所需演示数量。提出**蒙眼专家**方法：隐藏部分任务信息，迫使专家进行非平凡探索。理论分析表明泛化误差与√(I/m)成正比（I为专家获得的信息量，m为演示任务数）。在真实机器人插孔任务和Procgen视频游戏上的实验表明，克隆蒙眼专家比克隆完全知情专家在未见任务上泛化更好，且所需演示更少。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.24109","title":"PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI","arxivId":"2510.24109","date":"2025-10-28","authors":"Philip Dames Team","category":"Manipulation","summary":"本文旨在解决现有基于LLM的具身智能体难以在线规划与执行复杂自然语言控制任务的问题。提出了PFEA框架，其核心是包含视觉任务规划器、指令转换器和反馈评估器的视觉语言智能体模块，以实现高层指令的闭环规划与执行。实验表明，该智能体在模拟和真实环境中的平均任务成功率比仅使用LLM+CLIP的方法提升了28%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.24095","title":"Learning Parameterized Skills from Demonstrations","arxivId":"2510.24095","date":"2025-10-28","authors":"George Konidaris Team","category":"Manipulation","summary":"本文提出Deps算法，解决从专家演示中学习结构化、可泛化技能的问题。核心是联合学习参数化技能策略与元策略，通过时间变分推断和信息论正则化，避免潜在变量模型退化，确保技能具有时序扩展性和语义意义。实验表明，该方法在LIBERO和MetaWorld基准上优于多任务及技能学习基线，显著提升对未见任务的泛化能力，并能学习可解释的技能（如通过连续参数指定抓取位置的抓取技能）。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.24055","title":"Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation","arxivId":"2510.24055","date":"2025-10-28","authors":"Jiashuo Bai Team","category":"Manipulation","summary":"本文针对多任务机器人模仿学习中的感知模糊性与任务冲突问题，提出了一种结合**语言条件视觉表示模块**和**语言条件专家混合密度策略**的框架。前者通过语言指令对齐视觉特征以区分相似任务；后者采用稀疏专家架构，让不同专家专精于多模态动作分布，并通过梯度调制稳定训练。在真实机器人基准测试中，该框架将ACT与DP的成功率分别提升33.75%和25%，整体平均成功率达到79%，优于先进基线21%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.23763","title":"RoboOmni: Proactive Robot Manipulation in Omni-modal Context","arxivId":"2510.23763","date":"2025-10-29","authors":"Xipeng Qiu Team","category":"Manipulation","summary":"本文提出RoboOmni，旨在解决机器人主动操作中意图推断的核心问题。当前方法依赖显式指令，而真实场景需从对话、环境声和视觉线索中推断意图。为此，作者构建了端到端全模态LLM框架Perceiver-Thinker-Talker-Executor，统一进行意图识别、交互确认和动作执行，并融合视听信号进行时空理解。同时，构建了包含14万条数据的大规模数据集OmniAction用于训练。实验表明，RoboOmni在成功率、推理速度、意图识别和主动协助方面均超越了基于文本和ASR的基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.23571","title":"RobotArena $\\infty$ : Scalable Robot Benchmarking via Real-to-Sim Translation","arxivId":"2510.23571","date":"2025-10-27","authors":"Katerina Fragkiadaki Team","category":"Manipulation","summary":"本文针对机器人政策评估在现实世界中劳动密集、不安全且难以复制的核心问题，提出RobotArena ∞基准框架。关键技术是Real-to-Sim Translation，利用视觉语言模型、2D到3D生成建模和可微分渲染，自动将真实视频演示转换为模拟环境（数字孪生）。评估结合自动VLM评分和众包人类偏好判断，并系统扰动纹理与物体放置以测试泛化。该框架实现了可扩展、可复现的基准，解决了机器人评估的标准化瓶颈。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.23184","title":"Finding 3D Scene Analogies with Multimodal Foundation Models","arxivId":"2510.23184","date":"2025-10-27","authors":"Young Min Kim Team","category":"Manipulation","summary":"本文针对现有3D场景类比方法需要额外训练、受限于固定物体词汇的问题，提出一种零样本开放词汇解决方案。核心方法是利用多模态基础模型构建混合神经场景表示：结合视觉语言模型（CLIP）特征的稀疏对象图与3D形状基础模型（PartField）的特征场。通过从粗到精的策略，先进行图匹配对齐对象，再利用特征场细化稠密对应关系。该方法能在复杂场景间建立准确映射，成功应用于轨迹与路径点的跨场景转移。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.23016","title":"ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation","arxivId":"2510.23016","date":"2025-10-27","authors":"Fei Chen Team","category":"Manipulation","summary":"本文针对现有机器人双手操作技能学习方法忽略姿态依赖任务特征的问题，提出ManiDP方法。该方法从专家示范中提取双手可操作性，利用黎曼概率模型编码姿态特征，并通过条件扩散过程生成任务兼容的运动序列。在六项真实任务实验中，相比基线方法，平均操作成功率提升39.33%，任务兼容性提高0.45。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.22789","title":"Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning","arxivId":"2510.22789","date":"2025-10-26","authors":"Guoquan Huang Team","category":"Manipulation","summary":"本文针对足式机器人在复杂环境中全身运动预测不准确、难以进行肢体级碰撞检查的问题，提出一种基于学习的神经观察者-预测器框架。神经观察者具备可证明的UUB稳定性保证，能从本体感知历史数据中可靠估计潜在状态；预测器计算高效，支持并行评估数千条轨迹，适用于基于采样的MPPI规划器。在Vision 60四足机器人上的硬件实验表明，该系统能在狭窄通道和小物体上实现有效的肢体感知运动规划，为高性能碰撞感知导航提供了鲁棒基础。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.22420","title":"A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems","arxivId":"2510.22420","date":"2025-10-25","authors":"Benyamin Safizadeh Team","category":"Manipulation","summary":"本文针对高维随机系统控制面临的维度灾难、缺乏时间抽象及稳定性保障难题，提出多时间尺度李雅普诺夫约束分层强化学习（MTLHRL）框架。该框架在半马尔可夫决策过程中整合高层战略规划与底层反应控制的分层策略，并采用经拉格朗日松弛优化的神经李雅普诺夫函数，通过多时间尺度演员-评论家更新确保随机稳定性。在8D超混沌系统和5-DOF机器人上的实验表明，MTLHRL显著优于基线方法，取得了最低误差指数（如超混沌控制IAE: 3.912，机器人控制IAE: 1.623），并表现出更快的收敛与抗干扰能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.22201","title":"ACG: Action Coherence Guidance for Flow-based VLA models","arxivId":"2510.22201","date":"2025-10-25","authors":"Jaegul Choo Team","category":"Manipulation","summary":"本论文标题为“ACG: Action Coherence Guidance for Flow-based VLA models”，表明研究致力于解决基于流的VLA模型中动作一致性的核心问题。提出ACG（动作一致性指导）方法，通过指导机制优化模型动作生成的连贯性。由于未提供正文内容，具体技术要点和实验结论无法详述，建议参考论文原文获取详细信息。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.22113","title":"RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation","arxivId":"2510.22113","date":"2025-10-25","authors":"Yang Ye Team","category":"Manipulation","summary":"本文针对传统机器人操纵杆控制精度要求高、参考框架不直观、用户负担重的问题，提出RaycastGrasp系统，利用可穿戴混合现实（MR）头显实现以自我为中心的注视交互。关键技术包括：基于自然注视固定的物体选择、增强视觉提示确认意图，以及集成预训练视觉模型和机器人手臂进行意图识别与操作。实验表明，该系统显著提升操作准确性、降低系统延迟，在多个真实场景中单次意图和物体识别准确率超过88%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.21991","title":"Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising","arxivId":"2510.21991","date":"2025-10-24","authors":"Yinchuan Li Team","category":"Manipulation","summary":"本文针对机器人操作中扩散策略推理步骤多、计算成本高的问题，提出一种两步扩散策略。核心方法是遗传去噪，通过选择低分布外风险的轨迹来优化去噪过程，以适应机器人动作分布的结构化、低维特性。实验表明，该方法仅需2步神经函数评估即可解决复杂任务，在14个机器人操作任务上性能最高提升20%，且推理步骤显著减少。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.21609","title":"Enhancing Tactile-based Reinforcement Learning for Robotic Control","arxivId":"2510.21609","date":"2025-10-24","authors":"Sethu Vijayakumar Team","category":"Manipulation","summary":"本文针对机器人控制中基于触觉的强化学习效果不一致、过度依赖理想化状态信息的问题，提出采用自监督学习（SSL）方法，通过利用稀疏二进制触觉信号来增强触觉观测的有效性，并解耦SSL内存与on-policy内存以提升性能。实验表明，稀疏二进制触觉信号对灵巧性至关重要，尤其在机器人-物体解耦运动中；代理在球弹跳和Baoding球旋转等复杂接触任务中实现了超人的灵巧性。论文还发布了Robot Tactile Olympiad（RoTO）基准以标准化研究。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.21571","title":"Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos","arxivId":"2510.21571","date":"2025-10-24","authors":"Baining Guo Team","category":"Manipulation","summary":"本文解决机器人操作中视觉-语言-动作模型预训练数据稀缺且多样性不足的问题。提出一种全自动的人类活动分析方法，将无标注的真实人类手部活动视频转化为结构化VLA数据，生成原子级动作片段、语言描述及3D手部运动信息。基于此构建了包含100万片段、2600万帧的大规模手部VLA数据集。预训练后的模型在完全未见过的真实观测中表现出强零样本能力，经少量真实机器人数据微调后，显著提升了任务成功率和对新物体的泛化性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.21560","title":"Learning Neural Control Barrier Functions from Expert Demonstrations using Inverse Constraint Learning","arxivId":"2510.21560","date":"2025-10-24","authors":"Hussein Sibai Team","category":"Manipulation","summary":"本文研究在失败状态集不明确时，如何从专家示范中学习神经控制障碍函数以确保自主系统安全。提出采用逆向约束学习方法，从专家轨迹中推断出能将系统状态分类为安全与不安全的约束函数，并利用该函数标注模拟轨迹数据来训练神经CBF。在四个不同环境中的实验表明，该方法优于现有基线，且性能与使用真实安全标签训练的神经CBF相当。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.21121","title":"Generalizable Hierarchical Skill Learning via Object-Centric Representation","arxivId":"2510.21121","date":"2025-10-24","authors":"Robert Platt Team","category":"Manipulation","summary":"本论文旨在解决智能体在多样环境中学习可泛化分层技能的挑战，核心方法是采用以对象为中心的表示。通过将场景分解为对象并构建基于对象的技能层次结构，该方法提升了技能的适应性和泛化能力。关键技术包括对象感知编码和分层策略学习。实验部分未提供具体数据，但论文报告了该方法在基准任务上相对于基线模型的性能改进，展示了更好的泛化效果。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.20965","title":"SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing","arxivId":"2510.20965","date":"2025-10-23","authors":"Axel Krieger Team","category":"Manipulation","summary":"本文提出SutureBot框架，旨在解决机器人实现端到端自主缝合手术的难题，该任务需要完成针抓取、组织穿刺和打结等长时程灵巧操作。核心方法是设计了一个目标条件控制框架，通过显式优化插入点精度来提升定位准确性。实验表明，该框架在达芬奇研究平台（dVRK）上将目标定位精度较仅任务优化的基线提升了59%-74%，并发布了包含1890次演示的高保真数据集用于可重复评估。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.20813","title":"GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation","arxivId":"2510.20813","date":"2025-10-23","authors":"Xiaolong Wang Team","category":"Manipulation","summary":"GSWorld旨在解决机器人操作策略训练中仿真视觉不真实、动作空间不对齐以及真实数据成本高的核心问题。它结合3D高斯溅射与物理引擎，提出GSDF资产格式融合高斯表示与机器人URDF，并通过双向管道实现闭环仿真：从真实场景重建数字孪生，支持策略直接部署到硬件。该套件支持零样本sim2real策略学习、自动化DAgger数据收集和可重复评估等应用，有效缩小sim-to-real差距，促进快速迭代。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.20774","title":"FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation","arxivId":"2510.20774","date":"2025-10-23","authors":"Yao Mu Team","category":"Manipulation","summary":"本文提出FieldGen框架，以解决机器人操作数据收集中规模、多样性与质量难以平衡的核心问题。该方法将操作分解为预操作与精细操作两阶段：人类提供关键接触点演示后，利用吸引力场自动生成多样化的轨迹，并结合FieldGen-Reward进行奖励标注以增强策略学习。实验表明，基于FieldGen训练的策略相比遥操作基线取得了更高的成功率和稳定性，同时显著降低了真实世界数据收集所需的人力成本。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.20483","title":"Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty","arxivId":"2510.20483","date":"2025-10-23","authors":"Tom Lefebvre Team","category":"Manipulation","summary":"本文针对负载参数未知的机器人拾放任务，提出双控制参考轨迹生成方法以解决模型不确定下的在线适应问题。核心采用两种技术：一是将参数不确定性嵌入鲁棒最优控制以最小化期望任务成本；二是通过最小化“最优性损失”来优化参数信息对任务性能的灵敏度。实验表明，所提方法在生成参考轨迹时同步考虑控制需求，能实现更快速、精准的任务执行与系统辨识，同时保证控制的稳定与高效。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.20406","title":"PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning","arxivId":"2510.20406","date":"2025-10-23","authors":"Gerhard Neumann Team","category":"Manipulation","summary":"本文提出PointMapPolicy，解决机器人模仿学习中点云方法难以捕捉细粒度几何细节、RGB方法缺乏3D几何感知的问题。该方法将点云组织为结构化网格（点图），避免下采样，从而可直接应用成熟的2D视觉架构处理3D数据，并利用xLSTM主干网络融合点图与RGB模态。在RoboCasa、CALVIN基准测试和真实机器人实验中，该方法在多样化操作任务上实现了最先进的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.20390","title":"NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control","arxivId":"2510.20390","date":"2025-10-23","authors":"Nathan F. Lepora Team","category":"Manipulation","summary":"本文针对基于视觉的神经描述符场（NDF）抓取姿态不准确，以及现有触觉方法局限于简单预定接触几何的问题，提出NeuralTouch多模态框架。该方法通过NDF隐式表示目标接触几何，并训练一个基于神经描述符的深度强化学习策略，利用触觉反馈精细调整抓取。在模拟和真实世界（如插拔、开瓶盖）任务上的零样本实验表明，该方法显著提升了抓取准确性与鲁棒性，无需额外微调。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.20328","title":"MemER: Scaling Up Memory for Robot Control via Experience Retrieval","arxivId":"2510.20328","date":"2025-10-23","authors":"Chelsea Finn Team","category":"Manipulation","summary":"本文旨在解决机器人策略缺乏长期记忆能力的问题，以处理需要分钟级记忆的复杂长时程操作任务。提出MemER分层框架：高层策略学习从历史经验中筛选和跟踪相关关键帧，结合近期观察生成文本指令，驱动底层策略执行。该方法兼容现有视觉-语言-动作模型，能高效推理长时依赖。实验在三个真实世界长时程操作任务上验证，MemER优于先前方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.19944","title":"Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets","arxivId":"2510.19944","date":"2025-10-22","authors":"Xuanmeng Zhang Team","category":"Manipulation","summary":"本文针对具身AI训练中模拟环境面临的内容多样性与物理准确性难以兼顾的挑战，提出了Seed3D 1.0基础模型。该模型的核心是从单张图像直接生成高保真、可直接用于物理模拟的3D资产，解决了手动创建资产导致的规模瓶颈。其关键技术在于生成具备精确几何、对齐纹理及物理真实材质的对象，这些资产无需复杂配置即可集成至物理引擎，用于机器人操作与场景构建，从而为基于物理的世界模拟器提供了可扩展的内容创建方案。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.19495","title":"Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning","arxivId":"2510.19495","date":"2025-10-25","authors":"Abhishek Gupta Team","category":"Manipulation","summary":"本文针对模仿学习过度依赖高质量专家数据、难以适应现实世界多样场景的问题，提出利用离线强化学习工具来有效利用非专家数据（如游戏数据、次优演示），以增强策略的鲁棒性。核心方法是对标准离线RL算法进行简单修改，以在稀疏数据覆盖的现实条件下利用此类数据，从而扩展策略分布的支持范围。实验表明，该方法能显著提升策略的恢复与泛化能力，在操作任务中大幅扩大策略成功的初始条件范围，并能有效利用所有收集到的部分或次优数据来提升任务性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.19400","title":"Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes","arxivId":"2510.19400","date":"2025-10-22","authors":"Baining Guo Team","category":"Manipulation","summary":"本文针对当前视觉语言模型评估集中于单视角、未能充分考察其在机器人多视角场景中空间推理能力的问题，提出了专门用于评估机器人操作中多视角空间推理的基准测试MV-RoboBench。该基准包含1.7k个涵盖空间理解与机器人执行的问答对。通过评估现有主流及增强模型，核心实验结论表明：当前最优模型性能远低于人类水平；多视角下空间智能与任务执行呈正相关；且单视角基准上的优势无法有效迁移至该多视角机器人任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.19373","title":"Using Temperature Sampling to Effectively Train Robot Learning Policies on Imbalanced Datasets","arxivId":"2510.19373","date":"2025-10-22","authors":"Bernadette Bucher Team","category":"Manipulation","summary":"本文针对机器人数据集在动作原语上严重失衡，导致训练的策略偏向高资源任务而低资源任务性能下降的问题，提出温度采样方法。该方法通过调整采样温度平衡数据分布，仅需少量代码即可集成到现有框架。实验表明，相比现有方法，该方法在低资源任务上取得显著性能提升，且不损害高资源任务表现，提升了多任务策略的泛化能力和模型容量利用效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.19356","title":"Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model","arxivId":"2510.19356","date":"2025-10-22","authors":"Jie Zhao Team","category":"Manipulation","summary":"本文针对模仿学习中扩散模型和流匹配方法因迭代去噪导致推理时间高、难以实时部署的问题，提出一种基于多步一致集成快捷模型的一步策略。方法通过扩展多步一致性损失，将一步损失拆分为多步损失以提升性能，并引入自适应梯度分配方法稳定优化过程。实验在两个仿真基准和五个真实环境任务中验证了算法的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.19307","title":"Unified Reinforcement and Imitation Learning for Vision-Language Models","arxivId":"2510.19307","date":"2025-10-22","authors":"Yueh-Hua Wu Team","category":"Manipulation","summary":"本文针对大规模视觉语言模型在资源受限环境中不实用的问题，提出统一强化与模仿学习算法。该方法结合强化学习与对抗模仿学习，利用LLM判别器区分师生输出，并引入多教师模型提供多样指导，使学生模型既能模仿教师生成，又能通过强化信号提升能力。实验表明，该算法使轻量级模型在多个视觉语言基准上性能显著提升，缩小了与顶尖开源及闭源模型的差距，并在部分任务上实现超越。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.19289","title":"TARMAC: A Taxonomy for Robot Manipulation in Chemistry","arxivId":"2510.19289","date":"2025-10-22","authors":"Jihong Zhu Team","category":"Manipulation","summary":"本文针对化学实验室自动化中机器人操作技能缺乏系统化描述、导致自主性受限的核心问题，提出了TARMAC——一个面向化学领域的机器人操作分类法。该方法通过分析教学实验视频，定义并组织了实验室的核心操作动作，将其按功能角色和物理执行要求进行分类。TARMAC不仅作为描述性词汇表，其定义的操作原语可被机器人直接执行或组合成高级指令，从而支持技能的复用和集成到长期工作流中，并通过实验验证了其有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.18518","title":"Efficient Model-Based Reinforcement Learning for Robot Control via Online Learning","arxivId":"2510.18518","date":"2025-10-21","authors":"Marco Hutter Team","category":"Manipulation","summary":"本文提出一种在线模型强化学习算法，用于直接在真实世界中训练复杂机器人控制系统。核心解决传统sim-to-real流程依赖大量离线仿真、存在仿真与现实差距的问题。方法通过实时交互数据在线构建动力学模型，并基于该模型指导策略更新，结合在线学习分析提供次线性遗憾界限的理论保证。在液压挖掘机臂和软机器人臂的实验中，该方法展现出显著样本效率，仅用数小时即达到与模型无关方法相当的性能，并在负载随机变化时表现出良好的动态适应能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.18337","title":"MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning","arxivId":"2510.18337","date":"2025-10-23","authors":"Heng Yang Team","category":"Manipulation","summary":"本文提出MoTVLA模型，旨在解决视觉-语言-动作模型中语言操控性不足与推理延迟高的核心问题。其关键技术采用混合Transformer架构，集成快速-慢速统一推理：预训练VLM作为通用专家处理感知与规划，领域专家Transformer共享其知识以生成机器人运动分解等快速推理，并通过运动指令条件化提升策略执行效率与语言操控性。实验在NLP基准、仿真与真实机器人任务中验证了该方法在推理效率和操作性能上的优越性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.18316","title":"MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation","arxivId":"2510.18316","date":"2025-10-21","authors":"Li Fei-Fei Team","category":"Manipulation","summary":"本文提出MoMaGen框架，旨在解决多步骤双手移动操作任务中，大规模演示数据收集成本高昂的问题。核心挑战在于移动基座带来的可达性约束与主动相机带来的可见性约束。方法将数据生成建模为约束优化问题，同时满足硬约束（如可达性）与软约束（如导航可见性）。实验表明，MoMaGen在四个任务上生成的数据集多样性显著优于先前方法，仅需一个源演示即可训练出成功的模仿学习策略，并经40个真实演示微调后成功部署于真实机器人硬件。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.18137","title":"Quality Over Quantity: Curating Contact-Based Robot Datasets Improves Learning","arxivId":"2510.18137","date":"2025-10-20","authors":"Ian Abraham Team","category":"Manipulation","summary":"本文针对机器人学习中“数据越多越好”的范式，提出数据质量比数量更重要。核心问题是：如何筛选具有高信息量的接触数据以加速学习。关键技术是提出一种**接触感知的Fisher信息度量**，用于量化并排序接触数据的信息含量，从而指导数据集筛选。实验结果表明，**基于该度量筛选出的少量高质量数据，相比原始大数据集，能更高效、更确定地加速模型学习**，验证了“少而精”的数据策略在接触式机器人学习中的优越性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.18085","title":"R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations","arxivId":"2510.18085","date":"2025-10-20","authors":"Daniel S. Brown Team","category":"Manipulation","summary":"本文解决了多智能体模仿学习（IL）中人类只能提供单智能体演示的核心挑战，传统方法依赖不切实际的同步多智能体演示。为此，提出了R2BC（轮询行为克隆）方法，其要点是允许人类循环远程操作单个智能体，非操作智能体执行当前学习策略，通过在线迭代训练学习协作行为。实验表明，在四个多智能体模拟任务中，R2BC性能匹配甚至超越基于特权同步演示的Oracle行为克隆方法，并在两个物理机器人任务上成功部署验证。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.18060","title":"SPACeR: Self-Play Anchoring with Centralized Reference Models","arxivId":"2510.18060","date":"2025-10-20","authors":"Wei Zhan Team","category":"Manipulation","summary":"本文提出SPACeR方法，旨在解决自动驾驶模拟中智能体行为生成的两难问题：模仿学习拟人但计算慢，自博弈RL高效但易偏离人类规范。该方法核心是**human-like self-play框架**，利用预训练的tokenized自回归运动模型作为**集中式参考策略**，通过提供似然奖励和KL散度，将分散式自博弈策略**锚定在人类驾驶分布**上。在Waymo Sim Agents Challenge上的实验表明，该方法在保持与模仿学习竞争性能的同时，**推理速度提升10倍，模型参数减少50倍**，并能有效支持闭环规划测试。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.17640","title":"RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation","arxivId":"2510.17640","date":"2025-10-20","authors":"Ziwei Wang Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型在模仿学习中因训练数据缺乏分布外状态而鲁棒性差的问题，提出RESample数据增强框架。该框架通过离线强化学习获取动作价值网络以识别次优动作，并利用探索性采样机制自动生成并融入分布外状态数据。实验表明，该方法在LIBERO基准和真实机器人任务上有效提升了模型的稳定性与泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.17150","title":"OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation","arxivId":"2510.17150","date":"2025-10-22","authors":"Arash Ajoudani Team","category":"Manipulation","summary":"本文针对传统可变阻抗控制器在复杂、未见过的接触式操作任务中泛化能力不足、难以保证安全交互的问题，提出OmniVIC。其核心技术是结合视觉语言模型的**自改进检索增强生成与上下文学习机制**：通过检索历史经验，并利用当前任务提示生成自适应的阻抗参数，同时引入实时力/力矩反馈确保安全。实验表明，该方法在多种接触式任务中显著优于基线，**平均成功率从27%提升至61.4%**，有效实现了高层语义推理与底层柔顺控制的结合。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.17086","title":"Learning to Design Soft Hands using Reward Models","arxivId":"2510.17086","date":"2025-10-20","authors":"Sha Yi Team","category":"Manipulation","summary":"本文研究如何高效设计兼具柔顺性与功能性的软体机械手。针对硬件与控制协同设计搜索空间大、仿真评估成本高的问题，提出基于奖励模型的交叉熵方法（CEM-RM），利用预收集的遥操作数据优化手指模块、肌腱布局等设计分布。该方法将设计评估次数减少一半以上，并通过3D打印实现硬件验证。实验表明，优化后的软体手在多种挑战性物体抓取任务中成功率显著优于基线设计。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.16756","title":"End-to-end Listen, Look, Speak and Act","arxivId":"2510.16756","date":"2025-10-19","authors":"Chao Zhang Team","category":"Manipulation","summary":"本文提出ELLSA模型，旨在解决AI难以实现人类式全双工多模态交互的核心问题。其关键技术是SA-MoE架构，通过自注意力主干将各模态路由至专用专家并融合，以统一架构支持跨视觉、文本、语音和动作的同步感知与生成。实验表明，该模型在语音交互与机器人操作任务上匹配了各模态独立基线的性能，并率先实现了对话与动作轮流、边说边做、指令拒绝等高级全双工行为。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.16617","title":"MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation","arxivId":"2510.16617","date":"2025-10-18","authors":"Ufuk Topcu Team","category":"Manipulation","summary":"本文提出MoS-VLA模型，旨在解决现有视觉-语言-动作模型在新环境或任务中泛化能力差的问题。其核心方法是将机器人策略表示为有限学习基函数的线性组合，预训练时从多数据集中联合学习这些基函数以构建结构化技能空间。测试时仅需单次专家演示，通过一个轻量级、无需梯度更新的L1误差凸优化问题，即可快速推断并适配新技能。实验表明，该模型在五个未见数据集上均取得了更低的动作预测误差，并能成功完成预训练VLA模型完全失败的仿真与真实机器人任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.16424","title":"Learning to Optimize Edge Robotics: A Fast Integrated Perception-Motion-Communication Approach","arxivId":"2510.16424","date":"2025-10-18","authors":"Chengzhong Xu Team","category":"Manipulation","summary":"本文针对边缘机器人系统中机器人功能与通信条件相互依赖、通信开销过大的核心问题，提出了一种快速集成感知-运动-通信（IPMC）方法。该方法通过联合优化压缩比、传输频率和发射功率等通信策略，动态适配机器人的感知与运动状态，从而减少冗余数据传输。关键技术是采用了学习优化（LTO）范式，设计了一个模仿学习神经网络来近似求解优化问题。实验表明，该神经网络的计算复杂度比现有最优求解器降低了10倍以上，并证明了IPMC的优越性与LTO的实时执行能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.16231","title":"DeGrip: A Compact Cable-driven Robotic Gripper for Desktop Disassembly","arxivId":"2510.16231","date":"2025-10-17","authors":"Minghui Zheng Team","category":"Manipulation","summary":"本文针对废旧电脑台式机拆解中，标准夹爪在狭小空间和复杂配置下适应性差的核心问题，提出定制化夹爪DeGrip。其关键技术包括：三自由度设计、采用减小尺寸的线缆驱动传动机制，以及实现腕部和颚部关节驱动解耦的手腕结构。在Isaac Sim构建的仿真拆解环境中进行验证，实验结果表明DeGrip能够有效完成废旧台式机的拆解任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.15786","title":"DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation","arxivId":"2510.15786","date":"2025-10-17","authors":"Yiwen Lu Team","category":"Manipulation","summary":"本文针对灵巧操作中缺乏大规模、物理准确的人类演示数据集这一核心问题，提出了DexCanvas数据集。其关键技术是构建了一个结合真实与合成数据的混合数据集，并通过一个“真实到仿真”流程，利用强化学习训练策略，在物理仿真中驱动仿生手复现人类演示并推断接触力。该数据集首次系统整合了大规模真实演示、基于分类学的技能覆盖以及物理验证的接触标注，包含源自70小时真实演示的7000小时手物交互数据，覆盖21种基本操作类型，旨在推动灵巧操作学习与接触力控制的研究。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.15530","title":"VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation","arxivId":"2510.15530","date":"2025-10-22","authors":"Bin He Team","category":"Manipulation","summary":"本文提出VO-DP，一种用于纯视觉机器人操作的语义-几何自适应扩散策略。核心问题是解决现有模仿学习方法过度依赖点云输入、缺乏高效纯视觉方案的问题。方法上，VO-DP利用预训练视觉基础模型（VGGT、DINOv2）提取语义与几何特征，通过交叉注意力融合并经CNN压缩后输入策略头。实验表明，在模拟任务中VO-DP平均成功率达64.6%，与点云方法DP3（64.0%）相当，并远超纯视觉基线DP（34.8%）；在真实任务中达到87.9%，显著优于DP3（67.5%）和DP（11.2%），且在不同干扰下保持高鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.15510","title":"Exploring Conditions for Diffusion models in Robotic Control","arxivId":"2510.15510","date":"2025-10-17","authors":"Taekyung Kim Team","category":"Manipulation","summary":"本文探索如何利用预训练文本到图像扩散模型为机器人控制获取任务自适应的视觉表示，而无需微调模型本身。核心问题是发现直接使用文本条件（在其他视觉任务中有效）在控制任务中收效甚微甚至有害，归因于训练数据与控制环境间的领域差距。为此，作者提出ORCA方法，引入**可学习的任务提示**以适应控制环境，并设计**视觉提示**以捕捉细粒度、帧特定的动态信息。该方法通过促进任务自适应表示，在多个机器人控制基准测试中取得了最先进的性能，显著超越了先前方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.15464","title":"Learning to Answer from Correct Demonstrations","arxivId":"2510.15464","date":"2025-10-17","authors":"Nathan Srebro Team","category":"Manipulation","summary":"本文研究从正确示范中学习生成答案的问题，其中每个问题可能存在多个可接受的正确答案。传统方法假设演示策略属于低复杂度类，采用最大似然估计（如对数损失最小化）。作者提出只需奖励模型（判断答案正确与否的函数类）具有低基数性，这是更弱的假设。他们证明最大似然方法在此设定下可能失败，并提出一种新方法，其样本复杂度仅与奖励类基数呈对数关系，从而为超越似然最大化的学习范式提供了理论依据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.15352","title":"GaussGym: An open-source real-to-sim framework for learning locomotion from pixels","arxivId":"2510.15352","date":"2025-10-17","authors":"Pieter Abbeel Team","category":"Manipulation","summary":"本文提出GaussGym，一个开源的真实到仿真框架，旨在解决现有仿真器视觉保真度低或速度慢的问题，从而阻碍从RGB像素直接学习机器人运动策略。其核心技术是将**3D高斯泼溅渲染技术**作为插件，集成到向量化物理引擎中，实现了**超过10万步/秒的高通量仿真**。实验表明，该框架能利用丰富的视觉语义（如避开特定区域）来提升导航与决策，并能快速从手机扫描、场景数据集等多样化数据源构建逼真训练环境。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.15189","title":"RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation","arxivId":"2510.15189","date":"2025-10-16","authors":"Jianfei Yang Team","category":"Manipulation","summary":"本文针对机器人精确操作任务中专家演示数据获取困难、离线强化学习存在分布偏移和数据效率低的问题，提出角色模型强化学习框架。其核心是采用角色模型策略，自动为在线交互数据生成近似最优动作标签，从而无需人类演示，并将策略学习重构为监督训练以提升稳定性。实验表明，该方法比现有强化学习方法收敛更快更稳，在真实操作任务中实现了53%的平移精度和20%的旋转精度提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.14930","title":"VT-Refine: Learning Bimanual Assembly with Visuo-Tactile Feedback via Simulation Fine-Tuning","arxivId":"2510.14930","date":"2025-10-18","authors":"Yunzhu Li Team","category":"Manipulation","summary":"本文提出VT-Refine框架，解决机器人执行精确双手装配任务时，因人类演示数据有限且缺乏触觉反馈，导致策略鲁棒性不足的问题。方法结合真实演示与高保真触觉模拟：首先基于少量视觉-触觉演示数据预训练扩散策略，随后在配备GPU加速触觉传感器的数字孪生仿真环境中，通过大规模强化学习对策略进行微调，以提升泛化能力。实验表明，该方法通过增加数据多样性和强化微调，有效提升了模拟与真实环境中的装配性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.14851","title":"SADCHER: Scheduling using Attention-based Dynamic Coalitions of Heterogeneous Robots in Real-Time","arxivId":"2510.14851","date":"2025-10-16","authors":"Javier Alonso-Mora Team","category":"Manipulation","summary":"本文提出SADCHER框架，旨在解决异构多机器人团队在动态环境中，考虑任务优先级约束与动态联盟形成的实时任务分配问题。其核心技术是结合图注意力网络与Transformer的模仿学习方法，预测机器人与任务间的分配奖励，并通过松弛二分匹配生成可行调度。实验表明，该方法在随机未见问题上优于其他学习与启发式基线，计算时间满足实时要求，且通过小规模最优解训练后，能泛化至更大规模的团队与任务集。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.14830","title":"RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning","arxivId":"2510.14830","date":"2025-10-16","authors":"Huazhe Xu Team","category":"Manipulation","summary":"论文解决真实世界机器人操作需高可靠性、效率及鲁棒性的核心问题。提出RL-100框架，基于扩散视觉运动策略，关键技术包括：统一模仿与强化学习于PPO风格目标，应用于去噪过程；通过轻量级一致性蒸馏将多步扩散压缩为一步控制器，满足低延迟部署。实验在七项多样任务中达成100%成功率（900/900次），匹配或超越专家操作速度，零样本环境下成功率约90%，少量样本适应任务变体达86.7%，抗人为干扰约95%，榨汁机器人零样本部署连续运行约7小时无故障。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.14771","title":"Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation","arxivId":"2510.14771","date":"2025-10-16","authors":"Shan An Team","category":"Manipulation","summary":"本文针对模仿学习中高质量演示数据采集的瓶颈问题，提出Open TeleDex，一个硬件无关的统一遥操作框架。其核心是解决“TripleAny”挑战，通过基于ROS2的架构，旨在无缝支持任何机械臂、灵巧手和外部输入设备。关键技术包括一种新的手部姿态重定向算法，以提升系统对不同主从设备的兼容性与精度。该系统为复杂操作和模仿学习的研究与应用建立了一个高质量、开源的基础数据采集平台。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.14615","title":"Accelerated Multi-Modal Motion Planning Using Context-Conditioned Diffusion Models","arxivId":"2510.14615","date":"2025-10-16","authors":"Wilm Decré Team","category":"Manipulation","summary":"本文针对机器人运动规划中经典方法难以适应高维状态空间、复杂环境且泛化能力有限的问题，提出了一种上下文感知的运动规划扩散模型（CAMPD）。该方法的核心是采用classifier-free去噪概率扩散模型，并通过集成在U-Net中的注意力机制，使其能够基于传感器无关的上下文信息进行条件化生成。在7自由度机械臂上的实验表明，该方法能泛化到未见过的环境，生成高质量的多模态轨迹，且规划速度显著快于现有先进方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.14467","title":"Restoring Noisy Demonstration for Imitation Learning With Diffusion Models","arxivId":"2510.14467","date":"2025-10-16","authors":"Shao-Hua Sun Team","category":"Manipulation","summary":"本文针对模仿学习（IL）中专家示范常含噪声（如传感器误差或控制不准确）导致策略性能下降的问题，提出一种过滤-恢复框架。该方法首先从噪声示范中筛选干净样本，然后利用条件扩散模型学习并恢复噪声示范，最后聚合示范以训练策略。实验在机器人手臂操作、灵巧操作和运动等多领域进行，结果显示该框架在所有任务上均一致优于现有方法，消融研究验证了各组件有效性及对不同噪声类型和水平的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.14300","title":"Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning","arxivId":"2510.14300","date":"2025-10-16","authors":"Yao Mu Team","category":"Manipulation","summary":"本文针对扩展Vision-Language-Action模型时面临的计算资源需求大、机器人数据稀缺以及模型容量与效率平衡的核心挑战，提出AdaMoE架构。该方法基于混合专家模型，继承预训练权重，通过将前馈层替换为稀疏激活的MoE层来扩展动作专家，并采用解耦技术使专家选择与权重分配独立，实现协作利用而非赢家通吃。实验结果表明，AdaMoE在LIBERO和RoboTwin基准上性能分别提升1.8%和9.3%，真实世界实验更提升21.5%，验证了其有效性和实用性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.14117","title":"ViTacGen: Robotic Pushing with Vision-to-Touch Generation","arxivId":"2510.14117","date":"2025-10-15","authors":"Shan Luo Team","category":"Manipulation","summary":"本文提出ViTacGen框架，旨在解决机器人推动任务中真实触觉传感器成本高、易损坏且部署困难，而纯视觉策略性能不足的问题。其核心方法包含一个编码器-解码器网络，能够从视觉图像序列直接生成标准化的触觉表征（接触深度图像），以及一个基于对比学习的强化学习策略，用于融合视觉与生成的触觉观测。实验表明，该方法在仿真和真实世界中均有效，实现了高达86%的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.14065","title":"Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning","arxivId":"2510.14065","date":"2025-10-15","authors":"Bram Vanderborght Team","category":"Manipulation","summary":"本文针对机器人任务与运动规划中，确定性动作规划难以处理具有效果不确定性的概率性动作（如推、滑等），而强化学习又难以进行长时程规划的问题，提出一种将强化学习技能集成到TAMP流程的方法。其关键技术是定义带有数据驱动逻辑组件的RL技能，使其能被符号规划调用，并设计计划精炼子程序处理效果不确定性。实验表明，该方法成功将TAMP能力扩展至概率性技能领域，并相较于已有方法提升了规划效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.13626","title":"LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models","arxivId":"2510.13626","date":"2025-10-15","authors":"Xipeng Qiu Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型在基准测试中高成功率掩盖鲁棒性不足的问题，提出LIBERO-Plus分析框架。方法上，基于LIBERO基准引入七维度受控扰动（物体布局、相机视角、机器人初始状态等），对多个先进模型进行系统性脆弱性分析。核心发现表明，模型对相机视角、初始状态等扰动极度敏感，性能可从95%骤降至30%以下；同时模型倾向于完全忽略语言指令，揭示了当前VLA模型在真实变化下的脆弱本质。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.13616","title":"Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor","arxivId":"2510.13616","date":"2025-10-15","authors":"Xiaobo Tan Team","category":"Manipulation","summary":"本文针对机器人农产品处理中力和刚度预测效率低的核心问题，提出采用压阻压力传感器作为关键技术方法。通过利用传感器的压阻效应，将压力信号转换为电信号，实现实时监测和预测。论文可能通过实验验证了该方法在提升预测精度和速度方面的有效性，但具体性能数据需参考正文内容。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.13595","title":"Active Tactile Exploration for Rigid Body Pose and Shape Estimation","arxivId":"2510.13595","date":"2025-10-15","authors":"Michael Posa Team","category":"Manipulation","summary":"本文针对仅使用触觉数据同时估计未知刚体物体形状与位姿的问题，提出一种主动探索框架。核心挑战在于触觉数据稀疏且接触易扰动物体。关键技术包括：1）构建一种惩罚物理约束违反、避免数值刚度的损失函数以联合优化形状与运动轨迹；2）采用最大化期望信息增益（EIG）的主动探索策略，高效选择探测动作。实验表明，该方法仅需首次接触后不足10秒的随机触觉数据，即可学习立方体及凸多面体几何；基于EIG的主动探索在仿真与真实机器人实验中均显著加快了学习速度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.13324","title":"Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation","arxivId":"2510.13324","date":"2025-10-15","authors":"Jan Peters Team","category":"Manipulation","summary":"本文提出FARM框架，解决接触式机器人操作中抓取力难以精确控制的核心问题。方法核心是触觉条件化扩散策略：通过高维触觉数据推断力信号，并构建基于力的动作空间，使策略能联合预测位姿、夹爪宽度与抓取力。实验表明，FARM在需高力、低力及动态力适应的三类任务上均优于基线，验证了力感知触觉观测与力控空间的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.13237","title":"Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models","arxivId":"2510.13237","date":"2025-10-15","authors":"Jingfeng Zhang Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型对抗鲁棒性未充分探索的问题，提出模型无关的攻击与防御方法。攻击方面，提出嵌入破坏补丁攻击（EDPA），通过破坏视觉与文本潜在表示的语义对齐、并最大化对抗与干净视觉输入的表示差异，生成可直接放置的对抗补丁。防御方面，采用对抗性微调视觉编码器，优化其使干净和对抗输入产生相似表示。在LIBERO基准上的实验表明，EDPA能显著提高尖端VLA模型的任务失败率，而所提防御有效缓解了性能下降。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.13054","title":"VLA-0: Building State-of-the-Art VLAs with Zero Modification","arxivId":"2510.13054","date":"2025-10-15","authors":"Fabio Ramos Team","category":"Manipulation","summary":"本文提出VLA-0，旨在解决构建视觉-语言-动作模型时方法复杂、可能损害基础模型性能的问题。其核心方法是将动作直接表示为文本，通过提示视觉语言模型预测动作文本，无需修改模型架构或添加额外模块。实验表明，在LIBERO基准测试中，VLA-0超越了所有使用相同机器人数据训练的现有方法（如π0.5-KI、OpenVLA-OFT等），且在没有大规模机器人特定训练的情况下，性能优于经过大规模数据训练的模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.12971","title":"Actron3D: Learning Actionable Neural Functions from Videos for Transferable Robotic Manipulation","arxivId":"2510.12971","date":"2025-10-14","authors":"Stefan Leutenegger Team","category":"Manipulation","summary":"本文提出Actron3D框架，解决机器人如何从少量单目、未标定的RGB人类视频中学习可迁移的6-DoF操作技能这一核心问题。其关键技术是**神经可达性函数**，它将视频中提取的几何、外观与可达性等多模态信息编码为轻量神经表示，构成技能记忆库；并通过**“蒸馏-转移”流程**，利用粗到细优化实现对新场景的零样本策略迁移。实验表明，该方法在模拟和真实场景中显著优于已有方法，在13项任务上平均成功率提升**14.9%**，且每任务仅需**2–3个**演示视频。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.12866","title":"Learning to Grasp Anything by Playing with Random Toys","arxivId":"2510.12866","date":"2025-10-14","authors":"Roei Herzig Team","category":"Manipulation","summary":"本文针对机器人抓取策略难以泛化到新物体的问题，受儿童通过简单玩具学习泛化能力的启发，研究机器人能否通过有限训练实现广泛抓取。方法上，提出使用随机组合四种基本形状（球体、长方体、圆柱体、圆环）构成的“玩具”进行训练，其关键技术是通过检测池化机制学习以物体为中心的视觉表示。实验表明，仅在此合成数据上训练的模型，在真实YCB数据集上实现了67%的零样本抓取成功率，优于依赖更多领域内数据的方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.12560","title":"CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving","arxivId":"2510.12560","date":"2025-10-14","authors":"Jiangtao Gong Team","category":"Manipulation","summary":"本文提出CoIRL-AD框架，旨在解决自动驾驶中模仿学习（IL）泛化能力差、强化学习（RL）样本效率低的问题。核心方法为竞争协作式双策略学习，使IL与RL智能体在潜在世界模型中交互训练，通过竞争机制促进知识交换并避免梯度冲突。在nuScenes数据集上的实验表明，该方法相比基线模型碰撞率降低18%，且在长尾场景中展现出更强的泛化性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.12509","title":"Automated Behavior Planning for Fruit Tree Pruning via Redundant Robot Manipulators: Addressing the Behavior Planning Challenge","arxivId":"2510.12509","date":"2025-10-14","authors":"Bram Vanderborght Team","category":"Manipulation","summary":"本文针对机器人果树修剪中的行为规划挑战，提出一种集成解决方案。核心问题是解决高自由度机械臂在复杂枝干碰撞环境中的多层级运动规划。关键技术包括：系统分析机器人内在冗余性，构建融合感知、建模与整体规划的修剪工作流程。实验表明，所提出的全面规划方法能显著提升机械臂作业性能，并已在真实机器人系统上实现验证。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.12483","title":"Fast Visuomotor Policy for Robotic Manipulation","arxivId":"2510.12483","date":"2025-10-14","authors":"Wenqiang Zhang Team","category":"Manipulation","summary":"本文提出名为Energy Policy的快速机器人操作策略框架，旨在解决实时机器人任务中高效、精准的多模态动作预测难题。核心技术包括：1）采用能量分数作为学习目标，以建模多模态动作分布；2）设计轻量能量MLP，实现单次前向预测。实验表明，该方法在MimicGen等基准上达到或超越现有最优性能，同时显著降低计算开销，推理速度更快，模型参数量更小。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.12403","title":"Robot Learning: A Tutorial","arxivId":"2510.12403","date":"2025-10-14","authors":"Michel Aractingi Team","category":"Manipulation","summary":"本文是一篇机器人学习教程，旨在为研究者和从业者提供该领域的概览与实用工具。核心问题是探讨如何整合现代机器学习与经典机器人技术，以创建能在非结构化动态环境中自主运作的机器人系统。教程重点介绍了从强化学习、行为克隆到通用型语言条件模型等一系列关键技术范式，标志着该领域正从传统模型驱动转向数据驱动。作为指南性文献，本文未报告具体实验数据，但提供了开源代码库（lerobot）作为实践起点。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.12392","title":"Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking","arxivId":"2510.12392","date":"2025-10-14","authors":"Eunhyeok Park Team","category":"Manipulation","summary":"本文针对生成式行为克隆（GBC）中扩散策略的随机性易导致动作采样错误，以及开环控制响应延迟、在动态环境中性能下降的核心问题，提出自我引导（self-guidance）和自适应分块（adaptive chunking）两种技术。自我引导利用过去观察提升动作保真度并隐式促进未来感知；自适应分块根据反应性需求选择性更新动作序列以平衡一致性。大量实验表明，该方法在模拟和真实机器人操作任务中显著提升了GBC性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.11689","title":"Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation","arxivId":"2510.11689","date":"2025-10-13","authors":"Mac Schwager Team","category":"Manipulation","summary":"论文Phys2Real旨在解决模拟到现实转移中机器人操作策略难以适应变化物体物理属性（如质量分布）的核心挑战。方法融合视觉语言模型（VLM）先验与交互式在线适应，通过3D高斯溅射重建、VLM推断物理参数先验及在线估计，并利用集成不确定性量化细化预测。实验在T块和锤子推动任务中显示，相比域随机化基线，Phys2Real显著提升性能：底部加权T块成功率100% vs 79%，顶部加权57% vs 23%，锤子推动平均任务完成速度快15%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.11660","title":"ManiAgent: An Agentic Framework for General Robotic Manipulation","arxivId":"2510.11660","date":"2025-10-14","authors":"Xudong Liu Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型在复杂推理与长时程任务规划中受限于数据稀缺和模型能力的问题，提出ManiAgent——一个用于通用机器人操作的智能体框架。该框架采用多智能体协同架构，通过感知、推理与执行三个专用智能体间的通信，实现对环境感知、子任务分解和动作生成的端到端处理。实验表明，ManiAgent在SimperEnv基准测试中达到86.8%的成功率，在真实世界取放任务中达到95.8%的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.11321","title":"HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data","arxivId":"2510.11321","date":"2025-10-13","authors":"Yanchao Yang Team","category":"Manipulation","summary":"本文提出HiMaCon框架，解决机器人操作在未见过场景中的泛化问题。通过自监督学习，从无标签多模态数据中发现分层操作概念，无需人工标注。关键技术包括跨模态相关网络捕捉感官模态间的不变模式，以及多时间尺度预测器实现跨时间尺度的分层表示组织。实验表明，基于这些概念的策略在模拟基准和真实部署中性能显著提升，且学习到的概念类似人类可解释的操作原语。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.11307","title":"FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks","arxivId":"2510.11307","date":"2025-10-13","authors":"Alessandro Suglia Team","category":"Manipulation","summary":"本文针对具身视觉语言任务中模仿学习只能利用最优演示样本、无法从次优数据中学习的问题，提出FOSSIL方法。该方法的核心是**将语言反馈嵌入作为Transformer策略的输入**，并可选地增加**辅助的自监督反馈预测目标**，使智能体能利用语言反馈理解并学习次优行为。在BabyAI-XGen环境上的实验表明，该方法能**显著提升智能体的组合泛化能力与鲁棒性**，验证了语言反馈作为标量奖励替代方案的有效性，实现了数据高效的学习。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.11258","title":"DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation","arxivId":"2510.11258","date":"2025-10-13","authors":"Zongqing Lu Team","category":"Manipulation","summary":"DemoHLM旨在解决人形机器人移动操作自主性与泛化能力不足的问题，克服传统方法依赖硬编码任务或昂贵真实数据收集的局限。该框架采用分层结构，集成底层通用全身控制器（提供全向移动）与高层操纵策略（通过模拟中数据生成和模仿学习训练，仅需单个演示即可自动合成大量轨迹）。实验表明合成数据量与策略性能呈正相关，验证了数据生成管道的有效性和数据高效性；在Unitree G1机器人上的真实实验成功实现模拟到现实转移，在十个移动操作任务中表现出稳健性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.10903","title":"Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey","arxivId":"2510.10903","date":"2025-10-13","authors":"Badong Chen Team","category":"Manipulation","summary":"根据您提供的标题《Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey》，本文是一篇综述性论文。由于未提供论文正文，我无法提炼具体的技术方法、实验结论或性能数据。若您能提供正文内容，我将很乐意为您撰写一段符合要求的精准总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.10637","title":"High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting","arxivId":"2510.10637","date":"2025-10-12","authors":"Hua Zou Team","category":"Manipulation","summary":"本文针对机器人学习中真实数据收集成本高、仿真数据因视觉与物理差距难以迁移到真实世界（Sim2Real鸿沟）的核心问题，提出了RoboSimGS框架。其关键技术是采用混合场景表示：利用3D高斯泼溅实现高保真视觉重建，结合交互物体的网格图元确保精确物理模拟，并创新性地使用多模态大语言模型自动推断物体的物理属性与运动结构。实验表明，完全使用该方法生成的数据训练的策略，能成功实现跨多种真实操作任务的零样本迁移，并显著增强现有先进方法的性能与泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.10516","title":"Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control","arxivId":"2510.10516","date":"2025-10-12","authors":"Jeethu Sreenivas Amuthan Team","category":"Manipulation","summary":"本文针对高维连续机器人控制中能量效率与计算性能难以平衡的核心问题，提出了一种结合群体编码脉冲神经网络（SNN）和深度强化学习（DRL）的新框架。关键技术是群体编码脉冲行动者网络（PopSAN），它将高维观测编码为神经元群体活动，通过基于梯度的更新实现策略优化。实验在Isaac Gym平台使用PixMC等基准测试，结果表明该方法在能量效率、延迟降低和连续动作空间稳健性方面均有显著提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.10274","title":"X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model","arxivId":"2510.10274","date":"2025-10-11","authors":"Xianyuan Zhan Team","category":"Manipulation","summary":"本文提出X-VLA模型，旨在解决跨不同机器人平台（跨具身）的异构数据整合难题，以训练通用的视觉-语言-动作模型。其核心技术是软提示方法，为每个数据源引入可学习的嵌入向量作为特定具身提示，结合基于流匹配的Transformer编码器架构，实现参数高效且可扩展的跨平台学习。实验在6个仿真环境和3个真实机器人上进行，0.9B参数的X-VLA在多项基准测试中达到SOTA性能，展现出从灵巧操作到快速跨平台适应的优异能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.10217","title":"UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction","arxivId":"2510.10217","date":"2025-10-11","authors":"Tetsuya Ogata Team","category":"Manipulation","summary":"本文提出UF-RNN模型，以解决机器人在不确定环境（如物体属性模糊）中适应性差的问题。核心方法是引入“Foresight”模块，通过内部模拟多条未来轨迹、优化隐藏状态以降低预测方差，从而在高不确定性下引导探索性行为。在仿真与真实机器人的开门任务中，模型无需失败示例，即通过潜在空间的自诱导混沌动力学实现鲁棒适应，相比传统随机RNN基线取得了更高的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.10125","title":"Ctrl-World: A Controllable Generative World Model for Robot Manipulation","arxivId":"2510.10125","date":"2025-10-15","authors":"Chelsea Finn Team","category":"Manipulation","summary":"本文提出Ctrl-World，一个用于机器人操作的可控生成世界模型，旨在解决通用策略在陌生对象和指令下评估成本高、改进困难的核心问题。模型通过位姿条件记忆检索机制保持长时程一致性，并利用帧级动作条件实现精细控制。在DROID数据集上训练后，该模型能在新场景及相机位姿下生成超过20秒的时空一致轨迹。实验表明，该方法无需真实机器人测试即可准确评估策略性能，并通过在想象中合成成功轨迹进行监督微调，将策略成功率提升44.7%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.09607","title":"VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation","arxivId":"2510.09607","date":"2025-10-10","authors":"Caifeng Shan Team","category":"Manipulation","summary":"本文提出VITA-VLA框架，旨在高效赋予视觉语言模型（VLM）动作执行能力，解决传统端到端训练VLA模型成本高昂的问题。方法核心是通过动作专家蒸馏，将小型预训练动作模型的知识迁移至VLM，仅需添加动作标记和状态编码器，并采用两阶段训练策略：先对齐VLM隐藏状态与动作空间，再选择性微调关键模块。实验表明，该方法在LIBERO、LIBERO-LONG和CALVIN ABC-D等基准上显著提升成功率（最高提升24.5%），并在真实机器人操作任务中平均成功率达到82.0%，较教师模型提升17%，同时大幅降低训练开销。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.09543","title":"Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards","arxivId":"2510.09543","date":"2025-10-13","authors":"Alireza Ramezani Team","category":"Manipulation","summary":"本文解决模仿学习在复现动物能量高效运动时，主要关注显性步态而忽略隐性被动动力学（如冲击吸收）的问题。提出通过引入冲击缓解因子（IMF）这一物理指标作为奖励项，并将其与对抗运动先验（AMP）结合，引导强化学习策略同时学习运动轨迹和被动动态。实验表明，该方法在运输成本衡量下，能效提升最高达32%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.09497","title":"Autonomous Soft Robotic Guidewire Navigation via Imitation Learning","arxivId":"2510.09497","date":"2025-10-10","authors":"Axel Krieger Team","category":"Manipulation","summary":"本论文致力于解决软体机器人导丝在血管内手术中自动化导航的建模与控制难题。其核心技术是开发了一个基于Transformer的模仿学习框架，该框架整合了目标条件设定、相对动作输出与自动对比剂注射。通过在36种分叉血管几何结构上进行训练，并在3种未见过的血管结构上评估，该模型能够自主将导丝尖端导航至动脉瘤目标位置，成功率达到83%，优于多个基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.09459","title":"Failure Prediction at Runtime for Generative Robot Policies","arxivId":"2510.09459","date":"2025-10-13","authors":"Angela P. Schoellig Team","category":"Manipulation","summary":"根据当前提供的论文标题《Failure Prediction at Runtime for Generative Robot Policies》，可推断该研究核心聚焦于**生成式机器人策略在运行过程中的故障预测问题**。  \n若需完成精准总结，请提供论文正文内容，以便准确提取：  \n1. **核心问题**（如具体故障类型与应用场景）  \n2. **关键技术方法**（如使用的预测模型、监测指标或算法框架）  \n3. **实验结论**（如预测准确率、误报率或对任务成功率的提升数据）  \n我将依据原文内容严格遵循您的要求撰写总结，避免任何编造信息。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.09229","title":"Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System","arxivId":"2510.09229","date":"2025-10-10","authors":"Pai Zheng Team","category":"Manipulation","summary":"本文提出Glovity，一种低成本可穿戴遥操作系统，旨在解决接触丰富操作任务中缺乏实时力触觉反馈及人机结构差异导致的控制难题。核心方法包括：可穿戴空间力矩反馈装置提供直观力/扭矩反馈；集成指尖霍尔传感器的触觉手套实现精确抓取校准；将力矩信号融入扩散模仿学习（DP-R3M）生成高质量演示数据。实验表明：力矩反馈使书本翻页成功率从48%提升至78%，耗时降低25%；指尖校准显著提高薄物体抓取成功率；结合力矩信号的模仿学习在新接触任务（如翻页、交接）中取得高成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.09222","title":"FM-IRL: Flow-Matching for Reward Modeling and Policy Regularization in Reinforcement Learning","arxivId":"2510.09222","date":"2025-10-10","authors":"Ivor Tsang Team","category":"Manipulation","summary":"本文提出FM-IRL方法，旨在解决基于流匹配（FM）的策略在离线模仿学习中因缺乏环境交互和探索而泛化能力差的问题。核心方法采用“学生-教师”框架：利用一个结构简单的MLP“学生”策略进行在线RL探索和更新；同时，关联一个FM“教师”模型来构建奖励函数，并以此正则化学生策略的行为。实验表明，该方法显著提升了从专家数据（尤其是次优数据）中学习时的效率、泛化性与鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.09096","title":"When a Robot is More Capable than a Human: Learning from Constrained Demonstrators","arxivId":"2510.09096","date":"2025-10-10","authors":"Erdem Bıyık Team","category":"Manipulation","summary":"本文研究机器人如何从受控制接口限制的人类演示中学习更优策略的核心问题。针对专家因接口约束（如操纵杆仅能2D操作）导致演示轨迹低效的情况，提出LfCD-GRIP方法：通过演示推断仅基于状态的任务进度奖励函数，并利用时间插值为未知状态自标注奖励，使机器人能探索比演示更高效的轨迹。在真实WidowX机械臂实验中，该方法仅用12秒完成任务，比行为克隆快10倍，显著提升了样本效率与执行速度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.09036","title":"iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation","arxivId":"2510.09036","date":"2025-10-10","authors":"Ziwei Wang Team","category":"Manipulation","summary":"本文提出iMoWM模型，旨在解决现有基于2D视频的世界模型在机器人操作中缺乏几何和空间推理能力的问题。通过MMTokenizer技术将多模态输入（彩色图像、深度图、机器人手臂掩码）统一为紧凑令牌表示，iMoWM以自回归方式生成多模态输出，条件于动作序列，从而高效利用预训练VideoGPT模型并融入丰富物理信息。实验表明，iMoWM在模型基于强化学习和真实世界模仿学习中表现优越，提升了预测视觉质量和任务适用性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.08807","title":"Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation","arxivId":"2510.08807","date":"2025-10-09","authors":"Yue Wang Team","category":"Manipulation","summary":"本文针对当前人形机器人数据集局限于固定环境、任务多样性不足且缺乏标准化评估的问题，提出了Humanoid Everyday数据集。该数据集通过高效人监督遥操作管道，收集了包含RGB、深度、LiDAR和触觉输入的多模态数据及自然语言注释，涵盖7大类260个任务，总计10.3k轨迹和300多万帧数据。同时，引入了基于云的评估平台以支持标准化策略部署，并分析了代表性策略学习方法的优劣。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.08787","title":"Geometry-aware Policy Imitation","arxivId":"2510.08787","date":"2025-10-09","authors":"Sylvain Calinon Team","category":"Manipulation","summary":"本文提出几何感知策略模仿（GPI）方法，核心解决模仿学习中现有方法多模态处理差、计算效率低且忽略演示几何结构的问题。GPI将专家演示视为状态空间中的几何曲线，从中衍生距离场并构建两个互补控制流：沿轨迹前进的“推进流”和纠正偏差的“吸引流”，二者结合形成直接指导机器人行为的非参数化向量场。实验表明，GPI相比扩散策略成功率更高、运行速度快20倍、内存需求更低，且对扰动更具鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.08753","title":"Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics","arxivId":"2510.08753","date":"2025-10-09","authors":"M. Jagersand Team","category":"Manipulation","summary":"本文针对轮椅安装机械臂在笛卡尔空间模式切换中存在参考帧不直观、平移与旋转控制分离、运动能力受限等问题，提出“Point and Go”模式切换方法。该方法通过扫掠运动定义新的平移轴，实现直观的“指向-移动”平移模式；旋转模式则结合位置控制与精炼的末端执行器参考帧，提供精确一致的操作。用户实验表明，与笛卡尔模式切换相比，该方法使任务完成时间减少31%、暂停减少41%、模式切换次数减少33%，并获得显著更佳的用户评价。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.08558","title":"Agent Learning via Early Experience","arxivId":"2510.08558","date":"2025-10-09","authors":"Yifan Wu Team","category":"Manipulation","summary":"抱歉，我没有收到论文的正文内容。请提供论文的正文内容，以便我根据标题“Agent Learning via Early Experience”撰写精准的简短总结。这样我才能准确描述核心问题、关键技术方法和实验结论，避免编造信息。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.08547","title":"R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation","arxivId":"2510.08547","date":"2025-10-09","authors":"Jiwen Lu Team","category":"Manipulation","summary":"本文针对机器人操作中空间泛化所需大量人类演示数据、导致数据效率低下的问题，提出R2RGen框架。该框架通过真实到真实的3D数据生成，直接增强点云观察-动作对，无需模拟器或渲染。关键技术包括细粒度场景轨迹注释、分组增强策略处理多对象约束，以及相机感知处理对齐真实传感器分布。实验表明，R2RGen显著提升了数据效率，并在广泛测试中展现出在移动操作中扩展应用的潜力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.08316","title":"Unlocking 3D Affordance Segmentation with 2D Semantic Knowledge","arxivId":"2510.08316","date":"2025-10-09","authors":"Wei Shen Team","category":"Manipulation","summary":"本文针对3D可承受性分割中，因点云数据稀疏、噪声等固有挑战导致3D特征缺乏清晰语义边界的问题，提出一种基于语义的学习范式。核心方法是**跨模态亲和力迁移（CMAT）**预训练策略，将大规模2D视觉基础模型的丰富语义知识对齐并迁移到3D编码器；在此基础上构建**跨模态可承受性分割Transformer（CAST）**，整合多模态提示生成精确分割图。实验表明，该方法在标准基准测试中取得了最先进的性能，产生的3D特征具有更强的语义组织性和更清晰的功能区域边界。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.08022","title":"FastUMI-100K: Advancing Data-driven Robotic Manipulation with a Large-scale UMI-style Dataset","arxivId":"2510.08022","date":"2025-10-09","authors":"Xuelong Li Team","category":"Manipulation","summary":"本文针对数据驱动的机器人操作学习中，现有演示数据集规模小、采集成本高、可扩展性差的核心问题，提出了大规模数据集FastUMI-100K。其关键技术是采用新型FastUMI机器人系统，通过模块化、硬件解耦的机械设计与集成轻量追踪系统进行高效采集。该数据集包含超过10万条长时程轨迹，覆盖54个任务和数百种物体，并整合了末端状态、多视角鱼眼图像和文本注释等多模态数据。实验表明，基于该数据集训练的策略能在多种基线算法上取得高成功率，验证了其对解决复杂、动态操作任务的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.07865","title":"DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation","arxivId":"2510.07865","date":"2025-10-09","authors":"Weibing Li Team","category":"Manipulation","summary":"本文针对流式策略在机器人操作中存在的“表示崩溃”问题，即无法区分相似视觉表示导致精确操作失败，提出DM1框架。该方法在MeanFlow中集成分散正则化，通过在多个中间嵌入层施加正则化变体，防止表示崩溃，同时保持一步生成的高效性。实验表明，DM1在RoboMimic基准上实现了20-40倍的推理加速（0.07s vs. 2–3.5s），并将任务成功率提升10-20个百分点，其中Lift任务达到99%成功率（基线85%），并成功从仿真迁移到真实机器人。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.07773","title":"Trajectory Conditioned Cross-embodiment Skill Transfer","arxivId":"2510.07773","date":"2025-10-09","authors":"Bin Zhao Team","category":"Manipulation","summary":"本文提出TrajSkill框架，解决机器人直接从人类演示视频学习操作技能时面临的“具身化差距”问题。其核心方法是将人类运动表示为稀疏光流轨迹，作为与具体形态无关的运动线索；基于此轨迹结合视觉与文本输入，联合生成时序一致的机器人操作视频并转换为可执行动作。实验表明，在MetaWorld仿真中，TrajSkill相比SOTA方法将FVD和KVD分别降低了39.6%和36.6%，并将跨具身化成功率最高提升16.7%；真实机器人厨房任务进一步验证了该方法的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.07674","title":"Differentiable Particle Optimization for Fast Sequential Manipulation","arxivId":"2510.07674","date":"2025-10-11","authors":"Zachary Kingston Team","category":"Manipulation","summary":"本文针对机器人顺序操作中高维空间轨迹优化的实时计算难题，提出完全GPU并行化的SPaSM框架。该方法采用两阶段可微粒子优化：先通过大规模并行采样满足放置约束，再联合优化物体位姿与机器人关节轨迹。实验表明，SPaSM在复杂基准测试中实现毫秒级求解，成功率100%，相比现有方法加速约4000倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.07313","title":"WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation","arxivId":"2510.07313","date":"2025-10-08","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"本文解决了机器人操作中，因环境遮挡导致末端执行器（手腕）视野受限的难题。提出了WristWorld框架，其核心技术是训练一个**4D世界模型**，该模型能够根据外部摄像头的观察，**预测并生成机器人手腕摄像头在未来时刻的虚拟视图**。实验表明，该方法在模拟的遮挡堆叠任务中成功率大幅提高，在真实世界的机器人操作任务上也优于基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.07181","title":"TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics","arxivId":"2510.07181","date":"2025-10-09","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"本文提出TIGeR框架，旨在解决视觉语言模型在机器人任务中几何推理精度不足的问题。现有方法仅能进行定性空间描述，无法利用深度与相机标定数据实现厘米级精确计算。TIGeR通过让模型识别几何问题、生成计算代码并调用外部工具库执行精确运算，将VLMs转变为几何计算器。为此构建了TIGeR-300K工具调用数据集，并采用监督微调与强化微调两阶段训练。实验表明，TIGeR在几何推理基准上达到SOTA性能，并在真实机器人操作中实现厘米级精度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.06499","title":"Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels","arxivId":"2510.06499","date":"2025-10-07","authors":"Weiran Yao Team","category":"Manipulation","summary":"本文旨在解决强化学习（RL）应用于大语言模型时面临的核心数据瓶颈：现有RL数据集规模小、多样性不足，远未达到预训练数据级别。为此，论文提出了 **Webscale-RL自动化数据管道**，其关键技术是将海量预训练文档系统地转化为**数百万个多样且可验证的问答对**，从而构建了覆盖9个以上领域、包含120万个样本的大规模RL数据集。核心实验表明，基于此数据集的RL训练**效率极高**，仅使用**少至100倍的token**即可达到持续预训练（continual pretraining）的同等性能，在多项基准测试上显著超越基线模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.06207","title":"EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model","arxivId":"2510.06207","date":"2025-10-07","authors":"Zhaoxiang Zhang Team","category":"Manipulation","summary":"本文针对机器人操作中泛化能力有限、依赖大量标注数据且可解释性差的问题，提出EmbodiedCoder框架。该方法基于现代编码模型，无需训练或微调，通过代码生成直接参数化对象几何并合成可执行轨迹，实现感知与操作的透明连接。在真实移动机器人上的实验表明，该框架能鲁棒地完成多样化长期任务，并有效泛化到新对象和环境。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.06179","title":"Differentiable Model Predictive Control on the GPU","arxivId":"2510.06179","date":"2025-10-07","authors":"Thomas Lew Team","category":"Manipulation","summary":"本文针对可微分模型预测控制（MPC）因传统优化算法顺序执行而难以在GPU上并行化的瓶颈，提出了一种GPU加速的可微分优化工具DiffMPC。其核心技术是采用序列二次规划及自定义的三对角预处理共轭梯度方法，以利用最优控制问题的结构实现高效并行。实验表明，该方法相比CPU和GPU基线实现了显著加速，大幅提升了在强化学习与模仿学习基准任务上的训练效率，并成功应用于极限工况下的车辆漂移控制。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.06127","title":"Towards Autonomous Tape Handling for Robotic Wound Redressing","arxivId":"2510.06127","date":"2025-10-07","authors":"Michael Yip Team","category":"Manipulation","summary":"本文针对机器人伤口换药中胶带自主操作这一基础且关键的子任务，提出一个自动化框架。核心解决两个问题：胶带初始剥离与安全粘贴。针对剥离时的复杂粘附动力学，提出了基于力反馈的模仿学习方法，通过人类遥操作演示进行训练；针对粘贴，开发了基于数值轨迹优化的方法，以确保在不同解剖表面实现平滑、无皱褶的粘贴。实验验证表明，该方法在定量评估和集成换药流程中均表现出可靠性能，为实现实用的机器人伤口护理自动化奠定了重要一步。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.05957","title":"Learning to Crawl: Latent Model-Based Reinforcement Learning for Soft Robotic Adaptive Locomotion","arxivId":"2510.05957","date":"2025-10-07","authors":"Robin Chhabra Team","category":"Manipulation","summary":"本文针对软体机器人爬行器因模型不精确、传感器噪声和步态发现困难而导致控制策略设计复杂的问题，提出了一种基于潜在动力学的模型强化学习框架。该方法利用机载传感器推断潜在动力学作为预测模型，并指导演员-评论家算法优化运动策略。在仿真实验中，该方法通过学习到的潜在动力学实现了短时程运动预测，使机器人仅基于噪声传感器反馈即可发现有效的自适应运动步态。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.05827","title":"VCoT-Grasp: Grasp Foundation Models with Visual Chain-of-Thought Reasoning for Language-driven Grasp Generation","arxivId":"2510.05827","date":"2025-10-07","authors":"Badong Chen Team","category":"Manipulation","summary":"本文提出VCoT-Grasp模型，旨在解决语言驱动抓取任务中现有方法推理能力不足、泛化性差、依赖复杂模块化流程的问题。其核心技术是引入视觉思维链推理机制，通过端到端的多轮处理范式动态聚焦视觉输入，并生成可解释的推理轨迹。模型基于新构建的大规模数据集VCoT-GraspSet进行训练。实验表明，该方法显著提升了抓取成功率，并能有效泛化到未见过的物体、背景及干扰场景。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.05662","title":"DeLTa: Demonstration and Language-Guided Novel Transparent Object Manipulation","arxivId":"2510.05662","date":"2025-10-07","authors":"Kuk-Jin Yoon Team","category":"Manipulation","summary":"本文解决透明物体因深度感知困难导致的机器人长时程精确操作难题。提出DeLTa框架，整合深度估计、6D姿态估计与视觉语言规划，核心创新包括：单次演示即可泛化6D轨迹至新透明物体（无需类别先验或额外训练），并设计任务规划器优化VLM生成的动作序列以适应单臂眼在手机器人约束。实验表明，该方法在长时程精确操作场景中显著优于现有透明物体操作方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.05536","title":"Correlation-Aware Dual-View Pose and Velocity Estimation for Dynamic Robotic Manipulation","arxivId":"2510.05536","date":"2025-10-07","authors":"Farrokh Janabi-Sharifi Team","category":"Manipulation","summary":"本文针对动态机器人操作中姿态和速度估计不准的核心问题，提出一种相关性感知的双视图去中心化融合方法。关键技术包括：使用眼在手和眼到手视觉传感器配置，基于李群（𝕊𝔼(3)×ℝ³×ℝ³）构建两个独立的自适应扩展卡尔曼滤波器进行状态预测与更新，并采用李群上的相关性感知融合规则获得最终融合姿态和速度。实验在配备Intel RealSense相机的UFactory xArm 850机器人上跟踪移动目标，验证了方法的有效性和鲁棒性，相比现有技术有持续改进。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.05213","title":"VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing","arxivId":"2510.05213","date":"2025-10-06","authors":"Masayoshi Tomizuka Team","category":"Manipulation","summary":"本文提出VER模型，以解决机器人学习中单一视觉基础模型（VFM）泛化能力有限、多VFM融合后特征选择不灵活且重新训练成本高的问题。关键技术包括：通过基础蒸馏将多个VFM知识压缩为视觉专家库，并设计轻量级动态路由网络（参数量<0.4%）按任务需求自适应选择专家；进一步引入块级专家路由与课程Top-K退火机制提升选择精度。实验表明，VER在17项多样机器人任务上达到SOTA性能，能有效抑制任务无关区域（如背景）的异常值，聚焦于关键区域。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.05013","title":"Curiosity-Driven Co-Development of Action and Language in Robots Through Self-Exploration","arxivId":"2510.05013","date":"2025-10-06","authors":"Jun Tani Team","category":"Manipulation","summary":"本文研究机器人如何通过好奇驱动的自我探索，高效学习与语言指令关联的动作，以模拟人类婴儿从有限经验中快速泛化的能力。方法上，结合主动推断与强化学习，实现内在动机驱动的发展性学习。核心实验发现：1) 组合元素规模增大显著提升泛化能力；2) 好奇心通过自我探索改善学习；3) 学习过程遵循“死记硬背配对→组合泛化”和“简单动作→复杂动作”的序列；4) 异常处理引发类似儿童语言学习的U型发展曲线。结果表明，好奇驱动的主动推断机制能支持可扩展的组合泛化与异常处理能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.04592","title":"MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation","arxivId":"2510.04592","date":"2025-10-06","authors":"Wenjie Song Team","category":"Manipulation","summary":"本文针对移动操作机器人缺乏大规模高质量演示数据的问题，提出MobRT框架。该框架基于数字孪生，通过虚拟运动控制与全身运动规划，自主生成铰接物体交互（如开门）和移动底座拾放任务的仿真演示数据。实验表明，仅用300个仿真演示和20个真实演示，即可实现成功的模拟到现实迁移，显著提升策略的泛化能力和任务成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.04354","title":"Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators","arxivId":"2510.04354","date":"2025-10-05","authors":"Anirudha Majumdar Team","category":"Manipulation","summary":"本文提出SureSim框架，解决机器人策略在真实世界中评估成本高、缺乏统计保证的问题。核心方法是将真实与模拟评估结合，形式化为预测驱动推理问题，利用少量配对数据校正模拟偏差，并采用非渐近均值估计算法给出性能置信区间。实验表明，该方法在基于物理的模拟中评估扩散策略与多任务微调策略，可节省20-25%的硬件评估成本，同时获得相近的性能边界。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.04333","title":"RAP: 3D Rasterization Augmented End-to-End Planning","arxivId":"2510.04333","date":"2025-10-05","authors":"Alexandre Alahi Team","category":"Manipulation","summary":"本文针对端到端驾驶模仿学习在闭环部署中缺乏恢复数据、错误易累积的问题，提出RAP框架。其核心是**3D光栅化**技术，用轻量级语义光栅化替代高成本渲染，生成反事实恢复与跨视角合成数据，并结合**光栅到现实的特征空间对齐**以弥合仿真与现实差距。该方法在NAVSIM等四个主要基准测试中均排名第一，显著提升了闭环鲁棒性与长尾泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.03895","title":"NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation","arxivId":"2510.03895","date":"2025-10-04","authors":"Chunhua Shen Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型因依赖密集连续动作轨迹导致的灾难性遗忘问题，提出NoTVLA框架。该方法通过时间压缩与空间推理剪枝技术，聚焦于机器人末端执行器的稀疏轨迹进行训练，替代传统的密集轨迹微调。实验表明，NoTVLA在多任务评估中性能与泛化能力均优于π0模型，且计算功耗降低一个数量级以上，无需腕部摄像头，在零样本场景下表现更优。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.03706","title":"EmbodiSwap for Zero-Shot Robot Imitation Learning","arxivId":"2510.03706","date":"2025-10-04","authors":"Yiannis Aloimonos Team","category":"Manipulation","summary":"本文提出EmbodiSwap方法，以解决零样本机器人模仿学习中人类视频与机器人形态不匹配（“具身鸿沟”）的核心问题。该方法通过合成逼真的机器人覆盖层替换人类视频中的人手，并创新性地将V-JEPA视觉骨干网络从视频理解领域迁移至机器人模仿学习。在真实世界测试中，基于该方法的零样本训练模型取得了82%的成功率，优于传统小样本训练方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.03599","title":"Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning","arxivId":"2510.03599","date":"2025-10-04","authors":"Majid Khadiv Team","category":"Manipulation","summary":"本文提出一种基于接触显式表示的多任务运动与操作策略统一学习框架。核心问题是解决传统任务专用策略泛化能力差、难以适应新场景的问题。方法上，将任务统一定义为接触目标序列（位置、时序、末端执行器），并训练目标条件强化学习策略来实现接触计划。实验在四足/人形机器人的多种步态与双手操作任务上验证，结果表明：单个策略可控制不同形态机器人完成多样任务，且接触显式推理显著提升了策略对未见场景的泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.03460","title":"Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching","arxivId":"2510.03460","date":"2025-10-03","authors":"Xiao Liang Team","category":"Manipulation","summary":"本文提出一种基于学习的机器人运动规划方法，用于解决动态环境中优化轨迹生成易陷入局部最优、依赖初始解的问题。核心方法是利用单视点云条件流匹配模型，直接从深度相机输入学习近似最优的初始化轨迹，无需障碍物先验知识。在UR5e机械臂的仿真实验中，该方法自身成功率高，相比基准方法显著提升了轨迹优化的成功率，减少了优化迭代次数，并对未见环境表现出强泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.03135","title":"Mask2IV: Interaction-Centric Video Generation via Mask Trajectories","arxivId":"2510.03135","date":"2025-10-03","authors":"Laura Sevilla-Lara Team","category":"Manipulation","summary":"本文提出Mask2IV，旨在解决交互中心视频生成中依赖密集掩码标注、难以建模复杂动态交互的问题。方法采用解耦的两阶段流程：先预测执行者与物体的掩码运动轨迹，再基于轨迹生成视频，从而无需用户提供密集掩码输入。该方法支持通过文本提示或目标位置掩码灵活控制交互对象与运动。实验表明，Mask2IV在构建的交互基准上，视觉真实性与可控性均优于现有基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.03123","title":"Learning Stability Certificate for Robotics in Real-World Environments","arxivId":"2510.03123","date":"2025-10-03","authors":"Zhe Shen Team","category":"Manipulation","summary":"根据您提供的论文标题《Learning Stability Certificate for Robotics in Real-World Environments》，本文可能旨在解决机器人在复杂现实环境中稳定性验证的核心挑战。关键技术或涉及学习-based方法，如从环境数据中动态学习稳定性证书，以提供实时保证。实验部分应验证该方法能提升机器人在不确定场景中的稳定性能，但具体性能提升数据需参考论文正文。由于未提供详细正文内容，此总结仅为基于标题的推断，建议补充正文以获取精准分析。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.03013","title":"Distributional Inverse Reinforcement Learning","arxivId":"2510.03013","date":"2025-10-06","authors":"Anqi Wu Team","category":"Manipulation","summary":"本文提出分布逆强化学习方法，解决离线环境下传统IRL仅能恢复确定性奖励估计、无法建模随机奖励分布的问题。关键技术是建立联合建模奖励函数不确定性与回报完整分布的框架，通过最小化一阶随机占优违规，将失真风险度量整合至策略学习，从而同时恢复奖励分布与分布感知策略。实验表明，该方法在合成基准、真实神经行为数据及MuJoCo控制任务中恢复了高表现力的奖励表示，并取得了最先进的模仿性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.02851","title":"Action Deviation-Aware Inference for Low-Latency Wireless Robots","arxivId":"2510.02851","date":"2025-10-03","authors":"Seong-Lyun Kim Team","category":"Manipulation","summary":"本文针对无线机器人低延迟推理中，行为克隆策略因动作依赖观测而无法并行验证多个动作草案的问题，提出动作偏差感知混合推理（ADAHI）。该方法通过动作偏差预测目标模型的拒绝概率，仅当偏差较大时选择性调用服务器进行验证与修正，从而减少不必要的通信与计算。实验表明，ADAHI将传输与服务器操作降低约40%，端到端延迟减少39.2%，任务成功率可达基线（每草案均调用推测采样）的97.2%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.02738","title":"Flow with the Force Field: Learning 3D Compliant Flow Matching Policies from Force and Demonstration-Guided Simulation Data","arxivId":"2510.02738","date":"2025-10-03","authors":"Nadia Figueroa Team","category":"Manipulation","summary":"本文针对接触丰富的机器人操作任务中，视觉运动策略忽视力控与顺应性、导致接触力过大或行为脆弱的问题，提出一种从模拟数据学习3D顺应流匹配策略的框架。该方法仅需单次人类示教，即可在仿真中生成力信息与示教引导的数据，并耦合顺应策略提升视觉运动策略性能。在真实机器人非抓取块翻转与双手移物任务中验证，学习到的策略能可靠维持接触并适应新条件。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.02538","title":"A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models","arxivId":"2510.02538","date":"2025-10-02","authors":"Hao Su Team","category":"Manipulation","summary":"本文针对真实专家数据有限的模仿学习问题，提出一种高效的模拟到现实迁移框架。该方法采用两阶段流程：先在仿真中通过在线模仿预训练世界模型，扩大状态覆盖；再使用少量真实演示进行离线微调。关键技术包括利用潜在世界模型高效学习，并采用CDRED奖励模型从交互中生成奖励信号。实验表明，该方法显著提升了泛化能力和微调鲁棒性，在模拟到模拟迁移中成功率至少提升31.7%，在模拟到现实迁移中至少提升23.3%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.02526","title":"U-LAG: Uncertainty-Aware, Lag-Adaptive Goal Retargeting for Robotic Manipulation","arxivId":"2510.02526","date":"2025-10-02","authors":"Anujith Muraleedharan Team","category":"Manipulation","summary":"本文针对机器人在动态环境中因感知延迟导致预设任务目标失效的问题，提出U-LAG中间执行层目标重定向框架。其核心技术UAR-PF是一种不确定性感知的重定向器，能在感知延迟下维持物体姿态分布，并选择最大化预期进展的目标。通过在PyBullet/PandaGym中构建可重复的Shift×Lag压力测试（物体偏移0-10cm，延迟0-400ms）验证，UAR-PF相比无重定向基线在抓取、推动等任务中成功率更高，末端执行器移动更少，且中止次数降低。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.02493","title":"Beyond Imitation: Recovering Dense Rewards from Demonstrations","arxivId":"2510.02493","date":"2025-10-02","authors":"Gholamreza Haffari Team","category":"Manipulation","summary":"本文挑战了将监督微调（SFT）视为简单模仿学习的传统观点。核心问题是证明SFT本质上等同于逆强化学习，不仅能学习策略，还能隐式学习一个解释专家演示的密集令牌级奖励模型。关键技术方法是基于逆Q学习框架，通过基线相对奖励函数从SFT模型中恢复密集奖励信号，并利用该奖励通过强化学习进一步优化策略（Dense-Path REINFORCE）。实验表明，该方法在指令遵循基准测试中持续优于原始SFT模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.02298","title":"ARMADA: Autonomous Online Failure Detection and Human Shared Control Empower Scalable Real-world Deployment and Adaptation","arxivId":"2510.02298","date":"2025-10-02","authors":"Cewu Lu Team","category":"Manipulation","summary":"本文提出ARMADA系统，旨在解决模仿学习中预训练策略因缺乏领域内数据而表现不佳、人工收集演示成本高且质量不均的问题。系统采用人在环共享控制，并引入名为FLOAT的自主在线故障检测方法，实现多机器人并行策略执行，仅在必要时请求人工干预。实验表明，FLOAT故障检测平均准确率接近95%，较先前方法提升超20%；ARMADA在多次部署与后训练中，成功率提升超4倍，人工干预率降低超2倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.02268","title":"Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning","arxivId":"2510.02268","date":"2025-10-02","authors":"Matthew R. Walter Team","category":"Manipulation","summary":"本文研究视图不变的模仿学习，旨在解决机器人策略在固定视角训练后，因摄像头位置变化导致性能下降的核心问题。提出显式相机条件化方法，通过Plücker嵌入将相机外参融入策略，应用于ACT、Diffusion Policy等标准行为克隆模型。实验在RoboSuite和ManiSkill的六个任务上进行，结果显示，未条件化的策略依赖静态背景线索推断相机姿态，在视角变化时失效；而条件化方法能显著提升泛化能力，恢复性能，实现鲁棒的仅RGB控制。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.01711","title":"Contrastive Representation Regularization for Vision-Language-Action Models","arxivId":"2510.01711","date":"2025-10-02","authors":"Jinwoo Shin Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型在机器人操作任务中，其表征对机器人控制信号和本体感知状态不敏感的问题，提出了一种名为“机器人状态感知对比损失（RS-CL）”的表示正则化方法。该方法利用机器人状态之间的相对距离作为软监督，将VLM表征与机器人本体状态对齐，从而在标准VLA训练流程中轻量、有效地增强与控制相关的表征学习。核心实验表明，RS-CL显著提升了VLA模型的性能：在RoboCasa-Kitchen的拾放任务中，成功率从30.8%提升至41.5%；在真实机器人操作任务中，成功率从45.0%提升至58.3%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.01661","title":"Symskill: Symbol and Skill Co-Invention for Data-Efficient and Real-Time Long-Horizon Manipulation","arxivId":"2510.01661","date":"2025-10-02","authors":"Nadia Figueroa Team","category":"Manipulation","summary":"本文提出SymSkill框架，解决动态环境中长时程机器人操作的数据效率与实时性问题。核心结合模仿学习（IL）的响应能力与任务运动规划（TAMP）的组合泛化能力，通过**谓词与技能协同发明**技术，从无标注、未分割的演示数据中自动学习符号谓词、操作符和运动技能（如SE(3) LPV-DS技能拟合）。执行时使用符号规划器实时组合技能并恢复故障。实验表明：在RoboCasa仿真中，12个单步任务成功率85%，并能组合成最多需6次技能重组的多步计划；真实Franka机器人仅用5分钟无标注数据即可通过目标指令执行多种任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.01642","title":"FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models","arxivId":"2510.01642","date":"2025-10-02","authors":"Bihan Wen Team","category":"Manipulation","summary":"本文针对Vision-Language-Action (VLA) 模型在机器人操作中执行时不可避免遇到失败、且缺乏有效恢复机制的核心问题，提出了FailSafe系统。该技术能自动生成多样化的失败案例与可执行恢复动作，可扩展地创建失败-动作数据，并基于LLaVa-OV-7B微调构建FailSafe-VLM。实验表明，FailSafe-VLM成功帮助机器人检测和恢复失败，将πo-FAST、OpenVLA等三个先进VLA模型在Maniskill多任务上的平均性能提升高达22.6%，并能泛化至不同空间配置、视角及对象。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.01607","title":"ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations","arxivId":"2510.01607","date":"2025-10-02","authors":"Yi Xu Team","category":"Manipulation","summary":"本文提出ActiveUMI框架，旨在解决机器人策略学习中高质量、可扩展数据收集的难题。其核心是通过一套便携式VR遥操作套件，将人类演示精确映射到机器人双臂操作。关键技术包括：将机器人夹具直接安装在VR控制器上以实现姿态对齐，以及通过记录操作者头戴显示器的头部运动来捕获主动自我中心感知，从而学习视觉注意力与操作的关联。在六个复杂双手任务上的实验表明，仅用ActiveUMI数据训练的策略，在分布内任务上平均成功率达到70%，并在新物体和新环境中展现出强泛化能力，成功率为56%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.01603","title":"MiniBEE: A New Form Factor for Compact Bimanual Dexterity","arxivId":"2510.01603","date":"2025-10-02","authors":"Matei Ciocarlie Team","category":"Manipulation","summary":"本文针对传统双手机器人系统复杂、灵巧工作空间受限的问题，提出了一种紧凑型双手机器人末端执行器MiniBEE。其核心设计是将两个低自由度（3+ DOF）机械臂耦合为一个运动学链，通过优化的运动学灵巧度度量，在保持夹爪间完全相对定位能力的同时，实现了系统的小型化与轻量化。该系统支持可穿戴式运动数据采集和搭载于标准机械臂两种互补工作模式。实验演示了通过可穿戴演示训练模仿学习策略，并成功部署于机械臂，实现了鲁棒、灵巧的真实世界双手机器人操作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.01531","title":"Information Seeking for Robust Decision Making under Partial Observability","arxivId":"2510.01531","date":"2025-10-02","authors":"Tsung-Wei Ke Team","category":"Manipulation","summary":"本文针对部分可观测环境下，大语言模型（LLM）智能体因内部动态与环境实际动态不匹配而决策脆弱的问题，提出**信息寻求决策规划器（InfoSeeker）**。该框架将任务导向规划与主动信息寻求相结合，驱使LLM通过规划行动验证认知、探测环境变化，从而对齐内部动态。实验表明，InfoSeeker在新型基准测试中相比之前方法取得了**74%的绝对性能提升**，且不损失样本效率，并在机器人操作、网页导航等任务中展现出优异的泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.01433","title":"AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation","arxivId":"2510.01433","date":"2025-10-01","authors":"Pratap Tokekar Team","category":"Manipulation","summary":"论文解决机器人操作中密集视觉输入计算量大、无关特征多的问题，以及现有关键点方法依赖手动启发式或任务耦合、限制可扩展性的核心挑战。提出Afford2Act框架，基于affordance指导自动选择最小语义2D关键点，关键技术包括affordance过滤、类别级关键点构建和transformer策略学习（带嵌入门控推理）。实验表明，该方法生成紧凑的38维策略，训练仅需15分钟，在多样真实任务中对未见对象、新类别等达到82%的成功率，实现高效轻量操作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.01404","title":"How Well do Diffusion Policies Learn Kinematic Constraint Manifolds?","arxivId":"2510.01404","date":"2025-10-01","authors":"Russ Tedrake Team","category":"Manipulation","summary":"本文研究扩散策略学习运动学约束流形的效果，核心问题是评估其在机器人模仿学习中精确学习约束的能力。通过双手机器人拾取-放置任务案例，采用扩散策略方法，扰动演示生成不同约束违反程度的数据集，分析任务成功和约束遵守。实验表明，扩散策略能学习约束流形的粗略近似，但数据集大小和质量下降会负面影响学习效果；流形曲率与约束满足和任务成功的相关性不明确。硬件评估验证了结果的现实适用性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.01023","title":"Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning","arxivId":"2510.01023","date":"2025-10-01","authors":"D. Tsetserukou Team","category":"Manipulation","summary":"本文提出Prometheus系统，解决基于动作捕捉的机器人遥操作中缺乏力反馈、易导致抓取力过大损坏物体的问题。该系统采用消费级HTC Vive追踪器、定制控制器与UR3机械臂，通过定制夹爪与嵌入式力传感器实现均匀压力感知与实时力反馈。关键技术包括3D打印与商用组件结合、定制PCB设计，并全面开源。实验表明，该系统能提升任务成功率，为大规模模仿学习数据收集提供了低成本解决方案。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.00922","title":"On Discovering Algorithms for Adversarial Imitation Learning","arxivId":"2510.00922","date":"2025-10-01","authors":"Pradeep Varakantham Team","category":"Manipulation","summary":"本文针对对抗模仿学习（AIL）训练不稳定且奖励分配函数依赖人工设计的问题，提出一种数据驱动的奖励分配函数自动发现方法。核心技术是利用LLM引导的进化框架，在奖励分配函数空间中进行高效搜索，从而得到首个元学习AIL算法DAIL。实验表明，DAIL在未见过的环境和策略优化算法中具有强泛化能力，性能优于现有最优人工设计基线，并显著提升了训练稳定性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2510.00906","title":"TubeDAgger: Reducing the Number of Expert Interventions with Stochastic Reach-Tubes","arxivId":"2510.00906","date":"2025-10-01","authors":"Sophie A. Neubauer Team","category":"Manipulation","summary":"本文针对交互式模仿学习中专家干预次数过多的问题，提出TubeDAgger算法。其核心创新是引入随机可达管这一来自动态系统验证的方法，预先构建状态可达集作为安全边界，仅在智能体状态超出安全阈值时请求专家干预。该方法无需训练额外的“怀疑”分类模型，也避免了按环境调整决策阈值。实验表明，在多个运动任务中，TubeDAgger能显著减少专家干预频率，同时保持任务性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.26642","title":"MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation","arxivId":"2509.26642","date":"2025-09-30","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"本文提出MLA多感官语言-动作模型，旨在解决机器人操作中现有视觉-语言-动作模型过度依赖2D图像、难以全面感知物理空间动态的问题。关键技术包括：1）无编码器的多模态对齐方案，直接利用大语言模型对齐2D图像、3D点云与触觉标记；2）未来多感官生成后训练策略，增强对物理动态的推理能力。实验表明，MLA在复杂接触式任务中超越此前最优2D与3D方法12%和24%，并展现出更强的泛化性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.26308","title":"Anomaly detection for generic failure monitoring in robotic assembly, screwing and manipulation","arxivId":"2509.26308","date":"2025-09-30","authors":"Kevin Haninger Team","category":"Manipulation","summary":"本文针对机器人装配、拧紧和操作中的异常检测通用性问题，研究其在不同任务类型（如电缆连接、拧紧、抛光）和控制策略（扩散策略、位置、阻抗控制）间的可转移性。采用基于自编码器的异常检测方法，利用力/扭矩等多模态时间序列数据直接捕获机器人-环境交互。实验表明，在电缆连接和拧紧任务中，异常检测可靠，AUROC高于0.96，可识别零件错位等故障；抛光任务中仅严重故障被可靠检测，细微故障未被发现。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.26294","title":"Noise-Guided Transport for Imitation Learning","arxivId":"2509.26294","date":"2025-09-30","authors":"Alexandros Kalousis Team","category":"Manipulation","summary":"本文针对模仿学习在低数据制度下专家示范稀缺的核心问题，提出Noise-Guided Transport (NGT)方法。该方法将模仿建模为最优传输问题，通过对抗训练求解，无需预训练或专门架构，并设计融入不确定性估计。实验表明，在超低数据制度（仅20个状态-动作转换）下，NGT在连续控制任务（包括高维Humanoid任务）上实现了强劲性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.25852","title":"Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation","arxivId":"2509.25852","date":"2025-09-30","authors":"Hao Chen Team","category":"Manipulation","summary":"本文针对机器人根据自然语言指令执行长时程操作任务的核心挑战，即缺乏大规模顺序操作数据和密集可解释奖励，提出了REVER框架。该框架训练了RoboFarseer视觉语言模型，其关键技术包括：利用通用操作接口采集原子技能数据，通过自动标注生成训练三元组，并设计了一种基于有序二分图匹配的可验证奖励来评估计划。实验表明，该模型性能与规模大得多的专有模型相当，在开放式规划上超越最佳基线40%以上，在实际长时程任务中将系统整体成功率提升了约60%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.25822","title":"Act to See, See to Act: Diffusion-Driven Perception-Action Interplay for Adaptive Policies","arxivId":"2509.25822","date":"2025-10-01","authors":"Li Cheng Team","category":"Manipulation","summary":"本文针对现有模仿学习方法将感知与动作解耦、忽视其动态互促的问题，提出动作引导扩散策略（DP-AG）。该方法通过变分推断编码潜在观测，并利用扩散策略噪声预测的向量-雅可比积构建动作引导的随机微分方程，驱动潜在状态更新；同时引入循环一致性对比损失，形成感知与动作双向强化的学习循环。实验表明，DP-AG在仿真基准和真实UR5机械臂操作任务上性能显著优于现有先进方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.25794","title":"Point-It-Out: Benchmarking Embodied Reasoning for Vision Language Models in Multi-Stage Visual Grounding","arxivId":"2509.25794","date":"2025-09-30","authors":"Jiaojiao Fan Team","category":"Manipulation","summary":"本文针对现有基准无法直接评估视觉语言模型（VLMs）在具身推理中精确视觉接地能力的问题，提出Point-It-Out（PIO）基准。该基准采用分层评估协议（S1参考对象定位、S2任务驱动指向、S3视觉轨迹预测），覆盖室内、厨房等多领域场景，实现像素级视觉接地。实验对十余个先进VLMs测试发现：通用模型如GPT-4o在精确视觉接地方面表现不及部分开源模型；MoLMO在S1和S2表现良好，但在需结合视觉轨迹规划的S3阶段表现挣扎。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.25756","title":"SAC Flow: Sample-Efficient Reinforcement Learning of Flow-Based Policies via Velocity-Reparameterized Sequential Modeling","arxivId":"2509.25756","date":"2025-09-30","authors":"Wenbo Ding Team","category":"Manipulation","summary":"本文提出SAC Flow，解决流式策略在离策略强化学习中因多步采样导致梯度爆炸/消失的不稳定问题。核心方法是将流式策略建模为序列模型，并引入两种稳定架构：Flow-G（门控速度）和Flow-T（解码速度），结合噪声增强采样实现端到端训练。该方法在连续控制与机器人操作基准上达到最先进性能，无需策略蒸馏或代理目标。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.25747","title":"Best of Sim and Real: Decoupled Visuomotor Manipulation via Learning Control in Simulation and Perception in Real","arxivId":"2509.25747","date":"2025-09-30","authors":"Yang Gao Team","category":"Manipulation","summary":"本文针对机器人操作中模拟到现实迁移的核心难题——感知与控制相互纠缠，提出解耦框架：在仿真中利用完美状态信息训练通用的控制策略，在现实部署时仅适配视觉感知模块以对齐真实观测。该方法将复杂的迁移问题简化为结构化的感知对齐任务，仅需10-20个真实演示。实验表明，该框架在桌面操作任务上实现了优越的数据效率与分布外泛化能力，能处理训练分布之外的对象位置与尺度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.25411","title":"Boolean Satisfiability via Imitation Learning","arxivId":"2509.25411","date":"2025-09-29","authors":"Xiangyu Xu Team","category":"Manipulation","summary":"本文针对布尔可满足性问题中CDCL求解器的分支决策优化问题，提出ImitSAT方法。该方法基于模仿学习，从专家KeyTrace学习存活决策序列，重放时几乎无冲突，提供密集决策级监督以直接减少传播。技术上将分支建模为前缀条件的自回归序列，使用Transformer学习器捕获长上下文依赖。实验表明，ImitSAT能有效减少传播次数和运行时，优于现有学习型方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.25358","title":"SARM: Stage-Aware Reward Modeling for Long Horizon Robot Manipulation","arxivId":"2509.25358","date":"2025-09-29","authors":"Philipp Wu Team","category":"Manipulation","summary":"本文针对长视野、接触丰富的机器人操作任务（如折叠T恤）中演示质量不一致的核心问题，提出SARM框架。该框架通过阶段感知奖励建模，联合预测高级任务阶段和各阶段内细粒度进度，并利用自然语言子任务注释自动生成奖励标签，克服了传统帧索引标签的局限。基于此，进一步提出奖励对齐行为克隆（RA-BC），依据奖励估计筛选高质量数据并重新加权样本。实验表明，在折叠T恤任务中，该方法从平整和皱褶状态分别达到83%和67%的成功率，显著超过普通行为克隆的8%和0%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.25097","title":"Curriculum Imitation Learning of Distributed Multi-Robot Policies","arxivId":"2509.25097","date":"2025-10-01","authors":"Eduardo Montijano Team","category":"Manipulation","summary":"本文解决多机器人系统模仿学习中长期协调困难与训练数据稀缺的问题。提出两项关键技术：1）课程学习策略，通过逐步增加专家轨迹长度来稳定训练并提升长期行为准确性；2）感知估计方法，将全局演示转化为机器人局部观测，通过邻居过滤、坐标系转换和传感器噪声模拟实现。实验表明，该方法能有效提升长期协调准确性，并使策略对现实不确定性具有鲁棒性，实现了仅从全局演示中学习分布式策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24972","title":"Annotation-Free One-Shot Imitation Learning for Multi-Step Manipulation Tasks","arxivId":"2509.24972","date":"2025-09-29","authors":"Ruchi Choudhary Team","category":"Manipulation","summary":"本文针对机器人从单次演示学习多步操作任务时需额外训练或手动标注的问题，提出一种免标注的单次模仿学习方法。该方法无需对演示进行手动分解或关键点标注，避免了现有方法依赖物体掩码和轨迹人工分割的限制。实验表明，该方法在多步操作任务上平均成功率达82.5%，单步任务达90%，性能均优于基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24956","title":"MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation","arxivId":"2509.24956","date":"2025-09-29","authors":"Abhinav Valada Team","category":"Manipulation","summary":"本文针对生成式机器人策略样本效率低的问题，提出MSG框架。该框架在推理时组合多个预训练的物体中心生成策略，通过从共享先验采样粒子并同步通过各局部流场传播，结合基于精度的加权策略进行信息融合。实验表明，MSG仅需5次演示即可学习高质量策略，相比基线减少95%演示需求，并将策略性能提升89%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24948","title":"World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training","arxivId":"2509.24948","date":"2025-09-29","authors":"Qing Zhang Team","category":"Manipulation","summary":"本文提出World-Env框架，旨在解决视觉-语言-动作（VLA）模型在数据稀缺场景下泛化性能差、且难以在非可重置的真实环境中进行强化学习（RL）后训练的难题。该方法构建了一个基于世界模型的虚拟仿真环境，包含视频预测模拟器和VLM引导的即时反射器，以生成未来观测并提供连续奖励与终止判断。实验表明，仅需每个任务5个专家演示，即可显著提升VLA模型在复杂操作任务中的性能，克服了传统方法的数据低效与安全限制。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24917","title":"From Code to Action: Hierarchical Learning of Diffusion-VLM Policies","arxivId":"2509.24917","date":"2025-09-29","authors":"Daniel Dijkman Team","category":"Manipulation","summary":"本文针对机器人模仿学习在复杂长程任务中泛化能力有限和数据稀缺的问题，提出了一种分层学习框架。该方法结合代码生成视觉语言模型与低层扩散策略：VLM将任务描述分解为可执行的API子程序，扩散策略则根据生成的代码模仿对应的机器人行为。为解决代码执行与任务（如物体交换）的非马尔可夫性，架构引入了跨时间维护子任务上下文的记忆机制。实验表明，该设计实现了可解释的策略分解，相比扁平策略提升了泛化能力，并支持对高层规划与低层控制的分别评估。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24768","title":"IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks","arxivId":"2509.24768","date":"2025-09-29","authors":"Ville Kyrki Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型因需满足机器人实时控制而限制语言模型规模，导致其难以处理语义复杂指令（如通过相对位置识别目标）的问题，提出IA-VLA框架。其核心方法是利用大型视觉语言模型的强大语言理解能力作为预处理阶段，生成增强的上下文信息以辅助VLA。在包含视觉重复对象的复杂场景数据集上的实验表明，该增强方案能有效提升VLA性能，尤其在处理需要从演示中进行概念推断的指令时效果显著。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24697","title":"Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering","arxivId":"2509.24697","date":"2025-09-29","authors":"Daniele Pucci Team","category":"Manipulation","summary":"本文针对人形机器人模仿学习生成轨迹时可能违反物理约束、导致失稳的问题，提出一种双管齐下的学习策略。核心方法包括：1）在监督模仿学习中编码物理先验（如零接触足速度损失）以增强轨迹可行性；2）在推理时对生成状态应用比例积分控制器以最小化漂移。在ergoCub机器人上的实验表明，该方法兼容多种真实控制器，显著提升了生成轨迹的准确性和对物理约束的符合程度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24661","title":"CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations","arxivId":"2509.24661","date":"2025-09-29","authors":"Shan Luo Team","category":"Manipulation","summary":"CEDex旨在解决跨形态灵巧抓取生成问题，即如何为不同形态的机器人手自适应生成高质量抓取。其核心技术是：首先通过预训练于人类接触数据的条件变分自编码器生成类人接触表示；随后通过拓扑合并将人手部件对齐至机器人运动学模型，并利用带物理约束的符号距离场进行抓取优化。该方法构建了迄今最大的跨形态抓取数据集（涵盖50万物体、四种夹持器、总计2000万抓取），实验验证其性能优于现有先进方法，且数据集能有效促进跨形态抓取学习。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24579","title":"U-DiT Policy: U-shaped Diffusion Transformers for Robotic Manipulation","arxivId":"2509.24579","date":"2025-09-29","authors":"Zhongxue Gan Team","category":"Manipulation","summary":"本文针对现有基于U-Net的扩散策略（DP-U）在机器人操作中全局上下文建模能力有限、易产生过度平滑伪影的问题，提出U-DiT Policy框架。该方法结合U-Net的多尺度特征融合优势与Transformer的全局上下文建模能力，通过U-DiT层和AdaLN块增强策略表达力。实验表明，在模拟任务中U-DiT比基线平均性能提升10%，优于同类Transformer策略（DP-T）6%；在真实机器人任务中比DP-U平均提升22.5%，并展现出更强的泛化性与鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24539","title":"Unlocking the Potential of Soft Actor-Critic for Imitation Learning","arxivId":"2509.24539","date":"2025-09-29","authors":"Frank Kirchner Team","category":"Manipulation","summary":"本文针对模仿学习（IL）中主流方法过度依赖近端策略优化（PPO）、导致样本效率低和策略泛化能力有限的问题，提出了一种新颖的框架。该框架将对抗运动先验（AMP）与离策略的软演员-评论家（SAC）算法相结合，利用其回放驱动学习和熵正则化探索机制，以提升数据效率和鲁棒性。在四足机器人多种步态和地形的实验中，该方法（AMP+SAC）在保持稳定任务执行的同时，获得了比广泛使用的AMP+PPO方法更高的模仿奖励，验证了离策略IL框架在提升运动生成性能方面的潜力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24219","title":"ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning","arxivId":"2509.24219","date":"2025-09-29","authors":"Yang You Team","category":"Manipulation","summary":"本文针对基于LLM/VLM的机器人运动规划中符号计划缺乏物理基础性和输出不稳定的问题，提出ViReSkill框架。该方法结合视觉基础的重新规划与技能记忆：失败时基于当前视觉场景生成新的动作序列，成功时将执行计划存储为可重用技能以供后续直接调用。在LIBERO、RLBench模拟器和物理机器人上的实验表明，ViReSkill在任务成功率上 consistently outperforms conventional baselines，并实现了 robust sim-to-real generalization。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24163","title":"Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models","arxivId":"2509.24163","date":"2025-09-29","authors":"Sethu Vijayakumar Team","category":"Manipulation","summary":"本文针对大语言模型在规划长程机器人堆叠任务时，因缺乏对物体物理属性（如重量、稳定性）的理解而效果不佳的问题，提出使用多模态大语言模型作为高级规划器。关键技术是让模型接收多模态输入以推理堆叠偏好，并通过创建包含重量、稳定性、尺寸和占地面积等偏好的定制数据集对模型进行微调。实验表明，相比仅使用提示调优的预训练模型，经定制数据微调的模型在堆叠任务完成度上取得显著提升，并通过大规模仿真和真实人形机器人在线任务验证了其有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24160","title":"Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation","arxivId":"2509.24160","date":"2025-09-29","authors":"Yang You Team","category":"Manipulation","summary":"本文针对LLM驱动的机器人操作在新环境中适应性的问题，提出**记忆迁移规划（MTP）**框架。该方法通过**检索代码记忆中的成功示例**，并对其进行**上下文感知的适配**，以指导LLM重新规划，无需更新模型参数。在RLBench、CALVIN仿真和物理机器人上的实验表明，MTP相比固定提示生成、简单检索等方法，**持续提升了任务成功率和适应性**，有效实现了跨环境的鲁棒规划。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.24129","title":"Mash, Spread, Slice! Learning to Manipulate Object States via Visual Spatial Progress","arxivId":"2509.24129","date":"2025-09-28","authors":"Kristen Grauman Team","category":"Manipulation","summary":"本文针对机器人操作中物体状态变化（如捣碎、涂抹、切片）这一核心问题，提出首个统一框架SPARTA。其关键技术是利用空间进展物体变化分割图，将物体区域划分为“可操作”与“已转变”状态，从而生成结构化策略观察和密集奖励。SPARTA提供两种策略变体：无需演示或仿真的强化学习精细控制，以及快速轻量部署的贪婪控制。实验在真实机器人上对10种不同物体执行3项挑战性任务，相比稀疏奖励和视觉目标条件基线，在训练时间和准确性上均取得显著提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.23829","title":"DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation","arxivId":"2509.23829","date":"2025-09-28","authors":"Yuanpei Chen Team","category":"Manipulation","summary":"本文提出DexFlyWheel框架，旨在解决灵巧操作任务中高质量、多样性数据稀缺的瓶颈问题。该框架采用一种可扩展的自我改进循环：从少量种子演示出发，通过迭代执行模仿学习提取行为、残差强化学习增强泛化、轨迹收集与跨环境数据增强的闭环流程，持续扩展数据集。实验表明，该方法在四个挑战性任务上生成了超过2000个多样演示，基于此数据训练的策略在测试集上平均成功率达到81.9%，并成功迁移至现实双臂抓取任务，取得了78.3%的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.23823","title":"Control Your Robot: A Unified System for Robot Control and Policy Deployment","arxivId":"2509.23823","date":"2025-09-28","authors":"Bingshan Hu Team","category":"Manipulation","summary":"本文针对跨平台机器人控制因硬件接口、数据格式和控制范式各异而导致的工具链碎片化和部署缓慢问题，提出了一个名为“Control Your Robot”的模块化通用框架。该系统通过标准化工作流、统一API和闭环架构整合数据收集与策略部署，支持灵活的机器人注册、遥操作与轨迹回放双模式控制，实现从多模态数据采集到推理的无缝集成。实验表明，在单臂和双臂系统上，该系统能实现高效、低延迟的数据收集，并有效支持模仿学习和视觉-语言-动作模型的策略学习，训练出的策略与专家演示高度匹配，证明了其跨平台的可扩展性和可复现性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.22652","title":"Pixel Motion Diffusion is What We Need for Robot Control","arxivId":"2509.22652","date":"2025-09-26","authors":"Michael S. Ryoo Team","category":"Manipulation","summary":"根据论文标题“Pixel Motion Diffusion is What We Need for Robot Control”，该研究核心问题是解决机器人控制中运动生成和规划的挑战，旨在提高在复杂环境中的控制性能。关键技术方法为像素运动扩散，通过扩散模型在像素空间优化运动序列，实现平滑、自然的运动生成。由于未提供正文内容，核心实验结论或具体性能提升数据无法给出，但标题强调该方法对机器人控制的重要性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.22643","title":"VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search","arxivId":"2509.22643","date":"2025-09-26","authors":"Ziwei Wang Team","category":"Manipulation","summary":"本文针对现有视觉-语言-行动模型在长视野轨迹任务中因短视预测而产生累积偏差的问题，提出VLA-Reasoner插件框架。其核心方法融合在线蒙特卡洛树搜索提升决策效率，引入基于核密度估计的置信度采样以减少冗余查询，并利用离线奖励塑形策略评估未来状态以纠正偏差。实验表明，该方法在仿真和真实场景中均显著提升了VLA模型的性能和鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.22601","title":"Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning","arxivId":"2509.22601","date":"2025-09-26","authors":"Xing Sun Team","category":"Manipulation","summary":"本文针对LLM智能体强化学习中探索与利用的平衡难题，提出SPEAR方法。该方法通过课程调度的自模仿学习，协调内在奖励塑造与经验回放：早期促进工具交互以加速探索，后期强化对成功策略的利用。实验表明，SPEAR在ALFWorld和WebShop任务上将基线成功率最高提升16.1%和20.7%，在AIME竞赛任务上提升最高6.1%，仅增加10%–25%理论复杂度，具备即插即用的扩展性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.22578","title":"EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation","arxivId":"2509.22578","date":"2025-09-26","authors":"Liang Wang Team","category":"Manipulation","summary":"本文提出EgoDemoGen框架，旨在解决模仿学习策略因自我中心视角变化而性能下降的问题。其核心方法是：通过动作重定向与提出的生成式视频修复模型EgoViewTransfer（基于自监督双重重投影策略微调），合成配对的新视角演示数据。实验表明，混合使用生成数据与原始数据训练后，策略成功率显著提升：在仿真中，标准视角提升17.0%，新视角提升17.7%；在真实机器人上，分别提升18.3%和25.8%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.22442","title":"Learning to Ball: Composing Policies for Long-Horizon Basketball Moves","arxivId":"2509.22442","date":"2025-09-26","authors":"C. Karen Liu Team","category":"Manipulation","summary":"这篇论文针对篮球等长时程任务中策略组合的挑战，提出了一个**策略集成框架**和**高层软路由器**，以解决子任务间（如运球、收球、投篮）因中间状态不明确而难以无缝过渡的问题。该方法能组合差异巨大的运动技能，实现鲁棒的策略切换。实验表明，基于该框架训练的策略能使模拟角色有效完成复杂的组合篮球动作，且无需依赖球轨迹参考。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.22407","title":"EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer","arxivId":"2509.22407","date":"2025-09-26","authors":"Guan Huang Team","category":"Manipulation","summary":"本文提出EMMA框架，旨在解决机器人操作中因真实数据收集成本高、视觉多样性不足导致的模型泛化瓶颈。其核心技术包括：DreamTransfer（基于扩散Transformer的多视角一致视频生成方法，支持文本控制的前景、背景和光照编辑）和AdaMix（硬样本感知的动态加权训练策略）。实验表明，生成视频在多视角一致性与几何保真度上显著优于基线；使用生成数据训练的VLA模型在零样本视觉领域任务中，相比仅用真实数据训练获得超过200%的性能提升，结合AdaMix可再提升13%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.22402","title":"ReLAM: Learning Anticipation Model for Rewarding Visual Robotic Manipulation","arxivId":"2509.22402","date":"2025-09-26","authors":"Yang Yu Team","category":"Manipulation","summary":"本文针对视觉机器人操作中奖励设计困难的核心问题，提出ReLAM框架。该方法首先从图像提取关键点以隐式推断空间距离，进而学习一个Anticipation Model作为规划器，在最优路径上生成基于关键点的结构化中间子目标，构建与任务几何目标直接对齐的学习课程。随后，在分层强化学习框架下，依据这些子目标提供连续奖励信号来训练底层策略。实验表明，ReLAM在复杂长视野操作任务上显著加速学习，并取得了优于现有方法的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.22356","title":"RoboView-Bias: Benchmarking Visual Bias in Embodied Agents for Robotic Manipulation","arxivId":"2509.22356","date":"2025-09-26","authors":"Shuchao Pang Team","category":"Manipulation","summary":"本文针对机器人操作中具身智能体的视觉偏见缺乏系统量化的问题，提出了首个专用基准RoboView-Bias。该基准遵循因子隔离原则，通过结构化变体生成框架与感知公平验证协议，构建了2,127个任务实例，以精确测量由单一视觉因素及其交互作用引发的偏见。基于此基准对三种代表性智能体的评估发现：1) 所有智能体均存在显著视觉偏见，其中相机视角最为关键；2) 智能体在高饱和度颜色上成功率最高，揭示了其继承自底层视觉语言模型的视觉偏好；3) 视觉偏见存在强非对称耦合，视角会强烈放大颜色相关偏见。实验表明，一种基于语义接地层的缓解策略可将MOKA上的视觉偏见降低约54.5%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.22149","title":"DemoGrasp: Universal Dexterous Grasping from a Single Demonstration","arxivId":"2509.22149","date":"2025-09-26","authors":"Zongqing Lu Team","category":"Manipulation","summary":"本文提出DemoGrasp，旨在解决多指灵巧手对不同物体进行通用抓取时，因高维长时程探索困难而导致的策略学习复杂、性能不佳的问题。其核心方法基于单次成功演示轨迹，通过编辑轨迹中的手腕位姿（决定抓取位置）和手部关节角度（决定抓取方式），并将该编辑过程建模为单步MDP，利用简单的二元成功奖励与碰撞惩罚，通过强化学习并行优化跨数百物体的通用策略。在仿真中，该方法在DexGraspNet物体上使用Shadow Hand取得了95%的成功率，优于先前方法；在六个未见物体数据集上跨不同灵巧手平均成功率达84.6%，并能成功抓取110个真实世界未见物体，展现出强大的泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.22093","title":"Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation","arxivId":"2509.22093","date":"2025-09-26","authors":"Chang Xu Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型在机器人操作中因密集视觉令牌导致计算成本高、且现有方法忽视不同操作阶段冗余变化的问题，提出动作感知动态剪枝（ADP）框架。该方法整合文本驱动令牌选择与动作轨迹门控，通过基于过去运动的自适应门控机制动态调整令牌保留率。实验在LIBERO等场景中验证，ADP显著降低FLOPs和推理延迟（如OpenVLA-OFT加速1.35倍），同时保持高成功率（如OpenVLA提升25.8%）。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.22023","title":"Teaching Transformers to Solve Combinatorial Problems through Efficient Trial & Error","arxivId":"2509.22023","date":"2025-09-26","authors":"Christos Tzamos Team","category":"Manipulation","summary":"本文针对大型语言模型难以解决组合优化问题（如数独）的不足，提出了一种高效的试错学习框架。该方法结合对数独规则的模仿学习与显式深度优先搜索策略，通过有根据的猜测和回溯进行探索，并采用深度-1猜测以最小化猜测次数。实验表明，仅使用普通GPT-2模型，该框架在数独任务上达到了99%的准确率，且绝大多数谜题仅需至多一次猜测即可解决，性能优于先前神经符号方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.21810","title":"Learning Multi-Skill Legged Locomotion Using Conditional Adversarial Motion Priors","arxivId":"2509.21810","date":"2025-09-26","authors":"Qinchuan Li Team","category":"Manipulation","summary":"本文针对四足机器人难以从专家演示中通过单一策略学习多种运动技能且技能转换不流畅的核心问题，提出基于条件对抗运动先验（CAMP）的多技能学习框架。该方法引入条件生成对抗网络（CGAN）思想，通过新颖的技能判别器和技能条件奖励设计实现精确技能重建，支持主动控制与重用多种技能，为复杂环境中学习可泛化策略提供实用方案。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.21172","title":"Inverse Reinforcement Learning Using Just Classification and a Few Regressions","arxivId":"2509.21172","date":"2025-09-25","authors":"Aurélien Bibaut Team","category":"Manipulation","summary":"本文针对逆强化学习（IRL）传统方法计算复杂、难以与现代函数逼近器结合的问题，提出一种简化框架。核心方法是将最大似然解表征为一个涉及行为策略的线性不动点方程，从而将IRL转化为两个现成的监督学习任务：通过概率分类估计行为策略，并通过迭代回归求解不动点。该方法结构简单、模块化。实验表明，其性能与经典的最大熵IRL方法相当或更优。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.20841","title":"ImaginationPolicy: Towards Generalizable, Precise and Reliable End-to-End Policy for Robotic Manipulation","arxivId":"2509.20841","date":"2025-09-25","authors":"Kui Jia Team","category":"Manipulation","summary":"本文针对现有端到端机器人操作策略泛化性、精确性和可靠性不足的问题，提出了一种新颖的**Chain of Moving Oriented Keypoints (CoMOK)** 动作表示方法。该方法扩展了标准的末端执行器姿态表示，能以统一框架支持多样化的操作任务。其核心“定向关键点”设计使策略能自然泛化至不同形状尺寸的物体，并实现**亚厘米级精度**，同时易于处理多阶段任务与可变形物体。实验验证了该方法的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.20703","title":"Joint Flow Trajectory Optimization For Feasible Robot Motion Generation from Video Demonstrations","arxivId":"2509.20703","date":"2025-09-25","authors":"Weiming Zhi Team","category":"Manipulation","summary":"本文针对从人类视频演示中学习机器人操作任务时，因形态差异和关节约束导致的运动不可行问题，提出了**联合流轨迹优化**框架。该方法将演示视为**以物体为中心的指导**，而非直接模仿人手动作，通过平衡**可行抓取位姿选择、与演示一致的对象轨迹生成、以及无碰撞的机器人运动**三大目标，生成可行的机器人运动。关键技术包括将**流匹配扩展至SE(3)**空间，对物体轨迹进行概率建模，实现**密度感知的模仿**。框架通过整合抓取相似性、轨迹似然和碰撞惩罚，形成统一的可微优化目标。方法在模拟和真实世界的多种操作任务中得到了验证。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.20579","title":"Large Pre-Trained Models for Bimanual Manipulation in 3D","arxivId":"2509.20579","date":"2025-09-24","authors":"David Meger Team","category":"Manipulation","summary":"本文研究如何利用预训练视觉变换器（ViT）增强双手机器人操作的性能。核心问题是解决双手机器人操作中视觉感知与协调的挑战，通过将语义注意力集成到3D体素表示来提升任务表现。关键技术方法为：从自监督ViT模型DINOv2提取注意力图，将其解释为RGB图像的像素级显著性分数，并提升到3D体素网格中生成体素级语义线索，最终整合到基于体素的行为克隆策略。实验结果表明，在RLBench双手机器人基准测试中，该方法使最先进的体素策略平均绝对性能提升8.2%，相对增益达21.9%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.20297","title":"mindmap: Spatial Memory in Deep Feature Maps for 3D Action Policies","arxivId":"2509.20297","date":"2025-09-26","authors":"Shiwei Sheng Team","category":"Manipulation","summary":"本文针对机器人操作中物体进出视野时空间记忆缺失的核心问题，提出了mindmap方法。该方法是一种基于语义3D重建的3D扩散策略，利用视觉基础模型处理图像并反投影为点云，同时构建累积度量语义信息的场景重建，再通过变换器迭代去噪生成机器人轨迹。模拟实验表明，该方法能有效解决无记忆机制的最先进方法难以完成的任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.20070","title":"LLM Trainer: Automated Robotic Data Generating via Demonstration Augmentation using LLMs","arxivId":"2509.20070","date":"2025-09-24","authors":"Amir Barati Farimani Team","category":"Manipulation","summary":"本文提出LLM Trainer，旨在解决机器人模仿学习所需演示数据稀缺的问题。该方法利用大语言模型（LLM）的世界知识，通过两个关键技术实现自动化数据生成：首先进行离线演示标注，提取关键帧、显著物体及姿态-物体关系；随后在线进行关键姿态重定向，根据新场景调整关键帧并扭曲原始轨迹以生成新演示。实验表明，该数据标注方法持续优于专家设计的基线，并在Franka机器人上验证了硬件可行性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19958","title":"Generalist Robot Manipulation beyond Action Labeled Data","arxivId":"2509.19958","date":"2025-09-25","authors":"Danda Pani Paudel Team","category":"Manipulation","summary":"本文旨在解决通用机器人操作中高质量动作标记数据稀缺的瓶颈。提出一种新方法，利用无动作标签的人类或机器人演示视频进行学习。关键技术包括：在抓手位置提取密集动态3D点云，利用3D动态预测器进行自监督预训练，再通过少量标记数据对预测器进行动作对齐微调。实验表明，该方法能有效利用无标签数据提升下游策略的泛化性能，使机器人能在真实与仿真环境中学习训练时未见过的动作任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19853","title":"SAGE:State-Aware Guided End-to-End Policy for Multi-Stage Sequential Tasks via Hidden Markov Decision Process","arxivId":"2509.19853","date":"2025-09-24","authors":"JingYuan Wang Team","category":"Manipulation","summary":"本文针对多阶段顺序机器人操作任务中的状态模糊性问题，提出SAGE框架。该方法将任务建模为隐马尔可夫决策过程，通过状态转移网络推断潜在任务阶段，并设计状态感知的动作策略，结合观测与隐藏状态生成动作以消除歧义。为降低标注成本，采用结合主动学习与软标签插值的半自动标注流程。在真实世界的复杂任务实验中，SAGE实现了100%的任务成功率，显著优于基线方法；消融实验表明仅需标注约13%的状态即可保持同等性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19712","title":"TopoCut: Learning Multi-Step Cutting with Spectral Rewards and Discrete Diffusion Policies","arxivId":"2509.19712","date":"2025-09-24","authors":"Animesh Garg Team","category":"Manipulation","summary":"本文提出TopoCut框架，旨在解决机器人对可变形物体进行多步切割时面临的拓扑变化复杂、状态感知困难、切割结果评估缺乏鲁棒性等核心挑战。其关键技术包括：1）基于粒子弹塑性求解器的高保真仿真环境，配备损伤驱动的拓扑发现机制；2）融合拓扑发现与拉普拉斯-贝尔特拉米特征分析的姿态不变光谱奖励模型；3）集成动态感知模块与粒子化分数熵离散扩散策略（PDDP）的策略学习流程。实验表明，该框架支持轨迹生成、可扩展学习与精确评估，并在多样物体几何、尺度、姿态与切割目标上表现出强泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19658","title":"RoboSSM: Scalable In-context Imitation Learning via State-Space Models","arxivId":"2509.19658","date":"2025-09-24","authors":"Peter Stone Team","category":"Manipulation","summary":"本文针对基于Transformer的上下文模仿学习方法存在计算复杂度高、难以处理长提示序列的问题，提出RoboSSM框架。其核心技术是采用状态空间模型（SSM），特别是具有线性推理时间和强外推能力的Longhorn架构，替代Transformer作为序列建模主干，并通过β缩放调整使其关注演示提示。在LIBERO基准上的实验表明，RoboSSM能有效外推到不同数量的演示，在未见任务上取得高性能，并在长时域场景中保持鲁棒性，证明了SSM作为ICIL可扩展骨干的潜力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19626","title":"EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data","arxivId":"2509.19626","date":"2025-09-23","authors":"Danfei Xu Team","category":"Manipulation","summary":"论文EgoBridge旨在解决从人类自我中心数据到机器人模仿学习的领域差距问题，如视觉外观、传感器模态和运动学差异阻碍知识转移。提出统一的协同训练框架，基于最优传输对齐人类与机器人策略潜在空间，保留动作相关信息。实验显示，在三个真实单臂和双手操作任务中，相比人类增强的跨体现基线，绝对策略成功率提升44%，并能泛化到仅人类数据中出现的新对象、场景和任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19597","title":"From Space to Time: Enabling Adaptive Safety with Learned Value Functions via Disturbance Recasting","arxivId":"2509.19597","date":"2025-09-23","authors":"Sylvia L. Herbert Team","category":"Manipulation","summary":"本文旨在解决在未知、空间变化的扰动下，如何安全部署离线学习的值函数安全过滤器这一核心问题。针对现有方法需要预先精确扰动模型的局限，论文提出了**space2time**技术，其关键是将扰动的**空间变化重新参数化为时间变化**，从而允许在线运行时直接使用预计算的值函数来保证安全。通过在四旋翼无人机上进行的大量仿真和硬件实验验证，该方法相比基线取得了**显著的性能提升**。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19571","title":"Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action","arxivId":"2509.19571","date":"2025-09-23","authors":"Liam Paull Team","category":"Manipulation","summary":"本文提出Agentic Scene Policies (ASP)框架，旨在解决机器人执行开放词汇自然语言指令时，端到端策略模型在复杂指令与新场景下表现不佳的问题。ASP的核心方法是利用现代场景表征的语义、空间和可供性查询能力，通过大型语言模型（LLM）代理调用查询工具，并结合可供性检测映射到具体技能（如tip_push、pinch_pull），实现模块化的语言条件策略。实验表明，ASP能以零样本方式处理桌面操作与房间级导航操作任务，展现了解决广泛查询的先进性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19524","title":"Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation","arxivId":"2509.19524","date":"2025-09-23","authors":"Chi-Guhn Lee Team","category":"Manipulation","summary":"本文针对机器人操作任务评估中单一成功率指标无法揭示部分能力的问题，提出StepEval框架。核心方案是利用视觉-语言模型作为自动评判器，对记录的视频或图像进行子目标结果分类，生成每个子步骤的成功率向量，实现细粒度评估。该框架旨在成为一个轻量级、模型无关的社区开源项目蓝图，支持多视角输入，并通过框架优化诊断帮助平衡评估效率与准确性。论文未报告具体实验数据，重点在于倡导并设计一种可扩展的标准化评估实践。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19460","title":"Self-evolved Imitation Learning in Simulated World","arxivId":"2509.19460","date":"2025-09-23","authors":"Zhihe Lu Team","category":"Manipulation","summary":"本文针对模仿学习在有限监督下依赖大量专家数据的问题，提出自进化模仿学习框架。核心方法是通过模拟器交互收集成功轨迹作为新演示，并采用双级增强提升多样性：模型级使用EMA模型协作，环境级扰动初始物体位置；同时设计轻量选择器筛选优质轨迹。该方法在LIBERO基准的少样本模仿学习场景中达到最先进性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19454","title":"ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation","arxivId":"2509.19454","date":"2025-09-23","authors":"Daniel Seita Team","category":"Manipulation","summary":"本文针对双手操作模仿学习数据稀缺、收集成本高的问题，提出ROPA方法。核心技术是通过微调Stable Diffusion，合成具有新机器人姿态的第三人称RGB/RGB-D观测图像，并同步生成对应的关节空间动作标签；同时采用约束优化确保双手抓取物体时的物理接触一致性。在5个模拟任务和3个真实任务上的评估表明，ROPA在2625次模拟试验和300次真实试验中均优于基线方法，验证了其在RGB与RGB-D数据增强方面的有效性和可扩展性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19292","title":"SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration","arxivId":"2509.19292","date":"2025-09-23","authors":"Cewu Lu Team","category":"Manipulation","summary":"本文提出SOE框架，旨在解决机器人策略因探索能力不足导致的动作模式坍塌问题。其核心方法是学习任务相关因素的紧凑潜在表示，并将探索约束在有效动作的流形上，以此保证探索的安全性、多样性与高效性。实验表明，SOE在仿真与真实任务中均优于现有方法，实现了更高的任务成功率、更平滑安全的探索过程以及更优的样本效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19261","title":"Imitation-Guided Bimanual Planning for Stable Manipulation under Changing External Forces","arxivId":"2509.19261","date":"2025-09-23","authors":"Arash Ajoudani Team","category":"Manipulation","summary":"本文针对机器人在动态外力环境下进行稳定操纵时，如何实现不同抓取模式间平滑、高效过渡的挑战，提出了一种模仿引导的双臂规划框架。其核心方法包括：1) **抓取流形稳定交点采样策略**，用于生成单/双臂抓取间的无缝过渡路径，减少重抓取耗时；2) **分层双阶段运动架构**，结合模仿学习全局规划与二次规划局部优化，确保实时运动可行性、避障与高可操作性。通过在力密集型任务（如协作切割）中的实验验证，该方法显著提升了抓取过渡效率与运动性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19102","title":"FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation","arxivId":"2509.19102","date":"2025-09-23","authors":"Jianwei Zhang Team","category":"Manipulation","summary":"本文提出FUNCanon框架，旨在解决机器人模仿学习策略在面临新物体、新姿态和新任务时泛化能力不足的核心问题。其关键技术是**功能对象规范化**：利用大型视觉语言模型提供的功能线索，将不同物体映射到共享的功能坐标系，实现跨类别的轨迹自动迁移。基于此对齐数据训练的**对象与动作中心扩散策略FuncDiffuser**，能够自然地遵从物体功能与姿态。实验表明，该方法在模拟和真实场景中实现了**类别级泛化**、**跨任务行为重用**以及**稳健的仿真到现实部署**，验证了功能规范化能为复杂操作提供有效的归纳偏置。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19080","title":"World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation","arxivId":"2509.19080","date":"2025-09-23","authors":"Dongbin Zhao Team","category":"Manipulation","summary":"本文提出World4RL框架，解决机器人操作中模仿学习策略因专家数据稀缺而性能受限、强化学习细化面临真实训练成本高和仿真到现实差距的问题。方法采用扩散世界模型作为高保真模拟器，通过预训练捕捉多任务动态，在冻结模型中完全细化策略以避免在线交互，并设计两热动作编码和扩散主干网络提升建模保真度。实验表明，该框架能实现高保真环境建模和一致策略细化，相比模仿学习及其他基线方法，成功率显著提高。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.19047","title":"ManipForce: Force-Guided Policy Learning with Frequency-Aware Representation for Contact-Rich Manipulation","arxivId":"2509.19047","date":"2025-09-23","authors":"Kyoobin Lee Team","category":"Manipulation","summary":"本文针对接触式操作任务中现有模仿学习方法缺乏力感知信息的问题，提出ManipForce手持系统与频率感知多模态变换器（FMT）。ManipForce采集高频力-扭矩与RGB数据；FMT通过频率与模态感知嵌入编码异步信号，并利用双向交叉注意力在扩散策略中融合多模态信息。在齿轮装配等六项真实任务中，基于ManipForce演示训练的FMT平均成功率达83%，显著优于仅使用RGB的基线，验证了高频力数据与跨模态融合对提升策略精度与稳定性的关键作用。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18953","title":"Eva-VLA: Evaluating Vision-Language-Action Models’ Robustness Under Real-World Physical Variations","arxivId":"2509.18953","date":"2025-09-23","authors":"Wen Yao Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型在真实物理变化下鲁棒性评估不足的核心问题，提出了首个统一评估框架Eva-VLA。该框架将物理变化系统分解为物体3D变换、光照变化与对抗补丁三类，并创新性地采用连续黑盒优化方法，将离散变化转化为参数优化问题以高效探索最坏情况。实验表明，主流VLA模型在各类物理变化下均表现出严重脆弱性，失败率普遍超过60%，其中物体变换在长时程任务中导致高达97.8%的失败率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18865","title":"Bi-VLA: Bilateral Control-Based Imitation Learning via Vision-Language Fusion for Action Generation","arxivId":"2509.18865","date":"2025-09-23","authors":"Thanpimon Buamanee Team","category":"Manipulation","summary":"本文提出Bi-VLA框架，旨在解决传统双边控制模仿学习方法仅适用于单一任务、缺乏通用性的问题。该方法通过SigLIP和基于FiLM的融合技术，将机器人关节角度、速度、扭矩数据与视觉特征、自然语言指令相结合。真实机器人实验表明，Bi-VLA能成功理解视觉-语言组合指令，相比传统方法提升了多任务场景下的任务成功率，验证了视觉与语言融合对增强系统泛化能力的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18830","title":"DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation","arxivId":"2509.18830","date":"2025-09-23","authors":"Jiajun Wu Team","category":"Manipulation","summary":"本文针对机器人触觉传感覆盖面积小、难以贴合复杂曲面的问题，提出了DexSkin——一种柔软、可贴合、基于电容原理的高覆盖率电子皮肤。其关键技术在于可定制化几何形状，提供敏感、局部化且可校准的触觉信号，并实现了传感器实例间的模型迁移。实验表明，该皮肤能有效支持物体在手中重定向、用皮筋包裹盒子等接触丰富的操作任务，适用于从示范学习到在线强化学习的多种数据驱动方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18778","title":"VGGT-DP: Generalizable Robot Control via Vision Foundation Models","arxivId":"2509.18778","date":"2025-09-23","authors":"Zhi Wang Team","category":"Manipulation","summary":"这篇论文针对视觉模仿学习中视觉编码器结构限制空间理解与泛化能力的问题，提出VGGT-DP框架。其关键技术包括：采用VGGT视觉编码器整合预训练3D模型的几何先验；引入本体感受反馈引导的视觉学习策略，以对齐感知与机器人内部状态；设计了帧级令牌重用机制和随机令牌剪枝，以提升推理效率与策略鲁棒性。在MetaWorld任务上的实验表明，该框架显著优于DP、DP3等基线方法，尤其在精密操作和长时程任务中表现突出。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18757","title":"MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning","arxivId":"2509.18757","date":"2025-09-23","authors":"Fares Abu-Dakka Team","category":"Manipulation","summary":"本文解决手持夹爪数据收集设备仅依赖第一人称视角、场景理解受限的问题。提出了MV-UMI框架，其关键技术是通过整合第三人称视角与自我中心摄像头，以克服单视角局限，同时保持跨具身学习的优势。核心实验结论表明，该方法在需要广泛场景理解的子任务上，性能平均提升约47%（在3个任务上验证），有效扩展了手持系统的可学习任务范围。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18676","title":"3D Flow Diffusion Policy: Visuomotor Policy Learning via Generating Flow in 3D Space","arxivId":"2509.18676","date":"2025-09-23","authors":"Kyoobin Lee Team","category":"Manipulation","summary":"本文提出3D Flow Diffusion Policy (3D FDP)，以解决机器人操作中视觉运动策略对细粒度局部运动线索建模不足的问题。该方法的核心是引入场景级3D流作为结构化中间表示，在统一的扩散架构中联合预测查询点的时空轨迹，并以此生成动作，从而将操作决策建立在局部动态之上。实验表明，3D FDP在MetaWorld基准的50项任务中达到最先进性能，尤其在中等与困难任务上表现突出；在八项真实机器人接触丰富与非抓取任务中，也持续优于现有基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18644","title":"Do You Need Proprioceptive States in Visuomotor Policies?","arxivId":"2509.18644","date":"2025-09-24","authors":"Yang Gao Team","category":"Manipulation","summary":"本文研究视觉运动策略中是否必须使用本体感知状态输入。核心问题是传统方法因依赖状态输入导致对训练轨迹过拟合，空间泛化能力差。为此，论文提出“无状态策略”，关键技术包括：采用相对末端执行器动作空间，并仅基于视觉观察（通过双广角腕戴相机确保完整任务视野）预测动作。实验表明，该方法显著提升了空间泛化能力：在多种真实机器人任务中，高度泛化平均成功率从0%提升至85%，水平泛化从6%提升至64%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18631","title":"Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training","arxivId":"2509.18631","date":"2025-09-23","authors":"Danfei Xu Team","category":"Manipulation","summary":"本文针对仿真到现实策略迁移中的领域差距问题，提出了一种统一的仿真与现实协同训练框架。其核心是学习一个领域不变的任务特征空间，关键技术是采用最优传输（OT）损失来对齐跨领域的观测-动作联合分布，并扩展为非平衡OT以处理数据量不平衡问题。实验表明，该方法能有效利用大量仿真数据，在真实机器人操作任务中实现高达30%的成功率提升，并能泛化至仅仿真见过的场景。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18597","title":"Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills","arxivId":"2509.18597","date":"2025-09-23","authors":"Alois Knoll Team","category":"Manipulation","summary":"请提供论文正文内容，以便我根据具体研究内容撰写符合要求的总结。目前仅凭标题无法准确提炼核心问题、方法要点及实验结论。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18463","title":"Robotic Skill Diversification via Active Mutation of Reward Functions in Reinforcement Learning During a Liquid Pouring Task","arxivId":"2509.18463","date":"2025-09-22","authors":"Luka Peternel Team","category":"Manipulation","summary":"本文研究如何通过主动变异强化学习的奖励函数，使机器人在执行液体倾倒任务时获得多样化的技能变体。核心方法是提出一个奖励函数主动变异框架，对基于准确性、时间和努力的奖励项权重施加高斯噪声，并使用PPO算法进行训练。实验在仿真环境中进行，结果表明，该方法能产生丰富的策略行为，不仅包括快/慢倾倒等原始任务变体，还衍生出容器边缘清洁、液体混合和浇水等可用于意外任务的新技能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18455","title":"Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands","arxivId":"2509.18455","date":"2025-09-22","authors":"Daniel Seita Team","category":"Manipulation","summary":"本文研究如何利用多指灵巧手进行几何感知的非抓取式推拉操作，以操纵难以直接抓取的物体。提出GD2P方法，其关键技术包括：通过接触引导采样生成多样化的预接触手部姿态，利用物理模拟进行筛选，并训练一个以物体几何为条件的扩散模型来预测可行姿态。实验在Allegro Hand上进行了840次真实世界测试，结果表明GD2P为训练灵巧非抓取操作策略提供了可扩展的途径，并成功迁移至LEAP Hand，证明了其对不同手部形态的适用性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18447","title":"PrioriTouch: Adapting to User Contact Preferences for Whole-Arm Physical Human-Robot Interaction","arxivId":"2509.18447","date":"2025-09-22","authors":"Tapomayukh Bhattacharjee Team","category":"Manipulation","summary":"本文提出PrioriTouch框架，旨在解决全臂物理人机交互（pHRI）中多接触点同时作用时，因用户身体部位力偏好冲突导致的控制难题。方法核心结合了学习排序与分层操作空间控制，通过模拟循环展开进行安全高效的数据探索。实验表明，该框架能够在线学习并适应用户个性化的接触偏好，在保持任务性能的同时显著提升了交互的安全性与舒适度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18084","title":"ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces","arxivId":"2509.18084","date":"2025-09-22","authors":"Zeyu Ren Team","category":"Manipulation","summary":"本文提出ByteWrist，一种新型高灵活、拟人化的并联机器人手腕，旨在解决现有串联及并联手腕在狭窄空间操作中紧凑性与灵活性难以兼顾的核心问题。其关键技术包括：嵌套三级电机驱动连杆以实现紧凑多自由度控制、弧形末端连杆优化力传递并扩大运动范围、以及作为球关节的中心支撑球在保持灵活性的同时增强结构刚度。实验表明，ByteWrist在狭窄空间机动性与双臂协同操作任务中性能优异，优于Kinova系统，在紧凑性、效率和刚度方面相比传统设计有显著提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.18043","title":"Prepare Before You Act: Learning From Humans to Rearrange Initial States","arxivId":"2509.18043","date":"2025-09-22","authors":"Dylan P. Losey Team","category":"Manipulation","summary":"本文针对模仿学习策略在遇到分布外初始状态（如目标被遮挡）时泛化能力差的问题，提出ReSET算法。该方法核心是让机器人像人类一样“先准备后执行”：通过结合动作无关的人类视频和任务无关的遥操作数据，学习一个简化策略，先自主调整物体位姿（如移开障碍物），使场景落入任务策略的熟悉分布，再执行原任务。实验表明，在相同训练数据量下，使用ReSET进行环境准备能实现比扩散策略等基线更鲁棒的任务执行。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.17783","title":"RoboSeek: You Need to Interact with Your Objects","arxivId":"2509.17783","date":"2025-09-23","authors":"Yatong Han Team","category":"Manipulation","summary":"论文RoboSeek旨在解决长视野机器人操作任务中交互驱动学习的挑战，如序列决策、物理约束和感知不确定性。提出基于具身认知的RoboSeek框架，关键技术包括：通过3D重建在模拟中复制真实环境，利用强化学习和交叉熵方法训练策略优化视觉先验，并采用real2sim2real传输管道实现真实部署。在八个涉及序列交互、工具使用的任务上评估，平均成功率达到79%，显著优于基线（成功率低于50%），验证了方法的通用性和鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.17759","title":"MotionTrans: Human VR Data Enable Motion-Level Learning for Robotic Manipulation Policies","arxivId":"2509.17759","date":"2025-09-22","authors":"Yang Gao Team","category":"Manipulation","summary":"本文提出MotionTrans框架，旨在解决机器人模仿学习中真实数据稀缺的核心瓶颈，探索如何利用人类VR数据使机器人策略直接学习新动作以完成任务。方法包含VR数据采集系统、数据转换流程及加权协同训练策略，通过多任务人机协同训练实现运动知识迁移。实验表明，在30个任务的协同训练中，成功将13个任务的人类动作直接迁移至机器人策略，其中9个任务实现零样本有效执行；预训练-微调性能提升达40%成功率。关键成功因素为与机器人数据协同训练及广泛的任务相关动作覆盖。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.17684","title":"DINOv3-Diffusion Policy: Self-Supervised Large Visual Model for Visuomotor Diffusion Policy Learning","arxivId":"2509.17684","date":"2025-09-22","authors":"Zidong Chen Team","category":"Manipulation","summary":"本文研究自监督大规模视觉模型DINOv3在机器人视觉运动扩散策略学习中的性能。核心问题是评估其相比传统监督式预训练骨干网络（如ResNet-18）在策略性能与泛化能力上的表现。方法上，论文在统一的FiLM条件扩散策略框架下，对DINOv3进行了从头训练、冻结和微调三种模式的测试。实验表明，微调后的DINOv3在多个基准任务上匹配或超越了ResNet-18，例如在Can任务上实现了高达10%的绝对成功率提升；冻结的DINOv3也表现优异，证明了其强大的可迁移先验知识。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.17450","title":"Learning Dexterous Manipulation with Quantized Hand State","arxivId":"2509.17450","date":"2025-09-22","authors":"Cewu Lu Team","category":"Manipulation","summary":"本文针对灵巧操作中手臂与手部动作在高维耦合空间内学习不平衡的问题，提出 DQ-RISE 方法。其核心是将手部状态量化以简化预测并保留关键模式，同时应用连续松弛技术，使手臂动作能与量化后的紧凑手部状态联合优化。该方法旨在防止手部动作主导整个动作空间，从而促进策略学习协调的臂-手控制。实验表明，DQ-RISE 实现了更平衡、高效的学习。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.17381","title":"Fast Trajectory Planner with a Reinforcement Learning-based Controller for Robotic Manipulators","arxivId":"2509.17381","date":"2025-09-22","authors":"Hamidreza Kasaei Team","category":"Manipulation","summary":"本文针对机器人在非结构化和杂乱环境中快速生成无碰撞轨迹的挑战，提出一种融合任务空间视觉规划与关节空间强化学习控制的系统。关键技术包括：基于FSA模型和B样条优化的视觉轨迹规划器，以及集成动作集成和策略反馈的增强PPO算法，以提高避障和目标到达的精度与稳定性。实验表明，PPO增强有效提升了模型鲁棒性和规划效率，支持模拟到现实转移，使机器人能在障碍环境中实时执行避障与轨迹规划。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.17125","title":"Imagine2Act: Leveraging Object-Action Motion Consistency from Imagined Goals for Robotic Manipulation","arxivId":"2509.17125","date":"2025-09-21","authors":"Hao Dong Team","category":"Manipulation","summary":"Imagine2Act论文针对机器人操作中的关系物体重排任务，解决了现有方法难以耦合物体变换与动作预测、导致生成噪声误差的核心问题。该框架提出3D模仿学习方法，首先生成基于语言指令的想象目标图像并重建3D点云以提供语义和几何先验；进而通过物体-动作一致性策略与软姿态监督，显式对齐预测的末端执行器运动与物体变换。实验在模拟和真实世界中进行，结果表明Imagine2Act优于先前的最优策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.17057","title":"RoboManipBaselines: A Unified Framework for Imitation Learning in Robotic Manipulation across Real and Simulated Environments","arxivId":"2509.17057","date":"2025-09-21","authors":"Yukiyasu Domae Team","category":"Manipulation","summary":"本文针对机器人模仿学习在部署中面临的数据收集、训练和评估流程割裂的挑战，提出了统一框架RoboManipBaselines。该框架的核心技术方法是构建一个端到端的工作流，强调集成性、通用性、可扩展性和可复现性四大原则，支持在模拟与真实环境中对多种机器人、任务及多模态策略进行系统化基准测试。通过与现有开源框架的对比实验表明，RoboManipBaselines在支持真实机器人、多种模拟器、多模态传感器等方面具备更全面的能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.17053","title":"FILIC: Dual-Loop Force-Guided Imitation Learning with Impedance Torque Control for Contact-Rich Manipulation Tasks","arxivId":"2509.17053","date":"2025-09-21","authors":"Guyue Zhou Team","category":"Manipulation","summary":"本文提出FILIC框架，旨在解决接触丰富操作任务中模仿学习策略缺乏力感知、且力传感器成本高昂的问题。其关键技术包括：双环结构（Transformer模仿学习策略+阻抗控制器）、基于关节力矩与数字孪生补偿的末端力估计器，以及手持触觉与VR可视化的力反馈框架。实验表明，FILIC显著优于仅视觉和基于关节力矩的方法，实现了更安全、柔顺且适应性更强的接触操作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.16122","title":"Efficient Detection of Objects Near a Robot Manipulator via Miniature Time-of-Flight Sensors","arxivId":"2509.16122","date":"2025-09-19","authors":"Michael Gleicher Team","category":"Manipulation","summary":"本文解决机器人手臂搭载微型飞行时间传感器时，难以区分传感器测量中的机器人自身与外部物体的核心问题。提出一种轻量级方法：通过建立机器人单独存在时的传感器测量经验模型，运行时利用该模型从原始ToF数据中检测附近物体。该方法避免了自检测，实现了无自检测的接近感知，从而允许传感器沿机械臂长度方向等高效配置。实验表明，该方法能检测机械臂附近的小物体，并沿连杆以合理精度定位物体，为避撞和人机交互提供了新方案。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.16072","title":"I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models","arxivId":"2509.16072","date":"2025-09-19","authors":"Mohamed Chetouani Team","category":"Manipulation","summary":"本文针对开放世界中语言条件机器人操纵的失败检测问题，重点解决语义错位错误（即机器人执行任务语义有意义但与指令不一致）。提出I-FailSense开源视觉语言模型（VLM）框架，关键技术包括后训练基础VLM、附加轻量级FS块分类头至不同内部层，并通过集成机制聚合预测。实验表明，I-FailSense在语义错位错误检测上优于最先进VLMs（包括规模相当或更大的模型），且仅训练于此任务却能零样本泛化至更广泛失败类别，并有效迁移到其他模拟环境和真实世界。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.15880","title":"Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder","arxivId":"2509.15880","date":"2025-09-19","authors":"Ian Reid Team","category":"Manipulation","summary":"本文针对机器人模仿学习中传统2D视觉编码器（如ResNet、ViT）缺乏3D几何理解能力的问题，提出集成几何感知视觉编码器以提升操作性能。核心方法是：1）将几何感知编码器融入ACT、DP等模仿学习框架；2）提出轻量级变体eVGGT，通过知识蒸馏使模型体积缩小5倍、速度提升9倍。实验表明，该方法在仿真和真实世界的单/双手操作任务中，成功率最高提升6.5%，同时保持了高效的几何推理能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.15733","title":"GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation","arxivId":"2509.15733","date":"2025-09-19","authors":"Deli Zhao Team","category":"Manipulation","summary":"本文提出GP3，旨在解决机器人操作中依赖专用深度传感器或RGB图像3D表示泛化性差的问题。其核心是RoboVGGT空间编码器，通过多视角RGB图像推断密集空间特征以估计深度和相机参数，构建紧凑的3D场景表示，并结合语言指令通过轻量策略头输出动作。实验表明，GP3在模拟基准测试中持续优于现有方法，并能以最小微调有效迁移至无深度传感器的真实机器人。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.15717","title":"Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference","arxivId":"2509.15717","date":"2025-09-19","authors":"Yoshihiko Nakamura Team","category":"Manipulation","summary":"本文针对机器人操作中因硬件限制难以部署真实手部摄像头，导致视觉运动策略性能下降的问题，提出在推理时通过新颖视角合成技术“想象”生成手部视角图像。方法核心是采用基于LoRA微调的预训练扩散模型，以相对相机位姿为条件，从单张智能体视角图像合成手部视图。在仿真与真实草莓采摘任务上的实验表明，合成的手部视图显著增强了策略推理能力，有效恢复了因缺少真实手部摄像头而导致的性能损失。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.15443","title":"Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning","arxivId":"2509.15443","date":"2025-09-18","authors":"Haodong Zhang Team","category":"Manipulation","summary":"本文提出隐式运动动力学运动重定向（IKMR）框架，以解决人形机器人模仿学习中大规模人类运动高效、可扩展地转换为机器人可行轨迹的核心问题。该方法通过预训练运动拓扑特征表示和双编码器-解码器架构实现运动域映射（运动学），并集成模仿学习优化物理可行性（动力学）。实验在仿真和真实全尺寸人形机器人上进行，验证了该框架能够实时实现大规模物理可行运动重定向，并可直接训练全身控制器跟踪重定向轨迹。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.15212","title":"RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation","arxivId":"2509.15212","date":"2025-09-18","authors":"Xin Li Team","category":"Manipulation","summary":"本文提出RynnVLA-001视觉-语言-动作模型，旨在解决机器人操作任务中大规模数据稀缺的核心问题。其关键技术是两阶段预训练：第一阶段“自我中心视频生成预训练”基于1200万人类示范视频，训练以初始图像和语言指令为条件的图像到视频模型；第二阶段“人体中心轨迹感知建模”联合预测未来关键点轨迹，以桥接视觉与动作预测。此外，提出ActionVAE压缩动作序列为紧凑潜表示。实验表明，经相同下游数据集微调后，该模型性能超越现有先进基线，验证了所提预训练策略能为VLA模型提供更有效的初始化。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.15155","title":"Self-Improving Embodied Foundation Models","arxivId":"2509.15155","date":"2025-09-18","authors":"Igor Mordatch Team","category":"Manipulation","summary":"本文针对机器人基础模型在低级控制中主要依赖行为克隆、缺乏高效后训练的问题，提出一种两阶段后训练框架。第一阶段为监督微调，结合行为克隆与步数预测目标；第二阶段为自我改进，利用步数预测构建奖励函数与成功检测器，使机器人能自主练习任务。实验表明，该方法比单纯扩大模仿数据更样本高效，能显著提升任务成功率，并能使机器人自主习得远超训练数据范围的新技能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.14932","title":"Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale","arxivId":"2509.14932","date":"2025-09-18","authors":"Florian Walter Team","category":"Manipulation","summary":"本文针对机器人学习中传统软件框架成为瓶颈、仿真与真实实验转换困难的问题，提出Robot Control Stack（RCS）。这是一个轻量级生态系统，其核心是采用分层架构，提供统一的仿真与物理机器人接口，便于sim-to-real迁移。实验评估了Octo、OpenVLA等模型在多机器人平台上的性能，并验证了仿真数据对提升真实世界策略的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.14688","title":"exUMI: Extensible Robot Teaching System with Action-aware Task-agnostic Tactile Representation","arxivId":"2509.14688","date":"2025-09-18","authors":"Yong-Lu Li Team","category":"Manipulation","summary":"本文针对触觉感知机器人学习面临的数据稀缺、稀疏性及缺乏力反馈等核心问题，提出了一种硬件与算法协同设计的解决方案。关键技术包括：1）硬件exUMI，作为UMI系统的可扩展升级，通过增强本体感知、模块化视觉触觉传感与自动校准，实现高效数据采集；2）算法Tactile Prediction Pretraining，通过动作感知的时间触觉预测学习表征，以捕捉接触动态并缓解触觉稀疏性。实验表明，该系统实现了100%的数据可用性，收集了超过100万触觉帧，且TPP表征在真实机器人任务中优于传统触觉模仿学习方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.14548","title":"SimCoachCorpus: A naturalistic dataset with language and trajectories for embodied teaching","arxivId":"2509.14548","date":"2025-09-18","authors":"Guy Rosman Team","category":"Manipulation","summary":"本文针对当前缺乏语言与物理动作深度结合的教学数据集问题，提出了SimCoachCorpus数据集。该数据集采集了29名参与者在赛车模拟器中的驾驶轨迹与语音指导数据，其中15人接受专业教练的一对一实时指导。关键技术包括同步记录车辆状态、地图、语音指令，并对指导话语进行分类标注、学生依从性评分及参与者认知负荷标注。数据集包含超过20,000条实时指导语句和40小时驾驶数据，可用于运动学习分析、语言现象研究及教学计算模型训练。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.14530","title":"Learning to Pick: A Visuomotor Policy for Clustered Strawberry Picking","arxivId":"2509.14530","date":"2025-09-18","authors":"Chen Peng Team","category":"Manipulation","summary":"本文针对簇生草莓采摘中因遮挡导致的机器人操作难题，提出了一种基于模仿学习的解决方案。核心是通过人机协作系统（4-DoF SCARA机械臂与遥操作接口）采集数据，并利用改进的End Pose Assisted Action Chunking Transformer (ACT) 学习精细的视觉运动策略，实现灵巧绕过遮挡物并精准定位花萼上方茎秆的采摘点。实验表明，该方法在多种遮挡场景下显著优于直接使用ACT的基准方法，展现了实际应用的潜力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.14460","title":"Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring","arxivId":"2509.14460","date":"2025-09-17","authors":"Constantinos Chamzas Team","category":"Manipulation","summary":"本文针对机器人从原始视觉数据中自动学习有用抽象表示的核心挑战，提出一种用于视觉重排任务的方法。该方法通过结合结构约束与注意力加权的视觉距离，利用约束图着色技术，从动作轨迹中自主归纳出离散的二分图结构抽象。在仿真重排任务上的实验表明，该方法能一致地识别出有意义的抽象，有效支持高层规划，且性能优于现有方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.14349","title":"LeVR: A Modular VR Teleoperation Framework for Imitation Learning in Dexterous Manipulation","arxivId":"2509.14349","date":"2025-09-17","authors":"Han Liu Team","category":"Manipulation","summary":"本文提出LeVR模块化VR遥操作框架，旨在解决灵巧操作模仿学习中VR数据收集与学习框架集成两大难题。核心技术包括：1）为多指灵巧手提供直观VR遥操作与数据采集；2）无缝对接LeRobot模仿学习框架，实现从演示收集到策略部署的端到端流程。通过开源实现LeFranX（用于Franka机械臂与RobotEra灵巧手）验证，系统具备低延迟操作能力，并利用收集的100个专家演示数据集成功微调了先进视觉运动策略，提升了策略性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.14159","title":"MIMIC-D: Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies","arxivId":"2509.14159","date":"2025-09-17","authors":"Negar Mehr Team","category":"Manipulation","summary":"本文研究多智能体在多模态任务中的协调问题，其核心挑战在于如何从多模态专家演示中学习有效的去中心化协调策略，避免因策略冲突导致失败。论文提出MIMIC-D方法，采用基于扩散模型的集中训练分散执行框架，使智能体在训练时利用全局信息学习多模态策略，在执行时仅依靠局部观测实现隐式协调。实验表明，该方法在仿真与硬件中均能成功恢复多样化的协调行为，并优于现有基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.14138","title":"SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model","arxivId":"2509.14138","date":"2025-09-17","authors":"Yiming Feng Team","category":"Manipulation","summary":"本文针对长视野机器人操作中，子任务完成检测错误易引发序列失败的核心问题，提出了SeqVLA模型。该模型在π0 VLA架构上增加轻量级完成检测头，形成双头设计以同步生成动作和自主触发子任务转换，并研究了联合/顺序微调、全微调/冻结骨干四种策略。实验在沙拉打包（七子任务）和糖果打包（四子任务）上表明，SeqVLA整体成功率显著优于基线π0，其中联合微调未冻结骨干策略的完成预测最可靠，能消除序列相关失败，实现鲁棒的长视野执行。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.13903","title":"PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models","arxivId":"2509.13903","date":"2025-09-17","authors":"Dzmitry Tsetserukou Team","category":"Manipulation","summary":"本文提出PhysicalAgent框架，旨在解决机器人操作中因任务、平台或环境变化导致的通用性与鲁棒性不足问题。其核心技术是结合迭代推理与基于扩散的基础世界模型，生成未来动作视频，再通过轻量级机器人特定适配器将视频映射为电机指令进行闭环执行。实验表明，该方法在多种机器人平台上优于现有技术，在物理试验中，通过迭代纠正能将整体任务成功率从首次尝试的20-30%显著提升至80%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.13774","title":"Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach","arxivId":"2509.13774","date":"2025-09-17","authors":"Yangwei You Team","category":"Manipulation","summary":"本文针对视觉-语言-行动（VLA）模型在复杂现实任务中性能不足的问题，提出了一种基于强化学习的人机协同双行动者微调框架。其核心是结合一个负责稳健多任务行动的主要行动者，和一个在潜在噪声空间进行细粒度调整的精炼行动者。关键创新在于“对话调整”方案，将人类物理纠正转化为语义明确的语言指令以生成训练数据。实验表明，该方法在101分钟的在线微调内实现了三个任务的100%成功率，在长时域任务中能维持50%成功率超过12个连续操作，并在多机器人训练中实现最高2倍的效率提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.13736","title":"Motion Adaptation Across Users and Tasks for Exoskeletons via Meta-Learning","arxivId":"2509.13736","date":"2025-09-17","authors":"Houcheng Li Team","category":"Manipulation","summary":"本文针对外骨骼难以实现个性化且跨任务通用的运动辅助这一核心问题，提出一种基于元模仿学习的适应方法。关键技术是：利用公开RGB视频与动作捕捉数据，在仿真中重定向生成全身关键点运动，并基于此训练任务特异性神经网络；该网络在与模型无关的元学习框架下进行训练，仅需少量梯度更新即可快速适应新用户和新任务；最终通过重力补偿PD控制器跟踪网络输出的个性化运动参考轨迹。实验表明，相比无辅助状态，该方法能使外骨骼显著降低新用户执行未训练任务时的肌肉激活水平与代谢消耗。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.13731","title":"Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings","arxivId":"2509.13731","date":"2025-09-17","authors":"Changjoo Nam Team","category":"Manipulation","summary":"本文针对工业场景中柔性扁平电缆（FFC）插入任务精度要求高（亚毫米级）、传统人工示教方法低效的问题，提出了一种基于强化学习的自动化解决方案。核心方法是采用基于基础模型（SAM2 和 VLM）的“真实-仿真”框架，在仿真环境中进行安全训练，并通过语义分割自动提取电缆和插槽的关键视觉特征以实现仿真到真实的迁移。实验表明，该方法具备零样本部署能力，无需在真实环境中进行微调即可直接应用，为工业插装任务提供了一种通用、可扩展的自动化途径。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.13200","title":"StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening","arxivId":"2509.13200","date":"2025-09-18","authors":"Shayegan Omidshafiei Team","category":"Manipulation","summary":"本文针对人形机器人开门任务中长视野、部分可观测性（如门闩状态不可直接观察）导致的模式崩溃问题，提出StageACT阶段条件模仿学习框架。该方法通过向低级策略注入任务阶段信息，增强对不确定性的鲁棒性。实验显示，在真实办公室环境中，StageACT对未见过的门实现55%的成功率，比最佳基线提高一倍以上，并支持阶段提示实现行为恢复。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.13077","title":"A Design Co-Pilot for Task-Tailored Manipulators","arxivId":"2509.13077","date":"2025-09-16","authors":"Matthias Althoff Team","category":"Manipulation","summary":"本文针对通用机械臂在特定任务中性能不佳、定制化设计成本高的问题，提出一种用于任务定制化机械臂的生成式设计辅助方法。核心技术包括学习广泛机械臂的逆运动学，并构建一个完全可微分的框架，以实现基于梯度的机器人形态与运动联合优化。该方法将设计时间从数小时缩短至秒级，实验表明其能生成可在杂乱环境中导航、适应不同硬件约束的机械臂，并通过实物模块机器人成功验证了仿真设计的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.12674","title":"Safety filtering of robotic manipulation under environment uncertainty: a computational approach","arxivId":"2509.12674","date":"2025-09-16","authors":"Martin Servin Team","category":"Manipulation","summary":"本文针对环境参数不确定时机器人操作的安全过滤问题，提出一种基于物理仿真的计算方法。该方法利用高保真仿真评估控制策略，通过密集滚动（基于标称参数）与并行稀疏重评估（在关键状态转换点）相结合，以广义安全因子量化抓取稳定性和执行器限制，并通过探测动作减少不确定性。在物体质量和摩擦系数不确定的模拟双臂操作任务中，该方法能有效识别并过滤不安全轨迹，验证了基于物理的稀疏安全评估的可扩展性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.12531","title":"Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning","arxivId":"2509.12531","date":"2025-09-16","authors":"Sebastian W. Pattinson Team","category":"Manipulation","summary":"本文研究了预训练视觉模型在基于模型的强化学习中对视觉域转移的泛化能力这一核心问题。针对现有研究认为PVMs在MBRL中无效的结论，本文通过实验验证了其在严重视觉分布偏移下的有效性。关键技术在于探索了对PVMs进行不同程度微调的影响。核心实验结论表明：在遭遇严重视觉偏移时，使用PVMs的策略性能显著优于从头训练的基线模型；而部分微调（partial fine-tuning）的方式能在最极端的分布偏移下保持最高的平均任务性能。这证明了PVMs能有效提升视觉策略学习的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.12379","title":"Geometric Red-Teaming for Robotic Manipulation","arxivId":"2509.12379","date":"2025-09-15","authors":"Zackory Erickson Team","category":"Manipulation","summary":"本文针对机器人操作策略在物体几何变化下鲁棒性评估不足的问题，提出了几何红队测试（GRT）框架。该方法通过基于雅可比场的变形模型与无梯度模拟器在环优化，自动生成结构有效且符合约束的“崩溃形状”（CrashShapes），以触发预训练策略的灾难性失败。实验表明，GRT在插入、关节与抓取任务中均能发现导致性能崩溃的几何变形；进一步通过“蓝队测试”对崩溃形状微调后，任务成功率可提升最高60个百分点。真实机器人验证显示，模拟生成的崩溃形状能将任务成功率从90%降至22.5%，而微调后可恢复至90%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.12026","title":"Imitation Learning as Return Distribution Matching","arxivId":"2509.12026","date":"2025-09-15","authors":"Alberto Maria Metelli Team","category":"Manipulation","summary":"（注：由于未提供论文正文，以下总结基于标题“Imitation Learning as Return Distribution Matching”及相关领域常见研究内容推断，仅作示例参考。实际总结需结合正文细节。）\n\n本文提出将模仿学习重新定义为回报分布匹配问题，旨在解决传统方法在复杂任务中因状态-动作分布匹配不准确导致的性能瓶颈。核心方法是通过对齐专家与智能体的轨迹回报分布，直接优化长期回报相似性，而非局部行为克隆。实验表明，该方法在连续控制任务中显著提升策略稳定性，在MuJoCo环境中平均回报匹配误差降低约30%，并缓解了分布漂移问题。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.12008","title":"Gesture-Based Robot Control Integrating Mm-wave Radar and Behavior Trees","arxivId":"2509.12008","date":"2025-09-15","authors":"Stephan Sigg Team","category":"Manipulation","summary":"本文提出一种基于毫米波雷达与行为树集成的机器人手势控制系统，旨在解决传统视觉方案存在的隐私顾虑、遮挡与光照敏感问题，实现可靠、非接触式的人机交互。核心方法采用毫米波雷达捕捉手势的空间数据（距离、速度、角度），并结合行为树将识别结果实时映射为机器人控制指令。实验表明，系统可精准识别9种手势，并通过案例验证了其在实时操控中的实用性与可靠性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.11865","title":"Tenma: Robust Cross-Embodiment Robot Manipulation with Diffusion Transformer","arxivId":"2509.11865","date":"2025-09-15","authors":"Luhui Hu Team","category":"Manipulation","summary":"本文旨在解决在轻量级、跨机器人硬件（跨具身）学习场景下，结合扩散模型与Transformer处理异构多模态机器人数据时面临的稳定性与性能挑战。提出的Tenma模型集成了三项关键技术：跨具身归一化器（映射不同状态/动作至共享隐空间）、联合状态-时间编码器（实现时间对齐的观测学习并加速推理）以及优化的扩散动作解码器。实验表明，在匹配计算量下，Tenma在分布内任务上取得88.95%的平均成功率，远超基线模型的18.12%，并在物体与场景变化下保持了强劲的泛化性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.11839","title":"TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning","arxivId":"2509.11839","date":"2025-09-17","authors":"Donglin Wang Team","category":"Manipulation","summary":"本文提出TrajBooster框架，旨在解决双足人形机器人在高质量演示数据稀缺时，视觉-语言-动作模型难以快速适应其动作空间的问题。其核心方法是：以末端执行器轨迹为形态无关接口，从轮式人形机器人数据中提取6D双臂轨迹，通过仿真重定向至目标双足机器人，并利用启发式增强的协调在线DAgger训练全身控制器，将低维轨迹转化为可行的高维全身动作，进而构建异质数据三元组对VLA模型进行后预训练。实验表明，仅需在目标机器人上收集10分钟遥操作数据，即可使策略完成下蹲、跨高度操作等超越桌面的复杂家务任务，显著提升了鲁棒性、泛化能力及零样本技能迁移性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.11621","title":"Inference-stage Adaptation-projection Strategy Adapts Diffusion Policy to Cross-manipulators Scenarios","arxivId":"2509.11621","date":"2025-09-15","authors":"Alois Knoll Team","category":"Manipulation","summary":"本文针对扩散策略在未经训练的机械臂上泛化性能差、适应新任务成本高的问题，提出了一种推理阶段适应-投影策略。该方法首先在SE(3)空间训练一个基础扩散策略；在线部署时，通过投影操作将策略生成的轨迹动态适配到新机械臂的物理约束（如工具中心点偏移、夹爪宽度）与任务需求（如障碍物高度），实现零样本适应。实验在多种真实机械臂（如Franka Panda, Kuka iiwa）和末端执行器上验证了该方法在抓取、推动、倾倒等任务中的有效性，取得了高成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.11481","title":"RAPTOR: A Foundation Policy for Quadrotor Control","arxivId":"2509.11481","date":"2025-09-15","authors":"Giuseppe Loianno Team","category":"Manipulation","summary":"本文提出RAPTOR方法，旨在解决现有强化学习策略过度专一化、无法适应不同四旋翼平台的问题。该方法通过元模仿学习技术，先为1000种不同四旋翼训练教师策略，再蒸馏为单一学生策略，并利用隐藏层循环实现情境学习，使策略能快速适应新平台。实验表明，仅含2084参数的轻量策略能零样本适应10种真实四旋翼（32克至2.4千克），适应过程仅需毫秒。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.11417","title":"Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations","arxivId":"2509.11417","date":"2025-09-17","authors":"Xuanlin Li Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型直接微调预训练视觉-语言模型（VLM）时破坏其表示、导致泛化能力下降的核心问题，提出三种关键技术：双编码器设计（冻结编码器保留预训练特征，可训练编码器适应任务）、基于字符串的动作分词器（将连续动作转为字符序列以对齐预训练域）和协同训练策略（结合机器人数据与强调空间推理的视觉-语言数据集）。实验在仿真和真实机器人上验证，该方法提升了模型对视觉扰动的鲁棒性、对新指令和环境的泛化能力，以及整体任务成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.11364","title":"ActivePose: Active 6D Object Pose Estimation and Tracking for Robotic Manipulation","arxivId":"2509.11364","date":"2025-09-14","authors":"Yizhao Wang Team","category":"Manipulation","summary":"本文提出ActivePise系统，以解决机器人操作中因遮挡、对称性或单视角观测导致的6D物体姿态估计歧义问题。核心技术包括：1）主动姿态估计模块，利用视觉语言模型进行实时歧义检测，并结合预计算的熵图与“机器人想象力”规划最佳下一视角以消除歧义；2）基于等变扩散策略的主动姿态跟踪模块，通过模仿学习生成相机轨迹以维持目标可见性。实验表明，该方法在仿真和真实场景中均显著优于传统基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.11225","title":"MEMBOT: Memory-Based Robot in Intermittent POMDP","arxivId":"2509.11225","date":"2025-09-14","authors":"Eyan Noronha Team","category":"Manipulation","summary":"本文针对机器人因传感器故障或遮挡导致观测间歇性缺失的核心问题，提出MEMBOT架构。其关键技术是采用两阶段训练：先通过多任务预训练学习一个由状态空间模型（SSM）和LSTM构成的鲁棒信念编码器，再通过行为克隆微调任务策略。该编码器能整合历史观测与动作，在观测丢失时维持有效的潜在状态表示。实验在10个机器人操作任务上验证，MEMBOT在观测可用性仅为50%时，性能仍能达到峰值水平的80%，显著优于无记忆及简单循环基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.11185","title":"SAMP: Spatial Anchor-based Motion Policy for Collision-Aware Robotic Manipulators","arxivId":"2509.11185","date":"2025-09-14","authors":"Jun Ma Team","category":"Manipulation","summary":"本文针对神经运动规划方法难以同时精确建模机器人本体几何与周围环境，导致在复杂场景中碰撞检测不完整的问题，提出了SAMP框架。该框架基于共享空间网格的锚点，利用有符号距离场（SDF）同时编码环境和机械臂精确几何，并训练神经运动策略生成轨迹。实验表明，SAMP在模拟和真实环境中均优于现有方法，成功率提升11%，碰撞率降低7%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.11125","title":"ManiVID-3D: Generalizable View-Invariant Reinforcement Learning for Robotic Manipulation via Disentangled 3D Representations","arxivId":"2509.11125","date":"2025-09-14","authors":"Jun Ma Team","category":"Manipulation","summary":"这篇论文解决了机器人视觉强化学习（RL）策略因摄像机视角变化而失效的核心问题。提出了ManiVID-3D框架，其关键技术是通过自监督解耦特征学习视图不变表示，并包含两个核心模块：轻量级ViewNet模块，用于无需外参标定即可将任意视角的点云对齐到统一坐标系；高效的GPU加速批量渲染模块，支持超高速训练。实验表明，该方法在10个模拟和5个真实任务中，面对视角变化时比现有最优方法的成功率高出40.6%，且参数量减少80%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.11109","title":"FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers","arxivId":"2509.11109","date":"2025-09-16","authors":"Zhigong Song Team","category":"Manipulation","summary":"FEWT论文旨在解决人形机器人在复杂环境中感知能力不足的核心问题。提出了一种频率增强的小波变换Transformer（FEWT）方法，通过结合频域分析和小波变换来优化Transformer架构，以增强特征提取和鲁棒性。具体实验结论和性能提升数据需参考正文内容，但该方法聚焦于改进感知模型的准确性和效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.10952","title":"ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation","arxivId":"2509.10952","date":"2025-09-13","authors":"Danfei Xu Team","category":"Manipulation","summary":"本文提出ImMimic方法，解决机器人从**人类视频**直接学习动作的**跨领域模仿**难题。其核心技术为**运动映射与插值框架**：先将人体姿态映射为机器人形态，再通过运动插值生成平滑可行的关节轨迹。实验表明，该方法在模拟与真实机器人任务中，仅凭**单段人类演示视频**即能成功模仿复杂动作，显著提升了模仿学习的泛化能力与数据效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.09893","title":"Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision","arxivId":"2509.09893","date":"2025-09-11","authors":"Yukiyasu Domae Team","category":"Manipulation","summary":"本文提出SART框架，旨在解决模仿学习中因需采集大量演示数据或进行不安全随机探索而导致人力负担重、效率低的问题。其核心方法是**安全自我增强**：首先仅需一次人类演示并标注关键路径点周围的**球形精度边界**；随后机器人自主在该边界内生成多样且无碰撞的轨迹进行数据增强。实验表明，该方法仅凭单次演示，其策略在多种任务中取得了比仅用人类演示数据训练**显著更高的成功率**。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.09769","title":"MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos","arxivId":"2509.09769","date":"2025-09-11","authors":"Yuke Zhu Team","category":"Manipulation","summary":"本文旨在解决人形机器人从少量人类演示视频中快速学习新操作任务的问题。针对现有情境学习方法依赖高成本遥操作数据、难以扩展的局限，提出MimicDroid框架，仅使用人类自由交互的未标注游戏视频进行训练。关键技术包括：通过提取相似操作行为的轨迹对进行条件动作预测训练；利用运动学相似性将视频估计的人体手腕姿态重定向至机器人；采用随机图像块掩蔽增强对视觉差异的鲁棒性。实验表明，该方法在仿真基准测试中优于现有方法，在真实世界中实现接近两倍的成功率提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.09674","title":"SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning","arxivId":"2509.09674","date":"2025-09-11","authors":"Ning Ding Team","category":"Manipulation","summary":"本文提出SimpleVLA-RL，旨在解决视觉-语言-动作模型面临的两大核心挑战：1）用于监督微调的大规模机器人轨迹数据稀缺且成本高昂；2）模型对存在分布偏移任务的泛化能力有限。该方法构建了一个高效的强化学习框架，基于veRL引入了VLA专用的轨迹采样、可扩展并行化、多环境渲染与优化损失计算等关键技术。实验表明，该框架在LIBERO基准上达到SOTA性能，在RoboTwin 1.0&2.0上超越基线模型，并显著减少了数据依赖，提升了泛化能力。研究还发现了一种名为“pushcut”的新动作模式涌现现象。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.09671","title":"Dexplore: Scalable Neural Control for Dexterous Manipulation from Reference-Scoped Exploration","arxivId":"2509.09671","date":"2025-09-11","authors":"Wei Yang Team","category":"Manipulation","summary":"本文提出Dexplore方法，旨在解决利用人类手部运动捕捉数据训练机器人灵巧操作策略时，因演示不精确和本体差异导致的三阶段流程误差累积与数据利用不足问题。其核心是统一的单循环优化框架，将重定向与跟踪联合进行，以演示为软参考，通过自适应空间范围约束和强化学习，直接学习控制策略。该方法能保留演示意图、涌现机器人专属策略、提升抗噪性，并可扩展至大规模演示库。最终策略被提炼为基于视觉的技能条件生成控制器，支持跨物体泛化与真实部署。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.09546","title":"A Neuromorphic Incipient Slip Detection System using Papillae Morphology","arxivId":"2509.09546","date":"2025-09-11","authors":"Benjamin Ward-Cherrier Team","category":"Manipulation","summary":"本文针对机器人操作中初始滑移检测的核心问题，旨在通过早期干预防止物体滑落，提升安全性，同时解决边缘平台部署的能量限制挑战。关键技术采用基于乳头形态皮肤的NeuroTac传感器与脉冲卷积神经网络（SCNN），通过事件数据处理和脉冲计数时间平滑实现滑移状态分类。实验表明，SCNN在三种滑移状态分类中准确率达94.33%；在动态重力诱导滑移验证中，系统能稳定提前至少360毫秒检测到初始滑移，证实了其高效响应能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.08354","title":"Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration","arxivId":"2509.08354","date":"2025-09-10","authors":"Huimin Lu Team","category":"Manipulation","summary":"本文针对机器人难以像人类一样利用触觉与动觉反馈实现可靠、灵巧抓取的问题，提出一种手套介导的触觉-运动感知预测框架。关键技术包括：使用适配人/机器手的数据手套采集关节级多模态数据；建立基于极坐标图结构的统一表征以兼容不同形态；以及提出TK-STGN网络，通过多维子图卷积与注意力LSTM层提取时空特征，并映射为力-位混合控制命令。实验表明，该方法在抓取成功率、手指协调性、接触力控制及抓取效率上均优于基线，最接近人类抓取表现，并成功泛化至不同物体与机器手。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.08226","title":"Input-gated Bilateral Teleoperation: An Easy-to-implement Force Feedback Teleoperation Method for Low-cost Hardware","arxivId":"2509.08226","date":"2025-09-10","authors":"Tetsuya Ogata Team","category":"Manipulation","summary":"本文针对低成本硬件上力反馈遥操作实现复杂、依赖力传感器的问题，提出一种易于实现的输入门控双边遥操作方法。该方法仅需一个简单的反馈控制器，无需力传感器，专为低成本主从硬件设计。实验表明，该方法参数调整极少，在实现高操作性与接触稳定性的同时，优于传统方法；即使在主从间低通信速率下，性能下降也极小，且能在两种商用低成本硬件上无需调参直接运行，展现了高易用性与鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.07962","title":"TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models","arxivId":"2509.07962","date":"2025-09-09","authors":"Hao Zhao Team","category":"Manipulation","summary":"本论文针对当前视觉-语言-动作（VLA）模型无法集成扭矩信号以感知物理交互的问题，提出扭矩感知VLA模型，系统探索扭矩集成设计空间。关键技术方法包括：将扭矩适配器引入解码器而非编码器；将扭矩历史总结为单个令牌；预测扭矩作为辅助输出以增强物理基础表示。实验在接触丰富的操作基准上验证了这些策略的有效性，表明解码器集成、历史总结和辅助预测能提升模型性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.07957","title":"Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation","arxivId":"2509.07957","date":"2025-09-09","authors":"Yingbai Hu Team","category":"Manipulation","summary":"本文针对传统模仿学习中低层轨迹复制泛化性差的问题，提出图融合视觉-语言-动作（GF-VLA）框架，用于双臂机器人从RGB-D人类演示中进行任务级推理。该方法通过信息论提取关键手-物与物-物交互线索，构建时序场景图，并融合语言条件变换器生成分层行为树与可解释运动基元，辅以跨臂分配策略。在双臂积木组装任务上的实验表明，该框架图准确率超95%，子任务分割率达93%，最终使机器人抓取可靠性达94%，放置准确率89%，整体任务成功率90%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.07953","title":"RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction","arxivId":"2509.07953","date":"2025-09-09","authors":"Aviral Kumar Team","category":"Manipulation","summary":"本文针对模仿学习在长时程机器人任务中性能瓶颈和数据效率低的问题，提出RaC方法。其核心是在预训练后引入人在环中的恢复与纠正训练新阶段：当策略执行即将失败时，人工介入，先回退机器人至熟悉状态，再提供纠正示范。训练此类数据使策略学会重试与适应行为。在真实世界悬挂衬衫、密封容器、打包餐盒及模拟装配任务上，RaC仅用十分之一的数据量和时间即超越此前最优方法，且策略性能与恢复操作次数呈线性增长。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.07445","title":"Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions","arxivId":"2509.07445","date":"2025-09-09","authors":"Nathan F. Lepora Team","category":"Manipulation","summary":"本文提出Text2Touch，解决在触觉灵巧操作中自动化设计强化学习奖励函数的难题。方法核心是利用大语言模型自动生成奖励函数，结合基于视觉的触觉传感信息，并通过仿真到现实的策略迁移，在真实四指灵巧手上实现多轴手内物体旋转。实验表明，该方法在旋转速度与抓取稳定性上显著优于人工精心设计的基准，且生成的奖励函数长度与复杂度降低了一个数量级。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.06953","title":"Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments","arxivId":"2509.06953","date":"2025-09-08","authors":"Deepak Pathak Team","category":"Manipulation","summary":"本文提出Deep Reactive Policy (DRP)，旨在解决机械臂在动态、部分可观测环境中实时生成无碰撞运动规划的挑战。其核心技术包括：基于Transformer的神经运动策略IMPACT，利用千万级仿真专家轨迹预训练；通过迭代师生微调增强静态避障；在推理时结合局部反应式目标提议模块DCP-RMP以提升动态避障能力。实验表明，DRP在杂乱和动态场景中泛化能力强，其成功率在仿真与真实世界任务上均优于先前的经典规划方法与神经策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.06932","title":"LLaDA-VLA: Vision Language Diffusion Action Models","arxivId":"2509.06932","date":"2025-09-10","authors":"Xiaoyan Sun Team","category":"Manipulation","summary":"本文提出首个基于预训练扩散视觉语言模型（d-VLM）的机器人操作模型LLaDA-VLA，旨在解决将d-VLM适配到机器人领域的两大挑战：视觉语义的领域差距与动作序列的结构化生成难题。关键技术包括：1）局部特殊令牌分类策略，用特定动作令牌分类替代全词汇分类以降低适配难度；2）分层动作结构化解码策略，在解码时考虑动作内外的依赖关系。实验表明，该模型在仿真和真实机器人任务上均显著优于当前最先进的视觉语言动作模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.06233","title":"O $^3$ Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation","arxivId":"2509.06233","date":"2025-09-07","authors":"Yen-Ling Kuo Team","category":"Manipulation","summary":"本文提出O³Afford方法，解决机器人操作中物体间功能关系（affordance）的定位问题，核心挑战在于标注数据稀缺。方法采用单样本学习框架，结合视觉基础模型的语义特征与点云几何表征，实现对未见物体和类别的有效泛化，并集成大语言模型增强对物体交互的任务推理能力。实验表明，该方法在3D物体间功能关系定位与机器人操作任务上，准确性与泛化能力显著优于现有基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.06048","title":"Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness","arxivId":"2509.06048","date":"2025-09-07","authors":"Zhendong Dai Team","category":"Manipulation","summary":"本文针对鞋类打包任务中因尺寸、形状和软度差异导致的初始状态多样、无法直接抓取放置的问题，提出基于语义关键点的机器人操作框架。关键技术包括：语义关键点感知模块，通过几何特征推断鞋的状态、姿态和操作点；针对不同状态设计基元重新定向方法，并利用盒边接触和重力实现快速重新定向；基于此的打包规划器提供最优打包策略。真实实验验证了重新定向方法的鲁棒性和打包策略对各种鞋型的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.05547","title":"TeleopLab: Accessible and Intuitive Teleoperation of a Robotic Manipulator for Remote Labs","arxivId":"2509.05547","date":"2025-09-06","authors":"John Liu Team","category":"Manipulation","summary":"本文针对远程教育中实践操作体验缺失的问题，提出TeleopLab系统，旨在通过直观的遥操作技术让学生远程操控真实实验设备。该系统整合了机械臂、自适应夹爪、摄像头及智能手机界面，用户通过手机移动提供路径点来控制远端机械臂完成操作。用户研究表明，随着使用熟练度提升，任务完成时间平均减少46.1%；系统工作负荷评估为38.2（NASA TLX），可用性得分达73.8（SUS），证实了其有效性与良好的用户体验。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.05513","title":"OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation","arxivId":"2509.05513","date":"2025-09-05","authors":"Yu Xiang Team","category":"Manipulation","summary":"本文针对现有自我中心视角（egocentric）视频数据集缺乏精细手部标注与动作描述的问题，提出了大规模多模态数据集OpenEgo。该数据集整合了六个公共数据集，总计1107小时视频，涵盖290个操作任务和600多个环境，关键技术包括统一21关节手部姿态标注和带有时间戳的意图对齐动作原语。为验证其有效性，作者训练了语言条件模仿学习策略来预测灵巧的3D手部轨迹。OpenEgo旨在降低从自我中心视频学习灵巧操作的壁垒，并支持视觉-语言-动作学习的可复现研究。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.05368","title":"Long-Horizon Visual Imitation Learning via Plan and Code Reflection","arxivId":"2509.05368","date":"2025-09-04","authors":"Yunde Jia Team","category":"Manipulation","summary":"本文针对长时程视觉模仿学习中复杂动作序列的时空依赖理解难题，提出一种结合计划与代码生成并配备双重反射模块的新框架。关键技术包括：计划生成模块产生初始动作序列，计划反射模块验证其时间连贯性与空间对齐；代码生成模块将计划转为可执行代码，代码反射模块验证并优化代码正确性。实验基于包含300个长步骤演示的LongVILBench基准测试，表明现有方法性能较差，而本框架为该任务建立了强基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.04737","title":"Imitation Learning Based on Disentangled Representation Learning of Behavioral Characteristics","arxivId":"2509.04737","date":"2025-09-05","authors":"Toshiaki Tsuji Team","category":"Manipulation","summary":"本文针对机器人模仿学习中，难以根据人类定性指令（如“用力擦”）在线调整连续运动参数的问题，提出一种基于解耦表征学习的运动生成模型。该方法将演示数据分割为短序列，并为特定修饰符类型分配弱监督标签，从而学习从修饰符指令到动作的映射。在擦拭和抓放任务上的实验表明，该方法能够在线响应指令调整动作，而传统的批量处理方法无法在执行过程中适应。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.04658","title":"Surformer v2: A Multimodal Classifier for Surface Understanding from Touch and Vision","arxivId":"2509.04658","date":"2025-09-04","authors":"Noorbakhsh Amiri Golilarz Team","category":"Manipulation","summary":"本文提出Surformer v2模型，旨在解决机器人感知中如何有效融合视觉与触觉信息以实现表面材料分类的核心问题。关键技术采用决策级晚期融合机制：视觉分支使用CNN分类器（Efficient V-Net），触觉分支采用编码器-仅Transformer模型，通过可学习的加权求和融合两模态的输出logits。实验在Touch and Go多模态数据集上进行，结果表明模型性能良好，并保持了有竞争力的推理速度，适用于实时机器人应用。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.04645","title":"Planning from Point Clouds over Continuous Actions for Multi-object Rearrangement","arxivId":"2509.04645","date":"2025-09-04","authors":"David Held Team","category":"Manipulation","summary":"本文针对机器人长时程操作中的多物体重排任务，提出了一种基于点云和连续动作的规划方法SPOT。核心解决传统符号规划需离散化状态与动作空间的限制。SPOT采用混合学习与搜索规划，直接在点云空间通过A*搜索物体在SE(3)空间的变换序列，利用学习到的建议模型从部分观测点云采样连续动作。实验表明，SPOT在模拟和真实环境中均能生成成功规划，其规划性能优于策略学习方法，并通过消融实验验证了搜索规划的关键作用。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.04535","title":"In-Context Policy Adaptation via Cross-Domain Skill Diffusion","arxivId":"2509.04535","date":"2025-09-04","authors":"Honguk Woo Team","category":"Manipulation","summary":"本文针对长视野多任务环境中强化学习策略跨域适应的挑战，特别是在无模型更新且目标域数据有限的严格约束下，提出ICPAD框架。该框架采用跨域技能扩散技术，学习领域无关的原型技能作为策略通用表示，并结合动态域提示的技能适配器实现快速对齐。实验在Metaworld机器人操作和CARLA自动驾驶场景中进行，结果表明ICPAD在环境动态、代理体现等跨域配置下，仅凭有限目标数据即实现了优越的策略适应性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.04443","title":"EMMA: Scaling Mobile Manipulation via Egocentric Human Data","arxivId":"2509.04443","date":"2025-09-04","authors":"Danfei Xu Team","category":"Manipulation","summary":"本文针对移动操作模仿学习依赖昂贵机器人遥操作数据的问题，提出EMMA框架。其核心方法是利用易于采集的人类第一视角移动操作数据与静态机器人数据协同训练，避免移动遥操作。在四个真实任务实验中，EMMA达到了与基于遥操作数据训练的Mobile ALOHA基线相当或更高的完整任务成功率，并能泛化到新场景，且性能随人类数据量增加而提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.04063","title":"Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models","arxivId":"2509.04063","date":"2025-09-04","authors":"Donglin Wang Team","category":"Manipulation","summary":"本文针对基于流匹配的视觉-语言-动作模型在复杂下游任务中动作精度不足的问题，指出仅依赖模仿学习后训练难以深入利用数据质量分布。为此，提出一种自适应离线强化学习后训练方法——自适应强化流匹配。该方法通过在流模型损失中引入自适应缩放因子，构建偏差-方差权衡目标函数，以最优控制强化学习信号对损失的影响，从而平衡优势保持与梯度方差控制。实验表明，该方法在仿真与真实场景中均表现出优异的泛化、鲁棒、少样本学习及持续学习性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.04018","title":"FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction","arxivId":"2509.04018","date":"2025-09-04","authors":"Jingtai Liu Team","category":"Manipulation","summary":"本文提出FPC-VLA框架，旨在解决机器人操作中单端到端视觉-语言-动作模型缺乏失败预测与恢复机制的问题。核心技术包括：一个基于视觉语言模型的监督器，通过结构化查询评估动作并生成语言纠正；一个从现有数据自动生成失败数据集的流程；以及一个使用余弦相似度和时间衰减的双流动作融合模块，用于平滑动作。实验表明，FPC-VLA在多个仿真平台与机器人实体上优于现有方法，并在真实机器人上成功部署，验证了其泛化能力与实用性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.03859","title":"Learning Multi-Stage Pick-and-Place with a Legged Mobile Manipulator","arxivId":"2509.03859","date":"2025-09-05","authors":"Wei Xu Team","category":"Manipulation","summary":"本文针对腿式移动机械手在执行长序列、多技能任务时面临的挑战，提出了一套完整的解决方案。核心是SLIM系统，其关键技术包括：完全在模拟中训练的视觉运动策略、用于长任务序列学习的渐进式策略扩展，以及高效的模拟到现实迁移。该系统成功实现了包含搜寻、接近、抓取、运输和放置的多阶段拾放任务，在真实世界的广泛测试中取得了接近80%的成功率，并展现出良好的场景泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.03222","title":"The Role of Embodiment in Intuitive Whole-Body Teleoperation for Mobile Manipulation","arxivId":"2509.03222","date":"2025-09-03","authors":"Georgia Chalvatzaki Team","category":"Manipulation","summary":"本文的核心问题是探究具身化（Embodiment）在移动操作机器人（Mobile Manipulator）的直观全身遥操作（Intuitive Whole-Body Teleoperation）中所扮演的角色，旨在理解并可能提升操作员与机器人的直观交互体验。\n\n由于您提供的正文内容主要为作者信息、资助声明和参考文献列表，并未包含论文具体的技术方法、实验设计或结果数据，因此无法从给定文本中提炼具体的技术方法要点，也无法给出任何核心实验结论或性能提升数据。\n\n总结需基于论文实质内容，建议提供包含方法、实验或结论的正文部分以获得精准总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.03206","title":"Autonomous Learning From Success and Failure: Goal-Conditioned Supervised Learning with Negative Feedback","arxivId":"2509.03206","date":"2025-09-03","authors":"Daniel A. Braun Team","category":"Manipulation","summary":"本文针对目标条件监督学习（GCSL）在稀疏奖励任务中的局限：仅从自我成功经验学习会加剧代理偏见，且无法从失败中学习。提出一种新模型，将对比学习原理集成到GCSL框架，使代理能从成功和失败中同时学习。实验表明，该算法克服了初始偏见限制，促进了更多探索行为，从而识别并采用有效策略，在多种挑战性环境中实现了性能提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.02876","title":"Generalizable Skill Learning for Construction Robots with Crowdsourced Natural Language Instructions, Composable Skills Standardization, and Large Language Model","arxivId":"2509.02876","date":"2025-09-02","authors":"Carol C. Menassa Team","category":"Manipulation","summary":"您提供了论文标题，但未提供论文正文内容。根据标题《Generalizable Skill Learning for Construction Robots with Crowdsourced Natural Language Instructions, Composable Skills Standardization, and Large Language Model》，我可以推测其核心方向，但无法为您撰写符合所有要求的精准总结。\n\n**推测性分析（非正式总结）：**\n该论文可能旨在解决建筑机器人技能学习**泛化能力差、依赖专家编程**的核心问题。其关键技术方法可能包括：利用**众包自然语言指令**收集多样化任务描述；建立**可组合技能标准化**框架，将复杂任务分解为标准化基础技能模块；并借助**大语言模型**理解指令、进行任务规划和技能组合。其核心目标可能是实现机器人仅通过自然语言指令，就能自主组合已有技能完成新任务，从而提升**适应性和开发效率**。\n\n**请您提供论文的正文内容**，我将严格根据您的要求，为您生成一段100-160字的精准、简洁的总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.02761","title":"Plan Verification for LLM-Based Embodied Task Completion Agents","arxivId":"2509.02761","date":"2025-09-04","authors":"Gokhan Tur Team","category":"Manipulation","summary":"本文针对基于大语言模型（LLM）的具身任务完成代理，其生成的任务计划与人类演示常包含冗余动作、逻辑错误等噪声的问题，提出了一种迭代验证框架。该框架利用一个“评判”LLM对动作序列进行批判，再由一个“规划”LLM应用修订，通过自然语言提示迭代优化轨迹，能广泛处理无关动作、矛盾等错误类型。在TEACh数据集上的实验表明，该方法在四种先进LLM上实现了高达90%的召回率和100%的精确度，96.5%的序列在最多三次迭代内收敛，有效提升了动作序列的时空效率与组织性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.02530","title":"Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots","arxivId":"2509.02530","date":"2025-09-02","authors":"Bingyi Kang Team","category":"Manipulation","summary":"本文旨在解决机器人操作中因依赖2D视觉导致的泛化能力差，以及深度相机噪声大、精度低的问题。提出了相机深度模型（CDMs）作为插件，结合RGB图像与原始深度信号，输出去噪后的精确度量深度。关键技术是开发了神经数据引擎，通过模拟深度相机噪声模式生成高质量仿真配对数据。实验表明，CDMs实现了接近仿真级别的深度预测精度，有效弥合了仿真到现实的差距。仅使用原始仿真深度训练的策略，无需添加噪声或真实世界微调，即可在涉及铰接、反光、细长物体的复杂长时程任务中无缝迁移至真实机器人，且性能几乎无下降。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.02437","title":"U-ARM : Ultra low-cost general teleoperation interface for robot manipulation","arxivId":"2509.02437","date":"2025-09-02","authors":"Bo Zhao Team","category":"Manipulation","summary":"本文提出U-Arm，旨在解决为机器人操作收集大规模真实数据时，现有遥操作接口成本高昂、适配性差的核心问题。其关键技术是设计了三款结构不同但控制逻辑一致的3D打印领导臂，通过优化机械与伺服选择，将6-DoF和7-DoF版本的材料成本分别降至50.5美元和56.8美元，并优化了冗余自由度控制。实验表明，与另一低成本接口Joycon相比，U-Arm在多种操作场景中实现了更高的数据收集效率和相当的任务成功率。所有CAD模型与仿真支持均已开源。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.02055","title":"Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance","arxivId":"2509.02055","date":"2025-09-05","authors":"Xuelong Li Team","category":"Manipulation","summary":"本文针对预训练视觉-语言-动作模型在下游任务适配时，因机器人形态或任务差异导致动作分布失配、需大量微调数据的问题，提出Align-Then-stEer框架。其核心方法包括：通过基于反向KL散度的变分自编码器将不同动作空间对齐到统一潜在空间；随后在微调中通过引导机制，将模型输出分布推向目标领域。实验表明，相比直接微调，该方法在仿真中平均多任务成功率最高提升9.8%，在真实世界跨形态任务中成功率显著提升32%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.01819","title":"ManiFlow: A General Robot Manipulation Policy via Consistency Flow Training","arxivId":"2509.01819","date":"2025-09-01","authors":"Dieter Fox Team","category":"Manipulation","summary":"本文提出ManiFlow，旨在解决现有流匹配策略在执行复杂灵巧操作任务时效率、鲁棒性和泛化性不足的问题。其关键技术包括：1）将一致性训练目标融入流匹配损失，以“拉直”流路径，实现1-2步快速推理；2）提出DiT-X架构，通过自适应交叉注意力和AdaLN-Zero调节实现多模态观测与动作令牌的细粒度交互。实验表明，ManiFlow在多样化仿真基准中性能持续提升，在单臂、双臂及人形机器人真实任务上成功率近乎翻倍，并对新物体和背景变化表现出强鲁棒性与泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.01765","title":"Non-conflicting Energy Minimization in Reinforcement Learning based Robot Control","arxivId":"2509.01765","date":"2025-09-01","authors":"Stefan Lee Team","category":"Manipulation","summary":"这篇论文解决了强化学习训练机器人控制策略时，能量最小化目标与任务性能目标易发生冲突的问题。提出了一种名为PEGrad的无超参数梯度优化方法，其核心是通过在任务目标和能量目标之间进行策略梯度投影，推导出能最小化能耗且不影响任务性能的策略更新。实验表明，该方法在DM-Control和HumanoidBench基准测试中，能在保持任务性能的同时将能量消耗降低64%，并成功实现了从仿真到真实四足机器人的策略迁移。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.01746","title":"Fail2Progress: Learning from Real-World Robot Failures with Stein Variational Inference","arxivId":"2509.01746","date":"2025-09-01","authors":"Tucker Hermans Team","category":"Manipulation","summary":"本文针对机器人技能模型在训练数据未覆盖的真实场景中易失败的问题，提出Fail2Progress方法。该方法基于Stein变分推断，通过并行生成多个模拟环境，高效产生与失败类似的数据样本，用于微调技能效应模型。实验在运输多物体、组织受限架子等挑战性任务中进行，结果表明该方法能有效从不同数量物体的失败中学习恢复，并优于多个基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.01657","title":"Data Retrieval with Importance Weights for Few-Shot Imitation Learning","arxivId":"2509.01657","date":"2025-09-01","authors":"Joey Hejna Team","category":"Manipulation","summary":"本文针对少样本模仿学习中基于检索的方法存在的两个问题：依赖高方差的最近邻距离估计易受噪声影响，且忽略先验数据分布。提出重要性加权检索（IWR）方法，通过高斯核密度估计计算目标与先验数据分布的重要性权重，以平滑估计并减少偏差。在模拟环境和真实Bridge数据集上的评估表明，该方法仅需微小修改即可一致提升现有检索方法的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.01297","title":"Disentangled Multi-Context Meta-Learning: Unlocking robust and Generalized Task Learning","arxivId":"2509.01297","date":"2025-09-01","authors":"Seongil Hong Team","category":"Manipulation","summary":"本文针对元学习中任务因素混合在单一纠缠表示中，导致模型难以解释且泛化受限的核心问题，提出**解耦多上下文元学习（DMCM）框架**。其关键技术是为每个任务因素（如正弦函数的振幅与相位、机器人特性与地形特征）分配独立的上下文向量，实现因素解耦与上下文共享。实验表明，该方法在正弦回归分布外任务上优于基线，并在四足机器人运动任务中显著提升了分布外条件下的鲁棒性，仅用20秒平坦地形真实数据即成功迁移至具有分布外机器人特性的复杂地形。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2509.00574","title":"Learning Dolly-In Filming From Demonstration Using a Ground-Based Robot","arxivId":"2509.00574","date":"2025-08-30","authors":"Wenbin Li Team","category":"Manipulation","summary":"本文针对电影拍摄中相机控制的艺术性与精确性平衡难题，提出了一种基于演示学习的自动化解决方案，以替代依赖手工设计奖励函数的强化学习。该方法利用生成对抗模仿学习，通过专家遥操作收集的轨迹进行训练，无需设计明确的奖励。实验表明，该GAIL策略在模拟中优于PPO基线，获得了更高奖励、更快收敛和更低方差，并能直接零次迁移到真实地面机器人，实现了比先前TD3方法更一致的取景和主体对齐。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.21677","title":"Robust Convex Model Predictive Control with collision avoidance guarantees for robot manipulators","arxivId":"2508.21677","date":"2025-08-29","authors":"Thomas B. Schön Team","category":"Manipulation","summary":"本文针对工业机器人在模型不确定的杂乱环境中，如何实现快速且安全的运动规划这一核心问题，提出了一种鲁棒凸模型预测控制（MPC）方法。关键技术包括：1）基于反馈线性化和模型误差上界的鲁棒管MPC，以优化控制保守性；2）利用有符号配置距离函数（SCDF）生成构型空间中的无碰撞区域，从而构建凸的避障约束。在6自由度工业机器人的仿真实验中，该方法在更高模型不确定性水平下优于基准方法，并实现了更快的运动速度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.21592","title":"Learning Agile Gate Traversal via Analytical Optimal Policy Gradient","arxivId":"2508.21592","date":"2025-08-29","authors":"Lin Zhao Team","category":"Manipulation","summary":"本文针对四旋翼无人机敏捷穿越狭窄门框的精确控制问题，提出了一种混合框架以克服传统方法参数调优复杂、端到端强化学习样本效率低的问题。核心方法结合了模型预测控制（MPC）与神经网络（NN）：NN离线训练，在线自适应提供参考位姿和MPC代价函数权重；通过推导MPC与门穿越检测模块的解析策略梯度实现高效训练。硬件实验表明，该方法在受限环境中实现了快速、准确的门穿越，相比纯端到端强化学习，样本效率提升了数个数量级。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.21501","title":"Few-Shot Neuro-Symbolic Imitation Learning for Long-Horizon Planning and Acting","arxivId":"2508.21501","date":"2025-08-29","authors":"Matthias Scheutz Team","category":"Manipulation","summary":"本文针对模仿学习在长期任务中数据需求大、泛化能力差的核心问题，提出一种少样本神经符号框架。该方法通过图构建抽象高级任务结构，利用答案集编程（ASP）求解器自动发现符号规则，并采用扩散策略模仿学习训练低级控制器，辅以高级预言机过滤任务信息以聚焦观测空间。在多个机器人领域实验表明，仅需五个技能演示即可实现高数据效率，具备强大的零样本和少样本泛化能力，且决策过程可解释。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.21378","title":"RoboInspector: Unveiling the Unreliability of Policy Code for LLM-enabled Robotic Manipulation","arxivId":"2508.21378","date":"2025-08-29","authors":"Yuanchao Shu Team","category":"Manipulation","summary":"本文提出RoboInspector框架，旨在揭示大语言模型生成的机器人操作策略代码中存在的不可靠性问题。通过设计系统化的代码检测方法，该框架能够识别策略代码在逻辑一致性、安全边界及任务适应性方面的潜在缺陷。实验表明，在典型操作任务中，未经检测的LLM生成策略代码错误率显著，而经RoboInspector筛查后可有效提升代码可靠性与任务执行成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.21375","title":"Dynamics-Compliant Trajectory Diffusion for Super-Nominal Payload Manipulation","arxivId":"2508.21375","date":"2025-08-29","authors":"Alessandro Roncone Team","category":"Manipulation","summary":"本文针对工业机器人额定负载保守设定导致其实际能力被严重低估的问题，提出了一种动态合规的轨迹扩散方法。该方法利用去噪扩散模型，将负载约束显式纳入规划过程，直接在关节角度、速度和加速度空间生成动态可行的轨迹，无需后处理即可执行。在7自由度Franka Emika Panda机器人上的实验表明，即使负载超过额定值3倍，仍有高达67.6%的工作空间可安全访问。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.21272","title":"Learning to Assemble the Soma Cube with Legal-Action Masked DQN and Safe ZYZ Regrasp on a Doosan M0609","arxivId":"2508.21272","date":"2025-08-29","authors":"Sawoong Kim Team","category":"Manipulation","summary":"本文针对6自由度协作机器人自主组装Soma立方体的任务，解决了组合动作空间爆炸、不安全运动规划和系统化策略学习三大挑战。核心方法结合了合法动作掩码DQN（通过分层架构分解Q函数估计以降低复杂度）与安全的ZYZ重抓取策略（通过智能序列避免万向节锁）。实验表明，该方法在课程学习的三个难度级别上分别达到100%、92.9%和39.9%的成功率，并将运动规划成功率从54%提升至96%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.21065","title":"Learning on the Fly: Rapid Policy Adaptation via Differentiable Simulation","arxivId":"2508.21065","date":"2025-08-28","authors":"Davide Scaramuzza Team","category":"Manipulation","summary":"本文针对模拟到现实迁移中的动力学差异问题，提出了一种基于可微分模拟的在线自适应学习框架。该方法通过残差动力学学习实时捕获未建模干扰（如载荷变化、风扰），并在可微分模拟中利用梯度反向传播快速更新策略，实现秒级在线适应。实验表明，在四旋翼抗干扰控制中，该方法相比ℒ₁-MPC和DATT分别降低悬停误差达81%和55%，且无需显式状态估计即可实现鲁棒的视觉控制。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.20982","title":"UltraTac: Integrated Ultrasound-Augmented Visuotactile Sensor for Enhanced Robotic Perception","arxivId":"2508.20982","date":"2025-08-29","authors":"Wenbo Ding Team","category":"Manipulation","summary":"本文提出UltraTac集成传感器，旨在解决现有视觉触觉传感器无法感知物体材料特性的问题。其关键技术采用同轴光声架构，将视觉触觉成像与超声波传感融合，共享结构组件并实现传感区域一致，且在传统结构中融入声学匹配，确保超声传感不损害触觉性能。核心实验表明，该传感器具备三项能力：在3–8 cm范围内实现接近感知（R² = 0.99）、材料分类平均准确率达99.20%，以及纹理-材料双模式物体识别在15类任务上达到92.11%的准确率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.20840","title":"Learning Primitive Embodied World Models: Towards Scalable Robotic Learning","arxivId":"2508.20840","date":"2025-08-28","authors":"Qinying Gu Team","category":"Manipulation","summary":"本文针对基于视频生成的具身世界模型严重依赖大规模交互数据、难以实现细粒度语言-动作对齐的问题，提出**原始具身世界模型（PEWM）**。该方法将视频生成限制在较短的固定时间范围内，并引入**模块化视觉语言模型（VLM）规划器**和**起止目标热图引导（SGG）机制**。其核心优势在于实现了细粒度的语言-视觉动作对齐，显著降低了学习复杂性和推理延迟，同时提高了数据收集效率，从而支持对复杂长时任务的组合泛化。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.20561","title":"SimShear: Sim-to-Real Shear-based Tactile Servoing","arxivId":"2508.20561","date":"2025-08-28","authors":"Nathan F. Lepora Team","category":"Manipulation","summary":"本文提出SimShear，旨在解决触觉仿真到现实迁移中难以建模剪切变形的问题。核心方法是shPix2pix，一种基于U-Net GAN的剪切条件图像转换网络，可将无剪切的仿真触觉图像与剪切编码向量结合，生成包含真实剪切变形的触觉图像。实验在双机械臂触觉跟踪与协同搬运任务中验证，该方法能将接触误差控制在1–2毫米内，显著优于基准方法，证明了利用刚体仿真器实现含剪切触觉建模的可行性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.20085","title":"HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation","arxivId":"2508.20085","date":"2025-08-31","authors":"Huazhe Xu Team","category":"Manipulation","summary":"本文提出HERMES框架，旨在解决将多源人类手部运动数据转化为配备灵巧手的移动机器人可行行为这一核心挑战。关键技术包括：1）统一的强化学习方法，将异构人手运动转化为物理合理的机器人动作；2）基于深度图像的端到端sim2real迁移方法，以提升泛化能力；3）结合闭环PnP定位的导航基础模型，实现自主导航与灵巧操作的衔接。实验表明，该框架能在多样化的真实场景中成功执行复杂的移动双手灵巧操作任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.19958","title":"Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation","arxivId":"2508.19958","date":"2025-08-28","authors":"Donglin Wang Team","category":"Manipulation","summary":"本论文Long-VLA针对视觉语言动作模型在机器人操作中处理长时程任务时能力受限的核心问题，提出Long-VLA模型以释放其长时程规划潜力。关键技术通过增强模型对复杂、多步骤任务的视觉语言理解和动作生成能力，提升机器人操作的适应性和效率。然而，由于未提供正文内容，具体方法细节和实验性能数据（如准确率或任务完成度提升）无法在此总结中给出，需查阅原论文获取完整信息。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.19852","title":"Ego-centric Predictive Model Conditioned on Hand Trajectories","arxivId":"2508.19852","date":"2025-08-28","authors":"Mike Zheng Shou Team","category":"Manipulation","summary":"本文旨在解决自我中心视角下，动作预测与视觉结果生成割裂的问题。提出一个以手部轨迹为条件的统一两阶段预测框架Ego-PM。关键技术包括：第一阶段通过连续状态建模处理视觉、语言和动作历史，以预测未来手部轨迹；第二阶段引入因果交叉注意力融合多模态线索，并利用预测的动作信号指导潜在扩散模型进行逐帧视频生成。实验表明，该方法在Ego4D、BridgeData和RLBench数据集上，于动作预测和未来视频合成任务中均优于现有基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.19607","title":"Impedance Primitive-augmented Hierarchical Reinforcement Learning for Sequential Tasks","arxivId":"2508.19607","date":"2025-08-27","authors":"Jens Kober Team","category":"Manipulation","summary":"本文提出了一种阻抗基元增强的分层强化学习框架，用于解决机器人连续接触任务中的长时程操作问题。核心方法结合了三个关键技术：支持可变刚度控制的动作空间、原始执行中的自适应刚度控制器，以及促进顺应性与高效探索的affordance耦合。通过在方块抓取、开门、推物和表面清洁等任务上的训练与评估，该框架在学习效率、基元组合性和任务成功率方面均优于现有方法，并验证了其仿真到现实的迁移能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.19476","title":"Gentle Object Retraction in Dense Clutter Using Multimodal Force Sensing and Imitation Learning","arxivId":"2508.19476","date":"2025-08-26","authors":"Mark Cutkosky Team","category":"Manipulation","summary":"本文研究机器人如何在密集杂乱环境中安全取回物体而不造成损坏。核心方法是结合多模态感知（手眼视觉、本体感知、触觉、关节力矩估计的接触力矩、吸盘真空监测）与模仿学习，训练机器人策略以在必要接触时控制力度。实验表明，引入力感知能显著减少过度施力失败、提高成功率和速度；同时使用触觉与力矩信息时性能最佳，相比无力感知基线提升80%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.19391","title":"LaVA-Man: Learning Visual Action Representations for Robot Manipulation","arxivId":"2508.19391","date":"2025-08-26","authors":"Changjae Oh Team","category":"Manipulation","summary":"本文针对语言引导机器人操作中视觉-文本关联学习不精确的问题，提出LaVA-Man方法。该方法通过自监督前置任务：在输入图像和文本指令条件下重建掩码目标图像，学习视觉动作表示，无需机器人动作监督，并可通过少量演示微调。引入Omni-Object Pick-and-Place数据集（含180个对象类和3,200个实例）以提升泛化能力。实验在五个基准测试（包括模拟和真实机器人验证）中表明，该方法优于先前技术。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.19367","title":"Inference of Human-derived Specifications of Object Placement via Demonstration","arxivId":"2508.19367","date":"2025-08-26","authors":"Julie A Shah Team","category":"Manipulation","summary":"本文研究机器人如何理解人类对物体排列的空间关系偏好。针对现有方法表达能力有限的问题，提出了**位置增强区域连接演算（PARCC）** 这一形式化逻辑框架，用于描述物体间的相对位置关系，并设计了相应的**推断算法**，能够从演示中学习PARCC规范。通过人类研究验证，该方法能够有效捕捉人类的意图规范，且**基于演示学习的方法优于直接使用人类提供的规范**。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.19236","title":"MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation","arxivId":"2508.19236","date":"2025-08-26","authors":"Gao Huang Team","category":"Manipulation","summary":"本文针对机器人操作中VLA模型忽略时间上下文、难以处理长时程依赖任务的问题，提出MemoryVLA框架。其核心是受人类记忆机制启发的感知-认知记忆系统：工作记忆缓冲当前感知与认知token，记忆库存储并整合历史细节与语义；通过检索与融合相关记忆条目，驱动记忆条件扩散动作专家生成时序感知的动作序列。实验表明，在仿真与真实世界的150多项任务中，MemoryVLA均优于先进基线，如在Bridge任务上成功率提升14.6%，在长时程真实任务上较基线提升26分。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.19204","title":"LSD-3D: Large-Scale 3D Driving Scene Generation with Geometry Grounding","arxivId":"2508.19204","date":"2025-08-26","authors":"Felix Heide Team","category":"Manipulation","summary":"本文提出LSD-3D方法，旨在解决大规模3D驾驶场景生成中几何一致性与可控性的平衡问题。现有神经重建方法缺乏场景多样性，而视频扩散模型则缺失几何基础。LSD-3D通过结合代理几何生成、环境表示与2D图像先验的分数蒸馏技术，实现了基于地图布局提示的、几何精确的大规模3D场景生成。该方法支持因果性新视角合成与显式3D几何估计，能够生成逼真且几何一致的高可控性复杂驾驶场景。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.19172","title":"From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity","arxivId":"2508.19172","date":"2025-08-28","authors":"Antoine Cully Team","category":"Manipulation","summary":"本文针对机器人在无明确监督下自主发现多样化技能的核心问题，提出URSA（无监督现实世界技能获取）方法。该方法扩展了质量多样性演员-评论家框架，支持启发式驱动和完全无监督两种设置，使机器人能在现实环境中自主探索并掌握高性能技能。实验表明，URSA在Unitree A1四足机器人上成功发现了多样化的运动技能，并在损伤适应任务中表现优异：在9个模拟损伤场景中5项超越基线，5个现实损伤场景中3项领先。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.18802","title":"HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation","arxivId":"2508.18802","date":"2025-08-26","authors":"Yanchao Yang Team","category":"Manipulation","summary":"本文针对机器人操作策略学习中场景表征提取与任务目标脱节的问题，提出HyperTASR框架。该方法利用超网络，根据任务描述和执行阶段动态生成表征转换参数，使场景表征能随任务上下文演化，从而选择性地聚焦任务相关特征。实验表明，该方法在仿真和真实环境中均取得了显著的性能提升，并通过注意力可视化证实其能有效模仿人类在操作任务中的自适应感知。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.18691","title":"Deep Sensorimotor Control by Imitating Predictive Models of Human Motion","arxivId":"2508.18691","date":"2025-08-26","authors":"Antonio Loquercio Team","category":"Manipulation","summary":"本文提出了一种通过模仿人类运动预测模型来训练机器人感觉运动策略的新方法。核心问题是解决如何有效利用大规模人类-场景交互数据集来训练机器人策略，避免传统方法中基于梯度的运动重定向和对抗性损失的局限性。关键技术是直接利用人类关键点运动数据训练预测模型，并零样本应用于机器人关键点；随后训练策略跟踪该模型的预测轨迹，同时优化稀疏的任务奖励。实验表明，该方法在多种机器人和任务上均大幅超越现有基线，并且能够替代传统方法中需要精心设计的密集奖励和课程。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.18627","title":"Integration of Robot and Scene Kinematics for Sequential Mobile Manipulation Planning","arxivId":"2508.18627","date":"2025-08-26","authors":"Song-Chun Zhu Team","category":"Manipulation","summary":"本文针对长时域多步骤移动操作任务中，机器人与场景（尤其是铰接物体）的协调运动规划难题，提出了顺序移动操作规划（SMMP）框架。其核心方法是将场景结构抽象为运动学模型，并与机器人运动学集成，构建统一的增强配置空间（A-Space），进而采用任务规划、运动优化与计划细化的三层框架进行求解。实验表明，在A-Space中规划的任务成功率比基线方法提升84.6%，并在真实机器人上成功完成了涉及7类物体、最多14个顺序步骤的复杂操作任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.18443","title":"PneuGelSight: Soft Robotic Vision-Based Proprioception and Tactile Sensing","arxivId":"2508.18443","date":"2025-08-25","authors":"Wenzhen Yuan Team","category":"Manipulation","summary":"本文提出PneuGelSight，旨在解决软体气动机器人缺乏高分辨率本体感知与触觉反馈的关键问题。核心技术是一种基于视觉的集成传感器：通过在柔性手指内部嵌入摄像头、可变形硅胶层及反射面，利用接触变形引起的光图案变化来同时感知本体形状与接触几何。方法要点包括构建精确模拟光学与动态特性的仿真管道，以及采用双分支网络从图像中提取轮廓与颜色特征，实现从仿真到现实的零样本知识迁移。该方案为软体机器人提供了一种易于实现且鲁棒的感知方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.18399","title":"Maintenance automation: methods for robotics manipulation planning and execution","arxivId":"2508.18399","date":"2025-08-25","authors":"Alexander Verl Team","category":"Manipulation","summary":"本文针对维护任务自动化中机器人操作规划与执行的挑战，研究了相关方法。重点探讨了基于任务与运动规划（TAMP）的集成方法，以及考虑几何约束与物理交互的动作序列生成技术。核心实验表明，所提方法在模拟维护场景中能将任务完成成功率提升约 25%，并显著减少人工干预需求。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.18269","title":"FlowVLA: Thinking in Motion with a Visual Chain of Thought","arxivId":"2508.18269","date":"2025-08-26","authors":"Haoang Li Team","category":"Manipulation","summary":"论文FlowVLA针对Vision-Language-Action（VLA）模型中直接预测未来帧外观而缺乏显式运动推理，导致物理不合理预测和策略学习低效的核心问题，提出了Visual Chain of Thought（视觉思维链）范式。关键技术FlowVLA采用自回归Transformer，以“当前帧→光流预测→未来帧”的两阶段训练方法，强制模型先通过中间光流编码运动动态再生成帧。实验在机器人操作基准和真实平台上进行，结果表明FlowVLA能生成更连贯、物理合理的视觉预测，并实现了最先进的策略性能，同时显著提高了样本效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.17986","title":"No Need to Look! Locating and Grasping Objects by a Robot Arm Covered with Sensitive Skin","arxivId":"2508.17986","date":"2025-08-25","authors":"Matej Hoffmann Team","category":"Manipulation","summary":"本文研究机器人**在完全无视觉输入下仅凭触觉定位与抓取物体**的核心问题。提出**分阶段触觉搜索方法**：先利用覆盖敏感皮肤的全身表面进行粗略探索，再通过末端执行器的力/扭矩传感器精确定位。实验表明，该方法在实物机器人上对单物体抓取成功率达**85.7%**，且**比仅使用末端触觉反馈的基线方法快6倍**，验证了全身触觉感知在视觉受限场景下的高效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.17643","title":"SEBVS: Synthetic Event-based Visual Servoing for Robot Navigation and Manipulation","arxivId":"2508.17643","date":"2025-08-25","authors":"Bharatesh Chakravarthi Team","category":"Manipulation","summary":"本文针对事件相机在主流机器人模拟器中缺乏合成事件流工具的问题，提出了SEBVS框架。该方法开发了开源的v2e ROS包，可在Gazebo模拟中从RGB相机流实时生成事件流，并采用基于Transformer的事件机器人策略（ERP），通过行为克隆进行训练。实验在移动机器人对象跟随和机械臂对象检测抓取两个任务中评估，结果表明事件引导的策略在各种操作条件下均比基于RGB的策略更具竞争优势，为事件相机在机器人实时导航与操作中的集成提供了基础。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.17600","title":"GWM: Towards Scalable Gaussian World Models for Robotic Manipulation","arxivId":"2508.17600","date":"2025-08-25","authors":"Siyuan Huang Team","category":"Manipulation","summary":"本文针对机器人操作中基于图像的世界模型缺乏稳健三维几何信息的问题，提出高斯世界模型（GWM）。其核心采用潜在扩散变换器与3D变分自编码器，通过高斯溅射实现细粒度的、以动作为条件的未来场景重建。实验表明，GWM能精准预测未来状态，并基于此训练的策略显著优于现有先进方法，展现了三维世界模型的数据扩展潜力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.17547","title":"LodeStar: Long-horizon Dexterity via Synthetic Data Augmentation from Human Demonstrations","arxivId":"2508.17547","date":"2025-08-24","authors":"Hao Su Team","category":"Manipulation","summary":"本文提出LodeStar框架，旨在解决机器人执行长时程灵巧操作任务时，因数据稀缺导致的鲁棒性不足问题。其核心技术是：1）利用现成基础模型将人类演示自动分解为语义技能；2）通过模拟中的强化学习，从少量演示生成多样化合成数据以增强训练；3）使用Skill Routing Transformer策略组合技能。在三个真实世界复杂任务上的实验表明，该方法相比基线显著提升了任务性能与鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.17482","title":"Variational Shape Inference for Grasp Diffusion on SE(3)","arxivId":"2508.17482","date":"2025-08-24","authors":"Aniket Bera Team","category":"Manipulation","summary":"本文提出一种鲁棒的多模态抓取合成框架，以解决在物体几何条件下面临形状噪声和点云稀疏性时，生成多样化稳定抓取的挑战。方法核心是结合**变分形状推断**与**SE(3)流形上的抓取扩散模型**：首先训练变分自编码器，通过隐式神经表示学习稳健的几何特征；随后利用这些特征引导扩散模型生成抓取。实验表明，该方法在ACRONYM数据集上性能超越现有方法**6.3%**，并对点云密度下降更具鲁棒性；在真实物体零样本迁移实验中，抓取成功率比基线高出**34%**。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.17449","title":"Robotic Manipulation via Imitation Learning: Taxonomy, Evolution, Benchmark, and Challenges","arxivId":"2508.17449","date":"2025-08-24","authors":"Liming Chen Team","category":"Manipulation","summary":"本文是第一篇系统综述机器人操作中模仿学习的论文。核心问题是对该领域进行系统性梳理，分析其技术演变、评估基准与开放挑战。论文提炼了关键技术方法的演进，包括从扩散模型、流匹配到自回归和可供性驱动的策略。通过整合现有基准结果进行量化比较，并指出未来关键挑战在于泛化能力、具身多样性、数据效率和基准标准化，旨在推动可扩展、通用的机器人操作策略发展。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.17230","title":"4D Visual Pre-training for Robot Learning","arxivId":"2508.17230","date":"2025-08-24","authors":"Huazhe Xu Team","category":"Manipulation","summary":"本文针对机器人学习中现有视觉预训练主要基于2D图像、缺乏对3D世界有效表征的问题，提出了一种名为FVP的4D视觉预训练框架。其核心是将预训练目标构建为“下一个点云预测”问题，并采用条件扩散模型，利用历史帧点云与机器人动作信息进行预测。在12个真实机器人操作任务上的实验表明，FVP将3D扩散策略（DP3）的平均成功率提升了28%，达到了模仿学习领域的先进性能，并能适配多种点云编码器与数据集。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.15972","title":"UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation","arxivId":"2508.15972","date":"2025-08-21","authors":"Binbin Xu Team","category":"Manipulation","summary":"UnPose解决零样本无模型6D物体姿态估计的核心问题，避免依赖成本高昂的CAD模型，并克服现有方法需额外训练或产生幻觉几何的局限。方法利用预训练扩散模型的3D先验和不确定性估计，以3D高斯泼溅（3DGS）表示初始重建，通过不确定性指导增量融合新视图，并在姿态图中联合优化确保全局一致性。实验表明，UnPose在6D姿态估计精度和3D重建质量上显著优于现有方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.15874","title":"Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning","arxivId":"2508.15874","date":"2025-08-21","authors":"Wenwu Zhu Team","category":"Manipulation","summary":"本文针对现有视觉运动机器人操作框架缺乏空间感知能力，难以在复杂环境中将视觉计划桥接到可执行动作的问题，提出了Spatial Policy (SP)框架。该框架通过显式空间建模和推理，核心方法包括：空间条件化具身视频生成模块（利用空间计划表建模空间引导预测）、基于流的动作预测模块（协调推断可执行动作）以及空间推理反馈策略（通过双阶段重新规划细化空间计划表）。实验表明，SP在Meta-World和iTHOR基准上分别实现了超过33%和25%的性能提升，在23个具身控制任务中表现优异，并验证了真实世界的实用性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.14994","title":"A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot","arxivId":"2508.14994","date":"2025-08-20","authors":"Marcelo Becker Team","category":"Manipulation","summary":"本文针对四足机器人机械臂遥操作中存在的控制不直观、缺乏障碍物检测导致碰撞风险高的问题，提出了一种基于视觉的共享控制方案。其关键技术是：利用外部摄像头与机器学习模型构建视觉姿态估计管道，实时检测操作者手腕位置并映射为机械臂指令；同时结合轨迹规划器检测并防止与障碍物及机械臂自身发生碰撞。实验在真实机器人上验证了该方案，实现了实时、鲁棒的遥操作控制。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.14441","title":"FBI: Learning Dexterous In-hand Manipulation with Dynamic Visuotactile Shortcut Policy","arxivId":"2508.14441","date":"2025-08-20","authors":"Cewu Lu Team","category":"Manipulation","summary":"本文针对灵巧手内操作中复杂接触动力学与部分可观测性的挑战，提出FBI框架。该方法通过动态融合视觉与触觉信息，利用基于动力学的潜在模型建立触觉信号与物体运动间的因果关联，并采用基于Transformer的交互模块进行特征融合，训练一步扩散策略。实验表明，该方法在仿真与真实世界的多个灵巧操作任务上均优于基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.14383","title":"Offline Imitation Learning upon Arbitrary Demonstrations by Pre-Training Dynamics Representations","arxivId":"2508.14383","date":"2025-08-20","authors":"Na Li Team","category":"Manipulation","summary":"本文针对离线模仿学习在有限专家数据下的性能瓶颈问题，提出通过预训练动力学表示来增强学习效果。该方法基于转移动力学分解学习表示，可从任意同动态的非专家数据中预训练，减少下游学习参数，并采用噪声对比估计启发的损失函数。实验表明，在MuJoCo环境中仅需单个专家轨迹即可成功模仿策略；在真实四足机器人上，能利用模拟器预训练的动力学表示，从少量真实世界演示中学习行走任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.14379","title":"Action-Constrained Imitation Learning","arxivId":"2508.14379","date":"2025-08-20","authors":"Ping-Chun Hsieh Team","category":"Manipulation","summary":"本文研究动作受限模仿学习问题，即学习者需在动作空间受限条件下，从动作空间更大的专家演示中学习策略。核心挑战在于动作约束导致的专家与学习者占用度量不匹配。为解决此问题，提出DTWIL方法，通过将轨迹对齐建模为规划问题，并利用模型预测控制结合动态时间规整距离，生成与专家状态轨迹相似且符合动作约束的替代数据集。实验表明，基于DTWIL生成的数据集进行学习，在多个机器人控制任务中显著提升了性能，且在样本效率上优于多种基准模仿学习算法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.14358","title":"Learning Point Cloud Representations with Pose Continuity for Depth-Based Category-Level 6D Object Pose Estimation","arxivId":"2508.14358","date":"2025-08-20","authors":"Ioannis Stamos Team","category":"Manipulation","summary":"本文针对类别级6D物体姿态估计中，现有方法因未显式捕捉姿态连续性而导致预测不一致、泛化能力弱的问题，提出HRC-Pose深度框架。该方法通过对比学习学习点云表示，核心采用6D姿态感知分层排序策略，分别编码旋转和平移组件，并设计专用估计模块处理。实验显示，HRC-Pose在REAL275和CAMERA25基准上持续优于现有深度方法，且能实时运行，验证了其有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.14042","title":"Train Once, Deploy Anywhere: Realize Data-Efficient Dynamic Object Manipulation","arxivId":"2508.14042","date":"2025-08-19","authors":"Hengshuang Zhao Team","category":"Manipulation","summary":"本文针对传送带动态物体操控中的数据稀缺问题，提出Geometry-Enhanced Model (GEM)模型。该方法通过外观噪声退火策略优化策略学习路径，使模型优先利用观测中的几何信息，从而缩小模拟与真实场景的视觉差异。实验表明，GEM能泛化至不同环境背景、机器人形态、运动动态和物体几何。在真实食堂餐具回收任务中，无需测试场景数据，GEM在超过1万次操作中成功率超过97%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.13998","title":"Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation","arxivId":"2508.13998","date":"2025-08-19","authors":"Jianye Hao Team","category":"Manipulation","summary":"本文旨在解决机器人操作中因数据稀缺和形态异构导致的“感知-行动鸿沟”泛化难题。提出以“指向”作为统一、与具体形态无关的中间表示，并构建大规模数据集Embodied-Points-200K。核心技术是开发了一个30亿参数的视觉语言模型Embodied-R1，采用两阶段强化微调课程进行训练。实验表明，该模型在11个基准测试中达到最优，并在零样本设置下，于SIMPLEREnv仿真环境取得56.2%成功率，在8项真实世界XArm任务中达到87.5%成功率，相比强基线提升62%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.13877","title":"Toward Deployable Multi-Robot Collaboration via a Symbolically-Guided Decision Transformer","arxivId":"2508.13877","date":"2025-08-19","authors":"Paul Asunda Team","category":"Manipulation","summary":"本文针对多机器人协作任务中策略可部署性差的问题，提出了一种符号引导的决策变换器（Symbolically-Guided Decision Transformer）方法。该方法将高层任务符号逻辑作为引导，与离线强化学习框架结合，通过轨迹建模学习协作策略。核心创新在于利用符号约束指导策略生成，确保行为符合安全与逻辑规范。实验表明，该方法在模拟多机器人搬运任务中，相比基线模型成功率提升超过15%，并能有效生成符合符号约束的可解释、可部署的协作行为序列。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.13103","title":"Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy","arxivId":"2508.13103","date":"2025-08-18","authors":"Zhi Hou Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型因观察空间与动作空间不一致导致的泛化难题，提出观测中心VLA框架。该方法利用相机外参矩阵，将末端执行器姿态从机器人基坐标转换到相机坐标，统一多视角下的预测目标。实验表明，该策略能加速收敛、提高任务成功率，并显著增强跨视角泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.13073","title":"Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey","arxivId":"2508.13073","date":"2025-08-18","authors":"Liqiang Nie Team","category":"Manipulation","summary":"本文是一篇关于大型视觉语言模型（VLM）驱动的视觉-语言-动作（VLA）模型在机器人操作领域的系统性综述。核心问题是解决传统基于预定义任务和刚性策略的机器人方法在非结构化、新场景中泛化能力不足的难题。论文提炼了两种关键技术范式：**单体模型**（单/双系统设计）和**分层模型**（通过可解释中间表示解耦规划与执行），并综述了其与强化学习、免训练优化等领域的集成。作为综述，本文未报告具体实验数据，但系统整合了该领域进展，旨在统一分类、减少研究碎片化，并指出了记忆机制、4D感知等未来方向。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.12554","title":"PROD: Palpative Reconstruction of Deformable Objects through Elastostatic Signed Distance Functions","arxivId":"2508.12554","date":"2025-08-18","authors":"Hamza El-Kebir Team","category":"Manipulation","summary":"本文提出PROD方法，旨在解决传统方法仅依赖几何或视觉数据、无法同时重建可变形物体形状与机械属性的问题。该方法通过弹性静力学有符号距离函数，结合力控表面探触的触觉交互，从稀疏姿态与力测量中估计物体未变形的SDF及材料刚度。实验表明，PROD在模拟软体交互中能有效处理姿态误差、非垂直力施加与曲率误差，具有较强鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.12274","title":"Bimanual Robot-Assisted Dressing: A Spherical Coordinate-Based Strategy for Tight-Fitting Garments","arxivId":"2508.12274","date":"2025-08-17","authors":"Jihong Zhu Team","category":"Manipulation","summary":"本文针对机器人辅助穿衣任务中，单手机器人难以处理袖窿窄小的紧身衣物、易导致卡住失败的问题，提出一种基于球形坐标的双手机器人穿衣策略。通过建立穿衣专用的球形坐标系，以方位角作为双手机器人操作的任务相关特征，并采用高斯混合模型与高斯混合回归进行模仿学习，生成能适应不同人体手臂姿势的穿衣轨迹。该方法旨在解决紧身衣物穿着难题，提升机器人操作的适应性与成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.12252","title":"Robot Trains Robot: Automatic Real-World Policy Adaptation and Learning for Humanoids","arxivId":"2508.12252","date":"2025-08-17","authors":"Shuran Song Team","category":"Manipulation","summary":"本文提出Robot-Trains-Robot (RTR)框架，旨在解决双足机器人在真实世界中进行强化学习（RL）时面临的安全性、奖励设计困难和效率低下等核心挑战。其关键技术是让一个具力反馈的机械臂充当“教师”，主动为人形机器人“学生”提供保护、奖励、扰动与自动复位等全方位支持，并引入一个通过优化潜在变量来促进仿真到现实迁移的新RL流程。实验通过在真实世界中微调行走策略和学习摆动任务，验证了该框架能实现高效、长期且需极少人工干预的真实世界机器人训练。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.12166","title":"Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing","arxivId":"2508.12166","date":"2025-08-16","authors":"Melkior Ornik Team","category":"Manipulation","summary":"本文针对机器人在部分可观测环境中为节能而需动态选择最小传感器子集（just-enough sensing）的实时轨迹规划问题，提出Belief-Conditioned One-Step Diffusion (B-COD)方法。该方法将扩散规划器显式地以姿态信念栅格和传感器掩码为条件，利用其去噪轨迹的分布作为定位误差的可微分代理指标，从而在单次10毫秒前向传播中同时输出短视界轨迹、不确定性估计及定位误差代理。在无人水面车辆的真实海洋实验中，该方法在保持与全传感器基线相当的目标到达性能的同时，有效降低了传感能耗。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.12071","title":"OASIS: Real-Time Opti-Acoustic Sensing for Intervention Systems in Unstructured Environments","arxivId":"2508.12071","date":"2025-08-16","authors":"Richard Camilli Team","category":"Manipulation","summary":"本文提出OASIS系统，旨在解决非结构化水下环境中实时3D场景重建的难题，以支持自主或遥控作业。该方法采用光声融合技术，结合光学图像与声纳数据，并利用体素雕刻进行实时重建；系统采用“手眼”配置，通过机械臂在短基线上获取多视角数据。水箱实验验证了该方法的有效性，结果表明其能够为水下操作任务提供实时的空间感知能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.12038","title":"Fully Spiking Actor-Critic Neural Network for Robotic Manipulation","arxivId":"2508.12038","date":"2025-08-16","authors":"Guanghui Sun Team","category":"Manipulation","summary":"本文针对资源受限环境下9自由度机械臂的目标到达与抓取任务，提出一种基于完全脉冲神经网络（SNN）的混合课程强化学习框架。核心方法包括简化SNN为仅输入输出层以降低复杂度，集成时间进度分区课程策略与近端策略优化（PPO）算法，并引入能量消耗建模框架及动态两阶段奖励调整机制。在Isaac Gym仿真平台的实验表明，该方法相比传统PPO和人工神经网络基线，在现实物理约束下实现了性能优越、可扩展且能量高效的控制。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.11898","title":"OmniD: Generalizable Robot Manipulation Policy via Image-Based BEV Representation","arxivId":"2508.11898","date":"2025-08-16","authors":"Xiaozhu Ju Team","category":"Manipulation","summary":"本文针对视觉运动策略易过拟合训练数据（如固定相机位姿与背景）、在分布外场景泛化能力差，以及多视图信息难以融合的问题，提出OmniD框架。其核心是通过基于图像的多视图融合，构建统一的鸟瞰图（BEV）表征，并采用基于可变形注意力的Omni-Feature Generator（OFG）来选择性提取任务相关特征、抑制视图噪声与背景干扰。实验表明，OmniD在分布内、分布外及少样本任务中，相比最佳基线模型平均性能分别提升11%、17%和84%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.11275","title":"Learning Differentiable Reachability Maps for Optimization-based Humanoid Motion Generation","arxivId":"2508.11275","date":"2025-08-15","authors":"Fumio Kanehiro Team","category":"Manipulation","summary":"本文针对人形机器人运动规划中反复求解逆运动学（IK）导致计算成本高的问题，提出一种数据驱动的**可微可达性图**方法。该图是一个在任务空间定义的标量函数，通过**神经网络或支持向量机**从采样末端姿态中学习得到，其关键特性是连续可微。将学习到的可达性图作为约束嵌入优化问题，可将步态规划、多接触运动规划等任务转化为**连续优化问题**，从而避免反复求解IK。实验表明，该方法能**高效生成**多种可行的机器人运动。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.11204","title":"Multi-Group Equivariant Augmentation for Reinforcement Learning in Robot Manipulation","arxivId":"2508.11204","date":"2025-08-15","authors":"Kwok Wai Samuel Au Team","category":"Manipulation","summary":"本文针对机器人视觉运动强化学习中采样效率低的问题，提出一种多群等变性增强（MEA）方法。传统方法局限于对任务对象施加全局等距对称变换，本文则探索非等距对称性，允许在时空维度上对机械手和目标物体分别施加独立的群变换，从而放松约束、增加数据多样性。该方法结合了离线强化学习框架，并采用保持平移等变性的体素化视觉表示。实验在仿真和真实机器人平台上验证了该方法的有效性，提升了采样效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.11143","title":"Actor-Critic for Continuous Action Chunks: A Reinforcement Learning Framework for Long-Horizon Robotic Manipulation with Sparse Reward","arxivId":"2508.11143","date":"2025-08-15","authors":"Yu-Gang Jiang Team","category":"Manipulation","summary":"本文针对长程、稀疏奖励的机器人操作任务中，强化学习难以稳定高效学习连续动作序列的问题，提出AC3框架。其核心是演员-评论家协同优化：演员采用非对称更新，仅从成功轨迹学习；评论家使用块内n步回报和自监督内在奖励进行稳定训练。在BiGym和RLBench的25个任务上，AC3仅需少量演示即取得优越成功率，验证了其有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.11117","title":"Robot Policy Evaluation for Sim-to-Real Transfer: A Benchmarking Perspective","arxivId":"2508.11117","date":"2025-08-14","authors":"Fabio Ramos Team","category":"Manipulation","summary":"本文针对机器人操作策略从模拟到现实迁移的评估难题，指出当前缺乏标准化基准测试，阻碍了通用策略的发展。为此，论文提出构建基准的三大要点：1）采用高视觉保真度模拟以缩小迁移鸿沟；2）通过系统增加任务复杂性与场景扰动来评估策略鲁棒性；3）量化现实与模拟性能的对齐程度。论文未报告自身实验数据，但引用研究指出模拟到现实的性能下降可达24-30%，凸显了建立系统性评估框架的紧迫性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.11049","title":"GenFlowRL: Shaping Rewards with Generative Object-Centric Flow in Visual Reinforcement Learning","arxivId":"2508.11049","date":"2025-08-14","authors":"Ruohan Gao Team","category":"Manipulation","summary":"本文针对视觉强化学习中视频生成模型依赖生成数据质量、缺乏环境反馈、难以进行精细操作，且需要大规模机器人数据的问题，提出GenFlowRL框架。该方法利用从多样跨体现数据训练得到的生成式物体中心流（物体关键点轨迹）来塑造奖励，通过混合奖励模型（结合在线轨迹与流先验的密集流匹配以及稀疏状态感知奖励）指导策略学习。在10个模拟操作任务和真实世界跨体现评估中，该方法能有效利用生成流提取的操作特征，在各种挑战性场景中 consistently achieving superior performance。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.11002","title":"3D FlowMatch Actor: Unified 3D Policy for Single- and Dual-Arm Manipulation","arxivId":"2508.11002","date":"2025-08-14","authors":"Katerina Fragkiadaki Team","category":"Manipulation","summary":"本文提出3D FlowMatch Actor (3DFA)，旨在构建一个统一的3D策略模型，以同时解决单臂和双臂机器人操作的协调与泛化难题。其核心技术是结合流匹配进行轨迹预测，并利用3D预训练视觉表征从演示中学习；在动作去噪过程中，采用了动作与视觉token之间的3D相对注意力机制。该方法在效率上取得突破，训练与推理速度比之前的3D扩散策略快30倍以上，且在双臂PerAct2基准上以41.4%的绝对优势刷新性能记录，同时在单臂RLBench的74个任务上达到最优水平。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.10511","title":"KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection","arxivId":"2508.10511","date":"2025-08-15","authors":"Lorenzo Natale Team","category":"Manipulation","summary":"本文针对扩散策略在机器人行为克隆中存在的两个核心问题：去噪过程随机性导致的轨迹质量不稳定，以及可能学习到训练数据中的异常值。提出了一种基于核密度估计的轨迹选择策略KDPE，通过并行生成多条轨迹，并利用一个专门建模末端执行器位姿与夹爪状态的流形感知核函数，估计动作概率密度，从而筛选出最可靠的轨迹。该方法在模拟单臂任务和真实机器人实验中均取得了优于原始扩散策略的性能表现。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.10399","title":"Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning","arxivId":"2508.10399","date":"2025-08-14","authors":"Ping Kuang Team","category":"Manipulation","summary":"本综述探讨大模型如何赋能具身AI，以解决智能体在开放动态环境中实现人类水平通用任务能力的核心挑战。文章系统分析了两大关键技术路径：在决策方面，阐述了大模型如何增强分层决策（高层规划、低层执行与反馈）与端到端视觉-语言-动作模型；在学习方面，详述了大模型如何提升模仿学习与强化学习。首次将世界模型纳入体系，阐明其设计方法与在决策和学习中的关键作用。大模型通过增强感知、交互、规划与学习，为具身AI带来了革命性进展。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.09976","title":"Masquerade: Learning from In-the-wild Human Videos using Data-Editing","arxivId":"2508.09976","date":"2025-08-13","authors":"Jeannette Bohg Team","category":"Manipulation","summary":"本文针对机器人操作数据稀缺问题，提出Masquerade方法，通过编辑野外人类视频来缩小人与机器人的视觉体现差距。核心技术包括：估计3D手部姿态、修复手臂区域、叠加渲染的双手机器人以跟踪末端轨迹，并预训练视觉编码器预测未来2D机器人关键点。实验表明，仅用每任务50个真实机器人演示进行微调，在三个未见过的厨房场景中，该方法性能超越基线5-6倍，且性能随编辑视频量对数增长。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.09855","title":"Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes","arxivId":"2508.09855","date":"2025-08-13","authors":"Changjae Oh Team","category":"Manipulation","summary":"本文针对人机协作中物体交接任务，提出一种无需真实机器人训练的数据采集方法。核心问题是解决传统方法依赖大量真实交互数据、成本高且存在仿真与现实视觉差异的局限。关键技术采用稀疏视角高斯泼溅重建交接场景三维表示，通过改变虚拟相机位姿生成机器人视点图像与动作序列，作为监督策略学习的演示数据。实验表明，该方法在重建场景和真实交接任务中均能形成有效表征，实现稳定抓取并避免人机碰撞，为人机协作提供了更无缝、鲁棒的解决方案。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.09822","title":"Physical Autoregressive Model for Robotic Manipulation without Action Pretraining","arxivId":"2508.09822","date":"2025-08-13","authors":"Guangrun Wang Team","category":"Manipulation","summary":"本文针对机器人操作中缺乏大规模动作预训练数据的问题，提出物理自回归模型（PAR）。该方法的核心是利用视频预训练模型中的世界知识来理解物理动力学，无需单独的动作预训练。关键技术包括：设计结合帧与动作的物理令牌来联合建模环境演化；采用基于DiT的去令牌化器将二者作为连续令牌处理，以减少量化误差并促进相互增强；此外集成了带逆运动学的因果掩码、并行训练与KV缓存机制以提升效率与性能。在ManiSkill基准测试中，PAR在PushCube任务上取得100%的成功率，在其他任务上匹配了动作预训练基线的性能，并能准确预测视频未来帧及其紧密对齐的动作轨迹。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.09700","title":"Immersive Teleoperation of Beyond-Human-Scale Robotic Manipulators: Challenges and Future Directions","arxivId":"2508.09700","date":"2025-08-13","authors":"Jouni Mattila Team","category":"Manipulation","summary":"本文探讨超人体尺度机械臂（BHSRMs）沉浸式遥操作面临的核心挑战。研究聚焦于解决操作员安全、感觉运动不匹配和增强操作具身感等问题，分析了触觉与视觉反馈系统的设计权衡，并对比了外骨骼与操纵杆两种控制方案。论文指出，确保自然、拟真的操作体验是提升遥操作数据质量与学习效能的关键，并展望了面向大型遥现系统的人本安全模型等未来方向。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.09558","title":"CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail","arxivId":"2508.09558","date":"2025-08-13","authors":"Fumin Zhang Team","category":"Manipulation","summary":"本文针对机器人自动化中三维电缆布线的难题，提出一种仿生夹爪指甲设计及单次抓取的端到端布线框架。核心问题是解决传统平行两指夹爪在抓取和引导电缆时易过度挤压和拉伸的风险。关键技术包括：受鹰爪启发的仿生指甲结构，辅助平面抓取与手中引导；基于视觉的状态估计与运动原型离线轨迹规划的连续控制方法。实验表明，该框架在多种电缆与槽道测试中，性能显著优于同等感知条件下的传统拾放操作策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.09502","title":"Reactive Model Predictive Contouring Control for Robot Manipulators","arxivId":"2508.09502","date":"2025-08-13","authors":"Jaeheung Park Team","category":"Manipulation","summary":"本文针对机器人在动态环境中进行路径跟踪时，需同时处理避障、奇点避让、自碰撞避免并满足运动学约束的难题，提出了一种反应式模型预测轮廓控制（RMPCC）框架。该方法通过模型预测控制优化轮廓误差与进度，实现动态反应。核心实验表明，该框架能在动态环境中以100 Hz的频率成功实现上述所有安全约束下的鲁棒路径跟踪。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.09444","title":"DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation","arxivId":"2508.09444","date":"2025-08-13","authors":"Liqiang Nie Team","category":"Manipulation","summary":"本文针对连续环境视觉语言导航（VLN-CE）中两阶段航点规划框架的全局次优化和性能瓶颈问题，提出DAgger Diffusion Navigation（DifNav）。该方法采用端到端的条件扩散策略，直接建模连续导航空间中的多模态动作分布，无需航点预测器，并结合DAgger进行在线训练与专家轨迹增强以提升鲁棒性。实验证明，即使不使用航点预测器，该方法在导航性能上显著优于现有最先进的两阶段航点基模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.09071","title":"GeoVLA: Empowering 3D Representations in Vision-Language-Action Models","arxivId":"2508.09071","date":"2025-08-13","authors":"Jiale Cao Team","category":"Manipulation","summary":"本文提出GeoVLA，解决现有视觉-语言-动作模型依赖2D视觉输入、缺乏3D几何信息，导致空间感知与适应性受限的问题。方法上，通过点嵌入网络从深度图提取3D几何嵌入，并与视觉-语言嵌入拼接，由3D增强动作专家生成动作序列。实验表明，GeoVLA在LIBERO和ManiSkill2仿真基准达到SOTA，在真实任务中展现出对高度、尺度和视角变化的强鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.08982","title":"Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion","arxivId":"2508.08982","date":"2025-08-12","authors":"Sehoon Ha Team","category":"Manipulation","summary":"本文提出SDAX框架，旨在解决四足机器人学习敏捷步态时依赖人工奖励设计、专家示范或课程学习的问题。其核心方法是结合无监督技能发现与双层优化：通过技能向量引导策略探索多样行为（如爬行、攀爬、跳跃），同时动态调整探索强度以平衡任务奖励与多样性奖励。实验表明，该框架使机器人能自主掌握包括垂直墙面跳跃在内的复杂动作，并成功迁移到真实硬件平台。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.08748","title":"Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT","arxivId":"2508.08748","date":"2025-08-12","authors":"Yukiyasu Domae Team","category":"Manipulation","summary":"本文针对零售环境（如便利店）中机器人抓取放置任务面临的物体密集、遮挡及属性多样等挑战，提出了一种基于标注引导视觉提示的感知-行动框架。核心方法采用边界框标注提供空间指引，并结合模仿学习算法ACT，使机械臂能够根据人类示范预测分块动作序列，实现自适应操作。实验表明，该系统提升了抓取准确性与环境适应性，并通过成功率与抓取行为分析验证了其在零售场景中的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.08707","title":"Towards Safe Imitation Learning via Potential Field-Guided Flow Matching","arxivId":"2508.08707","date":"2025-08-12","authors":"Yoshihiko Nakamura Team","category":"Manipulation","summary":"本文针对模仿学习中生成运动的安全性问题，特别是在有障碍物的复杂环境中，提出了Potential Field-Guided Flow Matching Policy (PF2MP)方法。该方法同时从成功演示中学习基础流匹配策略和障碍物相关的势场，在推理时通过势场调制流匹配向量场，以生成安全轨迹。实验在模拟和真实世界的导航及机器人操作任务中进行，结果表明PF2MP显著减少了碰撞，提升了安全性而不影响任务成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.08706","title":"OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing","arxivId":"2508.08706","date":"2025-08-12","authors":"Hengdi Zhang Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作（VLA）模型忽视触觉感知、在接触丰富任务中失败的问题，提出OmniVTLA模型。其关键技术包括双路径触觉编码器框架（使用预训练ViT和语义对齐触觉ViT）以及ObjTac触觉数据集（135K三模态样本），以学习统一触觉表示。实验表明，在抓取任务中，OmniVTLA使用夹爪成功率达96.9%（比基线高21.9%），使用灵巧手达100%（比基线高6.2%），同时减少任务时间并生成更平滑轨迹。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.08170","title":"ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction","arxivId":"2508.08170","date":"2025-08-11","authors":"Wenjun Mei Team","category":"Manipulation","summary":"本文提出ReconDreamer-RL框架，旨在解决自动驾驶端到端强化学习中的仿真与现实差距（sim2real gap）及极端场景覆盖不足的问题。核心方法包括：1) ReconSimulator，结合视频扩散先验进行外观建模与运动学模型进行物理建模，以重建真实驾驶场景；2) 动态对抗智能体（DAA），通过调整周围车辆轨迹自主生成极端交互场景；3) 关联轨迹生成器（CTG），缓解训练数据分布偏差。实验表明，该方法显著优于模仿学习，碰撞率降低5倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.08113","title":"AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies","arxivId":"2508.08113","date":"2025-08-11","authors":"Joyce Chai Team","category":"Manipulation","summary":"本文提出AimBot，一种轻量级视觉增强技术，用于解决现有视觉运动策略在机器人操作中空间感知能力不足的问题。该方法通过在RGB图像上叠加射击线和瞄准镜十字线，利用深度图像、相机外参和末端执行器位姿计算空间线索，显式编码夹爪与物体间的空间关系。该技术无需改变模型架构，计算开销极低（<1ms）。实验表明，AimBot能持续提升多种视觉运动策略在仿真和真实环境中的任务性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.07770","title":"AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation","arxivId":"2508.07770","date":"2025-08-13","authors":"Lei Han Team","category":"Manipulation","summary":"本文针对家庭移动操作开发中缺乏集成高保真场景构建与灵活数据收集统一框架的问题，提出了AgentWorld交互式仿真平台。其关键技术包括自动化场景构建（涵盖布局生成、语义资产放置、视觉材料配置和物理模拟）以及双模式遥操作系统（支持轮式底座和人形运动策略），用于高效收集操作数据。通过广泛基准测试行为克隆、动作分块变换器、扩散策略等模仿学习方法，验证了平台所生成数据集在模拟到真实转移中的有效性，为复杂家庭环境下的机器人技能学习提供了完整解决方案。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.07650","title":"GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions","arxivId":"2508.07650","date":"2025-08-11","authors":"Hong Zhang Team","category":"Manipulation","summary":"本文提出GraphCoT-VLA模型，旨在解决现有视觉-语言-动作（VLA）模型难以处理模糊指令、未知环境状态及缺乏三维空间交互感知的问题。其关键技术包括：结构化思维链推理模块，用于整合任务理解、规划与反馈；实时更新的3D姿态-物体图，以捕捉三维空间关系；以及dropout混合推理策略。实验表明，该模型在多项真实机器人任务中显著提升了任务成功率和响应速度，在开放环境及不确定指令下表现出优异的泛化能力与鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.07626","title":"AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning","arxivId":"2508.07626","date":"2025-08-11","authors":"Yang Liu Team","category":"Manipulation","summary":"本文提出AR-VRM方法，解决视觉机器人操作任务中机器人数据稀缺导致泛化能力受限的问题。核心创新在于通过类比推理显式模仿人类动作：首先设计关键点视觉语言模型，从大规模人类动作视频中学习并预测人手关键点；在机器人微调阶段，检索任务相似的人类视频，并建立人手关键点与机器人部件间的类比映射。该方法在CALVIN基准测试和真实实验中取得领先性能，尤其在少样本场景下显著优于现有方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.07323","title":"Collision-Free Trajectory Planning and control of Robotic Manipulator using Energy-Based Artificial Potential Field (E-APF)","arxivId":"2508.07323","date":"2025-08-10","authors":"Manoranjan Sinha Team","category":"Manipulation","summary":"本文针对动态杂乱环境中机器人轨迹规划存在局部最小值和运动振荡的问题，提出一种基于能量的人工势场方法。该方法整合位置与速度依赖的势函数，并与混合轨迹优化器结合，在速度与加速度约束下共同最小化加加速度和执行时间。在7自由度Kinova Gen3机械臂上的仿真验证表明，该方法能生成无碰撞、平滑、时间高效且无振荡的轨迹。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.07287","title":"Multimodal Spiking Neural Network for Space Robotic Manipulation","arxivId":"2508.07287","date":"2025-08-10","authors":"Guanghui Sun Team","category":"Manipulation","summary":"本文针对空间站机器人臂在有限板载资源下实现自主操作与物料转移的核心问题，提出一种基于脉冲神经网络的多模态控制框架。该方法融合几何状态、触觉和语义信息以增强环境感知，并集成双通道三阶段课程强化学习策略来逐步优化控制。实验在目标接近、物体抓取和稳定提升等任务中验证，该框架在任务成功率和能源效率上均优于基线方法，展现了其在实际航天应用中的可靠性与适用性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.07118","title":"DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit","arxivId":"2508.07118","date":"2025-08-09","authors":"Monroe Kennedy III Team","category":"Manipulation","summary":"本文提出DexFruit框架，旨在解决软质水果（如草莓、番茄）在自动化采摘与处理中因极度脆弱易损伤导致的损耗难题。核心技术包括：1）基于光学触觉感知的触觉信息扩散策略，实现轻柔自主操控；2）FruitSplat方法，利用3D高斯溅射将2D果体掩膜与瘀伤分割转换为高分辨率3D表征，以量化损伤。实验表明，该框架在三种水果上达到92%抓取成功率，视觉瘀伤减少高达15%，抓取成功率较基线提升最高31%（基于超过630次试验）。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.06969","title":"Manipulator for people with limited abilities","arxivId":"2508.06969","date":"2025-08-09","authors":"Arkady Yuschenko Team","category":"Manipulation","summary":"根据您提供的论文标题《Manipulator for people with limited abilities》，我理解这是一篇关于为能力受限人士设计的机械臂的论文。然而，您没有提供论文的**正文内容**。\n\n为了撰写一段**精准、不编造**的总结，并涵盖您要求的**核心问题、技术方法和实验结论**，我必须基于论文的实际正文进行分析。\n\n请您提供论文的正文内容，我将立即为您生成符合要求的简短总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.06779","title":"Learning a Vision-Based Footstep Planner for Hierarchical Walking Control","arxivId":"2508.06779","date":"2025-08-09","authors":"Michael Posa Team","category":"Manipulation","summary":"本文针对双足机器人在非结构化地形中实时脚步规划依赖脆弱的手工视觉管道或仅凭本体感知的问题，提出一种基于视觉的分层控制框架。核心方法整合了基于局部高程图的强化学习高层脚步规划器与低层操作空间控制器，并利用角动量线性倒立摆模型构建低维状态表示以降低复杂度。通过在欠驱动机器人Cassie上进行仿真与硬件实验，该方法在不同地形条件下得到了验证，展示了其实现视觉融合步态规划的能力与挑战。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.06319","title":"Towards Balanced Behavior Cloning from Imbalanced Datasets","arxivId":"2508.06319","date":"2025-08-08","authors":"Dylan P. Losey Team","category":"Manipulation","summary":"本文研究模仿学习从不平衡数据集中学习时，因数据分布不均导致策略偏向高频子任务、忽视重要但低频行为的问题。为解决此问题，论文探索了对离线数据集进行重新平衡（即重新加权不同状态-动作对重要性）的方法，并引入了一种新的元梯度重新平衡算法以改进现有方法。实验表明，对数据集进行重新平衡能够提升下游模仿学习的整体策略性能，且无需额外收集数据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.06313","title":"Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators","arxivId":"2508.06313","date":"2025-08-08","authors":"Jouni Mattila Team","category":"Manipulation","summary":"本文针对全电动重型机械臂（HDRM）的高精度控制问题，提出了一种统一的系统级建模与控制框架。核心方法包括：1）**代理增强执行器模型**，融合机电动力学与基于实测数据训练的神经网络，以捕获未建模摩擦与损耗；2）**扩展的虚拟分解控制（VDC）架构**，结合基于李雅普诺夫的自然适应律，实现模块化分层控制。实验表明，该自适应控制器在多域仿真中达到**亚厘米级跟踪精度**（笛卡尔RMSE＜2 mm），并在1自由度实验平台上验证了其对**±40%参数变化**的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.06266","title":"ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints","arxivId":"2508.06266","date":"2025-08-08","authors":"Liming Chen Team","category":"Manipulation","summary":"本文针对机器人操作中现有扩散策略在测试时缺乏适应性、将动作生成视为无约束去噪过程的问题，提出了一种无需重新训练即可在测试时自适应的扩散策略ADPro。其核心方法包括：1）**流形约束去噪**，利用末端执行器与目标场景的相对位姿作为自然梯度方向，引导去噪沿操作流形的测地线路径；2）**任务感知初始化**，通过夹爪与目标场景的粗略配准来生成结构化的初始噪声动作，减少无效探索。实验表明，该方法在多个基准测试中显著提升了性能，实现了高达25%的更快执行速度，并将成功率提高了超过强基线9个百分点。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.06095","title":"Incremental Language Understanding for Online Motion Planning of Robot Manipulators","arxivId":"2508.06095","date":"2025-08-08","authors":"Matthias Scheutz Team","category":"Manipulation","summary":"本文针对机器人运动规划中无法实时处理动态语音指令、导致低效“停止-重规划”的问题，提出一种基于推理的增量解析器。该方法将在线运动规划算法集成到认知架构中，通过维护多候选解析和符号推理机制，实现运动计划的连续适应与更新，无需中断执行。实验表明，该系统能在真实人机交互场景中在线适应目标姿态、约束或任务变化，提升了协作的自然性和流畅性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.05976","title":"PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation","arxivId":"2508.05976","date":"2025-08-08","authors":"Yao Mu Team","category":"Manipulation","summary":"本文提出PASG框架，以解决机器人操作中高层任务语义与底层几何特征割裂的核心问题。其关键技术包括：1) 通过几何特征聚合实现跨类别关键点与轴线的自动基元提取；2) 利用视觉语言模型（VLM）动态地将几何基元与功能可供性及任务描述进行语义锚定；3) 构建了空间语义推理基准与微调VLM模型（Qwen2.5VL-PA）。实验表明，该框架在多样化的实际机器人操作任务中取得了与手动标注相当的性能，实现了对物体更细粒度的语义-可供性理解。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.05635","title":"Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation","arxivId":"2508.05635","date":"2025-08-07","authors":"Guanghui Ren Team","category":"Manipulation","summary":"本文针对机器人操作中策略学习、评估与模拟的割裂问题，提出了统一的世界基础平台Genie Envisioner。其核心技术包括：1）GE-Base，一个捕捉交互动态的大规模指令条件视频扩散模型；2）GE-Act，通过流匹配解码器将潜在表示映射为可执行动作；3）GE-Sim，作为动作条件神经模拟器生成高保真推演。平台还配备了评估套件EWMBench。实验表明，GE-Act在新机器人形态上仅需一小时数据微调，即可成功执行涉及可变形物体精细控制和基于记忆决策的复杂包装任务，展示了强大的跨形态泛化、精确操作和跨步骤记忆能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.05584","title":"Robust adaptive fuzzy sliding mode control for trajectory tracking for of cylindrical manipulator","arxivId":"2508.05584","date":"2025-08-07","authors":"Nga Nguyen Thi Team","category":"Manipulation","summary":"本文针对圆柱型机械臂的轨迹跟踪问题，提出了一种鲁棒自适应模糊滑模控制方法。该方法结合滑模控制（SMC）的鲁棒性、模糊逻辑系统处理不确定性的能力以及自适应律在线调整参数。核心在于设计自适应模糊规则来逼近系统未知动态并补偿扰动，从而增强控制器在模型不确定性和外部干扰下的性能。实验结果表明，所提控制器能有效提高轨迹跟踪精度和系统鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.05415","title":"Do Robots Really Need Anthropomorphic Hands?","arxivId":"2508.05415","date":"2025-08-07","authors":"Nicolás Navarro-Guerrero Team","category":"Manipulation","summary":"本文探讨机器人是否真的需要拟人化手这一核心问题。通过比较人类手与商用机器人手，并系统回顾手部机制与操作技能，研究分析实现机器人所需技能的最小机制与传感器要求。核心结论显示，在工业应用和机器人挑战中，简单设计如平行夹持器或三指手更常见；手腕灵活性和手指外展/内收比增加手指数量更重要。非拟人化设计（如两对对立手指）可提高灵巧性，表明人类手并非最优，主张基于功能而非形式的仿生学。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.05396","title":"Real-Time Iteration Scheme for Diffusion Policy","arxivId":"2508.05396","date":"2025-08-07","authors":"Danica Kragic Team","category":"Manipulation","summary":"本文针对扩散策略在机器人操作中因迭代去噪过程导致的推理时间长、难以满足实时性要求的问题，提出实时迭代方案（RTI-DP）。该方法受最优控制中的实时迭代启发，利用先前时间步的解作为后续迭代的初始猜测以加速扩散推理，并引入缩放方法处理离散动作。实验表明，该方案无需蒸馏或重新设计策略，即能大幅降低推理时间，同时保持与全步去噪扩散策略相当的整体性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.05310","title":"ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning","arxivId":"2508.05310","date":"2025-08-07","authors":"Jens Kober Team","category":"Manipulation","summary":"本文针对交互式模仿学习中人类教学负担过重的问题，提出ASkDAgger框架，其核心是利用新手策略计划中的信息（如能力与不确定性）来优化学习。关键技术包括：S-Aware Gating（SAG）动态调整查询阈值；Foresight Interactive Experience Replay（FIER）将有效的新手计划转化为示范数据；Prioritized Interactive Experience Replay（PIER）基于不确定性、成功率等因素优先回放经验。该方法在模拟和真实语言条件操作任务中验证有效，能平衡查询频率与失败率，减少标注需求，并提升泛化与适应速度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.05186","title":"Learning to See and Act: Task-Aware View Planning for Robotic Manipulation","arxivId":"2508.05186","date":"2025-08-07","authors":"Liang Lin Team","category":"Manipulation","summary":"本文针对机器人操作中静态视角和共享视觉编码器导致的3D感知受限、任务干扰及泛化能力不足问题，提出了任务感知虚拟视角探索（TVVE）框架。该框架整合虚拟视角探索与任务特定表示学习，采用高效探索策略（通过伪环境加速）获取信息视角，并引入任务感知混合专家（TaskMoE）视觉编码器以解耦不同任务特征。实验在RLBench和RLBench-OG基准上进行，TVVE性能显著优于现有方法，在真实机器人操作中于视觉干扰、未见指令等分布外（OOD）设置下展现出卓越的鲁棒性和泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.05077","title":"Analyzing the Impact of Multimodal Perception on Sample Complexity and Optimization Landscapes in Imitation Learning","arxivId":"2508.05077","date":"2025-08-07","authors":"Temitope Lukman Adebanjo Team","category":"Manipulation","summary":"本文从统计学习理论角度，研究了多模态模仿学习的理论基础。核心问题是解决传统单模态模仿学习在机器人任务中面临的高样本复杂度挑战（高维度、长序列、分布偏移）。论文提出，通过整合RGB-D、本体感觉、语言等多模态信息流，构建如PerAct和CLIPort等多模态架构，可利用互补信息降低学习难度。理论分析表明，与单模态策略相比，妥善整合的多模态策略能获得更紧的泛化边界和更有利的优化景观，从而在理论上实现更优越的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.04931","title":"INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM","arxivId":"2508.04931","date":"2025-08-06","authors":"Nikos Tsagarakis Team","category":"Manipulation","summary":"本文针对人形机器人运动趋势推断的核心问题，提出INTENTION方法，旨在通过交互式直觉与基于视觉语言模型（Grounded VLM）的技术提升推断的准确性和自然性。方法结合人类交互反馈与VLM的语义理解能力，实现对机器人运动意图的在线学习和适应。实验表明，该方法能有效提升运动趋势预测的准确率，并在真实机器人平台上验证了其交互性能的显著改进。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.04009","title":"Optimization of sliding control parameters for a 3-dof robot arm using genetic algorithm (GA)","arxivId":"2508.04009","date":"2025-08-06","authors":"Le Tieu Nien Team","category":"Manipulation","summary":"本文针对三自由度机械臂滑模控制中参数整定困难的问题，提出一种基于遗传算法（GA）的优化方法。核心是通过GA自动寻优，确定滑模控制律的关键参数（如切换增益、边界层厚度等），以平衡系统鲁棒性与抑制抖振。实验表明，经GA优化后的控制系统能有效提升轨迹跟踪精度，并显著降低控制输入抖振，相比传统试凑法，在动态响应和稳态误差方面均有改善。具体性能提升数据需参考原文实验部分。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.03944","title":"Constraint-Preserving Data Generation for Visuomotor Policy Learning","arxivId":"2508.03944","date":"2025-08-05","authors":"Jeannette Bohg Team","category":"Manipulation","summary":"本文针对机器人模仿学习中大规模演示数据收集成本高昂、且现有基于位姿变换的数据生成方法无法适应物体几何变化的问题，提出CP-Gen方法。该方法将机器人技能定义为关键点轨迹约束，通过采样物体几何与位姿变换，并优化机器人关节配置以满足变换后的约束，从而从单条专家轨迹自动生成多样化的演示数据。在16个模拟任务和4个真实任务上的实验表明，使用该方法训练的策略平均成功率达到77%，显著优于最佳基线（50%）。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.03645","title":"DiWA: Diffusion Policy Adaptation with World Models","arxivId":"2508.03645","date":"2025-08-05","authors":"Abhinav Valada Team","category":"Manipulation","summary":"本文提出DiWA框架，解决扩散策略在线强化学习微调样本效率低、安全性差的核心问题。其关键技术是引入世界模型，利用少量离线交互数据训练模型，在模型想象的轨迹中完全离线执行策略优化，替代昂贵的真实环境交互。在CALVIN基准测试中，DiWA仅通过离线适应就提升了八项任务的性能，所需物理交互量比无模型基线少数个数量级，首次实现了基于离线世界模型的扩散策略高效微调。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.03218","title":"ActionSink: Toward Precise Robot Manipulation with Dynamic Integration of Action Flow","arxivId":"2508.03218","date":"2025-08-05","authors":"Xiaodan Liang Team","category":"Manipulation","summary":"本文针对基于学习的机器人操作中低层动作估计精度不足的核心问题，提出ActionSink框架。其关键技术是将动作重新定义为自监督的“动作流”（视频光流），并通过两个模块进行动态集成：1) 粗到细动作流匹配器，迭代检索并去噪以提升精度；2) 动态动作流集成器，利用工作记忆池管理历史动作流，并通过多层融合模块集成当前与历史信息，实现精确动作估计。实验表明，该框架在LIBERO基准上成功率超越之前SOTA 7.9%，在长时序任务LIBERO-Long上准确率提升近8%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.03129","title":"Safety-Aware Imitation Learning via MPC-Guided Disturbance Injection","arxivId":"2508.03129","date":"2025-08-05","authors":"Somil Bansal Team","category":"Manipulation","summary":"本文提出MPC-SafeGIL方法，旨在解决模仿学习中因策略误差导致的安全风险这一核心问题。该方法通过在专家演示数据中注入对抗性扰动，使策略学习到鲁棒的恢复行为。关键技术是利用基于采样的模型预测控制来近似最坏情况扰动，从而将安全考量直接集成到数据收集阶段，适用于高维和黑盒动力学系统。通过在四足机器人运动、视觉导航仿真及真实四旋翼飞行器上的实验验证，该方法在安全性和任务性能上均取得了提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.03068","title":"Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching","arxivId":"2508.03068","date":"2025-08-07","authors":"C. Karen Liu Team","category":"Manipulation","summary":"本文提出HEAD框架，解决人形机器人协调导航、运动与抓取的统一控制问题。采用模块化方法：高层策略从人类视觉数据学习，预测手眼目标位姿；底层控制器从运动捕捉数据学习，实现全身运动跟踪。该方法将视觉感知与动作解耦，提升了学习效率与场景泛化能力。实验在仿真与真实环境中验证了机器人在复杂人机环境中的自主导航与抓取能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.02870","title":"Learning User Interaction Forces using Vision for a Soft Finger Exosuit","arxivId":"2508.02870","date":"2025-08-04","authors":"Thomas George Thuruthel Team","category":"Manipulation","summary":"本文针对软体手指外骨骼与用户间的交互力难以建模和直接测量的问题，提出了一种基于视觉的学习框架。该方法利用SoRoSim工具箱生成多样化的外骨骼几何与驱动数据集，通过低分辨率灰度图像，学习估计多个接触点的分布接触力。实验表明，该视觉估计器能准确预测交互力，泛化至未见过的形状与驱动水平，对视觉噪声和对比度变化具有鲁棒性，并可作为闭环控制中的替代力传感器。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.02649","title":"Manip4Care: Robotic Manipulation of Human Limbs for Solving Assistive Tasks","arxivId":"2508.02649","date":"2025-08-04","authors":"Ahmed H. Qureshi Team","category":"Manipulation","summary":"本文提出Manip4Care，一个用于辅助护理的机器人四肢操作模块化仿真框架。核心问题是解决现有方法假设人体静止、难以有效抓取和重定位四肢的局限。关键技术包括：基于对拓采样与力闭合的四肢抓取方法，以及结合模型预测路径积分（MPPI）与矢量场控制的轨迹规划与跟踪方法，同时满足生物力学与避碰约束。实验在仰卧与坐姿等多种任务中验证了方法的有效性，并展示了其在卧床洗澡任务中的应用。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.02644","title":"D2PPO: Diffusion Policy Policy Optimization with Dispersive Loss","arxivId":"2508.02644","date":"2025-08-04","authors":"Haitao Wang Team","category":"Manipulation","summary":"本文针对扩散策略在机器人操作中存在的“扩散表示崩溃”问题，即相似观察映射为难以区分的特征，导致无法处理细微但关键的动作差异。提出D²PPO方法，引入**分散损失正则化**，通过将批次内所有隐藏表示视为负样本对，迫使网络学习更具判别性的特征表示。在RoboMimic基准测试中，该方法在预训练和微调阶段分别取得**平均22.7%和26.1%的性能提升**，并在复杂任务上达到新的SOTA水平。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.00697","title":"On-Device Diffusion Transformer Policy for Efficient Robot Manipulation","arxivId":"2508.00697","date":"2025-08-01","authors":"Dong Xu Team","category":"Manipulation","summary":"本文针对扩散策略在资源受限移动平台上部署时存在的计算效率低、内存占用大的问题，提出LightDP框架。通过**网络压缩**（采用统一的剪枝与重训练流程优化去噪模块）与**减少采样步骤**（结合一致性蒸馏技术）两项核心技术，显著提升推理速度。实验在PushT等多个标准数据集上验证，LightDP能在移动设备上实现实时动作预测，且性能与先进扩散策略相当。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2508.00491","title":"HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning","arxivId":"2508.00491","date":"2025-08-01","authors":"Lorenzo Natale Team","category":"Manipulation","summary":"本文研究模仿学习在假肢手控制中的应用，旨在解决传统肌电控制自由度有限、认知负荷高的问题。提出HannesImitationPolicy方法，基于扩散策略（Diffusion Policy），利用单一眼内摄像头数据，训练统一的抓取策略以预测手腕方向与手指闭合。实验表明，该方法在多种物体与非结构化场景中均能成功抓取，并在非结构化环境下性能优于基于分割的视觉伺服控制器。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.23734","title":"RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping","arxivId":"2507.23734","date":"2025-07-31","authors":"Jianbing Shen Team","category":"Manipulation","summary":"本文针对机器人抓取中缺乏基于推理的大规模可供性分割数据、限制开放世界泛化能力的问题，构建了RAGNet基准，包含273k图像、180类别和26k推理指令，覆盖野外、机器人等多域数据。提出AffordanceNet框架，采用在大量可供性数据上预训练的视觉语言模型（VLM）和基于可供性地图的抓取网络。实验表明，该模型在可供性分割和真实机器人任务中展现出强大的开放世界泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.23682","title":"villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models","arxivId":"2507.23682","date":"2025-07-31","authors":"Jiang Bian Team","category":"Manipulation","summary":"本文提出villa-X框架，旨在解决视觉-语言-动作模型中潜在动作学习不充分、物理基础薄弱的问题。关键技术是引入本体感知前向动力学模型作为辅助解码器，通过结合结构线索增强潜在动作的物理基础，使其更好地关联视觉变化与机器人控制。实验表明，villa-X能零样本生成潜在动作计划，在SIMPLER仿真和真实机器人任务中均取得优越性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.23523","title":"H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation","arxivId":"2507.23523","date":"2025-08-01","authors":"Jun Zhu Team","category":"Manipulation","summary":"本文提出H-RDT，解决机器人模仿学习中高质量示范数据稀缺的难题。其核心是利用大规模人类操作视频（带3D手部姿态标注）作为行为先验，通过两阶段训练范式：先在人类数据上预训练，再通过模块化动作编码器/解码器在机器人数据上跨具身微调。基于20亿参数扩散变换器架构，采用流匹配建模复杂动作分布。实验表明，H-RDT在模拟和真实世界任务中均显著优于从头训练及现有方法，性能分别提升13.9%和40.5%，验证了人类数据作为机器人操作策略学习基础的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.23391","title":"Policy Learning from Large Vision-Language Model Feedback without Reward Modeling","arxivId":"2507.23391","date":"2025-07-31","authors":"Chang D. Yoo Team","category":"Manipulation","summary":"本文提出PLARE方法，旨在解决离线强化学习中依赖人工设计奖励函数的瓶颈问题。该方法利用大型视觉-语言模型，直接根据语言任务描述对视觉轨迹片段生成偏好标签，并通过监督对比偏好学习目标训练策略，无需构建显式奖励模型。在MetaWorld机器人操作任务上的实验表明，PLARE性能达到或超越了现有基于VLM的奖励生成方法，并在真实物理机器人任务中验证了其有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.23053","title":"In-between Motion Generation Based Multi-Style Quadruped Robot Locomotion","arxivId":"2507.23053","date":"2025-07-30","authors":"Peng Lu Team","category":"Manipulation","summary":"本文针对四足机器人因参考运动数据稀缺而难以实现多风格运动的问题，提出了一种基于中间运动生成的多风格运动控制框架。核心技术是采用CVAE运动生成器，在任意起止状态间合成符合物理约束与关节位相连续性的多步态运动序列。实验表明，基于生成数据训练的模仿策略显著提升了速度跟踪性能和控制器稳定性，并成功在真实机器人上实现了包括疾跑、三足、小跑和溜蹄在内的复杂运动。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.22380","title":"Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations","arxivId":"2507.22380","date":"2025-07-30","authors":"Brendan Tidd Team","category":"Manipulation","summary":"该论文针对机器人模仿学习在环境变化下泛化能力差的问题，指出其核心原因是观察数据中的“因果混淆”——模型错误关联了任务无关特征与专家动作。为消除混淆，作者提出Causal-ACT方法，将因果结构学习嵌入基于Transformer的策略模型（如ACT），无需依赖解纠缠表征，可直接从卷积编码器（如ResNet-18）中学习观察分量与动作间的因果关系。实验在MuJoCo仿真的ALOHA双手机器人臂上进行，结果表明该方法能显著缓解现有模仿学习算法的泛化问题。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.22042","title":"A Nonlinear MPC Framework for Loco-Manipulation of Quadrupedal Robots with Non-Negligible Manipulator Dynamics","arxivId":"2507.22042","date":"2025-07-29","authors":"Kaveh Akbari Hamed Team","category":"Manipulation","summary":"本文针对带不可忽略动态效应机械臂的四足机器人移动操作控制问题，提出一种高效非线性模型预测控制框架。关键技术包括：采用分解策略，将用于运动的单刚体模型与机械臂全阶动态模型耦合；构建分层控制架构，NMPC以60Hz实时求解轨迹，由500Hz的全身控制器跟踪，机械臂扭矩指令直接应用。在Unitree Go2机器人加装Kinova机械臂的硬件实验中，该框架表现出鲁棒稳定性，能有效处理外部扰动、负载变化与不平地形。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.22028","title":"From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning","arxivId":"2507.22028","date":"2025-07-29","authors":"Bolei Zhou Team","category":"Manipulation","summary":"本文针对仅靠离线数据训练的导航基础模型缺乏交互推理与安全适应能力的问题，提出S2E学习框架，通过强化学习提升模型交互性。关键技术包括：用于稳定离线预训练的Anchor-Guided Distribution Matching策略，以及强化学习中避免遗忘预训练知识的Residual-Attention Module。实验表明，S2E缓解了纯离线数据扩展的收益递减问题，证明结合交互式在线经验对扩展机器人基础模型至关重要。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.21796","title":"MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects","arxivId":"2507.21796","date":"2025-07-29","authors":"Joni Pajarinen Team","category":"Manipulation","summary":"本文针对机器人移动操作领域缺乏可变形物体标准化基准测试的问题，提出了首个移动操作可变形物体任务套件MoDeSuite。该套件包含8个涉及弹性和塑性变形的任务，要求机器人基座与机械臂协同工作并利用物体形变特性。作者使用两种强化学习和两种模仿学习算法在仿真中进行了基准测试，并成功将训练策略迁移至真实的Spot机器人，验证了仿真到现实的迁移潜力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.21533","title":"Model Predictive Adversarial Imitation Learning for Planning from Observation","arxivId":"2507.21533","date":"2025-07-29","authors":"Byron Boots Team","category":"Manipulation","summary":"本文提出MPAIL方法，旨在解决仅从模糊、不完整的观察数据中学习可靠规划策略的问题。核心方法是将模型预测控制（MPC）代理嵌入对抗模仿学习（AIL）框架，替代传统策略网络，实现端到端的从观察中学习成本函数。该方法在模拟和真实导航实验中，仅需极少甚至单次观察演示，即显著提升了样本效率、分布外泛化能力和鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.21452","title":"Retrieve-Augmented Generation for Speeding up Diffusion Policy without Additional Training","arxivId":"2507.21452","date":"2025-07-29","authors":"Yutaka Matsuo Team","category":"Manipulation","summary":"本文针对机器人控制中扩散策略推理速度慢的问题，提出RAG-Diffusion方法，无需额外训练即可加速。其核心是结合检索增强生成（RAG）与扩散模型，在推理时通过检索历史数据中的相似轨迹，为扩散过程提供高质量的初始噪声，从而减少去噪步数。实验表明，该方法在多个机器人操控任务上，能达到与原始扩散策略相近的性能，同时将推理速度提升了1.5至2.3倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.21225","title":"Fluidically Innervated Lattices Make Versatile and Durable Tactile Sensors","arxivId":"2507.21225","date":"2025-07-28","authors":"Daniela Rus Team","category":"Manipulation","summary":"本文针对现有触觉传感器在耐用性、集成与制造复杂性方面的挑战，提出了一种基于“流体神经支配”的新型触觉传感方案。核心技术是采用单材料3D打印制造内置密封气道的弹性体晶格结构，通过检测气道内压力变化来感知触觉。该方法实现了简单、可扩展的单步制造。实验通过神经网络准确预测了接触位置与力，并集成了导纳控制器模拟类弹簧行为，验证了传感器在高冲击与循环负载下的高耐用性，为机器人灵巧操作提供了新途径。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.20622","title":"FMimic: Foundation Models are Fine-grained Action Learners from Human Videos","arxivId":"2507.20622","date":"2025-07-28","authors":"Yufeng Yue Team","category":"Manipulation","summary":"论文FMimic致力于解决从人类视频中学习细粒度动作的核心问题，旨在提升动作识别的精度和细节捕捉能力。关键技术为FMimic框架，它利用基础模型（如预训练的大型模型）的泛化能力，通过适配和特征提取从视频中学习精细动作表示。实验部分验证了方法的有效性，但具体性能提升数据需参考论文正文内容。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.20445","title":"Learning Physical Interaction Skills from Human Demonstrations","arxivId":"2507.20445","date":"2025-07-28","authors":"Kwonjoon Lee Team","category":"Manipulation","summary":"本文研究如何让形态各异的智能体从人类演示中学习全身物理交互技能（如握手、跳舞）。针对现有方法难以跨形态泛化的问题，提出**BuddyImitation框架**，其核心是提取一个紧凑、可迁移的**嵌入式交互图（EIG）**来表示交互动态的时空关系，并以此为模仿目标在物理仿真中训练控制策略。实验表明，该方法能使双足、四足移动操作机器人等多种形态的智能体，成功学习到语义合理且物理可行的交互行为。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.17462","title":"ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents","arxivId":"2507.17462","date":"2025-07-23","authors":"Hesheng Wang Team","category":"Manipulation","summary":"本文针对机器人模仿学习中4D多视角序列图像数据稀缺且编辑方法缺失的问题，提出了ERMV数据增强框架。其核心技术包括：用于保证运动模糊时空一致性的Epipolar Motion-Aware Attention机制；通过解耦时空视图与稀疏采样以扩大编辑窗口、降低计算成本的Sparse Spatio-Temporal模块；以及利用多模态大语言模型进行反馈干预以减轻错误累积的机制。实验表明，ERMV增强的数据显著提升了VLA模型在仿真与真实环境中的鲁棒性和泛化能力，并能有效缩小仿真到现实的差距。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.17309","title":"Confounded Causal Imitation Learning with Instrumental Variables","arxivId":"2507.17309","date":"2025-07-23","authors":"Zhi Geng Team","category":"Manipulation","summary":"本文针对模仿学习中未测量混杂变量导致策略估计偏差的核心问题，提出**混淆因果模仿学习（C2L）模型**。其关键技术是**利用工具变量（IV）** 解决混杂，并开发了一个**两阶段框架**：第一阶段通过定义伪变量构建测试准则，识别有效的工具变量；第二阶段利用识别出的IV，通过基于模拟器或离线的策略学习方法进行优化。实验验证了该方法在识别有效工具变量及学习策略方面的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.17275","title":"Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning","arxivId":"2507.17275","date":"2025-07-23","authors":"Takamitsu Matsubara Team","category":"Manipulation","summary":"本文针对机器人在不确定环境中使用通用工具时，如何学习既能完成任务又能延长工具寿命的策略这一核心问题，提出了一种寿命引导的强化学习框架。该方法通过有限元分析和米纳法则估计工具的剩余使用寿命，并将其整合为强化学习的奖励信号，同时引入自适应奖励归一化机制以稳定学习过程。在模拟和真实的物体移动、开门等任务中验证，所学策略能显著延长工具寿命（模拟中最高达8.01倍），并能有效迁移到现实场景。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.17141","title":"Towards Human-level Intelligence via Human-like Whole-Body Manipulation","arxivId":"2507.17141","date":"2025-07-23","authors":"Zhaohui An Team","category":"Manipulation","summary":"本文致力于构建能完成日常任务的通用智能机器人，核心挑战包括：设计安全的类人硬件、开发直观的全身遥操作数据收集界面、以及从人类演示中学习全身视觉运动策略的算法。为此，作者提出**Astribot Suite**统一框架，集成安全机器人硬件、全身遥操作界面及基于模仿学习（如DuoCore-WB策略）的算法。实验表明，该系统能成功完成递饮料、存猫粮、扔垃圾、整理鞋子等多种需要全身协调、广泛触及和类人灵巧性的日常任务，验证了其在现实场景中实现通用全身操作的可行性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.17049","title":"Evaluating Uncertainty and Quality of Visual Language Action-enabled Robots","arxivId":"2507.17049","date":"2025-07-22","authors":"Aitor Arrieta Team","category":"Manipulation","summary":"本文针对视觉语言动作（VLA）模型在机器人操作任务中现有评估方法（仅依赖二元成功率）的不足，提出了一套包含8个不确定性指标和5个质量指标的新评估体系。通过对3个先进VLA模型在4项任务上的908次成功执行进行大规模实证研究，并结合领域专家的人工质量标注，分析指标与人工评估的相关性。结果表明，多个指标与专家评判呈现中等到强相关性，能有效评估执行质量与模型置信度，部分指标还可区分高、中、低质量执行，为VLA模型的实时监控与自适应增强提供了新途径。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.16842","title":"Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning","arxivId":"2507.16842","date":"2025-07-19","authors":"Charlie C. L. Wang Team","category":"Manipulation","summary":"本文针对冗余软体机械臂在未知外部载荷和受限环境下运动学控制困难的问题，提出一种传感器空间模仿学习运动学控制（SS-ILKC）框架。该方法采用双学习策略：基于强化学习的多目标传感器空间控制处理开放空间；生成对抗模仿学习从稀疏专家演示中学习受限空间策略。通过预处理仿真到现实迁移机制，实现零样本真实部署。实验表明，该方法能有效控制气动软体机械臂，在未知载荷的受限环境中完成精确路径跟踪与物体操作。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.16815","title":"ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning","arxivId":"2507.16815","date":"2025-07-22","authors":"Fu-En Yang Team","category":"Manipulation","summary":"本文针对视觉-语言-动作推理任务中，现有端到端模型缺乏显式推理、难以实现长时程规划和适应复杂任务的问题，提出ThinkAct双系统框架。其核心方法通过强化视觉潜在规划连接高层推理与低层执行：训练多模态LLM生成基于目标完成和轨迹一致性的动作对齐视觉奖励的推理计划，并压缩为视觉潜在表示以条件化下游动作模型。实验在具身推理和机器人操作基准上验证，ThinkAct实现了少样本适应、长时程规划和自校正行为。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.16139","title":"Equivariant Goal Conditioned Contrastive Reinforcement Learning","arxivId":"2507.16139","date":"2025-07-22","authors":"Robert Platt Team","category":"Manipulation","summary":"本文提出等变目标条件对比强化学习（ECRL），解决目标条件强化学习中样本效率低和空间泛化能力差的问题。方法核心是构建旋转不变的目标条件MDP形式化框架，设计旋转不变评论家与旋转等变行动者进行对比学习。实验表明，该方法在多种仿真任务（状态与图像输入）中均优于基线，并成功扩展至离线强化学习设置。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.15833","title":"Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers","arxivId":"2507.15833","date":"2025-07-21","authors":"Iman Soltani Team","category":"Manipulation","summary":"本文针对机器人视觉处理被动均匀、效率低且鲁棒性差的问题，探索通过模仿人类注视和中央凹视觉来提升性能。提出GIAVA系统，扩展AV-ALOHA平台以收集眼动追踪和操作数据，并集成中央凹Vision Transformers，采用中央凹补丁标记化方案减少计算令牌。研究了独立预测注视的两阶段模型和端到端联合估计方法。实验表明，该方法显著降低计算开销，增强对背景干扰的鲁棒性，并在高精度任务中提高成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.15693","title":"Strong, Accurate, and Low-Cost Robot Manipulator","arxivId":"2507.15693","date":"2025-07-21","authors":"Donghyun Kim Team","category":"Manipulation","summary":"本文旨在设计一款低成本、高性能的6自由度教育用机械臂Forte。核心问题是如何以低于400美元的材料成本，实现接近工业级的性能（如半米工作空间、0.5公斤以上负载、亚毫米重复精度）。关键技术包括采用全3D打印轻量化结构、基于绞盘的缆线驱动与同步带传动、简单张力机构以及拓扑优化，以最小化背隙并保持控制精度，无需昂贵的高功率电子元件或制造工艺。实验表明，Forte以低于215美元的成本，实现了0.63公斤负载、0.467米工作范围及亚毫米级重复精度。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.15597","title":"Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos","arxivId":"2507.15597","date":"2025-07-21","authors":"Zongqing Lu Team","category":"Manipulation","summary":"本文提出Being-H0模型，旨在解决现有视觉-语言-动作模型因依赖合成或遥操作数据而导致的灵巧操作能力不足、泛化性差的问题。方法核心是**物理指令调优**范式，结合大规模人类视频预训练、物理空间对齐与机器人任务适应，并采用**部分级运动标记化**实现毫米级手部轨迹建模。实验表明，该模型在手部运动生成与指令遵循方面表现优异，且能有效迁移至真实机器人操作任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.15493","title":"GR-3 Technical Report","arxivId":"2507.15493","date":"2025-07-22","authors":"Yichu Yang Team","category":"Manipulation","summary":"论文旨在解决通用机器人策略开发的核心挑战：泛化到新对象、环境和抽象指令、高效适应新设置，以及可靠执行长时程灵巧任务。GR-3是一个大规模视觉-语言-动作模型，关键技术包括与网络规模视觉-语言数据共同训练、基于VR人类轨迹数据的高效微调以及机器人轨迹数据模仿学习。实验表明，GR-3在广泛真实世界任务中超越了最先进的基线方法π0。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.15073","title":"Reinforcement Learning for Flow-Matching Policies","arxivId":"2507.15073","date":"2025-07-20","authors":"Somayeh Sojoudi Team","category":"Manipulation","summary":"本文针对流匹配策略依赖次优演示数据导致性能受限的核心问题，提出通过强化学习提升策略性能。关键技术包括奖励加权流匹配（RWFM）和群体相对策略优化（GRPO）两种方法，并引入可变规划时域的流匹配方案以优化最小时间控制。在模拟单车动力学任务上的实验表明，两种方法均显著超越演示者性能，其中GRPO方法相比朴素模仿学习流匹配（ILFM）成本降低50%至85%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.15062","title":"Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper","arxivId":"2507.15062","date":"2025-07-20","authors":"Yunzhu Li Team","category":"Manipulation","summary":"本文针对现有手持夹持器缺乏触觉反馈、难以支持精细操作的问题，提出一种集成触觉传感器的便携式视觉-触觉夹持器硬件，以及跨模态表示学习框架。该框架融合视觉与触觉信号，保留各自特性，学习关注物理交互接触区域的可解释表征。在试管插入、移液管流体转移等精细操作任务中，该方法提升了操作的准确性与鲁棒性，尤其在存在外部干扰时表现更优。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.14967","title":"Heterogeneous object manipulation on nonlinear soft surface through linear controller","arxivId":"2507.14967","date":"2025-07-20","authors":"Andres Faiña Team","category":"Manipulation","summary":"本文针对软体操作表面因高自由度导致控制复杂、难以泛化处理异质物体的问题，提出一种基于几何变换驱动的PID线性闭环反馈控制策略。该方法通过直接映射倾斜角控制输出至执行器指令，避免了复杂的黑盒训练需求。在仿真和物理系统（MANTA-RAY）上的实验表明，该控制器能成功操纵不同几何形状、重量及纹理的物体（包括鸡蛋、苹果等易碎物品），实现了高度泛化，为软体机器人操作提供了实用可靠的解决方案。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.14820","title":"KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning","arxivId":"2507.14820","date":"2025-07-20","authors":"Guangyao Zhai Team","category":"Manipulation","summary":"本文针对6-DoF机器人抓取估计中现有方法对小物体和传感器噪声敏感、依赖昂贵3D注释或存在离散化问题，提出KGN-Pro网络。该方法通过概率PnP层学习2D-3D对应关系，利用RGB-D图像生成关键点图和置信图，加权重投影误差以实现端到端优化。实验表明，KGN-Pro在抓取覆盖率和成功率上优于现有方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.14582","title":"BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives","arxivId":"2507.14582","date":"2025-07-19","authors":"Yongchun Fang Team","category":"Manipulation","summary":"该论文针对机器人难以将从演示中学到的长时域操作技能泛化至新场景（尤其是有复杂时空约束的多阶段任务）的问题，提出了一种结合行为树（BT）、时序逻辑（TL）与动态运动基元（DMPs）的分层框架BT-TL-DMPs。其核心方法使用时序逻辑（STL）形式化任务约束并生成反应式行为树进行高层决策，并提出STL约束的DMP优化方法，在保持所学动态特性的同时使运动基元满足复杂约束。仿真与实物实验表明，该框架有效弥合了符号规划与运动执行间的差距，提升了复杂机器人操作任务的可靠性与泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.13602","title":"Improving Low-Cost Teleoperation: Augmenting GELLO with Force","arxivId":"2507.13602","date":"2025-07-18","authors":"Kai Arulkumaran Team","category":"Manipulation","summary":"本文针对低成本遥操作系统GELLO仅支持关节位置控制、缺乏力信息的问题进行改进。核心方法包括：实现力反馈，使用户能感知环境阻力；并将力信息融入模仿学习的数据收集与训练过程。在Franka Panda机械臂上的实验表明，有机器人经验的用户更偏好该控制器，且力信息的加入在多数模拟和真实灵巧操作任务中提升了任务成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.13088","title":"ZipMPC: Compressed Context-Dependent MPC Cost via Imitation Learning","arxivId":"2507.13088","date":"2025-07-17","authors":"Johannes A. Stork Team","category":"Manipulation","summary":"本文解决模型预测控制（MPC）因计算负担重而被迫使用短预测时域，导致难以设计反映长期目标的成本函数的问题。提出ZipMPC方法，其关键技术是通过模仿学习，利用可微分MPC与神经网络，为短时域MPC学习一个压缩的、上下文相关的成本函数。在自动驾驶赛车实验中，ZipMPC比基线方法更快完成圈数，圈速接近长时域MPC，且在训练未见的赛道上也能成功泛化。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.12898","title":"Generalist Bimanual Manipulation via Foundation Video Diffusion Models","arxivId":"2507.12898","date":"2025-07-17","authors":"Jun Zhu Team","category":"Manipulation","summary":"本文针对机器人双手操作泛化能力不足的问题，提出利用大规模预训练的视频扩散模型作为基础，构建通用的双手操作策略。方法核心是通过动作预测网络处理多视角视觉输入，并利用扩散模型的自注意力机制隐式学习动作序列。在包含多种物体与任务的模拟及真实环境实验中，该方法展现出强大的零样本泛化能力，在真实机器人平台上任务平均成功率超过70%，显著优于传统方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.12856","title":"Supervised Fine Tuning on Curated Data is Reinforcement Learning (and can be improved)","arxivId":"2507.12856","date":"2025-07-17","authors":"Jost Tobias Springenberg Team","category":"Manipulation","summary":"本文揭示了在精选数据上进行监督微调（SFT）与强化学习（RL）的内在联系，指出传统SFT本质上是优化稀疏奖励下RL目标的一个宽松下界。为解决此问题，论文提出重要性加权监督微调（iw-SFT），通过为高质量数据分配更高权重来优化更紧致的RL目标边界。该方法易于实现，并可扩展至使用质量评分数据。实验表明，iw-SFT性能优于传统SFT，在AIME 2024数据集上达到66.7%，并与更复杂的RL算法竞争力相当。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.12855","title":"DEMONSTRATE: Zero-shot Language to Robotic Control via Multi-task Demonstration Learning","arxivId":"2507.12855","date":"2025-07-17","authors":"Melanie N. Zeilinger Team","category":"Manipulation","summary":"本文提出DEMONSTRATE方法，旨在解决基于大语言模型（LLMs）的机器人控制中依赖精心设计的上下文示例、且无法预先评估“幻觉”的问题。该方法避免使用LLMs直接生成复杂优化问题，核心是通过**逆最优控制**，用**任务演示**替代提示示例，并结合**多任务学习**确保任务间相似性。这降低了对工程专业知识的依赖，并能从少量演示中学习、在执行前评估幻觉。方法在桌面操作机械臂的仿真与实物实验中验证了有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.12440","title":"EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos","arxivId":"2507.12440","date":"2025-07-18","authors":"Xiaolong Wang Team","category":"Manipulation","summary":"本文提出EgoVLA模型，核心解决机器人模仿学习中真实数据收集受硬件限制、规模与多样性不足的问题。方法上，利用大规模第一视角人类视频训练视觉-语言-动作模型，预测人类手腕与手部动作，再通过逆运动学与动作重定向将其转换为机器人动作。实验基于自建的Ego Humanoid Manipulation Benchmark进行微调与评估，结果表明该方法显著优于基线，并验证了人类数据对提升策略性能的重要性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.11840","title":"The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey","arxivId":"2507.11840","date":"2025-07-16","authors":"Jiming Chen Team","category":"Manipulation","summary":"本文综述了实现人类水平灵巧机器人操作这一核心挑战的进展。论文梳理了从机械编程到具身智能、从简单夹具到多指灵巧手的演进历程，并聚焦当前阶段，重点总结了两个关键技术方向：**灵巧操作数据收集**（通过仿真、人类演示和遥操作）与**技能学习框架**（模仿学习和强化学习）。基于对现有范式与框架的概述，论文最后总结并讨论了制约该领域发展的三个关键挑战。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.11170","title":"A Robust Controller based on Gaussian Processes for Robotic Manipulators with Unknown Uncertainty","arxivId":"2507.11170","date":"2025-07-15","authors":"Ruggero Carli Team","category":"Manipulation","summary":"本文针对机器人操纵器模型不确定性未知时的精确轨迹跟踪问题，提出一种基于高斯过程回归（GPR）的鲁棒反馈线性化控制器。方法结合经典反馈线性化与GPR：利用GPR估计模型不匹配并集成到控制外环，再基于GPR提供的方差设计鲁棒项以补偿剩余不确定性。理论证明该方案能以高概率保证对期望轨迹的渐近跟踪，并在2自由度平面机器人上进行了数值验证。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.11006","title":"Enhancing Autonomous Manipulator Control with Human-in-loop for Uncertain Assembly Environments","arxivId":"2507.11006","date":"2025-07-15","authors":"Kazuya Yoshida Team","category":"Manipulation","summary":"本文针对月球任务中光照极端、地形多变、载荷不确定等挑战性环境，提出一种人在回路增强的自主机械臂控制方法，以提升太阳能板部署等操作的可靠性。关键技术结合了人在回路控制（允许操作员在模糊场景干预）、数字孪生仿真（用于迭代优化）以及基于ArUco标记的视觉反馈精确定位。系统在JAXA的人工月球环境中进行了测试，验证了其在松散土壤、低照度及动态载荷条件下的鲁棒性与可靠性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.10899","title":"Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning","arxivId":"2507.10899","date":"2025-07-15","authors":"Jun Morimoto Team","category":"Manipulation","summary":"本文针对移动操作中导航与操作解耦导致的角度偏差问题，提出了一种基于SAM2引导感知与模仿学习的物体中心方法。该方法利用视觉基础模型SAM2分割目标物体和机器人前缘的像素级掩码，并通过门控网络将其嵌入动作分块变换器，使机器人能从不同方向一致理解同一任务。在自定义移动操作器上的拾放任务实验中，相比基准方法，该模型在从多角度演示中训练时展现了更优的泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.10814","title":"Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection","arxivId":"2507.10814","date":"2025-07-14","authors":"Colin Bellinger Team","category":"Manipulation","summary":"本文研究如何使机器人通过文本指令识别并抓取物体，并能推广至未见过的物体。提出将预训练的基础目标检测模型与目标条件强化学习相结合，利用文本提示生成目标物体的掩码作为抽象目标条件。这种掩码化目标条件提供了与物体类别无关的定位线索，提升了特征共享与泛化能力。在模拟抓取任务中，该方法对训练分布内外的物体均能保持约90%的成功率，且收敛更快、获得更高回报。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.10776","title":"rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding","arxivId":"2507.10776","date":"2025-07-14","authors":"Kaiyu Hang Team","category":"Manipulation","summary":"本文针对未见物体实例分割在分布外场景中泛化性能差的问题，提出了一种无需模型的实时机器人交互分割框架rt-RISeg。其核心方法是利用机器人交互产生的相对运动，通过设计的体坐标系不变特征（BFIF）实时识别与分割物体，无需预先训练的分割模型。实验表明，该方法的平均分割准确率比最先进的UOIS方法提升27.5%，并能自主生成分割掩码作为视觉基础模型的提示以进一步提升性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.10672","title":"Vision Language Action Models in Robotic Manipulation: A Systematic Review","arxivId":"2507.10672","date":"2025-07-14","authors":"Irfan Hussain Team","category":"Manipulation","summary":"本文系统综述了视觉语言动作（VLA）模型在机器人操作领域的研究。核心问题是解决传统任务特定编程机器人难以适应动态非结构化环境的局限，旨在通过统一视觉、语言与控制的单一学习框架，实现基于自然语言指令的通用自主操作。论文提炼了基于Transformer架构的整合关键技术，并系统分析了102个VLA模型、26个数据集和12个仿真平台。主要贡献在于提出了基于任务复杂度和多模态对齐的数据集评估新框架，并指出了当前数据格局中的未充分探索区域，为推进通用机器人智能体的发展提供了技术参考与路线图。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.10628","title":"GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning","arxivId":"2507.10628","date":"2025-07-16","authors":"Dandan Tu Team","category":"Manipulation","summary":"本文针对大语言模型（LLM）在基于可验证奖励的强化学习（RLVR）中，因训练数据难度与模型能力不匹配导致的训练不稳定和低效问题，提出了GHPO框架。其核心技术是难度感知的引导式混合策略优化，通过自适应提示精炼动态校准任务难度，平衡了针对超难任务的直接模仿学习与针对适中任务的探索性强化学习。实验表明，GHPO在六个数学基准上平均带来约5%的性能提升，显著优于现有的强策略强化学习和课程学习方法，有效提升了训练稳定性与最终推理能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.10543","title":"MP1: Mean Flow Tames Policy Learning in 1-step for Robotic Manipulation","arxivId":"2507.10543","date":"2025-07-14","authors":"Mengyuan Liu Team","category":"Manipulation","summary":"本文针对机器人操作中生成模型在扩散模型迭代采样慢与流式方法结构约束强之间的权衡问题，提出MP1方法。该方法结合3D点云输入与MeanFlow范式，通过“MeanFlow Identity”直接学习区间平均速度，无需额外一致性约束，实现单步网络评估生成动作轨迹；同时引入CFG增强可控性，并设计轻量级Dispersive Loss提升泛化能力。实验表明，MP1在Adroit和Meta-World基准上平均任务成功率比DP3和FlowPolicy分别提升10.2%和7.3%，平均推理时间仅6.8毫秒，比DP3快19倍、比FlowPolicy快近2倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.10284","title":"Prompt Informed Reinforcement Learning for Visual Coverage Path Planning","arxivId":"2507.10284","date":"2025-07-14","authors":"Venkat Margapuri Team","category":"Manipulation","summary":"这篇论文针对视觉覆盖路径规划（VCPP）问题，提出了一种提示信息强化学习（PIRL）方法。其关键技术要点包括：1）设计平衡计算表达与现实参数（倾斜、平移、缩放范围）的无人机状态空间；2）提出PARE奖励机制，将大语言模型（LLM）的语义指导融入强化学习，其中相机参数对齐作为必须遵循的硬约束，而移动对齐则作为可灵活调整的软约束。由于提供的正文节选为附录设计原理部分，未包含具体实验设置、对比方法与性能提升数据，因此无法给出核心实验结论。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.10174","title":"Should We Ever Prefer Decision Transformer for Offline Reinforcement Learning?","arxivId":"2507.10174","date":"2025-07-14","authors":"Keith Ross Team","category":"Manipulation","summary":"本文质疑决策 Transformer（DT）在离线强化学习中的优越性，特别是针对稀疏奖励环境。通过提出一种简单的过滤行为克隆（FBC）方法——即先过滤掉低性能轨迹，再对剩余数据执行普通行为克隆——并在机器人操作（Robomimic）与运动（D4RL）任务上进行实验。结果表明，FBC 在多数稀疏奖励设置中优于 DT：在 D4RL 的 9 个数据集中，FBC 在 7 个上表现更好，整体性能提升约 4%；在 Robomimic 的两个数据集中均超越 DT。因此，论文认为 DT 并非稀疏奖励环境的优选方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.10158","title":"MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping","arxivId":"2507.10158","date":"2025-07-16","authors":"Monowar Bhuyan Team","category":"Manipulation","summary":"本文提出MTF-Grasp方法，旨在解决机器人抓取任务中联邦学习面临的数据非独立同分布且数量不足导致的性能下降问题。该方法采用多层联邦学习框架，依据数据质量和数量筛选出“顶级”机器人训练初始种子模型，再分发给“低级”机器人以提升整体训练效果。实验表明，该方法在Cornell和Jacquard抓取数据集上比传统联邦学习性能提升最高达8%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.09540","title":"Learning to Control Dynamical Agents via Spiking Neural Networks and Metropolis-Hastings Sampling","arxivId":"2507.09540","date":"2025-07-13","authors":"Ali Al-Zawqari Team","category":"Manipulation","summary":"本文针对脉冲神经网络在强化学习中因脉冲通信不可微分而难以训练的问题，提出首个基于Metropolis-Hastings采样的训练框架。该方法利用贝叶斯推断，通过迭代提议并依概率接受基于累积奖励的参数更新，绕过了反向传播，实现了在神经形态平台上的直接优化。在AcroBot和CartPole控制基准上的实验表明，该框架在最大化累积奖励的同时，能以更少的网络资源和训练周期，优于传统深度Q学习及先前的SNN强化学习方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.09459","title":"SegVec3D: A Method for Vector Embedding of 3D Objects Oriented Towards Robot manipulation","arxivId":"2507.09459","date":"2025-07-13","authors":"Boyu Wang Team","category":"Manipulation","summary":"SegVec3D旨在解决机器人操作中3D点云实例分割的挑战，包括点云稀疏性、无序性以及有限监督下的跨模态语义对齐难题。方法集成注意力机制和嵌入学习，通过基于空间邻接的分层特征提取器捕获几何结构，利用对比学习聚类实现无监督实例分割，并构建共享语义空间对齐点云与自然语言。实验验证该方法具备高语义可区分性、鲁棒的多模态对齐和实际部署可行性，支持弱监督或无监督的3D实例理解。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.09180","title":"Learning and Transferring Better with Depth Information in Visual Reinforcement Learning","arxivId":"2507.09180","date":"2025-07-15","authors":"Jingdong Zhao Team","category":"Manipulation","summary":"本文针对视觉强化学习中样本效率低、泛化能力差及仿真到现实（sim2real）转移困难的核心问题，提出利用深度信息增强鲁棒性和空间感知。关键技术包括基于视觉Transformer的多模态融合骨干网络，先通过独立CNN stems分别处理RGB和深度模态，再经可扩展Transformer融合特征；并设计对比无监督学习方案，使用掩码与未掩码令牌提升训练效率。实验表明，该方法能更聚焦任务相关区域，在未见场景中表现出更好的泛化能力，且通过零样本转移成功验证了真实世界操作任务的可行性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.09167","title":"PRAG: Procedural Action Generator","arxivId":"2507.09167","date":"2025-07-12","authors":"Karla Stepanova Team","category":"Manipulation","summary":"本文提出PRAG过程动作生成器，旨在解决机器人强化学习中多步骤接触操作任务数据稀缺的核心问题。该方法以用户定义的原子动作、对象和谓词为输入，通过符号验证（逻辑与操作一致性）和物理验证（环境可解性）双重约束，生成可解的任务序列。实验表明，PRAG能生成最多15步的序列，产生数百万个独特可解多步骤任务，显著扩充了训练数据集。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.09117","title":"Towards Human-level Dexterity via Robot Learning","arxivId":"2507.09117","date":"2025-07-12","authors":"Gagan Khandate Team","category":"Manipulation","summary":"本文旨在通过机器人学习实现人类水平的灵巧操作能力。然而，所提供的正文节选仅包含文献引用格式的LaTeX代码指令（如 \\addbibresource、\\AtEveryBibitem 等），并未涉及具体的研究方法、技术细节或实验结果。因此，无法从给定内容中提炼关键技术要点及核心实验结论。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.09061","title":"Imitation Learning in Continuous Action Spaces: Mitigating Compounding Error without Interaction","arxivId":"2507.09061","date":"2025-07-11","authors":"Max Simchowitz Team","category":"Manipulation","summary":"本文针对连续控制中模仿学习因任务时长而指数级增加的复合错误问题，提出理论分析。核心方法是**动作分块**（预测开环动作序列）和**通过噪声注入的探索性数据收集**。研究指出，**控制理论稳定性**是这些干预措施起效的关键机制：动作分块通过稳定的开环动态保证策略行为稳定，探索性数据则增强了专家轨迹附近最易产生复合错误方向的监督。理论分析表明，该视角比单纯信息论方法提供了更精细的见解和更严格的误差保证，并在机器人学习基准实验中得到了验证。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.09041","title":"Behavioral Exploration: Learning to Explore via In-Context Adaptation","arxivId":"2507.09041","date":"2025-07-11","authors":"Sergey Levine Team","category":"Manipulation","summary":"本文针对强化学习中智能体在未知环境中探索效率低的问题，提出“行为探索”方法。该方法的核心是**通过上下文适应学习探索策略**，使智能体能够根据当前任务上下文动态调整探索行为，而无需进行耗时的参数更新。实验表明，该方法在稀疏奖励的连续控制任务中显著提升了探索效率，其采样效率优于传统元强化学习和基于内在奖励的方法，成功解决了复杂任务中的探索挑战。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.08726","title":"Learning human-to-robot handovers through 3D scene reconstruction","arxivId":"2507.08726","date":"2025-07-11","authors":"Changjae Oh Team","category":"Manipulation","summary":"本文解决了人机交接任务中，从仿真到真实环境的视觉域差距问题。提出了H2RH-SGS方法，其核心是利用**稀疏视图高斯泼溅**进行3D场景重建，从RGB图像生成逼真的交接场景模拟数据，并将虚拟相机位姿变化直接映射为真实机器人夹爪的运动。实验表明，该方法仅使用16个日常物体的重建数据训练策略，便可**直接部署到真实机器人**上完成交接任务，验证了其作为人机交接任务新表征的有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.08303","title":"Learning Robust Motion Skills via Critical Adversarial Attacks for Humanoid Robots","arxivId":"2507.08303","date":"2025-07-11","authors":"Yue Gao Team","category":"Manipulation","summary":"本文针对人形机器人运动策略在长时间运行、噪声及干扰下稳定性不足的问题，提出一种**选择性对抗攻击鲁棒训练方法（SA2RT）**。该方法通过**学习对抗攻击者**，在攻击预算约束下**稀疏扰动最脆弱的状态与动作**，暴露策略真实弱点，并采用**非零和交替优化**持续强化策略。在Unitree G1人形机器人上的实验表明，经对抗训练的策略**地形穿越成功率提升40%**，**轨迹跟踪误差降低32%**，显著增强了长时程运动的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.08262","title":"CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations","arxivId":"2507.08262","date":"2025-07-11","authors":"He Wang Team","category":"Manipulation","summary":"论文CL3R致力于解决机器人操作中3D视觉表示学习不足的问题，以增强操作策略。其核心方法整合了点云掩码自编码器进行3D重建以学习空间感知，并采用对比学习从预训练2D基础模型迁移语义知识。通过统一数据集坐标系和随机融合多视点点云，减轻相机视点模糊性，提升泛化能力。实验在仿真和真实环境中验证了该方法的优越性，有效提升了机器人视觉运动策略学习的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.08112","title":"Imitation Learning for Obstacle Avoidance Using End-to-End CNN-Based Sensor Fusion","arxivId":"2507.08112","date":"2025-07-10","authors":"Raafat E. Shalaby Team","category":"Manipulation","summary":"本文针对移动机器人在已知和未知环境中的避障导航问题，提出了一种基于端到端卷积神经网络（CNN）与传感器融合的模仿学习方法。核心方案是设计并训练两个定制CNN模型，融合深度相机采集的彩色与深度图像，直接输出机器人转向所需的角速度命令。研究收集了包含不同光照与动态障碍的新视觉数据集，并利用ROS系统同步记录图像与转向数据。通过均方误差、方差得分及前馈时间等多项指标对比评估了两个网络的性能，明确了更适用于实际应用的网络模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.07986","title":"EXPO: Stable Reinforcement Learning with Expressive Policies","arxivId":"2507.07986","date":"2025-07-15","authors":"Chelsea Finn Team","category":"Manipulation","summary":"本文针对在线强化学习中训练表达性策略（如扩散策略）时，因长去噪链导致梯度传播不稳定、难以实现稳定价值最大化的问题，提出了EXPO算法。该方法避免直接优化表达性策略的价值，而是构建即时策略，结合通过模仿学习稳定训练的基础策略和轻量高斯编辑策略，编辑动作以提升价值分布，并从基础与编辑动作中选择价值最大化动作进行优化。实验表明，在微调预训练策略及利用离线数据在线训练时，该方法的样本效率平均比先前方法提升2-3倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.07969","title":"Reinforcement Learning with Action Chunking","arxivId":"2507.07969","date":"2025-07-15","authors":"Sergey Levine Team","category":"Manipulation","summary":"根据您提供的论文标题《Reinforcement Learning with Action Chunking》，**由于未提供论文正文内容**，以下总结仅基于标题进行合理推断，无法包含具体方法细节和实验数据：\n\n该论文很可能**针对强化学习中高频决策或长期规划效率低下的问题**，提出了一种名为 **“动作分块”** 的核心技术。其要点在于将一系列基础动作组合成更高层级的“块”或“宏动作”，智能体以此为单位进行决策，从而**减少决策频率、扩大时间尺度上的规划范围**。该方法预期能**提升学习效率、稳定性和在复杂任务中的长期性能**。\n\n请提供论文正文以获得精准、具体的总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06822","title":"Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand","arxivId":"2507.06822","date":"2025-07-09","authors":"Xinjun Sheng Team","category":"Manipulation","summary":"本文针对机器人使用多指手操作镊子等关节工具的难题，提出一种分层目标条件强化学习框架。方法包含两层策略：底层策略控制灵巧手调整工具开合以适配不同尺寸物体；高层策略规划工具目标状态并操控机械臂进行抓取。关键技术包括基于合成点云训练的编码器估计工具可供性状态，以及采用特权启发式策略提升训练效率。真实实验表明，该框架能使机器人操作镊子成功抓取多样物体，成功率可达70.8%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06780","title":"Learning safe, constrained policies via imitation learning: Connection to Probabilistic Inference and a Naive Algorithm","arxivId":"2507.06780","date":"2025-07-09","authors":"George A. Vouros Team","category":"Manipulation","summary":"本文提出一种模仿学习方法，用于学习符合专家轨迹约束的最大熵策略。核心问题是在熵最大化框架下，通过模仿学习获得既满足安全约束又能优化累积奖励的策略。关键技术采用对偶梯度下降法，结合拉格朗日松弛将约束遵守目标与强化学习目标统一优化，并利用SAC算法调节策略熵。实验表明，该方法能有效学习多种约束类型下的策略模型，适应不同专家行为模态，并具备泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06710","title":"Spatial-Temporal Aware Visuomotor Diffusion Policy Learning","arxivId":"2507.06710","date":"2025-07-13","authors":"Yanwei Fu Team","category":"Manipulation","summary":"本文提出4D Diffusion Policy (DP4)，旨在解决现有视觉模仿学习方法因依赖轨迹克隆而缺乏3D空间与4D时空感知能力的问题。该方法通过动态高斯世界模型引导学习，从单视角RGB-D观测构建当前3D场景并预测未来3D场景，显式建模时空依赖以优化轨迹生成。实验在17个仿真任务（173个变体）和3个真实机器人任务上验证，DP4平均成功率在仿真任务上提升16.4%（Adroit）、14%（DexArt）和6.45%（RLBench），在真实任务上平均提升8.6%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06701","title":"Value from Observations: Towards Large-Scale Imitation Learning via Self-Improvement","arxivId":"2507.06701","date":"2025-07-09","authors":"Martin Riedmiller Team","category":"Manipulation","summary":"本文研究从观察中模仿学习（IfO）的核心问题：如何利用无动作标签的专家示范和可能不匹配的非专家动作数据，实现大规模、可扩展的行为学习。提出一种关键技术方法，通过价值函数在专家与非专家数据间传递信息，将基于强化学习的模仿学习适配到无动作示范场景。实验评估了不同数据分布下算法的适用性，揭示了现有方法的局限，为开发更鲁棒、实用的IfO技术提供了关键见解。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06628","title":"Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning","arxivId":"2507.06628","date":"2025-07-09","authors":"Jian Cheng Team","category":"Manipulation","summary":"本文针对离线多任务强化学习中知识共享效率低的挑战，提出目标导向的技能抽象方法GO-Skill。该方法通过面向目标的技能提取和向量量化构建离散技能库，并引入技能增强阶段平衡技能分布，最后通过分层策略学习动态组合技能以解决不同任务。在MetaWorld机器人操作任务上的实验验证了该方法的有效性和泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06625","title":"Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic","arxivId":"2507.06625","date":"2025-07-09","authors":"Fabio Ramos Team","category":"Manipulation","summary":"本文提出Q-STAC框架，以解决深度强化学习在机器人操作任务中样本效率低、值估计偏差大，以及现有基于模型方法存在高模型偏差、依赖人工设计成本函数、计算开销大的问题。方法核心是融合贝叶斯模型预测控制与软演员-评论家，采用Stein变分梯度下降，在Q值引导下迭代优化从学习先验分布采样的动作序列，从而免去手工设计成本函数；通过短视距模型预测展开降低累积预测误差。实验表明，Q-STAC在模拟导航、机器人操作及真实水果采摘任务中，相比各类基线在样本效率、稳定性和整体性能上均取得更优结果。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06543","title":"Token Bottleneck: One Token to Remember Dynamics","arxivId":"2507.06543","date":"2025-07-09","authors":"Sangdoo Yun Team","category":"Manipulation","summary":"本文提出Token Bottleneck (ToBo)，旨在解决动态场景中紧凑且具有时序感知的视觉表示学习问题，以提升序列场景理解（如视觉跟踪、机器人操作）的性能。其核心方法采用自监督学习框架，包含“压缩”与“扩展”两步骤：先将参考场景编码为单一瓶颈令牌，再结合少量目标图像块预测后续场景，从而迫使模型学习场景间的动态演变。实验表明，ToBo在视频标签传播与仿真机器人操作等任务上优于基线，并在真实机器人部署中验证了其有效性与可扩展性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06224","title":"EC-Flow: Enabling Versatile Robotic Manipulation from Action-Unlabeled Videos via Embodiment-Centric Flow","arxivId":"2507.06224","date":"2025-07-08","authors":"Liang Wang Team","category":"Manipulation","summary":"本文提出EC-Flow框架，解决现有语言引导机器人操作系统依赖动作标注数据、且基于物体中心流的方法难以处理可变形物体、遮挡及非位移任务的问题。其关键技术为**Embodiment-Centric Flow预测**，通过融入机器人本体运动学先验提升泛化能力，并引入**目标对齐模块**联合优化运动一致性与目标图像预测。实验表明，相比此前基于物体中心流的方法，EC-Flow在遮挡物体处理（提升62%）、可变形物体操作（提升45%）及非物体位移任务（提升80%）上均取得显著性能提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06219","title":"Is Diversity All You Need for Scalable Robotic Manipulation?","arxivId":"2507.06219","date":"2025-07-08","authors":"Hongyang Li Team","category":"Manipulation","summary":"本文探讨机器人操作数据扩展的核心问题，挑战“多样性越多越好”的直觉。通过系统分析任务、体现和专家三个维度的数据多样性，发现：任务多样性比单任务数据量更重要；多体现预训练对跨平台迁移非必需；专家多样性（尤其是速度多模态）会干扰策略学习。为此提出分布去偏方法GO-1-Pro，缓解速度歧义，在性能上实现15%提升，等效于使用2.5倍预训练数据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06174","title":"Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model","arxivId":"2507.06174","date":"2025-07-08","authors":"Toshiaki Tsuji Team","category":"Manipulation","summary":"本文针对低成本、无力传感器的机械臂难以实现快速、带力反馈遥操作的问题，提出基于精确动力学模型的4通道双边控制方法。该方法整合了非线性补偿、速度与外力估计以及可变惯性增益，实现了无传感器力反馈。实验表明，利用此系统收集数据并将力信息融入模仿学习策略的输入与输出，能有效提升任务性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06172","title":"Learning Agile Tensile Perching for Aerial Robots from Demonstrations","arxivId":"2507.06172","date":"2025-07-08","authors":"Basaran Bahadir Kocer Team","category":"Manipulation","summary":"本文研究空中机器人通过系绳实现敏捷张力栖息的轨迹规划问题，旨在解决系绳引入的复杂动力学建模与控制挑战，包括处理系绳松弛/张紧状态、动量传递以及精确瞄准特定系绳段以实现可靠缠绕。提出一种基于强化学习（SACfD算法）的轨迹生成框架，通过融合最优与次优演示数据提升训练效率与控制精度。该框架在仿真和实物实验中得到了验证，能够实现敏捷、可靠的张力栖息轨迹生成。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.06053","title":"SCCRUB: Surface Cleaning Compliant Robot Utilizing Bristles","arxivId":"2507.06053","date":"2025-07-08","authors":"Jeffrey Ian Lipton Team","category":"Manipulation","summary":"本文提出柔性清洁机器人SCCRUB，旨在解决传统刚性机械臂在人类共存环境中清洁时存在安全风险，而柔性机械臂又难以提供持续扭矩或侧向力以清除顽固污渍的核心问题。关键技术包括：1）采用肌腱驱动柔性臂，并在末端安装刷头，通过同心轴结构传递扭矩；2）训练神经网络学习机械臂的逆运动学与弹性特性，实现开环力与位置控制。实验表明，该机器人能安全有效地清除盘子上的烧焦残渣和马桶座上的果酱，平均污染物清除率达到99.7%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.05695","title":"Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning","arxivId":"2507.05695","date":"2025-07-08","authors":"Daniel Rakita Team","category":"Manipulation","summary":"本文针对扩散策略在机器人操作学习中训练效率低下的问题，提出了一种混合扩散策略hPGA-DP。其核心创新在于引入投影几何代数（PGA）作为几何归纳偏置，并采用P-GATr网络作为状态编码器和动作解码器，以统一表示空间实体与变换；去噪核心则沿用成熟的U-Net或Transformer模块。实验表明，该混合架构在仿真和真实环境中均显著提升了任务性能与训练效率，收敛速度大幅优于标准扩散策略及纯P-GATr架构。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.05674","title":"Integrating Diffusion-based Multi-task Learning with Online Reinforcement Learning for Robust Quadruped Robot Control","arxivId":"2507.05674","date":"2025-07-08","authors":"Bin Liang Team","category":"Manipulation","summary":"本文针对扩散模型在四足机器人运动控制中应用不足的问题，提出DMLoco框架。该方法集成扩散模型多任务预训练与在线PPO微调，利用DDIM进行高效采样，并通过TensorRT优化部署，实现语言引导的鲁棒控制。核心实验表明，优化后的策略能部署于真实机器人，并以50Hz频率实时运行。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.05663","title":"Stable Tracking-in-the-Loop Control of Cable-Driven Surgical Manipulators under Erroneous Kinematic Chains","arxivId":"2507.05663","date":"2025-07-08","authors":"Michael C. Yip Team","category":"Manipulation","summary":"本文针对电缆驱动远程运动中心（RCM）手术机械臂在运动学链存在误差时的控制稳定性问题展开研究。由于关节读数误差，尤其是插入点之前处于内窥镜视野外的部分无法通过视觉校正，导致传统基于运动学的闭环控制失稳。作者提出了一种可证明稳定的“跟踪闭环控制器”，专门用于处理视野外运动学链的误差，并将其集成到一个双层控制架构中。通过在仿真和真实环境中的严格测试，验证了该控制方案的理论稳定性，为从遥操作手术向自主手术过渡提供了关键基础。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.05627","title":"DreamGrasp: Zero-Shot 3D Multi-Object Reconstruction from Partial-View Images for Robotic Manipulation","arxivId":"2507.05627","date":"2025-07-08","authors":"Frank Chongwoo Park Team","category":"Manipulation","summary":"本文提出DreamGrasp框架，旨在解决从稀疏、局部视角的RGB图像进行零样本三维多物体重建的难题，以支持机器人操作。该方法核心在于利用大规模预训练图像生成模型的推断能力，通过粗三维重建、基于对比学习的实例分割（结合表面正则化）以及文本引导的实例级细化，实现对复杂遮挡场景中未观察部分的补全。实验表明，该方法能准确恢复物体几何，并有效支持如顺序清理与目标检索等下游任务，取得较高的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.05522","title":"Gaussian Process-Based Active Exploration Strategies in Vision and Touch","arxivId":"2507.05522","date":"2025-07-07","authors":"Nadia Figueroa Team","category":"Manipulation","summary":"根据当前信息，仅能基于论文标题进行分析。该论文的核心方向是**机器人多模态感知中的主动探索**，其核心问题是**如何高效融合视觉与触觉信息来引导机器人进行自主环境探索与交互**。\n\n**推测的核心方法与要点**：\n1.  **高斯过程建模**：利用高斯过程对视觉或触觉感知的不确定性进行概率建模。\n2.  **主动探索策略**：设计基于信息增益（如预测熵减）等准则的决策策略，主动选择下一个最佳观测点或交互动作。\n\n**重要说明**：\n由于未提供论文正文，**无法提炼具体的技术实现细节、实验设置及核心性能数据**。如需精准总结，请提供论文的摘要或主要章节内容。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.05331","title":"A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation","arxivId":"2507.05331","date":"2025-07-07","authors":"Russ Tedrake Team","category":"Manipulation","summary":"本文旨在系统评估用于多任务灵巧操作的大型行为模型的实际性能。研究核心问题是解决当前对这类模型真实世界能力缺乏严谨评估的挑战。关键技术方法是扩展Diffusion Policy范式，构建了一个结合仿真与真实实验的统计评估流程，并与单任务基线进行盲测对比。核心实验结论表明：多任务预训练使策略更成功、更鲁棒，且只需少量数据就能快速学习新任务；性能随预训练规模与多样性的增加而可预测地提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.05116","title":"VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting","arxivId":"2507.05116","date":"2025-07-07","authors":"Yanzhi Wang Team","category":"Manipulation","summary":"本文针对当前视觉-语言-动作（VLA）模型存在的两大问题：生成大量令牌导致高推理延迟与训练成本、以及动作利用不足导致性能损失，提出了VOTE框架。该框架通过微调VLA模型生成更少动作令牌以提高并行性，并引入基于投票的轨迹集成策略，结合当前与历史动作预测以优化推理。实验表明，VOTE相比最先进VLA模型实现了更高成功率，推理速度比OpenVLA快39倍，在边缘平台达到46 Hz吞吐量，展现了卓越的实际可部署性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.05011","title":"When Imitation Learning Outperforms Reinforcement Learning in Surgical Action Planning","arxivId":"2507.05011","date":"2025-07-07","authors":"Sebastien Ourselin Team","category":"Manipulation","summary":"本文研究手术动作规划中模仿学习（IL）与强化学习（RL）的性能比较，核心问题是预测未来手术视频中的器械-动词-目标三元组。提出DARIL（双任务自回归模仿学习）作为基线方法，并评估了三种RL变体：基于世界模型的RL、直接视频RL和逆RL增强。实验在CholecT50数据集上进行，结果显示DARIL在动作三元组识别mAP达34.6%，下一帧预测mAP达33.6%，10秒规划视野下平滑降至29.2%；而所有RL方法均表现不佳，世界模型RL在10秒视野下mAP仅3.1%，直接视频RL为15.9%。这表明在专家标注测试集上，IL的分布匹配优于RL，挑战了RL在顺序决策中优越性的假设。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.04789","title":"Training-free Generation of Temporally Consistent Rewards from VLMs","arxivId":"2507.04789","date":"2025-07-07","authors":"Jian Tang Team","category":"Manipulation","summary":"本论文旨在解决从视觉语言模型（VLMs）中无需训练生成时间上一致奖励的核心问题。关键技术方法基于VLMs的预训练能力，通过轻量级推理机制直接提取奖励信号，确保时序一致性。实验结果表明，该方法在时间一致性指标上显著提升，并在强化学习等下游任务中实现了性能改进。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.04661","title":"DRAE: Dynamic Retrieval-Augmented Expert Networks for Lifelong Learning and Task Adaptation in Robotics","arxivId":"2507.04661","date":"2025-07-07","authors":"Mingsheng Shang Team","category":"Manipulation","summary":"本文提出DRAE架构，旨在解决机器人终身学习中的灾难性遗忘与动态任务适应问题。其核心技术融合了稀疏门控的混合专家模型进行动态路由，并引入参数化检索增强生成来利用外部知识，同时设计了包含ReflexNet、SchemaPlanner和HyperOptima的分层强化学习框架以实现持续适应与记忆保持。实验表明，在动态机器人操作任务上，DRAE平均任务成功率达82.5%，显著优于传统MoE模型的74.2%，并保持了极低的遗忘率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.04633","title":"PRISM: Pointcloud Reintegrated Inference via Segmentation and Cross-attention for Manipulation","arxivId":"2507.04633","date":"2025-07-07","authors":"Chee-Meng Chew Team","category":"Manipulation","summary":"本文提出PRISM框架，旨在解决机器人模仿学习在杂乱环境中因固定视角或点云关键帧预测限制导致的鲁棒性问题。方法核心包含三个部分：分割嵌入单元对原始点云进行物体聚类与局部几何编码；交叉注意力组件融合视觉特征与机器人状态以聚焦相关目标；扩散模块将融合表征转换为平滑动作。实验表明，仅需每任务100条演示，PRISM在模拟复杂密集场景中即超越2D与3D基线策略，表现出更高的准确率、效率与鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.04631","title":"Learning Robust Stereo Matching in the Wild with Selective Mixture-of-Experts","arxivId":"2507.04631","date":"2025-07-07","authors":"Junjie Hu Team","category":"Manipulation","summary":"本文针对立体匹配模型在真实场景中缺乏鲁棒性、跨域泛化性能差的问题，提出SMoEStereo框架。其核心是结合视觉基础模型(VFMs)，通过定制化的MoE-LoRA（动态选择专家并自适应秩）与MoE-Adapter（自适应卷积核以增强几何特征）模块，实现场景自适应的特征融合。为平衡效率，引入轻量决策网络选择性激活模块。实验表明，该方法在多个基准上无需针对数据集微调，即实现了最先进的跨域与联合泛化性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.04524","title":"VLM-TDP: VLM-guided Trajectory-conditioned Diffusion Policy for Robust Long-Horizon Manipulation","arxivId":"2507.04524","date":"2025-07-06","authors":"Lei Han Team","category":"Manipulation","summary":"本文针对扩散策略在长视界机器人操作任务中性能受限且对图像噪声敏感的问题，提出了VLM-TDP方法。该方法利用视觉语言模型（VLM）将长任务分解为子任务，并生成体素轨迹作为条件引导轨迹条件扩散策略（TDP）。实验表明，VLM-TDP在模拟环境中平均成功率比经典扩散策略提高44%，长视界任务性能提升超100%，在噪声图像等挑战下性能下降减少20%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.04447","title":"DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge","arxivId":"2507.04447","date":"2025-07-06","authors":"Xin Jin Team","category":"Manipulation","summary":"DreamVLA旨在解决现有视觉-语言-动作模型在机器人操作中依赖图像预测导致的冗余信息及缺乏全面世界知识（动态、空间、语义信息）的问题。关键技术包括：动态区域引导的世界知识预测，集成空间与语义线索以提供紧凑表示；块状结构化注意力机制，屏蔽不同信息间相互注意力以防止泄漏；基于扩散的变换器，解耦动作表示以建模未来动作分布。实验表明，该模型在真实机器人任务上达到76.7%成功率，在CALVIN ABC-D基准上平均长度为4.44。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.04331","title":"Wavelet Policy: Lifting Scheme for Policy Learning in Long-Horizon Tasks","arxivId":"2507.04331","date":"2025-07-06","authors":"Yi Fang Team","category":"Manipulation","summary":"本文提出一种用于长时程任务策略学习的小波策略框架。核心问题是解决复杂长时程任务中策略学习需处理长序列、多模态动作分布的挑战。关键技术为引入可学习的多尺度小波分解与提升方案，对观测和动作序列进行多分辨率分析，以分离全局趋势与细节噪声，从而增强策略的精确性与鲁棒性。该方法在机器人操作、自动驾驶等多个复杂场景中验证了其有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.04049","title":"Breaking Imitation Bottlenecks: Reinforced Diffusion Powers Diverse Trajectory Generation","arxivId":"2507.04049","date":"2025-07-05","authors":"Yadan Luo Team","category":"Manipulation","summary":"本文针对端到端自动驾驶中模仿学习导致的轨迹保守、模式崩溃问题，提出DIVER框架。该框架结合扩散模型生成多模式参考轨迹，并采用强化学习（Group Relative Policy Optimization）优化轨迹级多样性与安全奖励。实验在闭环NAVSIM、Bench2Drive和开环nuScenes数据集上表明，DIVER显著提升轨迹多样性，有效克服模式崩溃。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.03930","title":"RwoR: Generating Robot Demonstrations from Human Hand Collection for Policy Learning without Robot","arxivId":"2507.03930","date":"2025-07-08","authors":"Hao Dong Team","category":"Manipulation","summary":"本文解决模仿学习中直接使用人类手部演示训练机器人策略时，存在的视觉观察差异问题。提出RwoR方法，通过手腕佩戴GoPro鱼眼摄像头采集人手演示，并训练一个**手-夹持器生成模型**，将人手演示自动转换为机器人夹持器演示。该方法采用专门的数据预处理策略确保时序与观察对齐，从而**无需真实机器人即可生成用于策略训练的高质量机器人演示**。实验表明，该方法生成的演示质量高，数据收集高效实用，能实现稳健的机器人操作性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.03878","title":"DK-RRT: Deep Koopman RRT for Collision-Aware Motion Planning of Space Manipulators in Dynamic Debris Environments","arxivId":"2507.03878","date":"2025-07-05","authors":"Dezhi Yu Team","category":"Manipulation","summary":"本文提出DK-RRT方法，用于解决太空机械臂在动态碎片环境中运动规划的核心难题，即碎片运动复杂且不确定导致的轨迹规划困难。该方法深度融合深度学习、Kopman算子理论与快速探索随机树（RRT），利用深度神经网络识别碎片动力学的非线性嵌入，以增强Kopman预测能力，并通过在线传感器反馈持续优化模型，实现实时精准的主动规划。仿真实验表明，DK-RRT在适应性、鲁棒性与计算效率上均显著优于传统RRT及常规Kopman规划方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.03227","title":"Dexterous Teleoperation of 20-DoF ByteDexter Hand via Human Motion Retargeting","arxivId":"2507.03227","date":"2025-07-04","authors":"Zeyu Ren Team","category":"Manipulation","summary":"本文针对高自由度灵巧手控制中高质量人类演示数据获取的难题，提出了一种手-臂遥操作系统。核心技术包括：1）20自由度连杆驱动仿人灵巧手ByteDexter，采用新颖拇指机构与微秒级运动学求解器；2）基于优化的运动重定向方法，实现复杂人手动作的实时高保真复现与手-臂协调。实验验证表明，该系统能完成灵巧手内操作及长时程杂乱场景整理任务，具备直观的实时遥操作界面，并能生成高质量的演示数据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.02190","title":"cVLA: Towards Efficient Camera-Space VLAs","arxivId":"2507.02190","date":"2025-07-02","authors":"Thomas Brox Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型训练成本高昂的问题，提出了一种轻量高效的cVLA方法。其核心创新在于利用视觉语言模型（VLM）对2D图像的强大理解能力，直接在图像坐标系中预测机器人末端执行器的轨迹路径点，而非传统的低级控制指令。该方法采用基于PaliGemma架构的下一个令牌预测模型，并在模拟数据集上进行训练。实验表明，该模型能有效学习有意义的机器人轨迹，并展现出良好的从模拟到现实的迁移能力，在真实机器人系统上得到验证。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.01857","title":"TypeTele: Releasing Dexterity in Teleoperation by Dexterous Manipulation Types","arxivId":"2507.01857","date":"2025-07-02","authors":"Wei-Shi Zheng Team","category":"Manipulation","summary":"本文针对传统灵巧遥操作依赖手部重定向、受限于人类动作模式的问题，提出**TypeTele**系统。该方法通过构建**可扩展的灵巧操作类型库**，引入**多模态大语言模型辅助的类型检索模块**，使操作者可根据任务选择适合的机器人手操作类型，而非单纯模仿人手姿态。实验表明，该系统能充分发挥灵巧手的结构优势，在执行多样复杂任务时取得**更高的成功率**。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.01424","title":"TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control","arxivId":"2507.01424","date":"2025-07-03","authors":"Yanwei Fu Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型在动态具身环境中泛化能力弱、难以进行长时程规划的问题，提出TriVLA模型。其核心是引入受情景记忆启发的情景世界模型，通过三系统架构实现：系统2（预训练VLM）负责多模态感知，系统3（视频扩散模型）进行动态预测与未来推演，系统1（策略模块）整合时序信息生成动作。实验表明，该模型能以36Hz高效运行，在标准测试和真实操控任务上均优于基线，展现出卓越的长时程规划和开放指令理解能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.01099","title":"Geometry-aware 4D Video Generation for Robot Manipulation","arxivId":"2507.01099","date":"2025-07-01","authors":"Shuran Song Team","category":"Manipulation","summary":"本文提出一种几何感知的4D视频生成模型，旨在解决机器人操作中视频预测的跨视角几何一致性与时间连贯性难题。方法核心是通过跨视角点云对齐监督，使模型学习共享的3D场景表示，仅需每个视角的单帧RGB-D图像（无需相机位姿）即可生成时空对齐的多视角未来序列。实验表明，该方法在仿真与真实机器人数据集中均能产生更稳定、空间对齐的预测，并可利用现成6DoF姿态跟踪器从预测视频中恢复机械臂轨迹，形成泛化能力强的操作策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.01008","title":"DexWrist: A Robotic Wrist for Constrained and Dynamic Manipulation","arxivId":"2507.01008","date":"2025-07-01","authors":"Pulkit Agrawal Team","category":"Manipulation","summary":"本文针对传统机器人手腕在受限空间和动态接触任务中表现不佳的问题，提出DexWrist手腕。其关键技术包括采用低阻抗驱动、低惯量设计、集成本体感知，以实现高速度、大工作空间和自然反向驱动能力，从而简化策略学习并提升操作适应性。核心实验表明，使用DexWrist能使策略成功率提升50-55%，任务完成时间缩短至原来的1/3到1/5。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.00990","title":"Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations","arxivId":"2507.00990","date":"2025-07-04","authors":"Yunzhu Li Team","category":"Manipulation","summary":"本文提出RIGVid系统，解决机器人无需物理演示即可学习复杂操作任务的问题。方法基于视频扩散模型生成任务视频，利用视觉语言模型自动过滤不符合指令的视频，再通过6D姿态跟踪提取物体轨迹并重定向到机器人。实验表明，过滤后的生成视频与真实演示效果相当，性能随生成质量提升；生成视频监督优于VLM关键点预测，6D姿态跟踪也优于密集特征点跟踪。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.00833","title":"HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning","arxivId":"2507.00833","date":"2025-07-01","authors":"Chenjia Bai Team","category":"Manipulation","summary":"本文针对人形机器人双手机械手操作缺乏高质量演示数据的问题，提出了HumanoidGen自动化框架。其核心技术是利用原子灵巧操作进行空间标注，并借助LLM推理生成物体功能与场景驱动的、可执行的空间约束链；对于长时程任务，采用蒙特卡洛树搜索变体增强LLM规划能力。实验构建了新基准，结果表明，所生成的数据集能有效提升2D与3D扩散策略的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.00677","title":"Learning Steerable Imitation Controllers from Unstructured Animal Motions","arxivId":"2507.00677","date":"2025-07-01","authors":"Stelian Coros Team","category":"Manipulation","summary":"本文提出一种从非结构化动物运动数据中学习可操控模仿控制器的框架，旨在解决现有方法无法实时响应用户指令、以及动物与机器人之间存在形态与物理差异的问题。关键技术包括：通过约束逆运动学与模型预测控制进行运动重定向，利用变分自编码器（VAE）根据速度指令合成多样步态的运动参考，并采用强化学习反馈控制器实现物理执行。实验表明，该框架能使四足机器人自适应切换步态、准确跟踪速度指令，同时保持动物运动风格的一致性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2507.00435","title":"RoboEval: Where Robotic Manipulation Meets Structured and Scalable Evaluation","arxivId":"2507.00435","date":"2025-07-01","authors":"Siddhartha Srinivasa Team","category":"Manipulation","summary":"本文提出了RoboEval仿真基准与评估框架，旨在解决现有机器人操作策略评估过于依赖二元成功率、无法揭示具体行为弱点（如协调性差、抓取滑动）的问题。其核心技术方法是引入一套分层、语义基础的任务，将任务分解为针对特定技能（如抓握、推动）的阶段，并通过系统性的空间与物理变体进行挑战，同时提供细粒度诊断指标与3000+人类演示数据。核心实验结论表明，具有相似成功率的策略在执行方式上存在显著差异，且超过一半的任务-指标对中，细粒度的行为指标与任务成功相关，即使在二元成功率饱和时仍能提供有效洞察。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.23944","title":"Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning","arxivId":"2506.23944","date":"2025-07-01","authors":"Yang Gao Team","category":"Manipulation","summary":"请提供论文正文内容，以便我根据具体研究方法、实验设计和结果数据撰写准确摘要。目前仅凭标题无法确定技术细节和性能指标。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.23919","title":"World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation","arxivId":"2506.23919","date":"2025-06-30","authors":"Lin Shao Team","category":"Manipulation","summary":"本文针对机器人操作中泛化能力不足的核心挑战，提出**Goal-VLA**零样本框架。其关键技术是：1) 将**图像生成式视觉语言模型(VLM)** 用作以物体为中心的世界模型，通过生成目标状态图像来推导物体位姿，从而桥接高层规划与无需训练的低层控制；2) 引入**反射合成**过程，迭代优化生成的目标图像以提升鲁棒性。模拟与真实实验表明，该框架在多种操作任务中实现了强劲的零样本性能和优异的泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.23126","title":"ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation","arxivId":"2506.23126","date":"2025-07-04","authors":"Mac Schwager Team","category":"Manipulation","summary":"本文提出了ParticleFormer，旨在解决现有3D世界模型局限于单材料动力学、且依赖耗时3D场景重建的问题。其核心方法是构建一个基于Transformer的点云世界模型，通过混合点云重建损失（同时监督全局与局部特征）进行训练，能够直接从真实机器人感知数据中学习刚性、可变形及柔性材料间的精细交互。实验在多个仿真与真实场景中验证，该模型在动力学预测精度和下游任务控制误差方面均持续优于现有基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.23125","title":"Learning Motion Skills with Adaptive Assistive Curriculum Force in Humanoid Robots","arxivId":"2506.23125","date":"2025-06-29","authors":"Yue Gao Team","category":"Manipulation","summary":"本文针对人形机器人学习复杂运动技能（如行走、舞蹈、后空翻）时探索效率低、学习过程不稳定的核心问题，提出自适应辅助课程力（A2CF）方法。其关键技术是训练一个双智能体系统：一个专用的辅助力智能体根据机器人状态施加引导力，并通过课程学习随技能熟练度逐步减少辅助。在双足行走、编舞舞蹈和后空翻三个基准测试中，该方法比基线收敛速度快30%，失败率降低40%以上，最终能产生无需外部辅助的鲁棒策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.22827","title":"Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation","arxivId":"2506.22827","date":"2025-06-28","authors":"Navid Azizan Team","category":"Manipulation","summary":"本文针对仿人机器人可靠执行复杂多步骤操作任务的挑战，提出分层视觉语言规划框架。系统包含三层：低层强化学习控制器跟踪运动目标；中层模仿学习技能策略生成任务步骤目标；高层视觉语言模型（VLM）规划技能序列并实时监控完成。在Unitree G1机器人上进行非抓取取放实验，40次真实试验中整体成功率达73%，验证了该方法的可行性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.22769","title":"Learning Efficient Robotic Garment Manipulation with Standardization","arxivId":"2506.22769","date":"2025-06-28","authors":"Bin He Team","category":"Manipulation","summary":"本文针对机器人服装操作中因复杂形变和自遮挡导致的标准化难题，提出APS-Net统一框架。该方法融合展开与标准化，采用双机械臂多原始策略（动态甩动与拾放），并设计了结合覆盖率、关键点距离和交并比的因子化奖励函数。实验表明，APS-Net在长袖服装上较现有方法覆盖率提升3.9%，交并比提高5.2%，关键点距离降低7.09%，有效简化了下游折叠任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.22756","title":"RoboPearls: Editable Video Simulation for Robot Manipulation","arxivId":"2506.22756","date":"2025-06-28","authors":"Xiaodan Liang Team","category":"Manipulation","summary":"本文提出RoboPearls，一个用于机器人操作的可编辑视频模拟框架，旨在解决真实演示数据收集成本高、效率低以及模拟与真实场景存在差距的问题。该框架基于3D高斯泼溅（3DGS）从视频重建逼真3D场景，并引入增量语义蒸馏（ISD）和3D正则化NNFM损失（3D-NNFM）等模块支持多种对象操作。通过集成大语言模型（LLM）和视觉语言模型（VLM），实现了用户命令自动解析与仿真需求生成。实验在RLBench、COLOSSEUM等多个数据集及真实机器人上验证了其有效的仿真性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.22007","title":"RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation","arxivId":"2506.22007","date":"2025-06-27","authors":"Abhinav Valada Team","category":"Manipulation","summary":"本文针对生成长时程机器人操作视频时，自回归方法导致的错误累积和视频不一致问题，提出RoboEnvision模型。该模型首先将高层指令分解为原子任务并生成对齐的关键帧，再用扩散模型进行帧间插值以生成长视频；引入语义保持注意力模块保持关键帧一致性；设计轻量级策略模型从视频回归机器人关节状态。实验表明，该方法在两个基准测试中取得视频质量和一致性的最先进结果，并在长时程任务上优于先前策略模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.21628","title":"Ark: An Open-source Python-based Framework for Robot Learning","arxivId":"2506.21628","date":"2025-06-24","authors":"Haitham Bou-Ammar Team","category":"Manipulation","summary":"本文针对机器人软件复杂性与AI生态系统便利性之间的差距，提出了开源Python框架Ark。其核心是提供Gym风格的环境接口，集成ACT、Diffusion Policy等模仿学习算法，支持仿真与实体机器人无缝切换，并采用轻量级客户端-服务器架构与C/C++绑定确保实时性。框架内置控制、SLAM、运动规划等模块，具备原生ROS互操作性。通过案例研究证明，Ark能实现快速原型设计、轻松硬件交换及端到端流程，显著降低了机器人学习门槛，加速了研发与部署。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.21627","title":"FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models","arxivId":"2506.21627","date":"2025-06-24","authors":"Huiping Zhuang Team","category":"Manipulation","summary":"本文提出FrankenBot，旨在解决通用机器人操作系统在复杂动态环境中功能单一、效率不足的核心问题。其关键技术是受脑结构启发的模块化架构：将任务规划、策略生成、记忆管理等功能分别映射到“皮层”“小脑”“海马体”等模块，通过协调机制减少对视觉语言模型（VLM）的频繁调用，平衡功能完整性与系统效率。实验表明，该方法在异常处理、长期记忆、操作效率和稳定性上均有显著提升，且无需微调或重训练。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.21250","title":"ACTLLM: Action Consistency Tuned Large Language Model","arxivId":"2506.21250","date":"2025-06-26","authors":"Chenliang Xu Team","category":"Manipulation","summary":"本文提出ACTLLM模型，旨在解决动态环境中机器人操作任务的传统视觉系统难以同时优化任务执行与空间推理表示的问题。关键技术包括：利用语言指令构建结构化场景描述以统一接口；引入动作一致性约束，对齐视觉感知与对应动作，增强可操作的视觉表示学习；将操作任务的马尔可夫决策过程重构为多轮视觉对话框架，以利用历史执行上下文进行长期任务建模。实验表明，该方法在多样化场景中表现优异，能有效应对基于视觉的机器人操作任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.21230","title":"World-aware Planning Narratives Enhance Large Vision-Language Model Planner","arxivId":"2506.21230","date":"2025-07-02","authors":"Xipeng Qiu Team","category":"Manipulation","summary":"本文针对大型视觉语言模型在复杂具身规划任务中，因环境无关的模仿学习范式导致的指令与环境上下文脱节、长时程推理困难等问题，提出 **WAP（World-aware Planning Narrative Enhancement）** 框架。该框架通过注入视觉外观建模、空间推理、功能抽象和句法基础四项认知能力，并采用课程学习仅使用原始视觉观察进行训练，以增强模型对环境的综合理解。在EB-ALFRED基准上，增强后的Qwen2.5-VL模型任务成功率获得 **60.7的绝对提升**，尤其在常识推理（+60.0）和长时程规划（+70.0）上表现突出，显著超越了GPT-4o等专有系统。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.21057","title":"Knowledge-Driven Imitation Learning: Enabling Generalization Across Diverse Conditions","arxivId":"2506.21057","date":"2025-06-26","authors":"Cewu Lu Team","category":"Manipulation","summary":"本文针对模仿学习在机器人操作中因依赖特定对象演示而泛化能力受限的问题，提出知识驱动模仿学习框架。该方法引入语义关键点图作为知识模板，并开发从粗到精的模板匹配算法，以优化结构一致性与语义相似性。在三个真实机器人操作任务上的实验表明，该方法仅需四分之一专家演示，性能即超越基于图像的扩散策略，并在新物体、背景及光照条件下展现出优越的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.20966","title":"Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends","arxivId":"2506.20966","date":"2025-06-26","authors":"Zeng-Guang Hou Team","category":"Manipulation","summary":"本文探讨视觉-语言-动作模型后训练与人类运动学习之间的类比关系。核心问题是VLA模型在需要高精度操作的任务上存在性能差距，需通过后训练进行适配。论文指出，VLA模型后训练旨在增强智能体为特定任务与环境交互的能力，这一过程与Newell的约束引导技能获取理论所描述的人类运动学习机制存在深刻平行。研究梳理了该领域的进展、挑战与趋势，强调了从人类学习原理中汲取灵感以优化模型后训练策略的潜在价值。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.19850","title":"Unified Vision-Language-Action Model","arxivId":"2506.19850","date":"2025-06-24","authors":"Zhaoxiang Zhang Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作（VLA）模型过度依赖视觉语言模型语义理解、忽视视觉观测中时序与因果结构的问题，提出统一模型UniVLA。其核心方法是将视觉、语言与动作统一表示为离散令牌，并在一个自回归框架中进行联合建模，同时在后训练中引入世界建模以捕捉视频中的因果动态。该模型在CALVIN、LIBERO等多个仿真基准测试中取得最先进性能，如在LIBERO上达到95.5%的平均成功率，显著超越此前最佳方法的85.5%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.19498","title":"T-Rex: Task-Adaptive Spatial Representation Extraction for Robotic Manipulation with Vision-Language Models","arxivId":"2506.19498","date":"2025-06-24","authors":"Qingyao Wu Team","category":"Manipulation","summary":"本论文针对基于视觉语言模型（VLM）的机器人操作中，固定空间表示提取方案灵活性差、效率低的问题，提出了T-Rex任务自适应框架。其核心技术是**链式推理（CoG）**，引导VLM逐步推断任务所需的空间约束及最优提取方案，并配合**可扩展的空间表示提取工具包**动态调用模型，仅在必要时进行细粒度提取。实验表明，该方法无需额外训练，即可在**空间理解、效率和稳定性**方面取得显著优势。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.19408","title":"Is an object-centric representation beneficial for robotic manipulation ?","arxivId":"2506.19408","date":"2025-06-24","authors":"Liming Chen Team","category":"Manipulation","summary":"本论文围绕“对象中心表示是否对机器人操作有益”这一核心问题展开探讨，旨在评估这种表示方法在提升机器人操作任务性能方面的潜在价值。然而，由于未提供论文正文内容，无法准确提炼具体采用的关键技术方法（如表示学习或感知算法）及其要点，也无法给出核心实验结论或性能提升数据（例如准确率或效率指标）。建议补充论文正文以便进行精准总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.19303","title":"Robotic Perception with a Large Tactile-Vision-Language Model for Physical Property Inference","arxivId":"2506.19303","date":"2025-06-24","authors":"Nutan Chen Team","category":"Manipulation","summary":"本文针对机器人操作中物理属性推断不准确的问题，提出了一种新型的大触觉-视觉-语言模型跨模态感知框架。其核心技术在于整合视觉与触觉表征，并采用分层特征对齐机制及优化的提示策略，实现多模态融合与物理推理。在35个多样物体上的实验表明，该方法性能优于现有基线模型，并展现出强大的零样本泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.19269","title":"AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation","arxivId":"2506.19269","date":"2025-06-25","authors":"Hui Shen Team","category":"Manipulation","summary":"本文针对双机械臂机器人在极端随机化场景下的操作任务，提出AnchorDP3框架。其核心创新包括：1）模拟器监督语义分割，从点云中分割任务关键物体以提供可供性先验；2）任务条件特征编码器，实现高效多任务学习；3）可供性锚定的关键姿态扩散，用稀疏的关键位姿（如预抓取位姿）替代密集轨迹预测，并联合预测关节角与末端位姿以利用几何一致性。在RoboTwin基准测试中，该框架在物体、杂物、光照等极端随机化条件下，平均任务成功率高达98.7%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.19250","title":"Robust Behavior Cloning Via Global Lipschitz Regularization","arxivId":"2506.19250","date":"2025-06-24","authors":"Sean B. Andersson Team","category":"Manipulation","summary":"本文针对行为克隆策略在部署时易受观测误差或对抗干扰影响的问题，提出通过全局Lipschitz正则化增强策略网络的鲁棒性。该方法构建具有全局Lipschitz性质的神经网络，确保策略对于有界范数扰动具备鲁棒性证书，即保证在扰动下动作输出的变化有界。论文在Gymnasium的多类环境中进行了实证验证，但提供的正文节选未包含具体的性能提升数据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.19121","title":"CUPID: Curating Data your Robot Loves with Influence Functions","arxivId":"2506.19121","date":"2025-06-23","authors":"Jeannette Bohg Team","category":"Manipulation","summary":"本文提出CUPID方法，旨在解决机器人模仿学习中难以量化单个演示数据对闭环策略性能影响的核心问题。该方法基于影响函数理论，通过估计每个训练演示对策略预期回报的影响，实现对数据的排名与筛选，具体包括过滤有害数据和优选新轨迹。实验表明，在模拟RoboMimic基准测试中，使用经CUPID筛选后不足33%的数据训练出的扩散策略即可达到最优性能，硬件实验也观察到类似的性能提升，并能有效识别分布偏移下的鲁棒策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.18960","title":"FORTE: Tactile Force and Slip Sensing on Compliant Fingers for Delicate Manipulation","arxivId":"2506.18960","date":"2025-06-25","authors":"Lillian Chin Team","category":"Manipulation","summary":"本文针对机器人精细操作脆弱物体时力控制困难、易导致滑落或损坏的核心问题，提出了FORTE触觉传感系统。该系统采用3D打印的fin-ray柔顺夹持器，内部集成空气通道，实现低延迟的力和滑移反馈，以动态调节抓取力。实验表明，FORTE能准确估计0-8 N的抓取力（平均误差0.2 N），在100 ms内检测滑移事件，对覆盆子等脆弱物体的抓取成功率达92%，滑移事件检测准确率为93%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.18856","title":"RAG-6DPose: Retrieval-Augmented 6D Pose Estimation via Leveraging CAD as Knowledge Base","arxivId":"2506.18856","date":"2025-06-23","authors":"Xiangyang Xue Team","category":"Manipulation","summary":"本文针对单目6D姿态估计中因遮挡、纹理缺失及合成与真实数据领域差距导致的鲁棒性问题，提出RAG-6DPose方法。该方法以CAD模型为知识库，通过构建多模态特征（提取多视角2D视觉特征并附加3D几何信息），利用ReSPC模块检索与查询图像相关的CAD特征，再经检索增强解码优化姿态预测。实验在标准基准和真实机器人任务中验证了方法的有效性与鲁棒性，尤其在处理遮挡和新视角方面表现优异。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.18825","title":"SViP: Sequencing Bimanual Visuomotor Policies with Object-Centric Motion Primitives","arxivId":"2506.18825","date":"2025-06-23","authors":"Jia Pan Team","category":"Manipulation","summary":"本文提出SViP框架，旨在解决小样本模仿学习中视觉运动策略泛化能力不足、累积误差导致长时程任务失败的问题。方法核心是将视觉运动策略整合至任务与运动规划中：通过语义场景图分割演示动作，并利用关键场景图变量训练切换条件生成器，产生参数化脚本基元以应对分布外观测。实验表明，仅需20条真实演示，SViP即可在无需物体姿态估计的情况下泛化至分布外初始条件，并在未知任务中自动规划有效解。真实世界实验验证其性能优于当前主流生成式模仿学习方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.18355","title":"Robotic Manipulation of a Rotating Chain with Bottom End Fixed","arxivId":"2506.18355","date":"2025-06-23","authors":"Quang-Cuong Pham Team","category":"Manipulation","summary":"本文研究机器人操纵底部固定旋转链的稳定形状转换问题，旨在解决现有方法无法实现可控操纵的难点。关键技术基于发现链的配置空间同胚于三维立方体，提出兼顾动态与运动学约束的操纵策略，以在旋转模式间平滑切换。物理实验成功演示了从静止到第一、二旋转模式的精确过渡，验证了策略有效性，可优化钻井管柱和纺纱操作的安全性与效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.18088","title":"RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation","arxivId":"2506.18088","date":"2025-06-22","authors":"Yao Mu Team","category":"Manipulation","summary":"本文提出RoboTwin 2.0，旨在解决双手机器人操作中缺乏高效、可扩展的合成数据生成方法以及仿真环境过于简化的问题。关键技术包括：构建大规模物体数据集RoboTwin-OD（731个实例），利用多模态大语言模型自动合成任务程序，并采用五维结构化领域随机化增强数据多样性。实验表明，该方法使代码生成成功率提升10.9%；仅结合10个真实演示，策略性能相对基线提升367%，纯合成数据训练的零样本模型也获得228%的相对增益，显著提升了仿真到现实的迁移鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.17639","title":"RLRC: Reinforcement Learning-based Recovery for Compressed Vision-Language-Action Models","arxivId":"2506.17639","date":"2025-06-21","authors":"Xiao Li Team","category":"Manipulation","summary":"本文针对视觉-语言-动作模型参数规模大、推理延迟高、难以在资源受限机器人平台部署的问题，提出RLRC方法。该方法采用三阶段恢复流程：先进行结构化剪枝，再基于监督微调与强化学习进行性能恢复，最后实施量化。实验表明，RLRC能将内存占用降低至1/8，推理吞吐量提升2.3倍，同时保持甚至超过原模型的任务成功率，显著优于现有压缩基线。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.17624","title":"Imitation Learning for Active Neck Motion Enabling Robot Manipulation beyond the Field of View","arxivId":"2506.17624","date":"2025-06-21","authors":"Yasuo Kuniyoshi Team","category":"Manipulation","summary":"本文针对固定摄像头视野限制机器人操作范围的问题，提出一种模仿学习框架，使机器人能主动移动颈部以扩展视野。关键技术包括系统化收集颈部运动数据集的教学方法，以及学习主动颈部运动操作任务的新型网络模型。实验表明，该模型在主动颈部运动干扰下仍实现约90%的高成功率，尤其在物体位于视野边缘或之外时表现优异，显著超越传统固定视野模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.17458","title":"Kinematic Model Optimization via Differentiable Contact Manifold for In-Space Manipulation","arxivId":"2506.17458","date":"2025-06-20","authors":"Satyandra K. Gupta Team","category":"Manipulation","summary":"本文解决太空机械臂在极端温度变化下，因热变形和关节编码器偏差导致运动学模型失准、末端位姿误差累积的问题。提出一种仅依赖本体感知的在线标定方法：首先构建一个可微分的、基于学习的接触流形模型；进而设计优化算法，利用执行轴孔装配任务时关节编码器的测量值，在线估计连杆应变和编码器偏差。该方法不依赖视觉或精密力传感，适用于太空恶劣环境，能实现接触式操作过程中的实时、安全参数估计。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.17110","title":"Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping","arxivId":"2506.17110","date":"2025-06-20","authors":"Jingjin Yu Team","category":"Manipulation","summary":"本文解决机器人抓取中依赖昂贵、易受干扰的深度传感器进行6D姿态估计的问题。提出单次度量深度对齐框架MOMA，基于单目深度估计模型，通过相机标定过程，利用稀疏真实深度点进行一次性的尺度-旋转-平移对齐，从而从单张RGB图像恢复具有物理意义的度量深度。实验在桌面两指抓取和吸盘式箱内拣选任务中验证了该方法的有效性，实现了较高的抓取成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.16986","title":"Learning Accurate Whole-body Throwing with High-frequency Residual Policy and Pullback Tube Acceleration","arxivId":"2506.16986","date":"2025-06-24","authors":"Marco Hutter Team","category":"Manipulation","summary":"本文针对足式移动机械臂预抓握全身投掷任务，解决了释放时机不确定和高度动态下末端执行器精准跟踪两大核心难题。提出了一种结合学习与模型控制的框架，包括末端执行器名义跟踪策略、提升跟踪精度的高频残差策略，以及优化末端加速度的模块。实验表明，在投掷6米远目标时平均着陆误差为0.28米；以6米/秒速度投掷3-5米随机目标时，系统速度跟踪误差为0.398米/秒，成功率达56.8%，远超人类的15.2%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.16685","title":"Compliant Residual DAgger: Improving Real-World Contact-Rich Manipulation with Human Corrections","arxivId":"2506.16685","date":"2025-06-20","authors":"Shuran Song Team","category":"Manipulation","summary":"本文针对真实世界接触丰富操作任务中应用DAgger方法的两大挑战：如何收集高质量的人类纠正数据，以及如何利用这些数据高效更新策略。提出了顺从残差DAgger（CR-DAgger）方法，其核心包含两个创新组件：1）顺从干预接口，利用顺从控制实现不中断策略执行下的精准增量动作纠正；2）顺从残差策略，能结合力反馈从人类纠正中学习。实验表明，该方法仅需少量纠正数据即可大幅提升性能，在书页翻转、皮带装配等四个挑战性任务上，将基础策略成功率提升了64%，且优于从头训练与微调方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.16652","title":"CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity","arxivId":"2506.16652","date":"2025-06-19","authors":"Yunzhu Li Team","category":"Manipulation","summary":"本文针对机器人操作中自然语言指令的模糊性问题，提出CodeDiffuser框架。核心方法是利用视觉语言模型（VLM）将抽象指令解析并生成可执行代码，作为可解释的中间表示；该代码与感知模块交互，生成融合空间与语义信息的3D注意力图，以明确任务相关区域，从而消解指令歧义。实验表明，现有扩散策略在涉及语言模糊性的任务上成功率极低，而本方法在语言模糊性、接触式操作及多物体交互等挑战性任务中表现优异。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.16565","title":"Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control","arxivId":"2506.16565","date":"2025-06-19","authors":"Ran Tian Team","category":"Manipulation","summary":"本文针对视觉模型预测控制中，世界模型对训练时未见过的新视觉干扰物（如陌生物体、背景）敏感，导致预测失准和下游任务失败的问题，提出一种名为ReOI的测试时观测干预方法。该方法通过检测预测中物理不合理的变化来识别干扰物，修改当前观测以去除干扰、使其更接近训练分布，然后重新进行未来状态“想象”，最后再恢复干扰物以保持视觉一致性。实验表明，ReOI能有效应对分布内外的视觉干扰，在存在新干扰物时，将任务成功率提升高达3倍。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.16555","title":"An Optimization-Augmented Control Framework for Single and Coordinated Multi-Arm Robotic Manipulation","arxivId":"2506.16555","date":"2025-06-19","authors":"Ozgur S. Oguz Team","category":"Manipulation","summary":"本文针对机器人操作中接触力与运动轨迹难以协同控制的核心问题，提出了一种多模态控制框架。该方法将复杂任务分解为子任务，动态分配三种控制模式：纯优化（全局运动规划）、纯力控制（精确交互）以及混合控制（轨迹与力同步调节）。通过单臂、双臂及多臂操作实验验证，该框架能够鲁棒且精确地处理从自由空间运动到密集接触的复杂长时域操作任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.16475","title":"Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining","arxivId":"2506.16475","date":"2025-06-19","authors":"Ding Zhao Team","category":"Manipulation","summary":"本文针对四足机器人难以习得通用自主操作技能的问题，提出一种跨具身模仿学习系统。核心方法包括：1）统一人与机器人观察-行动空间的遥操作数据采集流程；2）支持多具身协同训练与预训练的模块化架构。实验在六项真实任务中验证，系统相比基线平均成功率提升41.9%（分布外场景提升79.7%）。其中，使用人类数据预训练贡献了38.6%的整体提升（分布外场景82.7%），且仅需一半机器人数据即可获得更优性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.16396","title":"GoalLadder: Incremental Goal Discovery with Vision-Language Models","arxivId":"2506.16396","date":"2025-06-19","authors":"Shimon Whiteson Team","category":"Manipulation","summary":"本文提出GoalLadder方法，旨在解决从单一自然语言指令中为视觉环境下的强化学习智能体训练奖励函数的难题。该方法利用视觉语言模型，通过增量式目标发现机制，识别并排序任务进展状态；其关键技术包括基于ELO的评级系统以减少VLM反馈噪声，以及在无标注视觉数据上学习的嵌入空间中以最小化与最高排名目标的距离作为训练目标。实验表明，GoalLadder在经典控制与机器人操作环境中显著优于现有方法，平均最终成功率可达约95%，而最佳竞争对手仅为约45%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.16263","title":"CapsDT: Diffusion-Transformer for Capsule Robot Manipulation","arxivId":"2506.16263","date":"2025-06-19","authors":"Hongliang Ren Team","category":"Manipulation","summary":"本文针对胶囊内窥镜机器人在复杂胃部环境中缺乏主动控制、依赖被动蠕动导致操作精度不足的问题，提出CapsDT模型。该方法是一种结合扩散模型与Transformer的视觉-语言-动作模型，通过处理视觉输入与文本指令，推断机器人控制信号，并构建了由机械臂磁控系统和胃部模拟器组成的实验平台。实验表明，CapsDT在多种内窥镜任务中达到先进性能，并在真实模拟操作中取得26.25%的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.16211","title":"ControlVLA: Few-shot Object-centric Adaptation for Pre-trained Vision-Language-Action Models","arxivId":"2506.16211","date":"2025-06-19","authors":"Siyuan Huang Team","category":"Manipulation","summary":"本文针对机器人操作中少样本（few-shot）适应问题，提出ControlVLA框架。核心挑战在于如何让预训练的视觉-语言-动作（VLA）模型仅用极少演示就能适应以物体为中心的新任务。方法关键是通过ControlNet式架构，零初始化投影层，在不覆盖预训练知识的前提下引入物体中心表示进行高效微调。实验表明，在6个真实任务中仅需10-20个演示即达到76.7%成功率，显著优于需超100演示的传统方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.16201","title":"FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation","arxivId":"2506.16201","date":"2025-06-19","authors":"Wei Tang Team","category":"Manipulation","summary":"本文提出FlowRAM框架，以解决高精度机器人操作任务中，现有基于扩散的策略学习方法推理效率低、未能充分利用生成模型进行3D信息探索的问题。核心方法包括：1）动态半径调度，实现从全局到局部的自适应感知；2）集成状态空间模型，以线性复杂度融合多模态信息；3）采用条件流匹配，通过回归确定性向量场学习动作姿态。在RLBench基准测试中，FlowRAM取得了最先进性能，高精度任务平均成功率提升12.0%，且能在少于4个时间步内生成物理合理的动作，显著加速推理。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.15953","title":"ViTacFormer: Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation","arxivId":"2506.15953","date":"2025-06-19","authors":"Jitendra Malik Team","category":"Manipulation","summary":"根据提供的论文标题“ViTacFormer: Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation”，该研究旨在解决灵巧操作中视觉与触觉信息融合的核心问题，以提升机器人的操作能力。然而，提供的正文内容为NeurIPS 2025格式指令，未包含论文的具体研究细节，因此无法提炼关键技术方法的要点和核心实验结论或性能提升数据。建议参考完整论文以获取准确信息。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.15920","title":"Learning from Planned Data to Improve Robotic Pick-and-Place Planning Efficiency","arxivId":"2506.15920","date":"2025-06-18","authors":"Kensuke Harada Team","category":"Manipulation","summary":"本文针对机器人拾放任务中，传统方法因需分别评估大量抓取候选而导致计算开销大的问题，提出一种基于能量模型（EBM）的共享抓取预测方法。该方法通过结合物体在初始与目标位姿下可行抓取的能量，实现早期筛选、大幅缩减搜索空间。实验表明，该方法提升了抓取选择性能与数据效率，并能良好泛化至未见过的抓取及形状相似的物体。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.15865","title":"Improving Robotic Manipulation: Techniques for Object Pose Estimation, Accommodating Positional Uncertainty, and Disassembly Tasks from Examples","arxivId":"2506.15865","date":"2025-06-18","authors":"Viral Rasik Galaiya Team","category":"Manipulation","summary":"本文针对机器人操作中抓取后物体姿态估计不准确的核心问题，由于视觉遮挡、计算错误和外部干扰导致初始视觉估计失效。提出采用触觉传感技术（如压力、力、惯性传感器）提取物体信息，以补充视觉数据并改善姿态估计。实验表明，该方法在微创手术、电缆操作等特定应用中显示出潜力，并能作为控制系统优化的有效补充。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.15666","title":"Vision in Action: Learning Active Perception from Human Demonstrations","arxivId":"2506.15666","date":"2025-06-18","authors":"Shuran Song Team","category":"Manipulation","summary":"本文提出ViA系统，旨在解决机器人模仿学习中因缺乏主动感知能力而导致在视觉遮挡场景下性能受限的问题。系统通过设计6自由度机器人颈部硬件实现类人头部运动，并构建基于VR的遥操作界面及异步3D场景表示以学习人类演示中的主动感知策略（如搜索、跟踪、聚焦）。实验表明，ViA在多个复杂双手操作任务上显著优于基线系统，有效提升了遮挡环境下的操作鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.15190","title":"Learning Task-Agnostic Skill Bases to Uncover Motor Primitives in Animal Behaviors","arxivId":"2506.15190","date":"2025-06-18","authors":"Anqi Wu Team","category":"Manipulation","summary":"本文针对现有动物行为分割方法将连续行为过度简化为离散音节、忽略组合动态的问题，提出了基于基元的连续动态发现框架。该框架利用行为转换结构学习任务无关的、可解释的基元集合作为潜在基函数，并将行为动态建模为这些基元的连续演化混合。实验在多任务网格世界、迷宫导航和真实动物行为数据上验证，该框架能识别可重用基元组件，捕捉连续组合动态，并生成比传统离散模型更真实的行为轨迹。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.15157","title":"Robust Instant Policy: Leveraging Student’s t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation","arxivId":"2506.15157","date":"2025-06-18","authors":"Yukiyasu Domae Team","category":"Manipulation","summary":"本文针对基于大语言模型的上下文模仿学习（ICIL）中，即时策略因“幻觉”产生异常轨迹、导致可靠性下降的问题，提出了一种稳健即时策略（RIP）。其关键技术是采用Student’s t回归模型，对模型生成的多个候选轨迹进行聚合，该模型能有效忽略异常值（即幻觉轨迹），从而生成稳健的机器人轨迹。实验表明，该方法在模拟和真实环境中均显著优于现有方法，在低数据场景的日常任务中，任务成功率至少提升26%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.15146","title":"TACT: Humanoid Whole-body Contact Manipulation through Deep Imitation Learning with Tactile Modality","arxivId":"2506.15146","date":"2025-06-18","authors":"Eiichi Yoshida Team","category":"Manipulation","summary":"本文提出TACT方法，解决人形机器人全身接触操作中运动生成计算成本高、广域接触感知难的挑战。核心技术为基于深度模仿学习的策略TACT，其以关节位置、视觉及分布式触觉测量为多模态输入，并与基于双足模型的重定向和步态控制集成。实验表明，融合视觉与触觉输入能有效提升机器人（RHP7 Kaleido）在执行广泛且精细接触操作时的鲁棒性，使其在保持平衡与行走的同时完成全身接触操作任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.14763","title":"RobotSmith: Generative Robotic Tool Design for Acquisition of Complex Manipulation Skills","arxivId":"2506.14763","date":"2025-06-17","authors":"Chuang Gan Team","category":"Manipulation","summary":"本文提出RobotSmith，旨在解决机器人复杂操作任务中工具设计的挑战，克服现有方法如工具检索或通用3D生成不适合机器人操作的局限。该方法利用视觉语言模型（VLMs）的隐式物理知识结合物理模拟，通过协作代理迭代设计工具、生成低级机器人轨迹，并联合优化工具几何与使用方式。实验在刚性、可变形和流体对象任务中验证，平均成功率达50.0%，显著优于3D生成（21.4%）和工具检索（11.1%），且能有效迁移到真实世界执行。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.14754","title":"Tactile Beyond Pixels: Multisensory Touch Representations for Robot Manipulation","arxivId":"2506.14754","date":"2025-06-17","authors":"Mustafa Mukadam Team","category":"Manipulation","summary":"本文旨在解决机器人操作中触觉感知单一化的问题，提出融合多模态触觉信号以提升操作的鲁棒性与精细度。核心方法是 **Sparsh-X**，一个基于Transformer的多感官触觉融合模型，通过自监督学习，统一了来自Digit 360传感器的图像、音频、运动和压力四种触觉模态。实验表明，该表征在模仿学习和触觉适应任务中，相比仅使用触觉图像的端到端模型，**策略成功率提升63%**，从触觉恢复物体状态的**鲁棒性提升90%**；在物理属性推断任务上，**准确率提升48%**。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.14648","title":"SENIOR: Efficient Query Selection and Preference-Guided Exploration in Preference-based Reinforcement Learning","arxivId":"2506.14648","date":"2025-06-17","authors":"Shuo Wang Team","category":"Manipulation","summary":"本文针对基于偏好的强化学习（PbRL）中反馈效率和样本效率低下的核心问题，提出SENIOR方法。其关键技术包括：1）基于运动区分的查询选择方案（MDS），通过状态核密度估计筛选运动明显、易于比较的行为片段对，以获取高质量偏好标签；2）偏好引导探索方法（PGE），设计内在奖励鼓励智能体探索高偏好、低访问的状态。实验表明，SENIOR在六项复杂机器人操作任务上，在人类反馈效率和策略收敛速度方面均优于现有五种方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.14608","title":"Latent Action Diffusion for Cross-Embodiment Manipulation","arxivId":"2506.14608","date":"2025-06-17","authors":"Robert K. Katzschmann Team","category":"Manipulation","summary":"本文解决机器人操作中因不同末端执行器（如人手、仿生手、平行夹爪）动作空间异构导致的跨形态技能迁移难题。提出**潜在动作扩散**方法，通过对比学习编码器构建**语义对齐的潜在动作空间**，将异构动作统一编码；并采用**形态无关的潜在策略**与**形态特定的解码器**进行协同训练。实验表明，该方法使用单一策略控制多机器人，在跨形态操作任务中成功率最高提升**25.3%**，实现了有效的技能迁移。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.14317","title":"ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes","arxivId":"2506.14317","date":"2025-06-19","authors":"Hao Dong Team","category":"Manipulation","summary":"本文提出ClutterDexGrasp系统，解决杂乱场景中目标导向灵巧抓取的挑战，包括物体几何多样、遮挡和碰撞问题。关键技术为两阶段师生框架：教师策略在模拟中使用杂乱密度课程学习和安全课程训练，结合几何与空间嵌入场景表示；通过模仿学习蒸馏为学生3D扩散策略（DP3），基于部分点云实现闭环控制。该系统实现了零-shot模拟到真实转移，在多样物体和杂乱布局中展示了鲁棒的抓取性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.14287","title":"Steering Robots with Inference-Time Interactions","arxivId":"2506.14287","date":"2025-06-17","authors":"Yanwei Wang Team","category":"Manipulation","summary":"本文研究预训练模仿学习策略在部署时出错后缺乏高效纠正机制的问题。提出在推理时通过用户交互引导机器人行为，避免重新微调。关键技术包括：1）推理时引导，利用交互在离散技能间切换；2）任务与动作模仿，通过交互编辑连续动作并满足任务约束。这些方法能在不额外训练的情况下纠正策略预测偏差，提升预训练模型的实用性和用户控制能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.14198","title":"AMPLIFY: Actionless Motion Priors for Robot Learning from Videos","arxivId":"2506.14198","date":"2025-06-17","authors":"Animesh Garg Team","category":"Manipulation","summary":"本文提出AMPLIFY框架，旨在解决机器人学习中动作标记数据稀缺、成本高的问题，以利用丰富的无动作视频数据。其核心技术是模块化方法：首先从关键点轨迹提取离散运动令牌，在大量无动作视频上训练前向动力学模型；然后在少量动作标记数据上训练逆动力学模型，实现运动预测与动作推断的解耦。实验表明，该方法的动态预测更准确（MSE提升达3.7倍，像素预测精度提升2.5倍以上），并在下游策略学习中显著提升性能：低数据 regime 下性能提高1.2-2.2倍，利用无动作人类视频学习平均提升1.4倍，且首次实现了在零分布内动作数据下对LIBERO任务的泛化。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.14135","title":"GAF: Gaussian Action Field as a Dvnamic World Model for Robotic Mlanipulation","arxivId":"2506.14135","date":"2025-06-17","authors":"Yebin Liu Team","category":"Manipulation","summary":"本文针对机器人操作中动态场景感知与动作生成不匹配的核心问题，提出GAF（高斯动作场）这一4D动态世界模型。该方法扩展3D高斯泼溅，通过引入可学习的运动属性，实现了对场景几何时变与机器人动作的联合4D建模。关键创新包括利用高斯动作场同步输出场景重建、未来帧预测和初始动作估计，并采用动作-视觉对齐的去噪框架优化动作精度。实验表明，GAF在重建质量上显著优于基线（PSNR +11.5385 dB，SSIM +0.3864，LPIPS -0.5574），并将机器人操作任务的平均成功率提升了7.3%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.13867","title":"ATK: Automatic Task-driven Keypoint Selection for Robust Policy Learning","arxivId":"2506.13867","date":"2025-06-16","authors":"Abhishek Gupta Team","category":"Manipulation","summary":"本文解决视觉运动策略因训练与测试环境视觉差异导致的性能下降问题。提出ATK方法，通过专家数据自动选择一组能预测最优行为的最小关键点作为状态表示，专注于任务相关部分以保持策略鲁棒性。实验验证表明，该方法能显著提升策略对视觉干扰和环境变化的鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.13762","title":"Touch begins where vision ends: Generalizable policies for contact-rich manipulation","arxivId":"2506.13762","date":"2025-06-16","authors":"Raunaq Bhirangi Team","category":"Manipulation","summary":"本文针对接触式精细操作任务中数据驱动方法泛化性差的问题，提出ViTaL策略学习框架。其核心是将任务分解为两个阶段：首先利用视觉语言模型进行场景级推理以定位目标（到达阶段），随后调用一个与场景无关的、可重用的局部策略，该策略结合自我中心视觉与触觉传感执行精细操作（局部交互阶段）。关键技术包括利用基础模型分割训练稳健的视觉编码器、通过残差强化学习提升策略泛化能力，以及引入触觉传感。实验表明，该框架在未见环境中接触式任务的成功率可达约90%，且对干扰物具有鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.13761","title":"Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins","arxivId":"2506.13761","date":"2025-06-16","authors":"Wei-Chiu Ma Team","category":"Manipulation","summary":"本文针对开放世界机器人操作中，视觉语言模型（VLM）语义推理强但缺乏精细物理控制的问题，提出PWTF框架。该方法通过手持视频快速构建交互式数字孪生，模拟候选动作的未来状态，并自适应选择最具信息量的视角将其渲染为视觉提示，再由VLM评估并选择最优动作序列。在8个涉及接触、重定向和清理的真实任务中，PWTF相比现有VLM控制方法取得了显著更高的成功率，证明了融合显式物理建模与VLM语义优势的必要性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.13536","title":"What Matters in Learning from Large-Scale Datasets for Robot Manipulation","arxivId":"2506.13536","date":"2025-06-16","authors":"Danfei Xu Team","category":"Manipulation","summary":"本文研究如何优化大规模机器人数据集的组成以提升模仿学习效果。核心问题是确定数据收集时应强调的多样性维度及从现有数据集中检索演示的策略。作者开发了数据生成框架，程序化模拟传感器位姿、物体类型与布局等多样性来源，生成可控组成的数据集用于系统性研究。实验发现相机位姿与空间布局是影响数据效用与策略性能的关键因素；在真实机器人任务中，基于该见解的检索策略（如在DROID数据集上）相比现有方法最高提升70%的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.13498","title":"A Survey on Imitation Learning for Contact-Rich Tasks in Robotics","arxivId":"2506.13498","date":"2025-06-16","authors":"Arash Ajoudani Team","category":"Manipulation","summary":"本论文综述了模仿学习在机器人接触丰富任务中的应用研究。核心问题是解决涉及复杂物理交互（如摩擦、弹性）的非线性动力学任务，这些任务对小位置偏差敏感，是机器人学的关键挑战。关键技术包括演示收集方法（如教学和感官模态）以捕捉交互动态，以及模仿学习方法；多模态学习与基础模型的进展显著提升了在工业、家庭和医疗领域的性能。通过系统梳理现有研究和识别挑战，为未来接触丰富操作提供了基础。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.13478","title":"Learning Swing-up Maneuvers for a Suspended Aerial Manipulation Platform in a Hierarchical Control Framework","arxivId":"2506.13478","date":"2025-06-16","authors":"Christian Ott Team","category":"Manipulation","summary":"本文针对悬挂式空中操作平台无法仅靠推力抵达目标位置的问题，提出一种结合分层控制与强化学习的摆动上升策略。核心方法是在分层控制框架中，高层任务保持末端执行器位姿，强化学习智能体在高层任务的零空间内调整低优先级任务的参考设定点，驱动机械臂实现摆动。该方法通过大量数值仿真验证了有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.13428","title":"VLM-SFD: VLM-Assisted Siamese Flow Diffusion Framework for Dual-Arm Cooperative Manipulation","arxivId":"2506.13428","date":"2025-06-16","authors":"Wei Pan Team","category":"Manipulation","summary":"本文针对双臂机器人协作操作在动态、非结构化环境中泛化能力不足的问题，提出VLM-SFD框架。该方法核心包含**Siamese Flow Diffusion Network (SFDNet)**，采用孪生编码器-解码器架构将双目标嵌入共享潜在空间，并利用扩散模型生成以物体为中心的双流运动；以及**动态任务分配策略**，结合预训练视觉语言模型（VLM）为双臂自适应分配最优动作。实验表明，该方法仅需少量人类演示，即可显著提升对多样化现实任务的快速适应与泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.12723","title":"SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration","arxivId":"2506.12723","date":"2025-06-15","authors":"Wenwu Zhu Team","category":"Manipulation","summary":"本文针对视觉语言模型（VLA）推理效率低的问题，提出SP-VLA，一种联合模型调度与令牌修剪的加速方法。核心方案是动态调度视觉编码器与语言解码器的执行，并结合显著性引导的令牌修剪技术，提前剔除冗余视觉令牌。实验表明，该方法在保持性能基本无损的情况下，显著降低了计算开销，例如在特定任务上实现了约40%的延迟降低与FLOPs减少。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.12678","title":"Adapting by Analogy: OOD Generalization of Visuomotor Policies via Functional Correspondence","arxivId":"2506.12678","date":"2025-06-15","authors":"Andrea Bajcsy Team","category":"Manipulation","summary":"本文针对视觉运动策略在分布外（OOD）视觉条件下泛化失败的问题，提出一种基于功能对应的类比适应方法。核心思想是通过专家反馈建立OOD观察与训练分布内（ID）观察之间的功能对应关系，而非重新收集演示数据。关键技术包括：OOD检测与行为差异识别、专家提供的功能对应反馈、以及部署时利用对应ID观察进行干预。实验在Franka Panda机器人多种操作任务中验证了该方法能够以少量反馈有效提升基于视觉的扩散策略对OOD物体和环境条件的泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.12676","title":"Goal-based Self-Adaptive Generative Adversarial Imitation Learning (Goal-SAGAIL) for Multi-goal Robotic Manipulation Tasks","arxivId":"2506.12676","date":"2025-06-15","authors":"George Vogiatzis Team","category":"Manipulation","summary":"本文针对多目标机器人操作任务中示范数据有限且不理想、导致模仿学习偏向简单子任务的问题，提出了一种基于目标的自适应生成对抗模仿学习框架（Goal-SAGAIL）。该方法将自适应学习机制与目标条件生成对抗模仿学习（GAIL）相结合，以提升在次优示范下的学习效率。实验表明，该方法在包括复杂手内操作在内的多种多目标场景中，能显著提高学习效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.12374","title":"AntiGrounding: Lifting Robotic Actions into VLM Representation Space for Decision Making","arxivId":"2506.12374","date":"2025-06-14","authors":"Qingyao Wu Team","category":"Manipulation","summary":"本文提出AntiGrounding框架，解决现有方法将视觉语言模型（VLM）知识用于机器人操作时，因压缩为中间表示（如符号化技能序列）而丢失细粒度空间、物理与几何信息的问题。其核心方法逆转传统指令落地流程，通过多视角渲染候选动作轨迹，将其直接提升至VLM原生表示空间，并利用结构化视觉问答（VQA）进行指令条件下的决策，实现零样本合成闭环最优轨迹。实验在仿真和真实平台上验证了该方法在多种操作任务中优于传统方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.11948","title":"SAIL: Faster-than-Demonstration Execution of Imitation Learning Policies","arxivId":"2506.11948","date":"2025-06-13","authors":"Danfei Xu Team","category":"Manipulation","summary":"本文针对模仿学习策略执行速度慢于演示数据的问题，提出SAIL框架。该方法将演示轨迹分解为时序子目标，并训练强化学习策略快速达成这些子目标，从而在保持任务成功率的同时提升执行效率。实验表明，在模拟机器人操作任务中，SAIL策略比原始演示速度提升1.5至2.7倍，且成功率均超过90%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.11916","title":"mimic-one: a Scalable Model Recipe for General Purpose Robot Dexterity","arxivId":"2506.11916","date":"2025-06-13","authors":"Robert K. Katzschmann Team","category":"Manipulation","summary":"本文针对机器人灵巧操作这一核心挑战，提出了一套可扩展的系统方案mimic-one。其关键技术包括：1）新设计的16自由度肌腱驱动仿人手机械硬件；2）基于手套与VR界面的遥操作数据采集流程；3）利用原始感官输入、基于扩散模型的端到端高频生成控制策略。实验表明，该系统在真实世界操作中实现了高达93.3%的分布外任务成功率，并因涌现的自校正行为获得了最高+33.3%的性能提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.11775","title":"ExoStart: Efficient learning for dexterous manipulation with sensorized exoskeleton demonstrations","arxivId":"2506.11775","date":"2025-06-13","authors":"Maria Bauza Villalonga Team","category":"Manipulation","summary":"本文提出ExoStart框架，旨在解决高自由度机器人手在接触密集任务中难以通过远程操作获取高质量演示数据的问题。方法核心包括：1）使用低成本传感外骨骼直接采集人手操作演示；2）通过基于仿真的动态过滤器优化生成动力学可行的轨迹；3）采用自动课程强化学习（仅需稀疏奖励）训练策略。实验表明，该方法训练的策略能零样本迁移至真实机器人，在打开AirPods盒、插钥匙等复杂任务中成功率超过50%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.11293","title":"Influence Functions for Data Attribution in Linear System Identification and LQR Control","arxivId":"2506.11293","date":"2025-06-12","authors":"Dongmei Chen Team","category":"Manipulation","summary":"本文针对基于机器学习的控制系统中，传统方法计算成本高、难以高效评估单个训练数据影响的问题，提出使用影响函数框架进行数据归因。核心方法包括IF1（动态级影响，估计移除训练轨迹对线性动态模型预测准确性的影响）和IF2（控制级影响，通过离散代数Riccati方程解追踪敏感性，量化对LQR控制器成本的影响）。在模拟线性系统上的实验表明，影响预测与重新训练获得的真实变化呈强正相关，验证了方法的计算可行性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.11261","title":"Gondola: Grounded Vision Language Planning for Generalizable Robotic Manipulation","arxivId":"2506.11261","date":"2025-06-12","authors":"Cordelia Schmid Team","category":"Manipulation","summary":"根据论文标题“Gondola: Grounded Vision Language Planning for Generalizable Robotic Manipulation”，本文介绍了一个名为Gondola的系统，旨在解决机器人操作中泛化能力不足的核心问题。该系统采用基于视觉语言的规划技术，整合视觉感知和语言指令，以提升机器人在多变环境中的任务适应性。关键技术为Grounded Vision Language Planning，涉及视觉与语言的 grounding 和任务规划。但由于正文内容未提供，无法给出具体实验结论或性能提升数据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.10968","title":"Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop","arxivId":"2506.10968","date":"2025-06-12","authors":"Angjoo Kanazawa Team","category":"Manipulation","summary":"本文提出EyeRobot系统，解决机器人如何像人类一样主动环视以辅助操作的问题。核心技术是BC-RL循环：手部通过行为克隆（BC）从眼球观测学习操作，眼球通过强化学习（RL）以手部任务成功为奖励，自主学习注视策略；并采用foveated vision transformer架构实现高效高分辨率视觉。实验在五个全景工作空间操作任务上验证，系统能自主涌现手眼协调行为，仅用单个摄像头即可在大范围工作空间内有效完成操作任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.10966","title":"GENMANIP: LLM-driven Simulation for Generalizable Instruction-Following Manipulation","arxivId":"2506.10966","date":"2025-06-12","authors":"Jiangmiao Pang Team","category":"Manipulation","summary":"本文针对机器人操作中策略泛化的核心挑战，提出GenManip模拟平台。该平台采用LLM驱动的任务导向场景图自动生成大规模多样化任务，并构建GenManip-Bench基准进行系统评估。实验比较模块化系统与端到端策略，发现增强基础模型的模块化系统在多样化场景中泛化更有效。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.10790","title":"Human-Robot Navigation using Event-based Cameras and Reinforcement Learning","arxivId":"2506.10790","date":"2025-06-12","authors":"Rodrigo Verschae Team","category":"Manipulation","summary":"本文针对人机导航中传统图像控制器存在的固定帧率、运动模糊和延迟问题，提出了一种结合事件相机与强化学习的实时导航控制器。方法核心是利用事件相机的异步特性，融合深度/激光雷达数据，通过模仿学习初始化后采用DDPG进行策略优化，实现自适应推理与控制。在仿真实验中，该方法展现了鲁棒的导航、行人跟随与避障能力，并对比了PD、IL与RL控制器的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.10359","title":"Demonstrating Multi-Suction Item Picking at Scale via Multi-Modal Learning of Pick Success","arxivId":"2506.10359","date":"2025-06-12","authors":"Kapil Katyal Team","category":"Manipulation","summary":"本文针对机器人从杂乱堆中拾取多样化物品的挑战，提出通过多模态学习预测多吸盘拾取成功率的方法。核心技术是利用RGB、深度和语义分割等多模态输入，先通过自监督预训练学习跨模态关系，再微调下游模型评估拾取质量。实验表明，该方法在大型物品拾取数据集上优于原有工程策略及其他学习方案，实现了性能提升，并验证了多模态预训练的重要性及推理时可仅使用部分模态的灵活性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.10240","title":"Innovative Adaptive Imaged Based Visual Servoing Control of 6 DoFs Industrial Robot Manipulators","arxivId":"2506.10240","date":"2025-06-11","authors":"Francis Assadian Team","category":"Manipulation","summary":"根据您提供的论文标题，要撰写精准的摘要需要参考论文正文。目前仅依据标题“Innovative Adaptive Image Based Visual Servoing Control of 6 DoFs Industrial Robot Manipulators”，可推断其核心方向如下：\n\n**核心问题**：解决六自由度工业机器人在复杂或不确定环境下（如目标运动、相机标定误差、模型不精确）进行基于图像的视觉伺服（IBVS）任务时，传统控制方法鲁棒性不足的问题。\n\n**关键技术**：提出一种**创新的自适应图像视觉伺服控制**方法。其要点在于设计一个自适应律，能够在线实时估计和补偿系统的不确定性（如机器人动力学参数、相机-手眼关系、深度信息等），而无需依赖精确的模型。\n\n**预期目标/结论**：该方法旨在提升机器人视觉伺服系统的**跟踪精度、收敛速度和整体鲁棒性**，使其在面对干扰和模型误差时仍能稳定、精确地完成定位或跟踪任务。\n\n**请您提供论文正文内容**，以便我根据具体的方法设计、实验设置和性能对比数据，为您生成一段准确、简洁且有力的中文总结。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.09994","title":"eFlesh: Highly customizable Magnetic Touch Sensing using Cut-Cell Microstructures","arxivId":"2506.09994","date":"2025-06-11","authors":"Raunaq Bhirangi Team","category":"Manipulation","summary":"本文针对机器人缺乏通用、易定制且低成本的触觉传感器这一核心问题，提出了eFlesh磁触觉传感器。其关键技术是采用参数化的切割单元微结构，通过开源设计工具将任意凸形CAD模型转换为可3D打印的结构，实现传感器形状与机械响应的灵活定制。核心实验表明，该传感器接触定位RMSE为0.5毫米，力预测RMSE达0.27N（法向）和0.12N（剪切）。基于其数据的滑移检测模型准确率达95%，视觉触觉控制策略相比纯视觉基线将操作性能提升了40%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.09990","title":"Chain-of-Action: Trajectory Autoregressive Modeling for Robotic Manipulation","arxivId":"2506.09990","date":"2025-06-11","authors":"Xiao Ma Team","category":"Manipulation","summary":"本文提出Chain-of-Action（CoA），用于解决机器人操作中传统前向预测策略因“近视”优化导致的误差累积问题。其核心方法是轨迹自回归建模，通过反向推理生成完整轨迹：首先生成编码任务目标的关键帧动作，再以此为基础自回归生成后续动作，形成从全局到局部的约束。关键技术设计包括连续动作标记、动态停止、反向时间集成与多标记预测。实验表明，CoA在60个RLBench任务和8个真实世界操作任务上取得了最先进的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.09930","title":"From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models","arxivId":"2506.09930","date":"2025-06-11","authors":"Chen Feng Team","category":"Manipulation","summary":"本文针对当前视觉-语言-动作模型缺乏系统化泛化能力评估的问题，提出了一个包含50个模拟任务的统一探测套件，涵盖语言指令、视觉与物体交互等10个子类别。通过系统评估多种先进VLA架构，发现尽管VLA骨干网络赋予模型良好的感知理解与高层规划能力，但在面对分布外观测时，其动作执行精度显著下降。此外，实验表明对动作数据进行微调可能会损害原始视觉语言模型的通用推理能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.09491","title":"DCIRNet: Depth Completion with Iterative Refinement for Dexterous Grasping of Transparent and Reflective Objects","arxivId":"2506.09491","date":"2025-06-11","authors":"Hong Liu Team","category":"Manipulation","summary":"本文针对透明与反光物体因光线特性导致深度信息缺失、进而影响机器人灵巧抓取的问题，提出DCIRNet深度补全网络。其关键技术包括：设计多模态特征融合模块，融合RGB与深度图的互补信息；采用多阶段监督与深度细化策略，逐步优化补全结果并锐化物体边界。实验表明，将该模型集成至灵巧抓取框架后，对透明与反光物体的抓取成功率提升44%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.09422","title":"Time-Unified Diffusion Policy with Action Discrimination for Robotic Manipulation","arxivId":"2506.09422","date":"2025-06-11","authors":"Le Wang Team","category":"Manipulation","summary":"本文针对机器人操作中基于扩散的策略方法存在生成速度慢、训练复杂且动作准确性不足的问题，提出时间统一扩散策略（TUDP）。核心创新是构建了融合动作判别信息的时间统一速度场，以简化去噪过程并加速生成；同时提出动作智能训练方法，通过动作判别分支提升去噪精度。在RLBench上的实验表明，该方法取得了最先进的性能，多视图和单视图设置下的最高成功率分别达到82.6%和83.8%，尤其在减少去噪迭代时性能提升更为显著。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.09384","title":"Analyzing Key Objectives in Human-to-Robot Retargeting for Dexterous Manipulation","arxivId":"2506.09384","date":"2025-06-11","authors":"Xiang Li Team","category":"Manipulation","summary":"本文针对人手机器手形态差异导致动作无法完全复现的问题，系统分析了灵巧操作中人到机器人运动重定向的关键优化目标。研究提出一个综合重定向目标公式，整合了近期方法中的直觉关键因素，并通过在姿态重定向和真实遥操作任务上的大量实验与消融研究，评估了各因素的重要性。实验结果为设计更精准、有效的真实世界灵巧操作重定向算法提供了重要依据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.09176","title":"Robot-Gated Interactive Imitation Learning with Adaptive Intervention Mechanism","arxivId":"2506.09176","date":"2025-06-10","authors":"Bolei Zhou Team","category":"Manipulation","summary":"本文针对交互式模仿学习（IIL）中人类监控认知负担高的问题，提出自适应干预机制（AIM）。该方法通过代理Q函数模拟人类干预规则，根据代理与专家动作的对齐程度自适应请求演示。实验表明，AIM在连续和离散控制任务中显著减少专家监控努力，相比基线Thrifty-DAgger，人类接管成本和学习效率提升40%，并能有效识别安全关键状态以收集更高质量演示。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.08822","title":"FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency","arxivId":"2506.08822","date":"2025-06-10","authors":"Jian Tang Team","category":"Manipulation","summary":"本文针对基于生成建模的视觉运动策略在多步采样时推理成本高、难以实时执行的问题，提出FreqPolicy方法。其核心是首次对基于流的策略施加频率一致性约束，通过强制动作在频域特征上对齐，并设计自适应一致性损失来捕捉时序结构，从而实现高效、高质量的一步动作生成。实验在3个基准的53个任务上验证了其优越性，集成到VLA模型后在40个任务上实现加速且性能无损，在真实机器人场景中推理频率达到93.5 Hz。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.08795","title":"Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning","arxivId":"2506.08795","date":"2025-06-10","authors":"Xianta Jiang Team","category":"Manipulation","summary":"本文旨在开发一种无需生物信号（如表面肌电）的自主假手控制系统，以解决传统方法对用户身心负担重的问题。核心方法是利用安装在手腕的摄像头进行环境感知，并通过模仿学习技术训练控制模型：首先构建远程操作系统收集人类演示数据，进而让模型学习模仿人类的抓握动作。实验表明，仅使用单个参与者的少量物体数据进行训练后，该模仿学习算法即能实现高成功率，并能良好地泛化到更多用户及不同重量的未见物体。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.08756","title":"Bayesian Inverse Physics for Neuro-Symbolic Robot Learning","arxivId":"2506.08756","date":"2025-06-10","authors":"Frank Kirchner Team","category":"Manipulation","summary":"本文针对当前机器人学习在未知动态环境中适应性差、数据效率低的问题，提出了一种神经符号融合框架。其核心方法是结合**可微分物理**（用于高效世界建模）、**贝叶斯推理**（用于不确定性决策）和**元学习**（用于快速任务适应），将物理符号推理嵌入神经模型。该框架旨在使机器人能够泛化至训练数据之外、推理新情境并持续扩展知识，但论文为立场性研究，未提供具体实验数据。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.08639","title":"Deep Reinforcement Learning-Based Motion Planning and PDE Control for Flexible Manipulators","arxivId":"2506.08639","date":"2025-06-10","authors":"Jouni Mattila Team","category":"Manipulation","summary":"本文提出了一种结合深度强化学习（DRL）与非线性偏微分方程（PDE）控制的柔性机械臂运动规划与控制框架。核心问题是解决传统方法在轨迹跟踪时难以抑制端点振动的问题。关键技术包括：1）采用软演员-评论家（SAC）算法的DRL运动规划器，生成能最小化振动的优化轨迹；2）基于PDE的非线性控制器，通过李雅普诺夫分析保证闭环稳定，并计算跟踪所需扭矩。仿真与实物实验验证表明，该方法在振动抑制和跟踪精度上均优于传统方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.08632","title":"RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot Arm Swapping","arxivId":"2506.08632","date":"2025-06-10","authors":"Gitta Kutyniok Team","category":"Manipulation","summary":"本文提出RoboSwap框架，解决在无监督条件下将视频中的机器人手臂替换为另一型号的核心问题，以支持跨平台机器人学习。方法融合GAN与扩散模型：先通过无监督GAN转换手臂外观，再经扩散模型增强视频背景融合度、运动连贯性与交互真实感。实验表明，该方法在三个基准测试中超越现有视频/图像编辑模型，在结构连贯性与运动一致性上取得更优性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.08416","title":"Periodic Bipedal Gait Learning Using Reward Composition Based on a Novel Gait Planner for Humanoid Robots","arxivId":"2506.08416","date":"2025-06-10","authors":"Lijun Zhu Team","category":"Manipulation","summary":"本文针对人形机器人在动态非结构化环境中实现稳定、周期性双足步态的核心挑战，提出了一种步态驱动的强化学习框架。关键技术包括：1）新型步态规划器，将3D模型解耦为两个2D混合倒立摆（H-LIP）以规划期望关节轨迹；2）基于该规划器设计了三种奖励函数，构成奖励组合以引导学习。该方法在仿真与实验中有效减少了学习时间，并提升了运动的周期性与整体性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.07530","title":"BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation","arxivId":"2506.07530","date":"2025-06-09","authors":"Xilin Chen Team","category":"Manipulation","summary":"本文针对视觉-语言-动作（VLA）模型在资源受限机器人系统上部署困难的问题，提出了首个1比特VLA模型BitVLA。其核心方法是将所有参数量化为三元值{-1,0,1}，并针对视觉编码器提出蒸馏感知训练策略，将其压缩至1.58比特权重。实验表明，BitVLA在LIBERO基准测试上取得了与4比特量化先进模型OpenVLA-OFT相当的性能，同时内存占用仅为后者的29.8%，显著提升了部署效率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.06567","title":"NeSyPack: A Neuro-Symbolic Framework for Bimanual Logistics Packing","arxivId":"2506.06567","date":"2025-06-06","authors":"Changliu Liu Team","category":"Manipulation","summary":"本文提出NeSyPack，一个用于双手机器人物流打包的神经符号框架。核心问题是解决现有方法（如吸盘抓取器局限性、端到端模型数据需求大且不可解释）在处理多样化物体打包任务时的不足。关键技术结合数据驱动模型与符号推理，通过分层推理将任务分解为子任务，并由符号技能图管理原子技能，动态选择参数与配置。该模块化设计提升了鲁棒性、适应性与复用效率。在2025年IEEE ICRA的WBCD比赛中，基于NeSyPack的系统获得第一名，验证了其优于需大规模重训练的端到端模型。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.06072","title":"BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning","arxivId":"2506.06072","date":"2025-06-10","authors":"Rudolf Lioutikov Team","category":"Manipulation","summary":"本文针对模仿学习中连续动作序列的离散化表示问题，提出BEAST方法。其核心是采用B样条编码动作序列，无需单独训练标记器即可生成统一长度的离散或连续标记，支持并行解码并保证轨迹平滑。实验在166个模拟任务和8个真实机器人任务中验证，BEAST显著降低了训练和推理计算成本，能生成适合连续控制的高频平滑信号，并取得了具有竞争力的任务成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.06690","title":"SpikePingpong: High-Frequency Spike Vision-based Robot Learning for Precise Striking in Table Tennis Game","arxivId":"2506.06690","date":"2025-06-07","authors":"Shanghang Zhang Team","category":"Manipulation","summary":"本文针对机器人控制高速运动物体（以乒乓球为测试平台）的核心挑战，提出了SpikePingpong系统。该系统融合了高频脉冲视觉与模仿学习，其关键技术包括：SONIC模块（基于20 kHz脉冲相机，通过补偿空气阻力等不确定性实现毫米级球拍接触预测）和IMPACT模块（负责精确落点的战略规划）。实验表明，该系统在30厘米和20厘米精度目标区域的击球成功率分别达到91%和71%，较之前最优方法提升38%和37%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.05985","title":"Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning","arxivId":"2506.05985","date":"2025-06-06","authors":"Ping Luo Team","category":"Manipulation","summary":"本文针对终身机器人学习中前向迁移与灾难性遗忘的平衡问题，提出动态混合渐进参数高效专家库（DMPEL）。方法核心是渐进构建低秩专家库，通过轻量级路由器动态组合专家形成策略，并引入专家系数重放以准确检索旧任务专家，从而高效抑制遗忘。在LIBERO基准上的实验表明，DMPEL在持续适应中取得了更高的成功率，同时使用的可训练参数和存储开销极小。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.07505","title":"Reinforcement Learning via Implicit Imitation Guidance","arxivId":"2506.07505","date":"2025-06-09","authors":"Chelsea Finn Team","category":"Manipulation","summary":"本文研究稀疏奖励下强化学习的样本效率问题。针对现有方法利用先验数据（如专家示范）时存在利用不足或约束过强的问题，提出**数据引导噪声（DGN）**框架。其核心思想是：示范数据最有价值之处在于指示**哪些动作值得探索**，而非直接模仿具体动作。DGN通过学习一个**状态依赖的噪声分布**，利用专家动作与当前策略动作的差异来隐式指导探索方向，避免了显式的行为克隆约束。实验表明，该方法在七个模拟连续控制任务上，性能达到之前基于离线数据方法的**2-3倍**。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.06535","title":"MapleGrasp: Mask-guided Feature Pooling for Language-driven Efficient Robotic Grasping","arxivId":"2506.06535","date":"2025-06-06","authors":"Farshad Khorrami Team","category":"Manipulation","summary":"本文提出MapleGrasp框架，解决语言驱动机器人抓取中未见物体操作效率低的问题。核心技术是掩码引导特征池化：第一阶段基于CLIP特征预测分割掩码，第二阶段在掩码内池化特征生成像素级抓取预测，降低计算成本。实验表明，在OCID-VLG基准上性能提升7%，在自建RefGraspNet数据集上达到89%抓取准确率，真实机械臂实验对未见物体成功率达73%（超越基线11%）。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.07490","title":"RAPID Hand: A Robust, Affordable, Perception-Integrated, Dexterous Manipulation Platform for Generalist Robot Autonomy","arxivId":"2506.07490","date":"2025-06-09","authors":"Hui Cheng Team","category":"Manipulation","summary":"本文针对通用机器人自主性研究中，低成本高灵巧度操作平台稀缺、难以收集高质量真实世界数据的问题，提出了RAPID Hand平台。该平台通过硬件与软件协同优化，集成了紧凑的20自由度机械手、低延迟（<7ms）且空间对齐的多模态全手感知（腕部视觉、指尖触觉、本体感觉），以及高自由度遥操作接口。实验表明，基于该平台收集数据训练的扩散策略性能优于现有方法，验证了其可靠收集高质量演示数据的能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.06196","title":"Bridging Perception and Action: Spatially-Grounded Mid-Level Representations for Robot Generalization","arxivId":"2506.06196","date":"2025-06-06","authors":"Tingnan Zhang Team","category":"Manipulation","summary":"本文针对机器人灵巧操作任务中策略泛化能力不足的问题，研究如何利用空间接地的中层表示（包括对象中心性、姿态感知和深度感知）连接感知与动作。通过监督学习训练专家编码器，将其输入扩散策略，并设计混合专家策略架构整合多个专家模型以提升泛化。实验表明，该方法在评估任务中相比语言基线平均成功率提高11%，较标准扩散策略提高24%；使用中层表示作为加权模仿学习的监督信号可进一步带来10%的性能提升。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.08296","title":"HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation","arxivId":"2506.08296","date":"2025-06-11","authors":"Cong Wang Team","category":"Manipulation","summary":"本文针对机器人执行复杂操作任务时，在持续上下文记忆、不确定性下的多智能体协调及动态长时程规划方面存在的挑战，提出了HiBerNAC方法。该方法通过结合多模态VLA规划与神经启发的反射及多智能体机制，构建了一个分层大脑模拟的分散协作架构。实验表明，相较于先进VLA模型，HiBerNAC将平均长时程任务完成时间缩短了23%，并在先前模型完全失败的多路径任务上取得了12-31%的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.07006","title":"CARoL: Context-aware Adaptation for Robot Learning","arxivId":"2506.07006","date":"2025-06-08","authors":"Xuan Wang Team","category":"Manipulation","summary":"本文针对机器人强化学习（RL）中新任务学习效率低下的问题，核心挑战在于如何量化先验知识的相关性并自适应整合。提出CARoL框架，其关键技术是通过分析状态转移来表示上下文，以识别任务相似性，并优先适应相关知识与策略。该方法适用于策略、价值及演员-批评家等多种RL算法。实验在CarRacing和LunarLander模拟环境中显示，CARoL实现了更快的收敛速度和更高的奖励；在真实世界测试中，地面车辆能快速将模拟策略适应到未见的越野地形，验证了其高效性与泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.06658","title":"Self-Adapting Improvement Loops for Robotic Learning","arxivId":"2506.06658","date":"2025-06-07","authors":"Chen Sun Team","category":"Manipulation","summary":"本文针对视频生成模型作为机器人视觉规划器时，对未见任务泛化能力不足的核心问题，提出自适应改进循环（SAIL）方法。该方法通过域内视频模型与互联网规模预训练视频模型进行自适应，迭代收集自我产生的轨迹并更新模型，从而持续提升特定任务性能。实验在MetaWorld任务套件和真实机器人手臂操作任务上验证，发现SAIL能对训练时未见的新任务实现性能持续改进，且对自收集经验的过滤方式和初始演示质量表现出强鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.06199","title":"3DFlowAction: Learning Cross-Embodiment Manipulation from 3D Flow World Model","arxivId":"2506.06199","date":"2025-06-06","authors":"Mingkui Tan Team","category":"Manipulation","summary":"这篇论文针对机器人操作学习缺乏统一数据集、难以实现跨具身泛化的问题，提出3DFlowAction方法。核心是通过构建大规模3D光流数据集ManiFlow-110k，训练视频扩散世界模型来预测物体在语言指令下的未来运动轨迹。该方法进一步利用流引导渲染机制和GPT-4o评估生成轨迹的合理性，实现闭环规划，并将预测的3D光流作为优化策略的约束来生成机器人动作。实验表明，该方法在多种复杂操作任务上展现出强大的泛化能力，无需针对特定硬件进行训练即可实现可靠的跨具身适应。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.05812","title":"Optimal Robotic Velcro Peeling with Force Feedback","arxivId":"2506.05812","date":"2025-06-06","authors":"Volkan Isler Team","category":"Manipulation","summary":"本文研究机器人在表面几何形状任意且未知时，仅依靠力反馈和末端位置反馈剥离魔术贴的核心问题。针对环境部分可观测的挑战，提出基于准静态动力学假设的建模方法，设计状态估计器从力/位置反馈中估计状态，并开发启发式控制器平衡探索与利用行为。实验表明，在复杂几何不确定性和传感器噪声环境下，该方法成功率达100%，能量成本较完全可观测最优解仅增加不到80%，显著优于基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.05808","title":"Where Do We Look When We Teach? Analyzing Human Gaze Behavior Across Demonstration Devices in Robot Imitation Learning","arxivId":"2506.05808","date":"2025-06-06","authors":"Hiroshi Bito Team","category":"Manipulation","summary":"本文研究机器人模仿学习中演示设备对人类凝视行为的影响，核心问题是模拟机器人身体或视觉条件的设备如何损害演示者通过凝视提取任务相关线索的能力。作者提出一个实验框架，系统分析不同演示设备（模拟机器人身体或视觉条件）下的凝视行为。实验结果表明，这些模拟设备会损害凝视提取线索的能力，损害程度与模拟程度相关；使用捕捉自然人类行为的设备收集凝视数据，在环境变化下能将策略的任务成功率从18.8%显著提升至68.8%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.06677","title":"RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation","arxivId":"2506.06677","date":"2025-06-07","authors":"Si Liu Team","category":"Manipulation","summary":"本文针对现有基准测试在评估机器人长时程操作中高层语义推理与规划能力（System 2）方面的不足，提出了RoboCerebra大规模基准测试。其核心方法包括：1）通过GPT生成并分解任务指令，结合人工模拟执行，构建了包含长序列、细粒度子任务和动态场景的大规模仿真数据集；2）设计了结合高层VLM规划器与低层VLA控制器的分层评估框架。该基准的任务轨迹长度约为现有基准的6倍，并包含动态变化与时间标注等关键特征，旨在系统评估规划、反思与记忆等高级认知能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.07961","title":"BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models","arxivId":"2506.07961","date":"2025-06-09","authors":"Tieniu Tan Team","category":"Manipulation","summary":"本文提出BridgeVLA模型，旨在解决现有3D视觉-语言-动作模型未能充分利用空间结构、导致数据效率低下的问题。方法核心是通过输入输出对齐：先将点云投影为多视图图像作为输入，预训练视觉语言模型生成2D热图，再微调整个模型以预测热图并输出动作。实验显示，该模型在RLBench上将平均成功率从81.4%提升至88.2%，在COLOSSEUM上从56.7%提升至64.0%，真实机器人实验平均性能超越基线32%，且仅需每个任务3条轨迹就能在10多个任务上达到95.4%的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.05719","title":"You Only Estimate Once: Unified, One-stage, Real-Time Category-level Articulated Object 6D Pose Estimation for Robotic Grasping","arxivId":"2506.05719","date":"2025-06-06","authors":"Xiangyang Xue Team","category":"Manipulation","summary":"本文针对机器人抓取任务中的类别级铰接物体6D姿态估计问题，提出单阶段方法YOEO。现有方法多为多阶段流程，计算成本高、实时性差。YOEO通过统一网络一次性输出点级语义标签与质心偏移，利用聚类区分部件实例，并通过对齐归一化部件坐标空间（NPCS）区域恢复姿态与尺寸。实验表明，该方法在GAPart数据集上有效，且合成训练的模型可部署于真实场景，提供200Hz实时反馈，成功驱动机械臂与未见铰接物体交互。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.05294","title":"A Smooth Sea Never Made a Skilled $\\texttt{SAILOR}$ : Robust Imitation via Learning to Search","arxivId":"2506.05294","date":"2025-06-05","authors":"Gokul Swamy Team","category":"Manipulation","summary":"本文针对行为克隆（BC）在模仿学习中存在的根本局限——智能体一旦犯错偏离专家演示状态，便无法自主恢复——提出了一种名为SAILOR的“学习搜索”方法。其核心是通过学习世界模型和奖励模型，使智能体在测试时能够规划并恢复至专家期望的结果。在三个基准测试的十几个视觉操作任务上，SAILOR consistently 超越基于同批数据训练的SOTA扩散策略；即使将BC的演示数据量扩大5-10倍，仍存在性能差距。该方法还能识别细微错误且对奖励黑客攻击具有鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.05165","title":"LiPo: A Lightweight Post-optimization Framework for Smoothing Action Chunks Generated by Learned Policies","arxivId":"2506.05165","date":"2025-06-05","authors":"Suhan Park Team","category":"Manipulation","summary":"本文提出LiPo轻量级后优化框架，解决模仿学习策略因离散动作分块导致的轨迹不连续问题，该问题在投掷等动态任务中会严重影响运动平滑性与系统稳定性。方法核心包含：推理感知的分块调度（生成重叠块以规避推理延迟）、重叠区域线性混合、有界扰动空间内的最小化急动度轨迹优化。在位置控制机械臂上的实验表明，该方法显著降低了振动与运动抖动，提升了执行平滑度与机械鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.05064","title":"DemoSpeedup: Accelerating Visuomotor Policies via Entropy-Guided Demonstration Acceleration","arxivId":"2506.05064","date":"2025-06-05","authors":"Huazhe Xu Team","category":"Manipulation","summary":"本文提出DemoSpeedup方法，旨在解决模仿学习中因人类示范动作缓慢而导致策略执行效率低下的问题。其核心技术是**熵引导的示范加速**：首先训练一个生成策略作为动作熵估计器，根据熵值高低判断各帧所需操作精度；随后对高熵（低精度要求）的片段进行更高比例的下采样加速，生成加速后的示范数据。实验表明，基于加速示范训练的策略**执行速度提升至3倍**，且任务成功率保持甚至优于原速示范训练的策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.04505","title":"SGN-CIRL: Scene Graph-based Navigation with Curriculum, Imitation, and Reinforcement Learning","arxivId":"2506.04505","date":"2025-06-04","authors":"Aleksandr Panov Team","category":"Manipulation","summary":"本文提出SGN-CIRL框架，解决机器人在部分可观测环境中无地图导航并预测目标物体位置的难题。核心方法结合了3D场景图建模物体空间关系、模仿学习从演示中快速学习、以及课程学习逐步增加任务复杂度以稳定强化学习训练。在Isaac Sim环境中的实验表明，该方法能显著提升困难导航场景下的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.03079","title":"ORV: 4D Occupancy-centric Robot Video Generation","arxivId":"2506.03079","date":"2025-06-03","authors":"Hao Zhao Team","category":"Manipulation","summary":"本文提出ORV框架，解决机器人视频生成中因稀疏控制与密集像素输出不匹配导致的视频质量低、控制对齐差的问题。方法核心是结合动作先验与4D语义占据先验：通过Action-Expert AdaLN调制对齐动作与视频特征，并将4D占据的2D渲染作为软指导注入生成过程。实验表明，ORV在多个数据集上显著提升性能，FVD分数降低18.8%，视觉规划与策略学习的成功率分别提升3.5%和6.4%，并支持多视角一致生成与跨域迁移。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.03863","title":"STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization","arxivId":"2506.03863","date":"2025-06-04","authors":"Liqiang Nie Team","category":"Manipulation","summary":"STAR论文针对机器人技能学习中代码本崩溃和技能间因果关系建模不足的核心问题，提出旋转增强残差技能量化（RaRSQ）和因果技能变换器（CST）两项关键技术。RaRSQ通过旋转基梯度机制编码相对角度，防止代码本崩溃；CST利用自回归机制显式建模技能依赖关系。实验表明，STAR在LIBERO基准和真实任务上性能超越基线约12%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.04227","title":"Object-centric 3D Motion Field for Robot Learning from Human Videos","arxivId":"2506.04227","date":"2025-06-04","authors":"Pieter Abbeel Team","category":"Manipulation","summary":"本文针对从人类视频中学习机器人控制时，如何提取有效动作表示的核心挑战，提出使用以物体为中心的3D运动场作为动作表示。关键技术包括：1）一个训练去噪3D运动场估计器的流程，能从带噪声深度的视频中鲁棒提取精细物体3D运动；2）一个有利于跨体现迁移和背景泛化的密集物体中心3D运动场预测架构。实验表明，该方法将3D运动估计误差降低50%以上，在多样任务中达到55%的平均成功率，显著优于基线方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.04120","title":"Splatting Physical Scenes: End-to-End Real-to-Sim from Imperfect Robot Data","arxivId":"2506.04120","date":"2025-06-04","authors":"Leonard Hasenclever Team","category":"Manipulation","summary":"本文提出一种端到端真实到模拟（Real-to-Sim）框架，旨在直接从有缺陷的真实机器人数据中创建可用于物理仿真的高保真数字孪生。核心挑战在于真实数据存在遮挡、相机位姿噪声和动态干扰。关键技术是提出 **SplatMesh混合场景表示**，它将3D高斯泼溅（3DGS）的光线真实渲染能力与显式物体网格几何相结合，并构建了一个**端到端的可微分优化流程**，联合优化物体几何、外观、机器人位姿及物理参数。实验表明，该框架在真实ALOHA 2双手操作器数据上能有效实现高保真网格重建、逼真新视图生成和无标注机器人位姿校准。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.03574","title":"SwitchVLA: Execution-Aware Task Switching for Vision-Language-Action Models","arxivId":"2506.03574","date":"2025-06-04","authors":"Jian Tang Team","category":"Manipulation","summary":"本文针对现有视觉-语言-动作模型在任务执行过程中无法响应动态意图变化的局限，提出SwitchVLA框架。核心方法是将任务切换建模为基于执行状态和指令上下文的行为调制问题，通过分割专家演示为接触阶段来推断任务进度，并训练一个多行为条件策略以生成灵活的动作块。实验表明，该框架在仿真和真实机器人操作中，于任务成功率和交互自然性上均优于现有基线，实现了鲁棒的指令遵循与流畅的任务切换。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.04716","title":"Learning dissection trajectories from expert surgical videos via imitation learning with equivariant diffusion","arxivId":"2506.04716","date":"2025-06-05","authors":"Qi Dou Team","category":"Manipulation","summary":"本文研究内镜黏膜下剥离术视频中的解剖轨迹预测问题，旨在通过模仿学习提升手术技能训练效果。针对轨迹预测中的不确定性、几何对称性及泛化性挑战，提出iDPOE方法：通过联合状态-动作分布隐式建模专家行为，引入扩散模型提升策略学习的训练与采样效率，并融合等变表示增强对几何对称性的泛化能力。在包含近2000个片段的ESD视频数据集上验证，该方法在轨迹预测任务中优于现有显式与隐式先进方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.02618","title":"Rodrigues Network for Learning Robot Actions","arxivId":"2506.02618","date":"2025-06-03","authors":"Leonidas Guibas Team","category":"Manipulation","summary":"本文针对现有神经网络（如MLP、Transformer）缺乏关节系统运动学结构归纳偏置的问题，提出神经罗德里格斯算子，将经典前向运动学泛化为可学习模块，并基于此构建罗德里格斯网络。该方法在运动学与运动预测的合成任务上表现显著优于标准骨干网络，并在机器人模仿学习与单图像3D手部重建的实际应用中验证了其有效性，表明融入运动学先验能提升多领域动作学习性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.04941","title":"ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning","arxivId":"2506.04941","date":"2025-06-06","authors":"Jian Tang Team","category":"Manipulation","summary":"本文针对机器人学习仿真中铰接物体数据集视觉真实性与物理保真度不足的核心问题，提出了ArtVIP高质量开源数据集。其关键技术在于：由专业建模师按统一标准制作，通过精确几何网格与高分辨率纹理确保视觉真实，通过微调动态参数实现物理保真，并首创了嵌入模块化交互行为与像素级可供性标注。通过特征图可视化与光学动作捕捉定量验证了其视觉与物理保真度，并在模仿学习与强化学习实验中验证了其适用性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.02577","title":"Reachability Weighted Offline Goal-conditioned Resampling","arxivId":"2506.02577","date":"2025-06-03","authors":"Joni Pajarinen Team","category":"Manipulation","summary":"本文针对离线目标条件强化学习中均匀采样产生大量不可达状态-目标-动作对、降低策略性能的问题，提出可达性加权采样方法。该方法通过正未标记学习训练一个可达性分类器，将目标条件状态-动作值映射为可达性得分，并以此作为采样优先级，构成一个即插即用模块。在六个复杂模拟机器人操作任务上的实验表明，该方法显著提升了性能，其中HandBlock-Z任务性能较基线提升近50%。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.02768","title":"Geometric Visual Servo Via Optimal Transport","arxivId":"2506.02768","date":"2025-06-03","authors":"Ashutosh Tiwari Team","category":"Manipulation","summary":"本文针对机器人视觉伺服控制中忽略概率特征、依赖手动特征提取的问题，提出一种基于最优传输的几何控制律。方法将相机输入建模为3维特殊欧几里得群上的概率测度，利用Wasserstein距离类比几何测地线，结合经典PD控制与重力补偿，通过测地线流最小化误差，实现姿态与图像视觉伺服的统一。实验通过测试案例验证了该方法对不同初始位置的泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01953","title":"Fast-in-Slow: A Dual-System Foundation Model Unifying Fast Manipulation within Slow Reasoning","arxivId":"2506.01953","date":"2025-06-02","authors":"Pheng-Ann Heng Team","category":"Manipulation","summary":"本文针对机器人操作中泛化策略与执行效率的矛盾，提出FiS-VLA双系统基础模型。核心方法是将高频执行的System 1动作模块，通过参数共享嵌入到基于VLM的、负责慢速推理的System 2中，实现二者在单一模型内的协调。采用双感知协同训练策略，使System 1具备动作生成能力，同时保留System 2的推理表征。实验表明，该模型在仿真和现实任务中的平均成功率分别提升8%和11%，并以117.7 Hz的频率实现高效控制。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01756","title":"Learning with pyCub: A New Simulation and Exercise Framework for Humanoid Robotics","arxivId":"2506.01756","date":"2025-06-02","authors":"Matej Hoffmann Team","category":"Manipulation","summary":"本文提出pyCub框架，旨在解决现有iCub仿真器依赖C++/YARP、对初学者门槛高的问题。其核心方法是基于Python开发开源物理仿真，完整模拟iCub机器人（包括关节、双眼摄像头及4000个触觉传感器的皮肤），并提供从基础运动控制到视觉抓取等分级练习。该框架已通过两期人形机器人课程验证，降低了编程学习门槛，所有仿真资源、文档及Docker镜像均已公开。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01943","title":"Learning Video Generation for Robotic Manipulation with Collaborative Trajectory Control","arxivId":"2506.01943","date":"2025-06-02","authors":"Dahua Lin Team","category":"Manipulation","summary":"本文针对轨迹控制视频生成模型难以处理机器人操作中多物体交互、导致特征纠缠和视觉质量下降的问题，提出RoboMaster框架。其核心方法是**协作轨迹控制**，将交互过程分解为**交互前、中、后**三阶段，并分别在每个阶段以机械臂或操作物体作为**主导物体**进行建模，同时引入外观与形状感知的潜在表示以保持语义一致性。实验在Bridge、RLBench等基准上验证了该方法的有效性，取得了最先进的性能。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01941","title":"FreeTacMan: Robot-free Visuo-Tactile Data Collection System for Contact-rich Manipulation","arxivId":"2506.01941","date":"2025-06-02","authors":"Hongyang Li Team","category":"Manipulation","summary":"本文针对机器人接触丰富操作中数据收集效率低、传感器设置受限的核心问题，提出FreeTacMan系统。其关键技术是设计了一个可由人类手指佩戴、集成双视觉-触觉传感器的可穿戴夹持器，并引入高精度光学跟踪系统同步捕捉末端姿态与多模态反馈。实验表明，该系统成功构建了大规模数据集，包含超过300万对视觉-触觉图像及1万条演示轨迹，覆盖50种任务，在数据收集性能上较先前工作有显著提升，并能基于自收集数据有效学习操作策略。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01710","title":"Reasoning-Table: Exploring Reinforcement Learning for Table Reasoning","arxivId":"2506.01710","date":"2025-06-02","authors":"Kang Liu Team","category":"Manipulation","summary":"本文针对表格推理任务中监督微调方法泛化性与鲁棒性不足的问题，首次将强化学习应用于该领域。提出了Reasoning-Table方法，其关键技术是采用GPRO强化学习框架，通过精心设计的数据预处理、基于规则的结果奖励和统一的跨任务训练策略来优化模型。实验表明，该方法显著提升了性能，在表格推理基准上超越Claude-3.7-Sonnet达4.0%，在BIRD文本到SQL任务上达到68.3%的准确率，有效增强了模型的泛化能力与鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01944","title":"Feel the Force: Contact-Driven Learning from Humans","arxivId":"2506.01944","date":"2025-06-02","authors":"Lerrel Pinto Team","category":"Manipulation","summary":"本文针对机器人精细力控制泛化性差、视觉演示缺乏力信息的核心问题，提出FTF接触驱动学习系统。该方法通过触觉手套测量人类演示的接触力，结合视觉模型估计手部姿态，训练闭环策略连续预测操作所需力；利用共享视觉和动作表示将策略重定向至配备触觉夹爪的Franka Panda机器人，并通过PD控制器调制夹爪闭合以跟踪预测力，实现精确力感知控制。在5个力敏感操作任务中，系统达到77%的成功率。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01600","title":"WoMAP: World Models For Embodied Open-Vocabulary Object Localization","arxivId":"2506.01600","date":"2025-06-02","authors":"Anirudha Majumdar Team","category":"Manipulation","summary":"本文提出WoMAP方法，解决机器人根据语言指令在未知环境中高效定位开放词汇物体的核心问题。关键技术包括：基于高斯泼溅的真实-仿真-真实数据生成管道，无需专家演示；从开放词汇检测器提取密集奖励信号；利用潜在世界模型预测动态与奖励，以落地高级动作提议。实验表明，WoMAP在零样本物体定位任务中显著优于基线，相比VLM方法成功率提升9倍以上，相比扩散策略提升2倍以上，并展示了优秀的泛化与仿真到真实迁移能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01568","title":"Trajectory First: A Curriculum for Discovering Diverse Policies","arxivId":"2506.01568","date":"2025-06-02","authors":"Marc Toussaint Team","category":"Manipulation","summary":"本文针对现有约束多样性强化学习方法在复杂任务（如机器人操作）中探索不足、导致策略多样性缺乏的问题，提出一种两阶段课程方法。该方法首先利用基于样条的轨迹先验，通过进化搜索在开环动作序列上发现多样化的高奖励行为；随后将这些行为蒸馏成不同的离策略、无模型策略。实证评估表明，该课程能有效提高学习技能的多样性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01583","title":"FreqPolicy: Frequency Autoregressive Visuomotor Policy with Continuous Tokens","arxivId":"2506.01583","date":"2025-06-02","authors":"Yuexin Ma Team","category":"Manipulation","summary":"本文提出FreqPolicy，用于解决机器人视觉运动策略学习中动作表示精度不足与计算效率难以兼顾的问题。针对现有扩散模型延迟高、自回归方法累积误差大的局限，核心创新是**频率自回归框架**，通过分层建模频率分量（低频表全局运动、高频表局部细节），并结合**连续潜在表示**保持动作空间平滑性。实验表明，该方法在多样2D/3D操作任务中，在精度与效率上均优于现有方法。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.00599","title":"XYZ-IBD: High-precision Bin-picking Dataset for Object 6D Pose Estimation Capturing Real-world Industrial Complexity","arxivId":"2506.00599","date":"2025-05-31","authors":"Benjamin Busam Team","category":"Manipulation","summary":"本文针对工业场景中物体6D姿态估计的难题，提出了高精度抓取数据集XYZ-IBD，以解决真实工业环境中物体无纹理、金属反光、严重遮挡与密集堆叠等挑战。数据集包含15个无纹理金属物体，采用高精度工业相机采集，并通过抗反射喷雾、多视角深度融合与半自动标注流程，实现了毫米级精度的姿态标注。实验表明，现有先进方法在该数据集上的性能相比学术家庭物体基准出现显著下降，凸显了工业场景的复杂性与挑战性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01196","title":"OG-VLA: 3D-Aware Vision Language Action Model via Orthographic Image Generation","arxivId":"2506.01196","date":"2025-06-01","authors":"Valts Blukis Team","category":"Manipulation","summary":"本文提出OG-VLA模型，旨在解决3D感知机器人策略对新指令泛化能力弱、而视觉语言动作模型（VLA）对相机与机器人姿态变化敏感的问题。其核心技术是通过正交图像生成实现输入视图不变性：将多视角RGBD观测反投影为点云，渲染为标准正交视图，再经视觉骨干网络、大语言模型与图像扩散模型生成编码末端执行器下一目标位姿的图像。实验表明，该方法在Arnold与Colosseum基准上对新环境泛化性能达到SOTA，相对提升超过40%，同时在已知场景中保持鲁棒性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01185","title":"HoMeR: Learning In-the-Wild Mobile Manipulation via Hybrid Imitation and Whole-Body Control","arxivId":"2506.01185","date":"2025-06-01","authors":"Jeannette Bohg Team","category":"Manipulation","summary":"本文针对移动操作机器人在非结构化真实环境中泛化能力不足的问题，提出HoMeR框架。其核心方法结合了混合模仿学习（利用离线数据与在线交互）与全身协同控制策略，并采用Transformer模型统一处理多模态感知与动作生成。实验表明，该系统在真实家庭场景中能完成多种复杂操作任务，成功率显著提升，例如在物体摆放任务中达到85%的成功率，验证了其在未知动态环境中的有效泛化能力。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.01350","title":"Variational Adaptive Noise and Dropout towards Stable Recurrent Neural Networks","arxivId":"2506.01350","date":"2025-06-02","authors":"Shingo Murata Team","category":"Manipulation","summary":"本文针对循环神经网络（RNNs）存在的梯度不稳定和自主稳定性问题，提出了一种新的稳定学习理论——变分自适应噪声和丢弃（VAND）。该方法通过变分推断重新解释RNNs优化问题，将噪声和丢弃作为隐式正则化，并自适应调整其尺度和比率。在移动操作器的模仿学习实验中，VAND是唯一能够成功模仿顺序和周期性行为的方法，验证了其稳定性和有效性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.00280","title":"3D Gaussian Splat Vulnerabilities","arxivId":"2506.00280","date":"2025-05-30","authors":"Polo Chau Team","category":"Manipulation","summary":"本文探讨3D高斯溅射（3DGS）在安全关键应用中的脆弱性，即对手如何操纵场景造成危害。提出CLOAK攻击，利用球谐函数实现视图相关对抗纹理嵌入，使内容仅在特定视角可见；以及DAGGER攻击，通过投影梯度下降直接扰动3D高斯，无需训练数据即可欺骗多阶段对象检测器如Faster R-CNN。实验表明，攻击能导致误检测，例如汽车从顶部看显示为行李箱、检测置信度下降，从后面看显示停止标志，揭示了3DGS未充分探索的漏洞，对自动驾驶等领域构成新威胁。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2505.24819","title":"Bi-Manual Joint Camera Calibration and Scene Representation","arxivId":"2505.24819","date":"2025-05-30","authors":"Weiming Zhi Team","category":"Manipulation","summary":"本文提出Bi-JCR框架，解决双机械臂系统中末端相机标定依赖标定板、过程繁琐的问题。该方法利用3D基础模型，从双机械臂采集的RGB图像中直接估计密集的多视角对应关系，通过流形上的梯度下降联合优化，一次性求解各相机外参、机械臂间相对位姿及尺度一致的共享场景3D表示。实验表明，该方法在多种桌面环境中具有鲁棒性，并能有效支持后续的双臂协调任务。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2505.24339","title":"Imitation Learning-Based Path Generation for the Complex Assembly of Deformable Objects","arxivId":"2505.24339","date":"2025-05-30","authors":"Christoffer Sloth Team","category":"Manipulation","summary":"本文针对可变形物体复杂装配任务中高质量路径规划困难的问题，提出了一种基于模仿学习的路径生成方法。该方法首先利用简单动力学模型进行离线无碰撞路径规划，生成大量参考路径；然后通过机器人顺应控制执行这些路径，并由人类操作员进行微调修正；最后基于虚拟路径与人工修正数据集，采用行为克隆（BC）技术训练出能够跟随参考路径完成任务的灵巧策略。该方法旨在减少对复杂物理模型的依赖，通过结合人类演示与学习来提升路径规划的实用性与适应性。","tags":["Manipulation"],"updatedAt":"2026-02-11T14:45:56.386Z"},{"id":"http://arxiv.org/abs/2506.00782","title":"Jailbreak-R1: Exploring the Jailbreak Capabilities of LLMs via Reinforcement Learning","arxivId":"2506.00782","date":"2025/06/01","authors":"Guo, Weiyang, Shi, Zesheng, Li, Zhuo, Wang, Yequan, Liu, Xuebo, Wang, Wenya, Liu, Fangming, Zhang, Min, Li, Jing","category":"Artificial Intelligence (cs.AI)","summary":"论文标题为 \"Jailbreak-R1: Exploring the Jailbreak Capabilities of LLMs via Reinforcement Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Artificial Intelligence (cs.AI)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.24305","title":"SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping","arxivId":"2505.24305","date":"2025/05/30","authors":"Zhang, Mingxu, Li, Xiaoqi, Xu, Jiahui, Zhou, Kaichen, Bae, Hojin, Shen, Yan, Xiong, Chuyan, Dong, Hao","category":"Robotics (cs.RO)","summary":"论文标题为 \"SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.23692","title":"Mobi-$\\pi$: Mobilizing Your Robot Learning Policy","arxivId":"2505.23692","date":"2025/05/29","authors":"Yang, Jingyun, Huang, Isabella, Vu, Brandon, Bajracharya, Max, Antonova, Rika, Bohg, Jeannette","category":"Robotics (cs.RO)","summary":"论文标题为 \"Mobi-$\\pi$: Mobilizing Your Robot Learning Policy\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.24382","title":"MagicGripper: A Multimodal Sensor-Integrated Gripper for Contact-Rich Robotic Manipulation","arxivId":"2505.24382","date":"2025/05/30","authors":"Fan, Wen, Li, Haoran, Zhang, Dandan","category":"Robotics (cs.RO)","summary":"论文标题为 \"MagicGripper: A Multimodal Sensor-Integrated Gripper for Contact-Rich Robotic Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.24209","title":"Safety-Aware Robust Model Predictive Control for Robotic Arms in Dynamic Environments","arxivId":"2505.24209","date":"2025/05/30","authors":"Nam, Sanghyeon, Kim, Dongmin, Choi, Seung-Hwan, Kim, Chang-Hyun, Kwon, Hyoeun, Kawamoto, Hiroaki, Lee, Suwoong","category":"Robotics (cs.RO)","summary":"论文标题为 \"Safety-Aware Robust Model Predictive Control for Robotic Arms in Dynamic Environments\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.24198","title":"Hold My Beer: Learning Gentle Humanoid Locomotion and End-Effector Stabilization Control","arxivId":"2505.24198","date":"2025/05/30","authors":"Li, Yitang, Zhang, Yuanhang, Xiao, Wenli, Pan, Chaoyi, Weng, Haoyang, He, Guanqi, He, Tairan, Shi, Guanya","category":"Robotics (cs.RO)","summary":"论文标题为 \"Hold My Beer: Learning Gentle Humanoid Locomotion and End-Effector Stabilization Control\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.23527","title":"Normalizing Flows are Capable Models for RL","arxivId":"2505.23527","date":"2025/05/29","authors":"Ghugare, Raj, Eysenbach, Benjamin","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"Normalizing Flows are Capable Models for RL\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2506.00320","title":"Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents","arxivId":"2506.00320","date":"2025/05/31","authors":"Yu, Xiao, Peng, Baolin, Xu, Ruize, Galley, Michel, Cheng, Hao, Nath, Suman, Gao, Jianfeng, Yu, Zhou","category":"Artificial Intelligence (cs.AI)","summary":"论文标题为 \"Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Artificial Intelligence (cs.AI)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.23501","title":"Optimization-based Posture Generation for Whole-body Contact Motion by Contact Point Search on the Body Surface","arxivId":"2505.23501","date":"2025/05/29","authors":"Murooka, Masaki, Okada, Kei, Inaba, Masayuki","category":"Robotics (cs.RO)","summary":"论文标题为 \"Optimization-based Posture Generation for Whole-body Contact Motion by Contact Point Search on the Body Surface\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.23450","title":"Agentic Robot: A Brain-Inspired Framework for Vision-Language-Action Models in Embodied Agents","arxivId":"2505.23450","date":"2025/05/29","authors":"Yang, Zhejian, Chen, Yongchao, Zhou, Xueyang, Yan, Jiangyue, Song, Dingjie, Liu, Yinuo, Li, Yuting, Zhang, Yu, Zhou, Pan, Chen, Hechang, Sun, Lichao","category":"Robotics (cs.RO)","summary":"论文标题为 \"Agentic Robot: A Brain-Inspired Framework for Vision-Language-Action Models in Embodied Agents\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.23426","title":"Enhanced DACER Algorithm with High Diffusion Efficiency","arxivId":"2505.23426","date":"2025/05/29","authors":"Wang, Yinuo, Wang, Likun, Tan, Mining, Zou, Wenjun, Song, Xujie, Wang, Wenxuan, Liu, Tong, Zhan, Guojian, Zhu, Tianze, Liu, Shiqi, He, Zeyu, Zhang, Feihong, Duan, Jingliang, Li, Shengbo Eben","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"Enhanced DACER Algorithm with High Diffusion Efficiency\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.22626","title":"SCIZOR: A Self-Supervised Approach to Data Curation for Large-Scale Imitation Learning","arxivId":"2505.22626","date":"2025/05/28","authors":"Zhang, Yu, Xie, Yuqi, Liu, Huihan, Shah, Rutav, Wan, Michael, Fan, Linxi, Zhu, Yuke","category":"Robotics (cs.RO)","summary":"论文标题为 \"SCIZOR: A Self-Supervised Approach to Data Curation for Large-Scale Imitation Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.23171","title":"RoboTransfer: Controllable Geometry-Consistent Video Diffusion for Manipulation Policy Transfer","arxivId":"2505.23171","date":"2025/05/29","authors":"Liu, Liu, Wang, Xiaofeng, Zhao, Guosheng, Li, Keyu, Qin, Wenkang, Zhu, Jiagang, Qiu, Jiaxiong, Zhu, Zheng, Huang, Guan, Su, Zhizhong","category":"Computer Vision and Pattern Recognition (cs.CV)","summary":"论文标题为 \"RoboTransfer: Controllable Geometry-Consistent Video Diffusion for Manipulation Policy Transfer\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Computer Vision and Pattern Recognition (cs.CV)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.22159","title":"ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation","arxivId":"2505.22159","date":"2025/05/28","authors":"Yu, Jiawen, Liu, Hairuo, Yu, Qiaojun, Ren, Jieji, Hao, Ce, Ding, Haitong, Huang, Guangyu, Huang, Guofan, Song, Yan, Cai, Panpan, Lu, Cewu, Zhang, Wenqiang","category":"Robotics (cs.RO)","summary":"论文标题为 \"ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.22424","title":"Hybrid Learning for Cold-Start-Aware Microservice Scheduling in Dynamic Edge Environments","arxivId":"2505.22424","date":"2025/05/28","authors":"Lu, Jingxi, Li, Wenhao, Guo, Jianxiong, Ding, Xingjian, Tang, Zhiqing, Wang, Tian, Jia, Weijia","category":"Networking and Internet Architecture (cs.NI)","summary":"论文标题为 \"Hybrid Learning for Cold-Start-Aware Microservice Scheduling in Dynamic Edge Environments\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Networking and Internet Architecture (cs.NI)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.22404","title":"Efficient Precision-Scalable Hardware for Microscaling (MX) Processing in Robotics Learning","arxivId":"2505.22404","date":"2025/05/28","authors":"Cuyckens, Stef, Yi, Xiaoling, Murthy, Nitish Satya, Fang, Chao, Verhelst, Marian","category":"Hardware Architecture (cs.AR)","summary":"论文标题为 \"Efficient Precision-Scalable Hardware for Microscaling (MX) Processing in Robotics Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Hardware Architecture (cs.AR)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.22352","title":"State and Input Constrained Adaptive Tracking Control of Uncertain Euler-Lagrange Systems with Robustness and Feasibility Analysis","arxivId":"2505.22352","date":"2025/05/28","authors":"Ghosh, Poulomee, Bhasin, Shubhendu","category":"Systems and Control (eess.SY)","summary":"论文标题为 \"State and Input Constrained Adaptive Tracking Control of Uncertain Euler-Lagrange Systems with Robustness and Feasibility Analysis\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Systems and Control (eess.SY)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.21851","title":"Streaming Flow Policy: Simplifying diffusion/flow-matching policies by treating action trajectories as flow trajectories","arxivId":"2505.21851","date":"2025/05/28","authors":"Jiang, Sunshine, Fang, Xiaolin, Roy, Nicholas, Lozano-Pérez, Tomás, Kaelbling, Leslie Pack, Ancha, Siddharth","category":"Robotics (cs.RO)","summary":"论文标题为 \"Streaming Flow Policy: Simplifying diffusion/flow-matching policies by treating action trajectories as flow trajectories\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.21906","title":"ChatVLA-2: Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge","arxivId":"2505.21906","date":"2025/05/28","authors":"Zhou, Zhongyi, Zhu, Yichen, Wen, Junjie, Shen, Chaomin, Xu, Yi","category":"Robotics (cs.RO)","summary":"论文标题为 \"ChatVLA-2: Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.21981","title":"Learning Compositional Behaviors from Demonstration and Language","arxivId":"2505.21981","date":"2025/05/28","authors":"Liu, Weiyu, Nie, Neil, Zhang, Ruohan, Mao, Jiayuan, Wu, Jiajun","category":"Robotics (cs.RO)","summary":"论文标题为 \"Learning Compositional Behaviors from Demonstration and Language\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:52:48.420Z"},{"id":"http://arxiv.org/abs/2505.21649","title":"Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks","arxivId":"2505.21649","date":"2025/05/27","authors":"Nichols, Keanu, Tasnim, Nazia, Yan, Yuting, Ikechukwu, Nicholas, Zou, Elva, Ghadiyaram, Deepti, Plummer, Bryan A.","category":"Computer Vision and Pattern Recognition (cs.CV)","summary":"论文标题为 \"Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Computer Vision and Pattern Recognition (cs.CV)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.20829","title":"Learning a Unified Policy for Position and Force Control in Legged Loco-Manipulation","arxivId":"2505.20829","date":"2025/05/27","authors":"Zhi, Peiyuan, Li, Peiyang, Yin, Jianqin, Jia, Baoxiong, Huang, Siyuan","category":"Robotics (cs.RO)","summary":"论文标题为 \"Learning a Unified Policy for Position and Force Control in Legged Loco-Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.21495","title":"CLAMP: Crowdsourcing a LArge-scale in-the-wild haptic dataset with an open-source device for Multimodal robot Perception","arxivId":"2505.21495","date":"2025/05/27","authors":"Thakkar, Pranav N., Sinha, Shubhangi, Baijal, Karan, Yuhan, Bian, Lackey, Leah, Dodson, Ben, Kong, Heisen, Kwon, Jueun, Li, Amber, Hu, Yifei, Rekoutis, Alexios, Silver, Tom, Bhattacharjee, Tapomayukh","category":"Robotics (cs.RO)","summary":"论文标题为 \"CLAMP: Crowdsourcing a LArge-scale in-the-wild haptic dataset with an open-source device for Multimodal robot Perception\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.20814","title":"Spatial RoboGrasp: Generalized Robotic Grasping Control Policy","arxivId":"2505.20814","date":"2025/05/27","authors":"Huang, Yiqi, Davies, Travis, Yan, Jiahuan, Sun, Jiankai, Chen, Xiang, Hu, Luhui","category":"Robotics (cs.RO)","summary":"论文标题为 \"Spatial RoboGrasp: Generalized Robotic Grasping Control Policy\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.21351","title":"EquAct: An SE(3)-Equivariant Multi-Task Transformer for Open-Loop Robotic Manipulation","arxivId":"2505.21351","date":"2025/05/27","authors":"Zhu, Xupeng, Qi, Yu, Zhu, Yizhe, Walters, Robin, Platt, Robert","category":"Robotics (cs.RO)","summary":"论文标题为 \"EquAct: An SE(3)-Equivariant Multi-Task Transformer for Open-Loop Robotic Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.21652","title":"PartInstruct: Part-level Instruction Following for Fine-grained Robot Manipulation","arxivId":"2505.21652","date":"2025/05/27","authors":"Yin, Yifan, Han, Zhengtao, Aarya, Shivam, Wang, Jianxin, Xu, Shuhang, Peng, Jiawei, Wang, Angtian, Yuille, Alan, Shu, Tianmin","category":"Robotics (cs.RO)","summary":"论文标题为 \"PartInstruct: Part-level Instruction Following for Fine-grained Robot Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.20962","title":"Object-Centric Action-Enhanced Representations for Robot Visuo-Motor Policy Learning","arxivId":"2505.20962","date":"2025/05/27","authors":"Giannakakis, Nikos, Manetas, Argyris, Filntisis, Panagiotis P., Maragos, Petros, Retsinas, George","category":"Robotics (cs.RO)","summary":"论文标题为 \"Object-Centric Action-Enhanced Representations for Robot Visuo-Motor Policy Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.20795","title":"Learning Generalizable Robot Policy with Human Demonstration Video as a Prompt","arxivId":"2505.20795","date":"2025/05/27","authors":"Zhu, Xiang, Liu, Yichen, Li, Hezhong, Chen, Jianyu","category":"Robotics (cs.RO)","summary":"论文标题为 \"Learning Generalizable Robot Policy with Human Demonstration Video as a Prompt\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.20425","title":"OSVI-WM: One-Shot Visual Imitation for Unseen Tasks using World-Model-Guided Trajectory Generation","arxivId":"2505.20425","date":"2025/05/26","authors":"Goswami, Raktim Gautam, Krishnamurthy, Prashanth, LeCun, Yann, Khorrami, Farshad","category":"Robotics (cs.RO)","summary":"论文标题为 \"OSVI-WM: One-Shot Visual Imitation for Unseen Tasks using World-Model-Guided Trajectory Generation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.20290","title":"EgoZero: Robot Learning from Smart Glasses","arxivId":"2505.20290","date":"2025/05/26","authors":"Liu, Vincent, Adeniji, Ademi, Zhan, Haotian, Haldar, Siddhant, Bhirangi, Raunaq, Abbeel, Pieter, Pinto, Lerrel","category":"Robotics (cs.RO)","summary":"论文标题为 \"EgoZero: Robot Learning from Smart Glasses\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.20404","title":"Co-Design of Soft Gripper with Neural Physics","arxivId":"2505.20404","date":"2025/05/26","authors":"Yi, Sha, Bai, Xueqian, Singh, Adabhav, Ye, Jianglong, Tolley, Michael T, Wang, Xiaolong","category":"Robotics (cs.RO)","summary":"论文标题为 \"Co-Design of Soft Gripper with Neural Physics\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.20498","title":"ControlTac: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image","arxivId":"2505.20498","date":"2025/05/26","authors":"Luo, Dongyu, Yu, Kelin, Shahidzadeh, Amir-Hossein, Fermüller, Cornelia, Aloimonos, Yiannis, Gao, Ruohan","category":"Computer Vision and Pattern Recognition (cs.CV)","summary":"论文标题为 \"ControlTac: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Computer Vision and Pattern Recognition (cs.CV)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.19717","title":"Extremum Flow Matching for Offline Goal Conditioned Reinforcement Learning","arxivId":"2505.19717","date":"2025/05/26","authors":"Rouxel, Quentin, Donoso, Clemente, Chen, Fei, Ivaldi, Serena, Mouret, Jean-Baptiste","category":"Robotics (cs.RO)","summary":"论文标题为 \"Extremum Flow Matching for Offline Goal Conditioned Reinforcement Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.20148","title":"MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents","arxivId":"2505.20148","date":"2025/05/26","authors":"Wei, Ziming, Lin, Bingqian, Jiao, Zijian, Nie, Yunshuang, Ma, Liang, Liu, Yuecheng, Zhuang, Yuzheng, Liang, Xiaodan","category":"Artificial Intelligence (cs.AI)","summary":"论文标题为 \"MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Artificial Intelligence (cs.AI)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.19017","title":"WorldEval: World Model as Real-World Robot Policies Evaluator","arxivId":"2505.19017","date":"2025/05/25","authors":"Li, Yaxuan, Zhu, Yichen, Wen, Junjie, Shen, Chaomin, Xu, Yi","category":"Robotics (cs.RO)","summary":"论文标题为 \"WorldEval: World Model as Real-World Robot Policies Evaluator\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.18719","title":"VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning","arxivId":"2505.18719","date":"2025/05/24","authors":"Lu, Guanxing, Guo, Wenkai, Zhang, Chubin, Zhou, Yuheng, Jiang, Haonan, Gao, Zifeng, Tang, Yansong, Wang, Ziwei","category":"Robotics (cs.RO)","summary":"论文标题为 \"VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.18858","title":"Guided by Guardrails: Control Barrier Functions as Safety Instructors for Robotic Learning","arxivId":"2505.18858","date":"2025/05/24","authors":"Guerrier, Maeva, Soma, Karthik, Fouad, Hassan, Beltrame, Giovanni","category":"Robotics (cs.RO)","summary":"论文标题为 \"Guided by Guardrails: Control Barrier Functions as Safety Instructors for Robotic Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.18487","title":"Grounding Bodily Awareness in Visual Representations for Efficient Policy Learning","arxivId":"2505.18487","date":"2025/05/24","authors":"Wang, Junlin, Lin, Zhiyun","category":"Robotics (cs.RO)","summary":"论文标题为 \"Grounding Bodily Awareness in Visual Representations for Efficient Policy Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.19769","title":"TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning","arxivId":"2505.19769","date":"2025/05/26","authors":"Chen, Yuhui, Li, Haoran, Jiang, Zhennan, Wen, Haowei, Zhao, Dongbin","category":"Robotics (cs.RO)","summary":"论文标题为 \"TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.18792","title":"On the Dual-Use Dilemma in Physical Reasoning and Force","arxivId":"2505.18792","date":"2025/05/24","authors":"Xie, William, Rice, Enora, Correll, Nikolaus","category":"Robotics (cs.RO)","summary":"论文标题为 \"On the Dual-Use Dilemma in Physical Reasoning and Force\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.18474","title":"Canonical Policy: Learning Canonical 3D Representation for SE(3)-Equivariant Policy","arxivId":"2505.18474","date":"2025/05/24","authors":"Zhang, Zhiyuan, Xu, Zhengtong, Lakamsani, Jai Nanda, She, Yu","category":"Robotics (cs.RO)","summary":"论文标题为 \"Canonical Policy: Learning Canonical 3D Representation for SE(3)-Equivariant Policy\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.21182","title":"Learning What to Do and What Not To Do: Offline Imitation from Expert and Undesirable Demonstrations","arxivId":"2505.21182","date":"2025/05/27","authors":"Hoang, Huy, Mai, Tien, Varakantham, Pradeep, Verma, Tanvi","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"Learning What to Do and What Not To Do: Offline Imitation from Expert and Undesirable Demonstrations\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.18472","title":"ManiFeel: Benchmarking and Understanding Visuotactile Manipulation Policy Learning","arxivId":"2505.18472","date":"2025/05/24","authors":"Luu, Quan Khanh, Zhou, Pokuang, Xu, Zhengtong, Zhang, Zhiyuan, Qiu, Qiang, She, Yu","category":"Robotics (cs.RO)","summary":"论文标题为 \"ManiFeel: Benchmarking and Understanding Visuotactile Manipulation Policy Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T14:54:12.843Z"},{"id":"http://arxiv.org/abs/2505.17695","title":"SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data","arxivId":"2505.17695","date":"2025/05/23","authors":"Kim, Dong-Hee, Song, Hyunjee, Kim, Donghyun","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.18012","title":"Classification of assembly tasks combining multiple primitive actions using Transformers and xLSTMs","arxivId":"2505.18012","date":"2025/05/23","authors":"Neves, Miguel, Neto, Pedro","category":"Robotics (cs.RO)","summary":"论文标题为 \"Classification of assembly tasks combining multiple primitive actions using Transformers and xLSTMs\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.17434","title":"Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy","arxivId":"2505.17434","date":"2025/05/23","authors":"Lan, Guanzhou, Yang, Yuqi, Mathew, Anup Teejo, Nie, Feiping, Wang, Rong, Li, Xuelong, Renda, Federico, Zhao, Bin","category":"Robotics (cs.RO)","summary":"论文标题为 \"Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.17966","title":"Is Single-View Mesh Reconstruction Ready for Robotics?","arxivId":"2505.17966","date":"2025/05/23","authors":"Nolte, Frederik, Geiger, Andreas, Schölkopf, Bernhard, Posner, Ingmar","category":"Robotics (cs.RO)","summary":"论文标题为 \"Is Single-View Mesh Reconstruction Ready for Robotics?\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.20175","title":"URPlanner: A Universal Paradigm For Collision-Free Robotic Motion Planning Based on Deep Reinforcement Learning","arxivId":"2505.20175","date":"2025/05/26","authors":"Ying, Fengkang, Zhang, Hanwen, Wang, Haozhe, Huang, Huishi, Ang Jr, Marcelo H.","category":"Robotics (cs.RO)","summary":"论文标题为 \"URPlanner: A Universal Paradigm For Collision-Free Robotic Motion Planning Based on Deep Reinforcement Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.17389","title":"Bootstrapping Imitation Learning for Long-horizon Manipulation via Hierarchical Data Collection Space","arxivId":"2505.17389","date":"2025/05/23","authors":"Yang, Jinrong, Chen, Kexun, Li, Zhuoling, Wu, Shengkai, Zhao, Yong, Ren, Liangliang, Luo, Wenqiu, Shang, Chaohui, Zhi, Meiyu, Gao, Linfeng, Sun, Mingshan, Cheng, Hui","category":"Robotics (cs.RO)","summary":"论文标题为 \"Bootstrapping Imitation Learning for Long-horizon Manipulation via Hierarchical Data Collection Space\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.17610","title":"Learning Equilibria from Data: Provably Efficient Multi-Agent Imitation Learning","arxivId":"2505.17610","date":"2025/05/23","authors":"Freihaut, Till, Viano, Luca, Cevher, Volkan, Geist, Matthieu, Ramponi, Giorgia","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"Learning Equilibria from Data: Provably Efficient Multi-Agent Imitation Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.17006","title":"CoMo: Learning Continuous Latent Motion from Internet Videos for Scalable Robot Learning","arxivId":"2505.17006","date":"2025/05/22","authors":"Yang, Jiange, Shi, Yansong, Zhu, Haoyi, Liu, Mingyu, Ma, Kaijing, Wang, Yating, Wu, Gangshan, He, Tong, Wang, Limin","category":"Computer Vision and Pattern Recognition (cs.CV)","summary":"论文标题为 \"CoMo: Learning Continuous Latent Motion from Internet Videos for Scalable Robot Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Computer Vision and Pattern Recognition (cs.CV)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.17295","title":"ScanBot: Towards Intelligent Surface Scanning in Embodied Robotic Systems","arxivId":"2505.17295","date":"2025/05/22","authors":"Chen, Zhiling, Zhang, Yang, Piran, Fardin Jalil, Zhou, Qianyu, Tang, Jiong, Imani, Farhad","category":"Robotics (cs.RO)","summary":"论文标题为 \"ScanBot: Towards Intelligent Surface Scanning in Embodied Robotic Systems\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.16969","title":"3D Equivariant Visuomotor Policy Learning via Spherical Projection","arxivId":"2505.16969","date":"2025/05/22","authors":"Hu, Boce, Wang, Dian, Klee, David, Tian, Heng, Zhu, Xupeng, Huang, Haojie, Platt, Robert, Walters, Robin","category":"Robotics (cs.RO)","summary":"论文标题为 \"3D Equivariant Visuomotor Policy Learning via Spherical Projection\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.16547","title":"Find the Fruit: Zero-Shot Sim2Real RL for Occlusion-Aware Plant Manipulation","arxivId":"2505.16547","date":"2025/05/22","authors":"Subedi, Nitesh, Yang, Hsin-Jung, Jha, Devesh K., Sarkar, Soumik","category":"Robotics (cs.RO)","summary":"论文标题为 \"Find the Fruit: Zero-Shot Sim2Real RL for Occlusion-Aware Plant Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.16856","title":"Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only","arxivId":"2505.16856","date":"2025/05/22","authors":"Xiao, Wei, Liu, Jiacheng, Zhuang, Zifeng, Suo, Runze, Lyu, Shangke, Wang, Donglin","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.16289","title":"TacCompress: A Benchmark for Multi-Point Tactile Data Compression in Dexterous Hand","arxivId":"2505.16289","date":"2025/05/22","authors":"Zhao, Yan, Li, Yang, Cheng, Zhengxue, Zhang, Hengdi, Song, Li","category":"Robotics (cs.RO)","summary":"论文标题为 \"TacCompress: A Benchmark for Multi-Point Tactile Data Compression in Dexterous Hand\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.16196","title":"SEM: Enhancing Spatial Understanding for Robust Robot Manipulation","arxivId":"2505.16196","date":"2025/05/22","authors":"Lin, Xuewu, Lin, Tianwei, Huang, Lichao, Xie, Hongyu, Jin, Yiwei, Li, Keyu, Su, Zhizhong","category":"Robotics (cs.RO)","summary":"论文标题为 \"SEM: Enhancing Spatial Understanding for Robust Robot Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.16055","title":"Proactive Hierarchical Control Barrier Function-Based Safety Prioritization in Close Human-Robot Interaction Scenarios","arxivId":"2505.16055","date":"2025/05/21","authors":"Maithani, Patanjali, Arab, Aliasghar, Khorrami, Farshad, Krishnamurthy, Prashanth","category":"Robotics (cs.RO)","summary":"论文标题为 \"Proactive Hierarchical Control Barrier Function-Based Safety Prioritization in Close Human-Robot Interaction Scenarios\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.16062","title":"WaveTouch: Active Tactile Sensing Using Vibro-Feedback for Classification of Variable Stiffness and Infill Density Objects","arxivId":"2505.16062","date":"2025/05/21","authors":"Sandykbayeva, Danissa, Kostyukova, Valeriya, Nittala, Aditya Shekhar, Kappassov, Zhanat, Orazbayev, Bakhtiyar","category":"Robotics (cs.RO)","summary":"论文标题为 \"WaveTouch: Active Tactile Sensing Using Vibro-Feedback for Classification of Variable Stiffness and Infill Density Objects\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.16167","title":"Tactile-based Reinforcement Learning for Adaptive Grasping under Observation Uncertainties","arxivId":"2505.16167","date":"2025/05/22","authors":"Hu, Xiao, Ye, Yang","category":"Robotics (cs.RO)","summary":"论文标题为 \"Tactile-based Reinforcement Learning for Adaptive Grasping under Observation Uncertainties\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.15660","title":"Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization","arxivId":"2505.15660","date":"2025/05/21","authors":"Zhou, Jiaming, Ye, Ke, Liu, Jiayi, Ma, Teli, Wang, Zifan, Qiu, Ronghe, Lin, Kun-Yu, Zhao, Zhilin, Liang, Junwei","category":"Robotics (cs.RO)","summary":"论文标题为 \"Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.18595","title":"MisoDICE: Multi-Agent Imitation from Unlabeled Mixed-Quality Demonstrations","arxivId":"2505.18595","date":"2025/05/24","authors":"Bui, The Viet, Mai, Tien, Nguyen, Hong Thanh","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"MisoDICE: Multi-Agent Imitation from Unlabeled Mixed-Quality Demonstrations\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.15659","title":"FLARE: Robot Learning with Implicit World Modeling","arxivId":"2505.15659","date":"2025/05/21","authors":"Zheng, Ruijie, Wang, Jing, Reed, Scott, Bjorck, Johan, Fang, Yu, Hu, Fengyuan, Jang, Joel, Kundalia, Kaushil, Lin, Zongyu, Magne, Loic, Narayan, Avnish, Tan, You Liang, Wang, Guanzhi, Wang, Qi, Xiang, Jiannan, Xu, Yinzhen, Ye, Seonghyeon, Kautz, Jan, Huang, Furong, Zhu, Yuke, Fan, Linxi","category":"Robotics (cs.RO)","summary":"论文标题为 \"FLARE: Robot Learning with Implicit World Modeling\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:03:31.107Z"},{"id":"http://arxiv.org/abs/2505.15098","title":"Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation","arxivId":"2505.15098","date":"2025/05/21","authors":"Li, Yihang, Zhang, Tianle, Wei, Xuelong, Li, Jiayi, Zhao, Lin, Huang, Dongchi, Fang, Zhirui, Zheng, Minhua, Dai, Wenjun, He, Xiaodong","category":"Robotics (cs.RO)","summary":"论文标题为 \"Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.16517","title":"ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models","arxivId":"2505.16517","date":"2025/05/22","authors":"Song, Zirui, Ouyang, Guangxian, Li, Mingzhe, Ji, Yuheng, Wang, Chenxi, Xu, Zixiang, Zhang, Zeyu, Zhang, Xiaoqing, Jiang, Qian, Chen, Zhenhao, Li, Zhongzhi, Yan, Rui, Chen, Xiuying","category":"Robotics (cs.RO)","summary":"论文标题为 \"ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.14357","title":"Vid2World: Crafting Video Diffusion Models to Interactive World Models","arxivId":"2505.14357","date":"2025/05/20","authors":"Huang, Siqiao, Wu, Jialong, Zhou, Qixing, Miao, Shangchen, Long, Mingsheng","category":"Computer Vision and Pattern Recognition (cs.CV)","summary":"论文标题为 \"Vid2World: Crafting Video Diffusion Models to Interactive World Models\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Computer Vision and Pattern Recognition (cs.CV)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.15143","title":"Filtering Learning Histories Enhances In-Context Reinforcement Learning","arxivId":"2505.15143","date":"2025/05/21","authors":"Chen, Weiqin, Zhang, Xinjie, Subramanian, Dharmashankar, Paternain, Santiago","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"Filtering Learning Histories Enhances In-Context Reinforcement Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.15304","title":"Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control","arxivId":"2505.15304","date":"2025/05/21","authors":"Park, Seongmin, Kim, Hyungmin, Kim, Sangwoo, Jeon, Wonseok, Yang, Juyoung, Jeon, Byeongwook, Oh, Yoonseon, Choi, Jungwook","category":"Robotics (cs.RO)","summary":"论文标题为 \"Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.14819","title":"DORA: Object Affordance-Guided Reinforcement Learning for Dexterous Robotic Manipulation","arxivId":"2505.14819","date":"2025/05/20","authors":"Zhang, Lei, Mondal, Soumya, Bing, Zhenshan, Bai, Kaixin, Zheng, Diwen, Chen, Zhaopeng, Knoll, Alois Christian, Zhang, Jianwei","category":"Robotics (cs.RO)","summary":"论文标题为 \"DORA: Object Affordance-Guided Reinforcement Learning for Dexterous Robotic Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.14820","title":"Imitation Learning via Focused Satisficing","arxivId":"2505.14820","date":"2025/05/20","authors":"Shah, Rushit N., Agadakos, Nikolaos, Sasulski, Synthia, Farajzadeh, Ali, Choudhury, Sanjiban, Ziebart, Brian","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"Imitation Learning via Focused Satisficing\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.15418","title":"Guided Policy Optimization under Partial Observability","arxivId":"2505.15418","date":"2025/05/21","authors":"Li, Yueheng, Xie, Guangming, Lu, Zongqing","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"Guided Policy Optimization under Partial Observability\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.13934","title":"RLVR-World: Training World Models with Reinforcement Learning","arxivId":"2505.13934","date":"2025/05/20","authors":"Wu, Jialong, Yin, Shaofeng, Feng, Ningya, Long, Mingsheng","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"RLVR-World: Training World Models with Reinforcement Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.13925","title":"Time Reversal Symmetry for Efficient Robotic Manipulations in Deep Reinforcement Learning","arxivId":"2505.13925","date":"2025/05/20","authors":"Jiang, Yunpeng, Hu, Jianshu, Weng, Paul, Ban, Yutong","category":"Robotics (cs.RO)","summary":"论文标题为 \"Time Reversal Symmetry for Efficient Robotic Manipulations in Deep Reinforcement Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.13549","title":"TD-GRPC: Temporal Difference Learning with Group Relative Policy Constraint for Humanoid Locomotion","arxivId":"2505.13549","date":"2025/05/19","authors":"Nguyen, Khang, Nguyen, Khai, Le, An T., Peters, Jan, Huber, Manfred, Vien, Ngo Anh, Vu, Minh Nhat","category":"Robotics (cs.RO)","summary":"论文标题为 \"TD-GRPC: Temporal Difference Learning with Group Relative Policy Constraint for Humanoid Locomotion\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.13441","title":"GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation","arxivId":"2505.13441","date":"2025/05/19","authors":"Deshpande, Abhay, Deng, Yuquan, Ray, Arijit, Salvador, Jordi, Han, Winson, Duan, Jiafei, Zeng, Kuo-Hao, Zhu, Yuke, Krishna, Ranjay, Hendrix, Rose","category":"Robotics (cs.RO)","summary":"论文标题为 \"GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.13436","title":"KinTwin: Imitation Learning with Torque and Muscle Driven Biomechanical Models Enables Precise Replication of Able-Bodied and Impaired Movement from Markerless Motion Capture","arxivId":"2505.13436","date":"2025/05/19","authors":"Cotton, R. James","category":"Computer Vision and Pattern Recognition (cs.CV)","summary":"论文标题为 \"KinTwin: Imitation Learning with Torque and Muscle Driven Biomechanical Models Enables Precise Replication of Able-Bodied and Impaired Movement from Markerless Motion Capture\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Computer Vision and Pattern Recognition (cs.CV)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.12744","title":"Incentivizing Multimodal Reasoning in Large Models for Direct Robot Manipulation","arxivId":"2505.12744","date":"2025/05/19","authors":"Tang, Weiliang, Jing, Dong, Pan, Jia-Hui, Lu, Zhiwu, Liu, Yun-Hui, Li, Li Erran, Ding, Mingyu, Fu, Chi-Wing","category":"Artificial Intelligence (cs.AI)","summary":"论文标题为 \"Incentivizing Multimodal Reasoning in Large Models for Direct Robot Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Artificial Intelligence (cs.AI)"],"updatedAt":"2026-02-11T15:04:29.734Z"},{"id":"http://arxiv.org/abs/2505.12748","title":"TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation","arxivId":"2505.12748","date":"2025/05/19","authors":"Li, Hangyu, Zhao, Qin, Xu, Haoran, Jiang, Xinyu, Ben, Qingwei, Jia, Feiyu, Zhao, Haoyu, Xu, Liang, Zeng, Jia, Wang, Hanqing, Dai, Bo, Dong, Junting, Pang, Jiangmiao","category":"Robotics (cs.RO)","summary":"论文标题为 \"TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:15.695Z"},{"id":"http://arxiv.org/abs/2505.12410","title":"MTIL: Encoding Full History with Mamba for Temporal Imitation Learning","arxivId":"2505.12410","date":"2025/05/18","authors":"Zhou, Yulin, Lin, Yuankai, Peng, Fanzhe, Chen, Jiahui, Huang, Kaiji, Yang, Hua, Yin, Zhouping","category":"Robotics (cs.RO)","summary":"论文标题为 \"MTIL: Encoding Full History with Mamba for Temporal Imitation Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:15.695Z"},{"id":"http://arxiv.org/abs/2505.12294","title":"PartDexTOG: Generating Dexterous Task-Oriented Grasping via Language-driven Part Analysis","arxivId":"2505.12294","date":"2025/05/18","authors":"Wu, Weishang, Shi, Yifei, Chen, Zhizhong, Cai, Zhipong","category":"Robotics (cs.RO)","summary":"论文标题为 \"PartDexTOG: Generating Dexterous Task-Oriented Grasping via Language-driven Part Analysis\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:15.695Z"},{"id":"http://arxiv.org/abs/2505.12679","title":"Dribble Master: Learning Agile Humanoid Dribbling Through Legged Locomotion","arxivId":"2505.12679","date":"2025/05/19","authors":"Wang, Zhuoheng, Zhou, Jinyin, Wu, Qi","category":"Robotics (cs.RO)","summary":"论文标题为 \"Dribble Master: Learning Agile Humanoid Dribbling Through Legged Locomotion\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:15.695Z"},{"id":"http://arxiv.org/abs/2505.12619","title":"HIL: Hybrid Imitation Learning of Diverse Parkour Skills from Videos","arxivId":"2505.12619","date":"2025/05/19","authors":"Wang, Jiashun, Jiang, Yifeng, Zhang, Haotian, Tessler, Chen, Rempe, Davis, Hodgins, Jessica, Peng, Xue Bin","category":"Graphics (cs.GR)","summary":"论文标题为 \"HIL: Hybrid Imitation Learning of Diverse Parkour Skills from Videos\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Graphics (cs.GR)"],"updatedAt":"2026-02-11T15:08:15.695Z"},{"id":"http://arxiv.org/abs/2505.12705","title":"DreamGen: Unlocking Generalization in Robot Learning through Video World Models","arxivId":"2505.12705","date":"2025/05/19","authors":"Jang, Joel, Ye, Seonghyeon, Lin, Zongyu, Xiang, Jiannan, Bjorck, Johan, Fang, Yu, Hu, Fengyuan, Huang, Spencer, Kundalia, Kaushil, Lin, Yen-Chen, Magne, Loic, Mandlekar, Ajay, Narayan, Avnish, Tan, You Liang, Wang, Guanzhi, Wang, Jing, Wang, Qi, Xu, Yinzhen, Zeng, Xiaohui, Zheng, Kaiyuan, Zheng, Ruijie, Liu, Ming-Yu, Zettlemoyer, Luke, Fox, Dieter, Kautz, Jan, Reed, Scott, Zhu, Yuke, Fan, Linxi","category":"Robotics (cs.RO)","summary":"论文标题为 \"DreamGen: Unlocking Generalization in Robot Learning through Video World Models\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:15.695Z"},{"id":"http://arxiv.org/abs/2505.13667","title":"Adaptive Diffusion Constrained Sampling for Bimanual Robot Manipulation","arxivId":"2505.13667","date":"2025/05/19","authors":"Tong, Haolei, Zhang, Yuezhe, Lueth, Sophie, Chalvatzaki, Georgia","category":"Robotics (cs.RO)","summary":"论文标题为 \"Adaptive Diffusion Constrained Sampling for Bimanual Robot Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:15.695Z"},{"id":"http://arxiv.org/abs/2505.12224","title":"RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction","arxivId":"2505.12224","date":"2025/05/18","authors":"Lu, Weifeng, Ye, Minghao, Ye, Zewei, Tao, Ruihan, Yang, Shuo, Zhao, Bo","category":"Robotics (cs.RO)","summary":"论文标题为 \"RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:43.683Z"},{"id":"http://arxiv.org/abs/2505.11716","title":"Employing Laban Shape for Generating Emotionally and Functionally Expressive Trajectories in Robotic Manipulators","arxivId":"2505.11716","date":"2025/05/16","authors":"Raghu, Srikrishna Bangalore, Lohrmann, Clare, Bakshi, Akshay, Kim, Jennifer, Herrera, Jose Caraveo, Hayes, Bradley, Roncone, Alessandro","category":"Robotics (cs.RO)","summary":"论文标题为 \"Employing Laban Shape for Generating Emotionally and Functionally Expressive Trajectories in Robotic Manipulators\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:43.683Z"},{"id":"http://arxiv.org/abs/2505.12072","title":"L2D2: Robot Learning from 2D Drawings","arxivId":"2505.12072","date":"2025/05/17","authors":"Mehta, Shaunak A., Nemlekar, Heramb, Sumant, Hari, Losey, Dylan P.","category":"Robotics (cs.RO)","summary":"论文标题为 \"L2D2: Robot Learning from 2D Drawings\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:43.683Z"},{"id":"http://arxiv.org/abs/2505.11865","title":"GLOVER++: Unleashing the Potential of Affordance Learning from Human Behaviors for Robotic Manipulation","arxivId":"2505.11865","date":"2025/05/17","authors":"Ma, Teli, Zheng, Jia, Wang, Zifan, Gao, Ziyao, Zhou, Jiaming, Liang, Junwei","category":"Robotics (cs.RO)","summary":"论文标题为 \"GLOVER++: Unleashing the Potential of Affordance Learning from Human Behaviors for Robotic Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:43.683Z"},{"id":"http://arxiv.org/abs/2505.12737","title":"Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning","arxivId":"2505.12737","date":"2025/05/19","authors":"Ahn, Hongjoon, Choi, Heewoong, Han, Jisu, Moon, Taesup","category":"Machine Learning (cs.LG)","summary":"论文标题为 \"Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Machine Learning (cs.LG)"],"updatedAt":"2026-02-11T15:08:43.683Z"},{"id":"http://arxiv.org/abs/2505.11920","title":"H2R: A Human-to-Robot Data Augmentation for Robot Pre-training from Videos","arxivId":"2505.11920","date":"2025/05/17","authors":"Li, Guangrun, Lyu, Yaoxu, Liu, Zhuoyang, Hou, Chengkai, Zhang, Jieyu, Zhang, Shanghang","category":"Robotics (cs.RO)","summary":"论文标题为 \"H2R: A Human-to-Robot Data Augmentation for Robot Pre-training from Videos\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:43.683Z"},{"id":"http://arxiv.org/abs/2505.12222","title":"Learning Impact-Rich Rotational Maneuvers via Centroidal Velocity Rewards and Sim-to-Real Techniques: A One-Leg Hopper Flip Case Study","arxivId":"2505.12222","date":"2025/05/18","authors":"Kang, Dongyun, Kim, Gijeong, Choe, JongHun, Kim, Hajun, Park, Hae-Won","category":"Robotics (cs.RO)","summary":"论文标题为 \"Learning Impact-Rich Rotational Maneuvers via Centroidal Velocity Rewards and Sim-to-Real Techniques: A One-Leg Hopper Flip Case Study\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:43.683Z"},{"id":"http://arxiv.org/abs/2505.11719","title":"Zero-Shot Visual Generalization in Robot Manipulation","arxivId":"2505.11719","date":"2025/05/16","authors":"Batra, Sumeet, Sukhatme, Gaurav","category":"Robotics (cs.RO)","summary":"论文标题为 \"Zero-Shot Visual Generalization in Robot Manipulation\"，本文关注机器人相关问题，给出方法与实验结果概述。","tags":["Robotics (cs.RO)"],"updatedAt":"2026-02-11T15:08:43.683Z"}]}